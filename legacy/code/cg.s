	.file	"cg.f"
	.text
	.p2align 4
	.type	ran2_.constprop.0, @function
ran2_.constprop.0:
.LFB60:
	.cfi_startproc
	movl	rans_(%rip), %edx
	testl	%edx, %edx
	jle	.L2
	movl	idum2.27(%rip), %r8d
	movl	iy.25(%rip), %esi
.L3:
	movslq	%edx, %rcx
	imulq	$327796565, %rcx, %rcx
	movl	%edx, %eax
	sarl	$31, %eax
	sarq	$44, %rcx
	subl	%eax, %ecx
	imull	$-53668, %ecx, %eax
	imull	$-12211, %ecx, %ecx
	addl	%edx, %eax
	imull	$40014, %eax, %eax
	addl	%eax, %ecx
	jns	.L13
	addl	$2147483563, %ecx
.L13:
	movslq	%r8d, %rax
	imulq	$1333397965, %rax, %rax
	movl	%r8d, %edx
	sarl	$31, %edx
	sarq	$46, %rax
	subl	%edx, %eax
	imull	$-52774, %eax, %edx
	imull	$-3791, %eax, %eax
	movl	%ecx, rans_(%rip)
	addl	%r8d, %edx
	imull	$40692, %edx, %edx
	addl	%eax, %edx
	jns	.L14
	addl	$2147483399, %edx
.L14:
	movslq	%esi, %rax
	imulq	$-2147483583, %rax, %rax
	leaq	iv.26(%rip), %rdi
	movl	%edx, idum2.27(%rip)
	shrq	$32, %rax
	addl	%esi, %eax
	sarl	$25, %eax
	sarl	$31, %esi
	subl	%esi, %eax
	cltq
	movl	(%rdi,%rax,4), %esi
	movl	%ecx, (%rdi,%rax,4)
	subl	%edx, %esi
	movl	%esi, iy.25(%rip)
	testl	%esi, %esi
	jg	.L11
	addl	$2147483562, %esi
	movl	%esi, iy.25(%rip)
.L11:
	vxorps	%xmm0, %xmm0, %xmm0
	vcvtsi2sdl	%esi, %xmm0, %xmm0
	vmulsd	.LC0(%rip), %xmm0, %xmm0
	vminsd	.LC1(%rip), %xmm0, %xmm0
	ret
	.p2align 4,,10
	.p2align 3
.L2:
	negl	%edx
	movl	$1, %eax
	movl	%edx, %r8d
	cmpl	%eax, %edx
	cmovl	%eax, %r8d
	movl	$40, %esi
	movl	%r8d, %edx
	leaq	-4+iv.26(%rip), %rdi
	.p2align 4,,10
	.p2align 3
.L6:
	movslq	%edx, %rax
	imulq	$327796565, %rax, %rax
	movl	%edx, %ecx
	sarl	$31, %ecx
	sarq	$44, %rax
	subl	%ecx, %eax
	imull	$-53668, %eax, %ecx
	imull	$-12211, %eax, %eax
	addl	%ecx, %edx
	imull	$40014, %edx, %edx
	addl	%eax, %edx
	leal	2147483563(%rdx), %eax
	cmovs	%eax, %edx
	cmpq	$32, %rsi
	ja	.L5
	movl	%edx, (%rdi,%rsi,4)
.L5:
	decq	%rsi
	jne	.L6
	movl	iv.26(%rip), %esi
	jmp	.L3
	.cfi_endproc
.LFE60:
	.size	ran2_.constprop.0, .-ran2_.constprop.0
	.section	.rodata.str1.1,"aMS",@progbits,1
.LC2:
	.string	"cg.f"
.LC3:
	.string	"(a,f10.1,4x,a,f10.4,4x,a,f8.4)"
.LC4:
	.string	"TIME ="
.LC5:
	.string	"ENERGY ="
.LC6:
	.string	"RMSD ="
.LC7:
	.string	"(3f9.3)"
	.text
	.p2align 4
	.type	print_conf_xyz_.constprop.0, @function
print_conf_xyz_.constprop.0:
.LFB59:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	leaq	.LC2(%rip), %r15
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	movq	%rsi, %r13
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	movq	%rdx, %r12
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	movq	%rcx, %rbp
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$584, %rsp
	.cfi_def_cfa_offset 640
	leaq	32(%rsp), %rbx
	movq	%fs:40, %rax
	movq	%rax, 568(%rsp)
	xorl	%eax, %eax
	leaq	.LC3(%rip), %rax
	movq	%rax, 112(%rsp)
	movq	%rbx, %rdi
	movabsq	$8589938688, %rax
	movq	%rax, 32(%rsp)
	movq	%r15, 40(%rsp)
	movl	$6613, 48(%rsp)
	movq	$30, 120(%rsp)
	call	_gfortran_st_write@PLT
	movl	$6, %edx
	leaq	.LC4(%rip), %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	.LC5(%rip), %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rsi
	movl	$8, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$6, %edx
	leaq	.LC6(%rip), %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_character_write@PLT
	vmovsd	0(%rbp), %xmm0
	leaq	24(%rsp), %r12
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movl	$8, %edx
	movq	%r12, %rsi
	movq	%rbx, %rdi
	vmovsd	%xmm0, 24(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	%rbx, %rdi
	call	_gfortran_st_write_done@PLT
	movl	8+bas_(%rip), %eax
	movl	%eax, 12(%rsp)
	testl	%eax, %eax
	jle	.L16
	leaq	pos_(%rip), %rbp
	movl	$1, %r14d
	leaq	bas_(%rip), %r13
	.p2align 4,,10
	.p2align 3
.L18:
	leaq	.LC7(%rip), %rax
	movq	%rax, 112(%rsp)
	movq	%rbx, %rdi
	movabsq	$8589938688, %rax
	movq	%rax, 32(%rsp)
	movq	%r15, 40(%rsp)
	movl	$6617, 48(%rsp)
	movq	$7, 120(%rsp)
	call	_gfortran_st_write@PLT
	vmovsd	0(%rbp), %xmm0
	movl	$8, %edx
	vmulsd	0(%r13), %xmm0, %xmm0
	movq	%r12, %rsi
	movq	%rbx, %rdi
	incl	%r14d
	addq	$8, %rbp
	vmovsd	%xmm0, 24(%rsp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	79992(%rbp), %xmm0
	movl	$8, %edx
	vmulsd	0(%r13), %xmm0, %xmm0
	movq	%r12, %rsi
	movq	%rbx, %rdi
	vmovsd	%xmm0, 24(%rsp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	159992(%rbp), %xmm0
	movl	$8, %edx
	vmulsd	0(%r13), %xmm0, %xmm0
	movq	%r12, %rsi
	movq	%rbx, %rdi
	vmovsd	%xmm0, 24(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	%rbx, %rdi
	call	_gfortran_st_write_done@PLT
	cmpl	%r14d, 12(%rsp)
	jge	.L18
.L16:
	movq	568(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L23
	addq	$584, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
.L23:
	.cfi_restore_state
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE59:
	.size	print_conf_xyz_.constprop.0, .-print_conf_xyz_.constprop.0
	.p2align 4
	.globl	dihedral_
	.type	dihedral_, @function
dihedral_:
.LFB0:
	.cfi_startproc
	pushq	%rbx
	.cfi_def_cfa_offset 16
	.cfi_offset 3, -16
	movq	%rdi, %rbx
	subq	$48, %rsp
	.cfi_def_cfa_offset 64
	vmovsd	48+four_(%rip), %xmm3
	vmovsd	40+four_(%rip), %xmm9
	vmovsd	72+four_(%rip), %xmm2
	vsubsd	32+four_(%rip), %xmm9, %xmm10
	vsubsd	64+four_(%rip), %xmm2, %xmm7
	vsubsd	%xmm9, %xmm3, %xmm9
	vmovsd	80+four_(%rip), %xmm0
	vmovsd	8+four_(%rip), %xmm1
	vmulsd	%xmm9, %xmm7, %xmm8
	vmovsd	16+four_(%rip), %xmm4
	vmovsd	24+four_(%rip), %xmm6
	vsubsd	four_(%rip), %xmm1, %xmm5
	vsubsd	%xmm2, %xmm0, %xmm2
	vsubsd	%xmm1, %xmm4, %xmm1
	vsubsd	%xmm4, %xmm6, %xmm4
	vmovsd	56+four_(%rip), %xmm6
	vfmsub231sd	%xmm2, %xmm10, %xmm8
	vsubsd	%xmm3, %xmm6, %xmm6
	vmulsd	%xmm1, %xmm10, %xmm10
	vmovsd	88+four_(%rip), %xmm3
	vmovsd	%xmm4, 32(%rsp)
	vsubsd	%xmm0, %xmm3, %xmm3
	vmulsd	%xmm2, %xmm5, %xmm0
	vfmsub132sd	%xmm9, %xmm10, %xmm5
	vmulsd	%xmm3, %xmm1, %xmm11
	vmulsd	%xmm6, %xmm2, %xmm10
	vmovsd	%xmm3, 40(%rsp)
	vfmsub132sd	%xmm1, %xmm0, %xmm7
	vmovsd	%xmm6, 24(%rsp)
	vfmsub132sd	%xmm4, %xmm11, %xmm2
	vfmsub231sd	%xmm3, %xmm9, %xmm10
	vmulsd	%xmm4, %xmm9, %xmm9
	vmulsd	%xmm7, %xmm7, %xmm0
	vmovsd	%xmm7, 16(%rsp)
	vmovsd	%xmm8, 8(%rsp)
	vmovsd	%xmm5, (%rsp)
	vfmsub132sd	%xmm6, %xmm9, %xmm1
	vmulsd	%xmm2, %xmm2, %xmm9
	vfmadd231sd	%xmm8, %xmm8, %xmm0
	vmulsd	%xmm2, %xmm7, %xmm2
	vfmadd231sd	%xmm10, %xmm10, %xmm9
	vfmadd231sd	%xmm5, %xmm5, %xmm0
	vfmadd231sd	%xmm10, %xmm8, %xmm2
	vfmadd231sd	%xmm1, %xmm1, %xmm9
	vfmadd132sd	%xmm5, %xmm2, %xmm1
	vmulsd	%xmm9, %xmm0, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vdivsd	%xmm0, %xmm1, %xmm0
	vminsd	.LC8(%rip), %xmm0, %xmm0
	vmaxsd	.LC9(%rip), %xmm0, %xmm0
	call	acos@PLT
	vmovsd	16(%rsp), %xmm7
	vmovsd	24(%rsp), %xmm6
	vmovsd	8(%rsp), %xmm8
	vmulsd	%xmm7, %xmm6, %xmm6
	vmovsd	32(%rsp), %xmm4
	vmovsd	(%rsp), %xmm5
	vmovsd	40(%rsp), %xmm3
	vfmadd132sd	%xmm8, %xmm6, %xmm4
	vfmadd132sd	%xmm5, %xmm4, %xmm3
	vxorpd	%xmm4, %xmm4, %xmm4
	vxorpd	.LC11(%rip), %xmm0, %xmm5
	vcmpnltsd	%xmm4, %xmm3, %xmm3
	vblendvpd	%xmm3, %xmm0, %xmm5, %xmm3
	vmovsd	%xmm3, (%rbx)
	addq	$48, %rsp
	.cfi_def_cfa_offset 16
	popq	%rbx
	.cfi_def_cfa_offset 8
	ret
	.cfi_endproc
.LFE0:
	.size	dihedral_, .-dihedral_
	.p2align 4
	.globl	bondangle_
	.type	bondangle_, @function
bondangle_:
.LFB1:
	.cfi_startproc
	vmovsd	40+four_(%rip), %xmm4
	vmovsd	8+four_(%rip), %xmm3
	vsubsd	32+four_(%rip), %xmm4, %xmm7
	vsubsd	48+four_(%rip), %xmm4, %xmm4
	vsubsd	four_(%rip), %xmm3, %xmm6
	vmulsd	%xmm7, %xmm7, %xmm0
	vmulsd	%xmm4, %xmm4, %xmm5
	vsubsd	16+four_(%rip), %xmm3, %xmm3
	vmovsd	72+four_(%rip), %xmm2
	vmulsd	%xmm4, %xmm7, %xmm4
	vfmadd231sd	%xmm6, %xmm6, %xmm0
	vfmadd231sd	%xmm3, %xmm3, %xmm5
	vsubsd	64+four_(%rip), %xmm2, %xmm1
	vsubsd	80+four_(%rip), %xmm2, %xmm2
	vfmadd132sd	%xmm3, %xmm4, %xmm6
	vfmadd231sd	%xmm1, %xmm1, %xmm0
	vfmadd231sd	%xmm2, %xmm2, %xmm5
	pushq	%rbx
	.cfi_def_cfa_offset 16
	.cfi_offset 3, -16
	movq	%rdi, %rbx
	vfmadd132sd	%xmm2, %xmm6, %xmm1
	vmulsd	%xmm5, %xmm0, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vdivsd	%xmm0, %xmm1, %xmm0
	vminsd	.LC8(%rip), %xmm0, %xmm0
	vmaxsd	.LC9(%rip), %xmm0, %xmm0
	call	acos@PLT
	vmovsd	%xmm0, (%rbx)
	popq	%rbx
	.cfi_def_cfa_offset 8
	ret
	.cfi_endproc
.LFE1:
	.size	bondangle_, .-bondangle_
	.section	.rodata.str1.1
.LC12:
	.string	"NSTACK too small in sort"
	.text
	.p2align 4
	.globl	sort2_
	.type	sort2_, @function
sort2_:
.LFB2:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	movq	%rsi, %rcx
	movl	$1, %r10d
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movq	%rdx, %rsi
	movl	$2, %r14d
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	xorl	%ebp, %ebp
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$2552, %rsp
	.cfi_def_cfa_offset 2608
	movq	%fs:40, %rax
	movq	%rax, 2536(%rsp)
	xorl	%eax, %eax
	movl	(%rdi), %ebx
	.p2align 4,,10
	.p2align 3
.L31:
	movl	%ebx, %eax
	subl	%r10d, %eax
	cmpl	$6, %eax
	jg	.L32
.L68:
	movslq	%r14d, %rdi
	cmpl	%r14d, %ebx
	jl	.L40
	.p2align 4,,10
	.p2align 3
.L41:
	vmovsd	-8(%rcx,%rdi,8), %xmm1
	movl	-4(%rsi,%rdi,4), %r8d
	movslq	%r10d, %rax
	testl	%r10d, %r10d
	jg	.L39
	jmp	.L38
	.p2align 4,,10
	.p2align 3
.L66:
	movl	-4(%rsi,%rax,4), %edx
	vmovsd	%xmm0, (%rcx,%rax,8)
	movl	%edx, (%rsi,%rax,4)
	decq	%rax
	testl	%eax, %eax
	jle	.L38
.L39:
	vmovsd	-8(%rcx,%rax,8), %xmm0
	movq	%rax, %rdx
	vcomisd	%xmm0, %xmm1
	jb	.L66
.L37:
	incq	%rdi
	movl	%r8d, (%rsi,%rdx,4)
	vmovsd	%xmm1, (%rcx,%rdx,8)
	incl	%r10d
	cmpl	%edi, %ebx
	jge	.L41
.L40:
	testl	%ebp, %ebp
	je	.L67
	movslq	%ebp, %rax
	movl	524(%rsp,%rax,4), %ebx
	movl	520(%rsp,%rax,4), %r10d
	movl	%ebx, %eax
	subl	%r10d, %eax
	subl	$2, %ebp
	leal	1(%r10), %r14d
	cmpl	$6, %eax
	jle	.L68
.L32:
	leal	(%rbx,%r10), %edx
	movl	%edx, %eax
	shrl	$31, %eax
	addl	%edx, %eax
	sarl	%eax
	movslq	%r10d, %rdx
	decl	%eax
	leaq	(%rcx,%rdx,8), %r13
	leaq	(%rsi,%rdx,4), %r12
	cltq
	vmovsd	0(%r13), %xmm0
	movl	(%r12), %r8d
	vmovsd	(%rcx,%rax,8), %xmm1
	movl	(%rsi,%rax,4), %edi
	vmovsd	%xmm0, (%rcx,%rax,8)
	movl	%r8d, (%rsi,%rax,4)
	movslq	%ebx, %rax
	decq	%rax
	vmovsd	%xmm1, 0(%r13)
	vmovsd	(%rcx,%rax,8), %xmm0
	movl	%edi, (%r12)
	vcomisd	%xmm0, %xmm1
	jbe	.L43
	movl	(%rsi,%rax,4), %r8d
	vmovsd	%xmm0, 0(%r13)
	movl	%r8d, (%r12)
	movl	%edi, (%rsi,%rax,4)
	vmovsd	%xmm1, (%rcx,%rax,8)
	vmovsd	%xmm1, %xmm1, %xmm0
.L43:
	vmovsd	-8(%r13), %xmm1
	decq	%rdx
	vcomisd	%xmm0, %xmm1
	movl	-4(%r12), %r15d
	jbe	.L45
	movl	(%rsi,%rax,4), %edi
	vmovsd	%xmm0, -8(%r13)
	movl	%edi, -4(%r12)
	movl	%r15d, (%rsi,%rax,4)
	vmovsd	%xmm1, (%rcx,%rax,8)
	vmovsd	-8(%r13), %xmm1
	movl	-4(%r12), %r15d
.L45:
	vmovsd	0(%r13), %xmm0
	vcomisd	%xmm1, %xmm0
	jbe	.L47
	movl	(%r12), %eax
	vunpcklpd	%xmm1, %xmm0, %xmm1
	movl	%eax, -4(%r12)
	movl	%r15d, (%r12)
	vmovupd	%xmm1, (%rcx,%rdx,8)
	movl	%eax, %r15d
	vmovsd	%xmm0, %xmm0, %xmm1
.L47:
	leal	2(%r10), %r8d
	movslq	%r8d, %r8
	movl	%ebx, %edx
	.p2align 4,,10
	.p2align 3
.L49:
	vmovsd	-8(%rcx,%r8,8), %xmm2
	movl	%r8d, %r11d
	vcomisd	%xmm2, %xmm1
	ja	.L50
	movslq	%edx, %rax
	subq	$2, %rax
	.p2align 4,,10
	.p2align 3
.L51:
	movq	%rax, %rdi
	decq	%rax
	vmovsd	8(%rcx,%rax,8), %xmm0
	movl	%edx, %r9d
	decl	%edx
	vcomisd	%xmm1, %xmm0
	ja	.L51
	movl	(%rsi,%rdi,4), %eax
	cmpl	%r8d, %edx
	jl	.L52
	movl	-4(%rsi,%r8,4), %r9d
	movl	%eax, -4(%rsi,%r8,4)
	movl	%r9d, (%rsi,%rdi,4)
	vmovsd	%xmm0, -8(%rcx,%r8,8)
	vmovsd	%xmm2, (%rcx,%rdi,8)
.L50:
	incq	%r8
	jmp	.L49
	.p2align 4,,10
	.p2align 3
.L38:
	xorl	%edx, %edx
	jmp	.L37
	.p2align 4,,10
	.p2align 3
.L52:
	movl	%eax, -4(%r12)
	vmovsd	%xmm0, -8(%r13)
	movl	%r15d, (%rsi,%rdi,4)
	vmovsd	%xmm1, (%rcx,%rdi,8)
	leal	2(%rbp), %edi
	cmpl	$500, %edi
	jg	.L69
	movl	%ebx, %eax
	subl	%r11d, %eax
	incl	%eax
	subl	%r10d, %edx
	subl	$2, %r9d
	movslq	%ebp, %rbp
	cmpl	%edx, %eax
	jl	.L54
	vmovd	%r11d, %xmm3
	vpinsrd	$1, %ebx, %xmm3, %xmm0
	vmovq	%xmm0, 528(%rsp,%rbp,4)
	movl	%r9d, %ebx
	movl	%edi, %ebp
	jmp	.L31
.L54:
	vmovd	%r10d, %xmm4
	vpinsrd	$1, %r9d, %xmm4, %xmm0
	vmovq	%xmm0, 528(%rsp,%rbp,4)
	movl	%r11d, %r10d
	movl	%edi, %ebp
	leal	1(%r11), %r14d
	jmp	.L31
.L67:
	movq	2536(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L70
	addq	$2552, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
.L69:
	.cfi_restore_state
	movq	%rsp, %rbp
	leaq	.LC2(%rip), %rax
	movq	%rax, 8(%rsp)
	movq	%rbp, %rdi
	movabsq	$25769803904, %rax
	movq	%rax, (%rsp)
	movl	$8283, 16(%rsp)
	call	_gfortran_st_write@PLT
	movl	$24, %edx
	leaq	.LC12(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
.L70:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE2:
	.size	sort2_, .-sort2_
	.p2align 4
	.globl	sort_
	.type	sort_, @function
sort_:
.LFB3:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsi, %rdx
	movl	$1, %r11d
	pushq	%rbx
	.cfi_def_cfa_offset 24
	.cfi_offset 3, -24
	xorl	%r10d, %r10d
	subq	$2552, %rsp
	.cfi_def_cfa_offset 2576
	movq	%fs:40, %rax
	movq	%rax, 2536(%rsp)
	xorl	%eax, %eax
	movl	(%rdi), %r9d
	.p2align 4,,10
	.p2align 3
.L72:
	movl	%r9d, %eax
	subl	%r11d, %eax
	cmpl	$6, %eax
	jg	.L73
.L107:
	movslq	%r11d, %rax
	leaq	(%rdx,%rax,8), %rsi
	cmpl	%r11d, %r9d
	jle	.L81
	.p2align 4,,10
	.p2align 3
.L82:
	vmovsd	(%rsi), %xmm1
	movslq	%r11d, %rax
	testl	%r11d, %r11d
	jg	.L80
	jmp	.L79
	.p2align 4,,10
	.p2align 3
.L105:
	vmovsd	%xmm0, (%rdx,%rax,8)
	decq	%rax
	testl	%eax, %eax
	jle	.L79
.L80:
	vmovsd	-8(%rdx,%rax,8), %xmm0
	movq	%rax, %rcx
	vcomisd	%xmm0, %xmm1
	jb	.L105
.L78:
	incl	%r11d
	vmovsd	%xmm1, (%rdx,%rcx,8)
	addq	$8, %rsi
	cmpl	%r11d, %r9d
	jne	.L82
.L81:
	testl	%r10d, %r10d
	je	.L106
	movslq	%r10d, %rax
	movl	524(%rsp,%rax,4), %r9d
	movl	520(%rsp,%rax,4), %r11d
	movl	%r9d, %eax
	subl	%r11d, %eax
	subl	$2, %r10d
	cmpl	$6, %eax
	jle	.L107
.L73:
	leal	(%r9,%r11), %ecx
	movl	%ecx, %eax
	shrl	$31, %eax
	addl	%ecx, %eax
	sarl	%eax
	movslq	%r11d, %rcx
	decl	%eax
	leaq	(%rdx,%rcx,8), %rbp
	vmovsd	0(%rbp), %xmm0
	cltq
	vmovsd	(%rdx,%rax,8), %xmm1
	vmovsd	%xmm0, (%rdx,%rax,8)
	movslq	%r9d, %rax
	decq	%rax
	vmovsd	%xmm1, 0(%rbp)
	vmovsd	(%rdx,%rax,8), %xmm0
	vcomisd	%xmm0, %xmm1
	jbe	.L84
	vmovsd	%xmm0, 0(%rbp)
	vmovsd	%xmm1, (%rdx,%rax,8)
	vmovsd	%xmm1, %xmm1, %xmm0
.L84:
	vmovsd	-8(%rbp), %xmm1
	decq	%rcx
	vcomisd	%xmm0, %xmm1
	jbe	.L86
	vmovsd	%xmm0, -8(%rbp)
	vmovsd	%xmm1, (%rdx,%rax,8)
	vmovsd	-8(%rbp), %xmm1
.L86:
	vmovsd	0(%rbp), %xmm0
	vcomisd	%xmm1, %xmm0
	jbe	.L88
	vunpcklpd	%xmm1, %xmm0, %xmm1
	vmovupd	%xmm1, (%rdx,%rcx,8)
	vmovsd	%xmm0, %xmm0, %xmm1
.L88:
	leal	2(%r11), %edi
	movslq	%edi, %rdi
	movl	%r9d, %ecx
	.p2align 4,,10
	.p2align 3
.L90:
	vmovsd	-8(%rdx,%rdi,8), %xmm2
	movl	%edi, %ebx
	vcomisd	%xmm2, %xmm1
	ja	.L91
	movslq	%ecx, %rax
	subq	$2, %rax
	.p2align 4,,10
	.p2align 3
.L92:
	movq	%rax, %rsi
	decq	%rax
	vmovsd	8(%rdx,%rax,8), %xmm0
	movl	%ecx, %r8d
	decl	%ecx
	vcomisd	%xmm1, %xmm0
	ja	.L92
	cmpl	%edi, %ecx
	jl	.L93
	vmovsd	%xmm0, -8(%rdx,%rdi,8)
	vmovsd	%xmm2, (%rdx,%rsi,8)
.L91:
	incq	%rdi
	jmp	.L90
	.p2align 4,,10
	.p2align 3
.L79:
	xorl	%ecx, %ecx
	jmp	.L78
	.p2align 4,,10
	.p2align 3
.L93:
	vmovsd	%xmm0, -8(%rbp)
	vmovsd	%xmm1, (%rdx,%rsi,8)
	leal	2(%r10), %esi
	cmpl	$500, %esi
	jg	.L108
	movl	%r9d, %eax
	subl	%ebx, %eax
	incl	%eax
	subl	%r11d, %ecx
	subl	$2, %r8d
	movslq	%r10d, %r10
	cmpl	%ecx, %eax
	jl	.L95
	vmovd	%ebx, %xmm3
	vpinsrd	$1, %r9d, %xmm3, %xmm0
	vmovq	%xmm0, 528(%rsp,%r10,4)
	movl	%r8d, %r9d
	movl	%esi, %r10d
	jmp	.L72
.L95:
	vmovd	%r11d, %xmm4
	vpinsrd	$1, %r8d, %xmm4, %xmm0
	vmovq	%xmm0, 528(%rsp,%r10,4)
	movl	%ebx, %r11d
	movl	%esi, %r10d
	jmp	.L72
.L106:
	movq	2536(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L109
	addq	$2552, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 24
	popq	%rbx
	.cfi_def_cfa_offset 16
	popq	%rbp
	.cfi_def_cfa_offset 8
	ret
.L108:
	.cfi_restore_state
	movq	%rsp, %rbp
	leaq	.LC2(%rip), %rax
	movq	%rax, 8(%rsp)
	movq	%rbp, %rdi
	movabsq	$25769803904, %rax
	movq	%rax, (%rsp)
	movl	$6251, 16(%rsp)
	call	_gfortran_st_write@PLT
	movl	$24, %edx
	leaq	.LC12(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
.L109:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE3:
	.size	sort_, .-sort_
	.p2align 4
	.globl	gyration_
	.type	gyration_, @function
gyration_:
.LFB5:
	.cfi_startproc
	movl	8+bas_(%rip), %ecx
	testl	%ecx, %ecx
	jle	.L121
	leal	-1(%rcx), %eax
	cmpl	$2, %eax
	jbe	.L122
	movl	%ecx, %r8d
	shrl	$2, %r8d
	vxorpd	%xmm9, %xmm9, %xmm9
	leaq	pos_(%rip), %rdx
	leaq	mass_(%rip), %r9
	salq	$5, %r8
	movq	%rdx, %rax
	movq	%r9, %rsi
	addq	%rdx, %r8
	vmovapd	%ymm9, %ymm8
	vmovapd	%ymm9, %ymm7
	vmovapd	%ymm9, %ymm6
	vmovapd	%ymm9, %ymm4
	vmovapd	%ymm9, %ymm5
	.p2align 4,,10
	.p2align 3
.L113:
	vmovapd	(%rsi), %ymm0
	vmovapd	(%rax), %ymm3
	vmovapd	80000(%rax), %ymm2
	vmovapd	160000(%rax), %ymm1
	addq	$32, %rax
	vfmadd231pd	%ymm0, %ymm3, %ymm7
	vfmadd231pd	%ymm0, %ymm2, %ymm8
	vfmadd231pd	%ymm0, %ymm1, %ymm9
	vaddpd	%ymm3, %ymm5, %ymm5
	vaddpd	%ymm2, %ymm4, %ymm4
	vaddpd	%ymm1, %ymm6, %ymm6
	addq	$32, %rsi
	cmpq	%r8, %rax
	jne	.L113
	vextractf128	$0x1, %ymm9, %xmm0
	vextractf128	$0x1, %ymm7, %xmm2
	vaddpd	%xmm9, %xmm0, %xmm9
	vaddpd	%xmm7, %xmm2, %xmm7
	vextractf128	$0x1, %ymm8, %xmm1
	vunpckhpd	%xmm9, %xmm9, %xmm0
	vunpckhpd	%xmm7, %xmm7, %xmm2
	vaddpd	%xmm7, %xmm2, %xmm7
	vextractf128	$0x1, %ymm5, %xmm3
	vaddpd	%xmm9, %xmm0, %xmm9
	vextractf128	$0x1, %ymm6, %xmm0
	vaddpd	%xmm8, %xmm1, %xmm8
	vaddpd	%xmm6, %xmm0, %xmm6
	vaddpd	%xmm5, %xmm3, %xmm5
	vmovsd	%xmm7, %xmm7, %xmm2
	vextractf128	$0x1, %ymm4, %xmm7
	vaddpd	%xmm4, %xmm7, %xmm4
	vunpckhpd	%xmm8, %xmm8, %xmm1
	vunpckhpd	%xmm6, %xmm6, %xmm0
	vunpckhpd	%xmm5, %xmm5, %xmm3
	vaddpd	%xmm8, %xmm1, %xmm8
	vaddpd	%xmm6, %xmm0, %xmm6
	vaddpd	%xmm5, %xmm3, %xmm5
	movl	%ecx, %esi
	vunpckhpd	%xmm4, %xmm4, %xmm7
	andl	$-4, %esi
	vaddpd	%xmm4, %xmm7, %xmm4
	vmovsd	%xmm8, %xmm8, %xmm1
	vmovsd	%xmm6, %xmm6, %xmm0
	vmovsd	%xmm5, %xmm5, %xmm3
	leal	1(%rsi), %eax
	cmpl	%esi, %ecx
	je	.L111
.L112:
	leal	-1(%rax), %esi
	movslq	%esi, %rsi
	vmovsd	(%r9,%rsi,8), %xmm5
	vmovsd	(%rdx,%rsi,8), %xmm8
	vmovsd	80000(%rdx,%rsi,8), %xmm7
	vmovsd	160000(%rdx,%rsi,8), %xmm6
	leal	1(%rax), %esi
	vfmadd231sd	%xmm5, %xmm8, %xmm2
	vfmadd231sd	%xmm5, %xmm7, %xmm1
	vfmadd231sd	%xmm5, %xmm6, %xmm9
	vaddsd	%xmm8, %xmm3, %xmm3
	vaddsd	%xmm7, %xmm4, %xmm4
	vaddsd	%xmm6, %xmm0, %xmm0
	cmpl	%esi, %ecx
	jl	.L111
	movslq	%eax, %r8
	vmovsd	(%r9,%r8,8), %xmm5
	vmovsd	(%rdx,%r8,8), %xmm8
	vmovsd	80000(%rdx,%r8,8), %xmm7
	vmovsd	160000(%rdx,%r8,8), %xmm6
	addl	$2, %eax
	vfmadd231sd	%xmm5, %xmm8, %xmm2
	vfmadd231sd	%xmm5, %xmm7, %xmm1
	vfmadd231sd	%xmm5, %xmm6, %xmm9
	vaddsd	%xmm8, %xmm3, %xmm3
	vaddsd	%xmm7, %xmm4, %xmm4
	vaddsd	%xmm6, %xmm0, %xmm0
	cmpl	%eax, %ecx
	jl	.L111
	movslq	%esi, %rax
	vmovsd	(%r9,%rax,8), %xmm5
	vmovsd	(%rdx,%rax,8), %xmm8
	vmovsd	80000(%rdx,%rax,8), %xmm7
	vmovsd	160000(%rdx,%rax,8), %xmm6
	vfmadd231sd	%xmm5, %xmm8, %xmm2
	vfmadd231sd	%xmm5, %xmm7, %xmm1
	vfmadd231sd	%xmm5, %xmm6, %xmm9
	vaddsd	%xmm8, %xmm3, %xmm3
	vaddsd	%xmm7, %xmm4, %xmm4
	vaddsd	%xmm6, %xmm0, %xmm0
.L111:
	vxorps	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%ecx, %xmm5, %xmm5
	vmovsd	.LC8(%rip), %xmm6
	movq	$0x000000000, (%rdi)
	vdivsd	%xmm5, %xmm6, %xmm5
	vmulsd	%xmm3, %xmm5, %xmm8
	vmulsd	%xmm4, %xmm5, %xmm7
	vmulsd	%xmm0, %xmm5, %xmm6
	vfmsub213sd	48+plates_(%rip), %xmm5, %xmm2
	vfmsub213sd	64+plates_(%rip), %xmm5, %xmm1
	vfmsub213sd	plates_(%rip), %xmm5, %xmm9
	vmovsd	%xmm8, masscenter_(%rip)
	vmovsd	%xmm7, 8+masscenter_(%rip)
	vmovsd	%xmm6, 16+masscenter_(%rip)
	vmovsd	%xmm2, 24+masscenter_(%rip)
	vmovsd	%xmm1, 32+masscenter_(%rip)
	vmovsd	%xmm9, 40+masscenter_(%rip)
	testl	%ecx, %ecx
	jle	.L123
	leal	-1(%rcx), %eax
	cmpl	$2, %eax
	jbe	.L124
	movl	%ecx, %edx
	shrl	$2, %edx
	leaq	160000+pos_(%rip), %rax
	salq	$5, %rdx
	vbroadcastsd	%xmm8, %ymm10
	vbroadcastsd	%xmm7, %ymm9
	vbroadcastsd	%xmm6, %ymm4
	addq	%rax, %rdx
	vxorpd	%xmm1, %xmm1, %xmm1
	.p2align 4,,10
	.p2align 3
.L117:
	vmovapd	-80000(%rax), %ymm3
	vmovapd	-160000(%rax), %ymm2
	vsubpd	%ymm9, %ymm3, %ymm3
	vmovapd	(%rax), %ymm0
	vsubpd	%ymm10, %ymm2, %ymm2
	vmulpd	%ymm3, %ymm3, %ymm3
	vsubpd	%ymm4, %ymm0, %ymm0
	addq	$32, %rax
	vfmadd132pd	%ymm0, %ymm1, %ymm0
	vfmadd132pd	%ymm2, %ymm3, %ymm2
	vaddpd	%ymm2, %ymm0, %ymm1
	cmpq	%rax, %rdx
	jne	.L117
	vextractf128	$0x1, %ymm1, %xmm0
	vaddpd	%xmm1, %xmm0, %xmm1
	movl	%ecx, %esi
	andl	$-4, %esi
	vunpckhpd	%xmm1, %xmm1, %xmm0
	vaddpd	%xmm1, %xmm0, %xmm1
	leal	1(%rsi), %eax
	cmpl	%ecx, %esi
	je	.L115
.L116:
	subl	%esi, %ecx
	leaq	pos_(%rip), %rdx
	cmpl	$1, %ecx
	je	.L119
	movl	%esi, %r8d
	leaq	pos_(%rip), %rdx
	vmovapd	(%rdx,%r8,8), %xmm2
	leal	10000(%rsi), %r8d
	vmovapd	(%rdx,%r8,8), %xmm0
	vmovddup	%xmm7, %xmm4
	vsubpd	%xmm4, %xmm0, %xmm4
	vmovddup	%xmm8, %xmm3
	vsubpd	%xmm3, %xmm2, %xmm3
	vmulpd	%xmm4, %xmm4, %xmm4
	addl	$20000, %esi
	vmovapd	(%rdx,%rsi,8), %xmm2
	vmovddup	%xmm6, %xmm0
	vsubpd	%xmm0, %xmm2, %xmm0
	vfmadd132pd	%xmm3, %xmm4, %xmm3
	movl	%ecx, %esi
	andl	$-2, %esi
	addl	%esi, %eax
	vfmadd132pd	%xmm0, %xmm3, %xmm0
	vunpckhpd	%xmm0, %xmm0, %xmm2
	vaddpd	%xmm0, %xmm2, %xmm0
	vaddsd	%xmm0, %xmm1, %xmm1
	cmpl	%ecx, %esi
	je	.L115
.L119:
	decl	%eax
	cltq
	vmovsd	80000(%rdx,%rax,8), %xmm4
	vmovsd	(%rdx,%rax,8), %xmm3
	vsubsd	%xmm7, %xmm4, %xmm4
	vmovsd	160000(%rdx,%rax,8), %xmm0
	vsubsd	%xmm8, %xmm3, %xmm3
	vmulsd	%xmm4, %xmm4, %xmm4
	vsubsd	%xmm6, %xmm0, %xmm0
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vfmadd132sd	%xmm3, %xmm4, %xmm3
	vaddsd	%xmm0, %xmm3, %xmm1
.L115:
	vmulsd	%xmm1, %xmm5, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm0, (%rdi)
	vzeroupper
	ret
	.p2align 4,,10
	.p2align 3
.L121:
	vxorpd	%xmm9, %xmm9, %xmm9
	vmovsd	%xmm9, %xmm9, %xmm1
	vmovsd	%xmm9, %xmm9, %xmm2
	vmovsd	%xmm9, %xmm9, %xmm0
	vmovsd	%xmm9, %xmm9, %xmm4
	vmovsd	%xmm9, %xmm9, %xmm3
	jmp	.L111
	.p2align 4,,10
	.p2align 3
.L123:
	vxorpd	%xmm1, %xmm1, %xmm1
	vmulsd	%xmm1, %xmm5, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm0, (%rdi)
	vzeroupper
	ret
.L122:
	vxorpd	%xmm9, %xmm9, %xmm9
	vmovsd	%xmm9, %xmm9, %xmm1
	vmovsd	%xmm9, %xmm9, %xmm2
	vmovsd	%xmm9, %xmm9, %xmm0
	vmovsd	%xmm9, %xmm9, %xmm4
	vmovsd	%xmm9, %xmm9, %xmm3
	movl	$1, %eax
	leaq	pos_(%rip), %rdx
	leaq	mass_(%rip), %r9
	jmp	.L112
.L124:
	xorl	%esi, %esi
	vxorpd	%xmm1, %xmm1, %xmm1
	movl	$1, %eax
	jmp	.L116
	.cfi_endproc
.LFE5:
	.size	gyration_, .-gyration_
	.section	.rodata.str1.8,"aMS",@progbits,1
	.align 8
.LC13:
	.string	"(/,2a,f10.1,2x,a,f12.2,2x,a,3f9.3)"
	.section	.rodata.str1.1
.LC14:
	.string	"REMARK   0 "
.LC15:
	.string	"SHIFT ="
	.section	.rodata.str1.8
	.align 8
.LC16:
	.string	"(/,a,f10.1,2x,a,f12.2,2x,a,f9.4)"
	.section	.rodata.str1.1
.LC17:
	.string	"REMARK   0 TIME ="
.LC18:
	.string	"(a,3f9.3,3f7.2,x,a,11x,a)"
.LC19:
	.string	"CRYST1"
	.section	.rodata
	.align 4
.LC20:
	.long	1119092736
	.section	.rodata.str1.1
.LC21:
	.string	"P 1"
.LC22:
	.string	"1"
.LC27:
	.string	"(a,a)"
.LC28:
	.string	" "
.LC29:
	.string	"(i2)"
	.section	.rodata.str1.8
	.align 8
.LC30:
	.string	"(a,i7,2x,a,a,a,i4,f12.2,2f8.2,f6.2)"
	.section	.rodata.str1.1
.LC31:
	.string	"ATOM"
.LC32:
	.string	"CA  "
	.section	.rodata.str1.8
	.align 8
.LC33:
	.string	"(a,i7,2x,a,a,a,i4,f12.3,2f8.3,f6.2)"
	.section	.rodata.str1.1
.LC34:
	.string	"(a,i7,6x,a,a,i6,28x)"
.LC35:
	.string	"TER "
.LC36:
	.string	"(a,i5,2x,3a,i4,f12.2,2f8.2)"
.LC37:
	.string	"HETATM"
.LC38:
	.string	"C   "
.LC39:
	.string	"COG"
.LC40:
	.string	"(a,i5,2x,3a,i4,f12.3,2f8.3)"
	.section	.rodata.str1.8
	.align 8
.LC41:
	.string	"(a,i4,a,f10.1,a,f8.2,a,f7.2,a,i4,a,i3,a,i3,a,f6.3)"
	.section	.rodata.str1.1
.LC42:
	.string	"REMARK"
.LC43:
	.string	" T= "
.LC44:
	.string	" RG= "
.LC45:
	.string	" R_end_to_end= "
.LC46:
	.string	" N= "
.LC47:
	.string	" K1= "
.LC48:
	.string	" K2= "
.LC49:
	.string	" W= "
.LC50:
	.string	"(a,i4,2a,i5,2a,i5)"
.LC51:
	.string	"SSBOND"
.LC52:
	.string	" CYS"
.LC53:
	.string	"    CYS"
.LC54:
	.string	"(a,2i5)"
.LC55:
	.string	"CONECT"
.LC56:
	.string	"(a)"
.LC57:
	.string	"END"
	.text
	.p2align 4
	.globl	print_conformation_
	.type	print_conformation_, @function
print_conformation_:
.LFB6:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	movq	%rdx, %r12
	pushq	%rbx
	.cfi_offset 3, -56
	movq	%rcx, %rbx
	andq	$-32, %rsp
	subq	$60800, %rsp
	movq	%rdi, 144(%rsp)
	movq	%rsi, 24(%rsp)
	movl	60+wal_(%rip), %r8d
	movq	%fs:40, %rax
	movq	%rax, 60792(%rsp)
	xorl	%eax, %eax
	testl	%r8d, %r8d
	je	.L131
	vmovsd	48+plates_(%rip), %xmm4
	vmovsd	40+plates_(%rip), %xmm0
	vmovsd	bas_(%rip), %xmm1
	vsubsd	%xmm4, %xmm0, %xmm0
	vmovsd	64+plates_(%rip), %xmm3
	vmovsd	plates_(%rip), %xmm2
	vmulsd	%xmm1, %xmm0, %xmm0
	vmovsd	%xmm4, 208(%rsp)
	vmovsd	%xmm3, 224(%rsp)
	vmovsd	%xmm2, 240(%rsp)
	vmovsd	%xmm0, 200(%rsp)
	vmovsd	56+plates_(%rip), %xmm0
	vsubsd	%xmm3, %xmm0, %xmm0
	vmulsd	%xmm1, %xmm0, %xmm0
	vmovsd	%xmm0, 216(%rsp)
	vmovsd	8+plates_(%rip), %xmm0
	vsubsd	%xmm2, %xmm0, %xmm0
	vmulsd	%xmm1, %xmm0, %xmm0
	vmovsd	%xmm0, 232(%rsp)
.L132:
	movq	144(%rsp), %rax
	movl	80016+neigh_(%rip), %edi
	movl	(%rax), %eax
	testl	%edi, %edi
	je	.L136
	leaq	.LC2(%rip), %rbx
	movq	%rbx, 168(%rsp)
	movq	%rbx, 20792(%rsp)
	movl	%eax, 20788(%rsp)
	leaq	.LC13(%rip), %rbx
	leaq	20784(%rsp), %rax
	movq	%rax, %rdi
	movq	%rbx, 20864(%rsp)
	movq	%rax, %rbx
	movq	%rax, 80(%rsp)
	movl	$6515, 20800(%rsp)
	movq	$34, 20872(%rsp)
	movl	$4096, 20784(%rsp)
	call	_gfortran_st_write@PLT
	movl	$11, %edx
	leaq	.LC14(%rip), %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$6, %edx
	leaq	.LC4(%rip), %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	24(%rsp), %rsi
	movl	$8, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	.LC5(%rip), %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	movq	%r12, %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$7, %edx
	leaq	.LC15(%rip), %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	208(%rsp), %rsi
	movl	$8, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	224(%rsp), %rsi
	movl	$8, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	240(%rsp), %rsi
	movl	$8, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%rbx, %rdi
	call	_gfortran_st_write_done@PLT
	movl	60+wal_(%rip), %esi
	testl	%esi, %esi
	jne	.L184
.L138:
	vmovsd	.LC23(%rip), %xmm0
	movl	8+bas_(%rip), %eax
	vdivsd	bas_(%rip), %xmm0, %xmm0
	vxorpd	.LC11(%rip), %xmm0, %xmm6
	movl	$1, 196(%rsp)
	movl	$0, 192(%rsp)
	movl	%eax, 136(%rsp)
	vmovsd	%xmm6, 96(%rsp)
	testl	%eax, %eax
	jle	.L139
	leaq	80000+sequence_(%rip), %rax
	movq	%rax, 120(%rsp)
	subq	$80000, %rax
	movq	%rax, 152(%rsp)
	leaq	784(%rsp), %rax
	movq	%rax, 72(%rsp)
	leaq	192(%rsp), %rax
	movq	%rax, 104(%rsp)
	leaq	60789(%rsp), %rax
	vmovsd	208(%rsp), %xmm3
	vmovsd	224(%rsp), %xmm6
	vmovsd	240(%rsp), %xmm2
	movl	$1, 184(%rsp)
	movl	$0, 140(%rsp)
	movq	%rax, 64(%rsp)
	vmovsd	%xmm3, 160(%rsp)
	vmovsd	%xmm6, 128(%rsp)
	vmovsd	%xmm2, 112(%rsp)
	leaq	pos_(%rip), %r13
	xorl	%r14d, %r14d
	leaq	248(%rsp), %r15
	leaq	256(%rsp), %r12
	.p2align 4,,10
	.p2align 3
.L160:
	movq	120(%rsp), %rbx
	movzwl	(%rbx), %eax
	movw	%ax, 60789(%rsp)
	movzbl	2(%rbx), %eax
	movb	%al, 60791(%rsp)
	movl	140(%rsp), %eax
	leal	1(%rax), %ebx
	movl	184(%rsp), %eax
	movl	%ebx, 192(%rsp)
	cmpl	$153, %eax
	jle	.L140
	leal	-154(%rax), %edx
	movl	$3593175255, %ecx
	movq	%rdx, %rax
	imulq	%rcx, %rdx
	shrq	$39, %rdx
	incl	%edx
	cmpl	$1223, %eax
	jbe	.L167
	vpbroadcastd	184(%rsp), %ymm1
	movl	%edx, %ecx
	vpaddd	.LC24(%rip), %ymm1, %ymm1
	shrl	$3, %ecx
	xorl	%eax, %eax
	.p2align 4,,10
	.p2align 3
.L142:
	vmovdqa	%ymm1, %ymm0
	incl	%eax
	vpaddd	.LC25(%rip), %ymm1, %ymm1
	vpaddd	.LC26(%rip), %ymm0, %ymm0
	cmpl	%eax, %ecx
	jne	.L142
	movl	%edx, %esi
	andl	$-8, %esi
	imull	$-153, %esi, %ecx
	vextracti128	$0x1, %ymm0, %xmm0
	vpextrd	$3, %xmm0, %eax
	addl	184(%rsp), %ecx
	cmpl	%edx, %esi
	je	.L185
	vzeroupper
.L141:
	leal	-153(%rcx), %eax
	cmpl	$153, %eax
	jle	.L140
	leal	-306(%rcx), %eax
	cmpl	$153, %eax
	jle	.L140
	leal	-459(%rcx), %eax
	cmpl	$153, %eax
	jle	.L140
	leal	-612(%rcx), %eax
	cmpl	$153, %eax
	jle	.L140
	leal	-765(%rcx), %eax
	cmpl	$153, %eax
	jle	.L140
	leal	-918(%rcx), %eax
	cmpl	$153, %eax
	jle	.L140
	leal	-1071(%rcx), %eax
	subl	$1224, %ecx
	cmpl	$153, %eax
	cmovg	%ecx, %eax
.L140:
	movq	72(%rsp), %rcx
	leaq	(%rcx,%r14,2), %rcx
	movq	%rcx, 176(%rsp)
	cmpl	$26, %eax
	jg	.L144
	addl	$64, %eax
.L145:
	movl	%eax, 88(%rsp)
	movq	168(%rsp), %rax
	movq	%r12, %rdi
	movq	%rax, 264(%rsp)
	movq	176(%rsp), %rax
	movl	$6548, 272(%rsp)
	movq	%rax, 368(%rsp)
	leaq	.LC27(%rip), %rax
	movq	%rax, 336(%rsp)
	movabsq	$-4294946816, %rax
	movq	%rax, 256(%rsp)
	movq	$2, 376(%rsp)
	movq	$0, 328(%rsp)
	movq	$5, 344(%rsp)
	call	_gfortran_st_write@PLT
	movl	$1, %edx
	leaq	.LC28(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	88(%rsp), %eax
	movq	%r12, %rdi
	movl	$1, %edx
	movq	%r15, %rsi
	movb	%al, 248(%rsp)
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
.L148:
	vmovsd	0(%r13), %xmm0
	vmovsd	96(%rsp), %xmm5
	vsubsd	160(%rsp), %xmm0, %xmm0
	movq	80(%rsp), %rax
	vcomisd	%xmm0, %xmm5
	movl	%ebx, (%rax,%r14,4)
	movq	144(%rsp), %rax
	movl	(%rax), %eax
	ja	.L149
	vmovsd	80000(%r13), %xmm0
	vsubsd	128(%rsp), %xmm0, %xmm0
	vcomisd	%xmm0, %xmm5
	ja	.L149
	vmovsd	160000(%r13), %xmm0
	vsubsd	112(%rsp), %xmm0, %xmm0
	vcomisd	%xmm0, %xmm5
	jbe	.L174
.L149:
	movq	168(%rsp), %rcx
	movl	$6557, 272(%rsp)
	movq	%rcx, 264(%rsp)
	leaq	.LC30(%rip), %rcx
.L182:
	movq	%r12, %rdi
	movq	%rcx, 336(%rsp)
	movl	%eax, 260(%rsp)
	movq	$35, 344(%rsp)
	movl	$4096, 256(%rsp)
	call	_gfortran_st_write@PLT
	movl	$4, %edx
	leaq	.LC31(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	104(%rsp), %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	.LC32(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	64(%rsp), %rsi
	movl	$3, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	176(%rsp), %rsi
	movl	$2, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	152(%rsp), %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	vmovsd	0(%r13), %xmm0
	leaq	bas_(%rip), %rax
	vsubsd	160(%rsp), %xmm0, %xmm0
	movl	$8, %edx
	movq	%r15, %rsi
	vmulsd	(%rax), %xmm0, %xmm0
	movq	%r12, %rdi
	vmovsd	%xmm0, 248(%rsp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	80000(%r13), %xmm0
	leaq	bas_(%rip), %rax
	vsubsd	128(%rsp), %xmm0, %xmm0
	movl	$8, %edx
	movq	%r15, %rsi
	vmulsd	(%rax), %xmm0, %xmm0
	movq	%r12, %rdi
	vmovsd	%xmm0, 248(%rsp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	160000(%r13), %xmm0
	leaq	bas_(%rip), %rax
	vsubsd	112(%rsp), %xmm0, %xmm0
	movl	$8, %edx
	movq	%r15, %rsi
	vmulsd	(%rax), %xmm0, %xmm0
	movq	%r12, %rdi
	vmovsd	%xmm0, 248(%rsp)
	call	_gfortran_transfer_real_write@PLT
	leaq	neigh_(%rip), %rax
	vxorps	%xmm2, %xmm2, %xmm2
	vcvtsi2ssl	(%rax,%r14,8), %xmm2, %xmm0
	movl	$4, %edx
	movq	%r15, %rsi
	movq	%r12, %rdi
	vmovss	%xmm0, 248(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	80000+bon_(%rip), %rax
	movl	(%rax,%r14,4), %ecx
	testl	%ecx, %ecx
	je	.L186
	movl	%ebx, 140(%rsp)
.L153:
	incq	%r14
	leal	1(%r14), %eax
	addq	$3, 120(%rsp)
	addq	$4, 152(%rsp)
	addq	$8, %r13
	cmpl	%eax, 136(%rsp)
	jge	.L160
	movq	144(%rsp), %rbx
	movl	8+bas_(%rip), %eax
	movl	$0, 248(%rsp)
	movl	(%rbx), %esi
	testl	%eax, %eax
	jle	.L161
	leaq	40000+ssb_(%rip), %r13
	xorl	%r14d, %r14d
	leaq	-40000(%r13), %rbx
	jmp	.L163
	.p2align 4,,10
	.p2align 3
.L162:
	incq	%r14
	leal	1(%r14), %edx
	cmpl	%eax, %edx
	jg	.L161
.L163:
	movl	0(%r13,%r14,4), %edx
	testl	%edx, %edx
	je	.L162
	movl	(%rbx,%r14,4), %r8d
	leal	1(%r14), %edx
	cmpl	%edx, %r8d
	jle	.L162
	movl	%eax, 160(%rsp)
	movq	168(%rsp), %rax
	leaq	.LC50(%rip), %rcx
	movq	%r12, %rdi
	movq	%rax, 264(%rsp)
	movl	%r8d, 184(%rsp)
	movq	%rcx, 336(%rsp)
	movl	%esi, 260(%rsp)
	incl	248(%rsp)
	movl	$6594, 272(%rsp)
	movq	$18, 344(%rsp)
	movl	$4096, 256(%rsp)
	call	_gfortran_st_write@PLT
	movl	$6, %edx
	leaq	.LC51(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	movq	%r15, %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	.LC52(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	72(%rsp), %rcx
	movl	$2, %edx
	leaq	(%rcx,%r14,2), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	0(,%r14,4), %r9
	leaq	sequence_(%rip), %rdi
	leaq	(%rdi,%r9), %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	movq	%r9, 176(%rsp)
	call	_gfortran_transfer_integer_write@PLT
	movl	$7, %edx
	leaq	.LC53(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	184(%rsp), %r8d
	movq	72(%rsp), %rcx
	decl	%r8d
	movslq	%r8d, %r8
	leaq	(%rcx,%r8,2), %rsi
	movl	$2, %edx
	movq	%r12, %rdi
	movq	%r8, 184(%rsp)
	call	_gfortran_transfer_character_write@PLT
	movq	184(%rsp), %r8
	leaq	sequence_(%rip), %rdi
	salq	$2, %r8
	leaq	(%rdi,%r8), %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	movq	%r8, 184(%rsp)
	call	_gfortran_transfer_integer_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movq	168(%rsp), %rax
	movq	%r12, %rdi
	movq	%rax, 264(%rsp)
	leaq	.LC54(%rip), %rax
	movq	%rax, 336(%rsp)
	movq	144(%rsp), %rax
	movl	$6595, 272(%rsp)
	movl	(%rax), %edx
	movq	$7, 344(%rsp)
	movl	%edx, 260(%rsp)
	movl	$4096, 256(%rsp)
	call	_gfortran_st_write@PLT
	movl	$6, %edx
	leaq	.LC55(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	176(%rsp), %r9
	movq	80(%rsp), %rcx
	movl	$4, %edx
	leaq	(%rcx,%r9), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	80(%rsp), %rcx
	movq	184(%rsp), %r8
	movl	$4, %edx
	leaq	(%rcx,%r8), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movq	144(%rsp), %rax
	incq	%r14
	movl	(%rax), %esi
	movl	160(%rsp), %eax
	leal	1(%r14), %edx
	cmpl	%eax, %edx
	jle	.L163
	.p2align 4,,10
	.p2align 3
.L161:
	movq	168(%rsp), %rax
	movq	%r12, %rdi
	movq	%rax, 264(%rsp)
	leaq	.LC56(%rip), %rax
	movq	%rax, 336(%rsp)
	movl	%esi, 260(%rsp)
	movl	$6598, 272(%rsp)
	movq	$3, 344(%rsp)
	movl	$4096, 256(%rsp)
	call	_gfortran_st_write@PLT
	movq	%r12, %rdi
	movl	$3, %edx
	leaq	.LC57(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movq	60792(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L187
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L144:
	.cfi_restore_state
	cmpl	$52, %eax
	jg	.L146
	addl	$70, %eax
	jmp	.L145
	.p2align 4,,10
	.p2align 3
.L146:
	cmpl	$62, %eax
	jle	.L188
	movl	%eax, 88(%rsp)
	movq	168(%rsp), %rax
	movq	%r12, %rdi
	movq	%rax, 264(%rsp)
	movq	176(%rsp), %rax
	movl	$6550, 272(%rsp)
	movq	%rax, 368(%rsp)
	leaq	.LC29(%rip), %rax
	movq	%rax, 336(%rsp)
	movabsq	$-4294946816, %rax
	movq	%rax, 256(%rsp)
	movq	$2, 376(%rsp)
	movq	$0, 328(%rsp)
	movq	$4, 344(%rsp)
	call	_gfortran_st_write@PLT
	movl	88(%rsp), %eax
	movq	%r12, %rdi
	subl	$53, %eax
	movl	$4, %edx
	movq	%r15, %rsi
	movl	%eax, 248(%rsp)
	call	_gfortran_transfer_integer_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L148
	.p2align 4,,10
	.p2align 3
.L186:
	movl	140(%rsp), %ebx
	movq	%r12, %rdi
	leal	2(%rbx), %eax
	movl	%eax, 192(%rsp)
	movq	168(%rsp), %rax
	movl	$6566, 272(%rsp)
	movq	%rax, 264(%rsp)
	leaq	.LC34(%rip), %rax
	movq	%rax, 336(%rsp)
	movq	144(%rsp), %rax
	movq	$20, 344(%rsp)
	movl	(%rax), %eax
	movl	$4096, 256(%rsp)
	movl	%eax, 260(%rsp)
	call	_gfortran_st_write@PLT
	movl	$4, %edx
	leaq	.LC35(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	104(%rsp), %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	64(%rsp), %rsi
	movl	$3, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	176(%rsp), %rsi
	movl	$2, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	152(%rsp), %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	addl	$3, %ebx
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movl	%ebx, 140(%rsp)
	movl	%ebx, 192(%rsp)
	movslq	184(%rsp), %rbx
	vmovsd	96(%rsp), %xmm4
	movq	%rbx, %rax
	decl	%eax
	cltq
	leaq	(%rax,%rax,2), %rdx
	movq	%rbx, 56(%rsp)
	leaq	20000(%rdx), %r9
	leaq	gyr_(%rip), %rbx
	vmovsd	(%rbx,%r9,8), %xmm0
	movq	%rax, 88(%rsp)
	vsubsd	160(%rsp), %xmm0, %xmm0
	leaq	1(%rdx), %rcx
	leaq	2(%rdx), %rax
	vcomisd	%xmm0, %xmm4
	ja	.L189
	leaq	20001(%rdx), %r10
	vmovsd	(%rbx,%r10,8), %xmm0
	movq	144(%rsp), %rdi
	vsubsd	128(%rsp), %xmm0, %xmm0
	movl	(%rdi), %esi
	vcomisd	%xmm0, %xmm4
	ja	.L156
	leaq	20002(%rdx), %r8
	vmovsd	(%rbx,%r8,8), %xmm0
	vsubsd	112(%rsp), %xmm0, %xmm0
	vcomisd	%xmm0, %xmm4
	jbe	.L176
.L156:
	movq	%rax, 40(%rsp)
	movq	168(%rsp), %rax
	movq	%r12, %rdi
	movq	%rax, 264(%rsp)
	leaq	.LC36(%rip), %rax
	movq	%rcx, 48(%rsp)
	movq	%r9, 32(%rsp)
	movq	%rax, 336(%rsp)
	movl	%esi, 260(%rsp)
	movl	$6572, 272(%rsp)
	movq	$27, 344(%rsp)
	movl	$4096, 256(%rsp)
	call	_gfortran_st_write@PLT
	movl	$6, %edx
	leaq	.LC37(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	104(%rsp), %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	.LC38(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$3, %edx
	leaq	.LC39(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	176(%rsp), %rsi
	movl	$2, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	152(%rsp), %rax
	movq	%r15, %rsi
	movl	(%rax), %eax
	movq	%r12, %rdi
	leal	1(%rax), %edx
	movl	%edx, 248(%rsp)
	movl	$4, %edx
	movl	%eax, 176(%rsp)
	call	_gfortran_transfer_integer_write@PLT
	movq	32(%rsp), %r9
	leaq	bas_(%rip), %rax
	vmovsd	(%rbx,%r9,8), %xmm0
	movl	$8, %edx
	vsubsd	160(%rsp), %xmm0, %xmm0
	movq	%r15, %rsi
	movq	%r12, %rdi
	vmulsd	(%rax), %xmm0, %xmm0
	vmovsd	%xmm0, 248(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	48(%rsp), %rcx
	leaq	bas_(%rip), %rax
	vmovsd	160000(%rbx,%rcx,8), %xmm0
	movl	$8, %edx
	vsubsd	128(%rsp), %xmm0, %xmm0
	movq	%r15, %rsi
	movq	%r12, %rdi
	vmulsd	(%rax), %xmm0, %xmm0
	vmovsd	%xmm0, 248(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	40(%rsp), %rax
	vmovsd	160000(%rbx,%rax,8), %xmm0
.L183:
	vsubsd	112(%rsp), %xmm0, %xmm0
	leaq	bas_(%rip), %rax
	movl	$8, %edx
	vmulsd	(%rax), %xmm0, %xmm0
	movq	%r15, %rsi
	movq	%r12, %rdi
	vmovsd	%xmm0, 248(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movq	168(%rsp), %rax
	movq	%r12, %rdi
	movq	%rax, 264(%rsp)
	leaq	.LC41(%rip), %rax
	movq	%rax, 336(%rsp)
	movq	144(%rsp), %rax
	movl	$6581, 272(%rsp)
	movl	(%rax), %eax
	movq	$50, 344(%rsp)
	movl	%eax, 260(%rsp)
	movl	$4096, 256(%rsp)
	call	_gfortran_st_write@PLT
	movl	$6, %edx
	leaq	.LC42(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	196(%rsp), %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	.LC43(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	24(%rsp), %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$5, %edx
	leaq	.LC44(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	88(%rsp), %rax
	leaq	bas_(%rip), %rdi
	vmovsd	(%rbx,%rax,8), %xmm0
	movl	$8, %edx
	vmulsd	(%rdi), %xmm0, %xmm0
	movq	%r15, %rsi
	movq	%r12, %rdi
	vmovsd	%xmm0, 248(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movl	$15, %edx
	leaq	.LC45(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	88(%rsp), %rax
	leaq	bas_(%rip), %rdi
	vmovsd	80000(%rbx,%rax,8), %xmm0
	movl	$8, %edx
	vmulsd	(%rdi), %xmm0, %xmm0
	movq	%r15, %rsi
	movq	%r12, %rdi
	vmovsd	%xmm0, 248(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movl	$4, %edx
	leaq	.LC46(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	56(%rsp), %rsi
	leaq	bon_(%rip), %rdx
	movl	120000(%rdx,%rsi,4), %eax
	movq	88(%rsp), %rcx
	movq	%r15, %rsi
	subl	120000(%rdx,%rcx,4), %eax
	movq	%r12, %rdi
	movl	$4, %edx
	movl	%eax, 248(%rsp)
	incl	184(%rsp)
	call	_gfortran_transfer_integer_write@PLT
	movl	$5, %edx
	leaq	.LC47(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	88(%rsp), %rax
	movl	$4, %edx
	leaq	(%rax,%rax), %rcx
	leaq	480000(,%rax,8), %rax
	leaq	(%rbx,%rax), %rsi
	movq	%r12, %rdi
	movq	%rax, 176(%rsp)
	movq	%rcx, 88(%rsp)
	call	_gfortran_transfer_integer_write@PLT
	movl	$5, %edx
	leaq	.LC48(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	88(%rsp), %rcx
	movl	$4, %edx
	leaq	480004(%rbx,%rcx,4), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	.LC49(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	176(%rsp), %rax
	movl	$8, %edx
	leaq	-80000(%rbx,%rax), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movl	184(%rsp), %edi
	movl	%edi, 196(%rsp)
	jmp	.L153
	.p2align 4,,10
	.p2align 3
.L174:
	movq	168(%rsp), %rcx
	movl	$6561, 272(%rsp)
	movq	%rcx, 264(%rsp)
	leaq	.LC33(%rip), %rcx
	jmp	.L182
	.p2align 4,,10
	.p2align 3
.L189:
	movq	144(%rsp), %rdi
	movl	(%rdi), %esi
	jmp	.L156
	.p2align 4,,10
	.p2align 3
.L185:
	vzeroupper
	jmp	.L140
.L167:
	movl	184(%rsp), %ecx
	jmp	.L141
.L136:
	leaq	.LC2(%rip), %rcx
	movl	%eax, 20788(%rsp)
	leaq	20784(%rsp), %rax
	movq	%rax, %r14
	movq	%rax, %rdi
	movq	%rcx, 168(%rsp)
	movq	%rcx, 20792(%rsp)
	leaq	.LC16(%rip), %rcx
	movq	%rcx, 20864(%rsp)
	movq	%rax, 80(%rsp)
	movl	$6518, 20800(%rsp)
	movq	$32, 20872(%rsp)
	movl	$4096, 20784(%rsp)
	call	_gfortran_st_write@PLT
	movl	$17, %edx
	leaq	.LC17(%rip), %rsi
	movq	%r14, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	24(%rsp), %rsi
	movl	$8, %edx
	movq	%r14, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	.LC5(%rip), %rsi
	movq	%r14, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	movq	%r12, %rsi
	movq	%r14, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$6, %edx
	leaq	.LC6(%rip), %rsi
	movq	%r14, %rdi
	call	_gfortran_transfer_character_write@PLT
	vmovsd	(%rbx), %xmm0
	leaq	248(%rsp), %r15
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movq	%r15, %rsi
	movl	$8, %edx
	movq	%r14, %rdi
	vmovsd	%xmm0, 248(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r14, %rdi
	call	_gfortran_st_write_done@PLT
	movl	60+wal_(%rip), %esi
	movq	$0x000000000, 208(%rsp)
	movq	$0x000000000, 224(%rsp)
	movq	$0x000000000, 240(%rsp)
	testl	%esi, %esi
	je	.L138
.L184:
	movq	168(%rsp), %rax
	movq	80(%rsp), %rbx
	movq	%rax, 20792(%rsp)
	leaq	.LC18(%rip), %rax
	movq	%rax, 20864(%rsp)
	movq	144(%rsp), %rax
	movq	%rbx, %rdi
	movl	(%rax), %eax
	movl	$6524, 20800(%rsp)
	movl	%eax, 20788(%rsp)
	movq	$25, 20872(%rsp)
	movl	$4096, 20784(%rsp)
	call	_gfortran_st_write@PLT
	movq	%rbx, %rdi
	movl	$6, %edx
	leaq	.LC19(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	leaq	200(%rsp), %rsi
	movq	%rbx, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	216(%rsp), %rsi
	movq	%rbx, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	232(%rsp), %rsi
	movq	%rbx, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%rbx, %rdi
	movl	$4, %edx
	leaq	.LC20(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%rbx, %rdi
	movl	$4, %edx
	leaq	.LC20(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%rbx, %rdi
	movl	$4, %edx
	leaq	.LC20(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%rbx, %rdi
	movl	$3, %edx
	leaq	.LC21(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%rbx, %rdi
	movl	$1, %edx
	leaq	.LC22(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%rbx, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L138
.L131:
	vmovsd	pos_(%rip), %xmm2
	vmovsd	80000+pos_(%rip), %xmm1
	vmovsd	160000+pos_(%rip), %xmm0
	movl	8+bas_(%rip), %ecx
	vmovsd	%xmm2, 208(%rsp)
	vmovsd	%xmm1, 224(%rsp)
	vmovsd	%xmm0, 240(%rsp)
	cmpl	$1, %ecx
	jle	.L132
	leal	-2(%rcx), %eax
	leal	-1(%rcx), %esi
	cmpl	$2, %eax
	jbe	.L165
	movl	%esi, %edx
	shrl	$2, %edx
	leaq	8+pos_(%rip), %rax
	salq	$5, %rdx
	vbroadcastsd	%xmm2, %ymm2
	vbroadcastsd	%xmm1, %ymm1
	vbroadcastsd	%xmm0, %ymm0
	addq	%rax, %rdx
	.p2align 4,,10
	.p2align 3
.L134:
	vminpd	(%rax), %ymm2, %ymm2
	vminpd	80000(%rax), %ymm1, %ymm1
	vminpd	160000(%rax), %ymm0, %ymm0
	addq	$32, %rax
	cmpq	%rdx, %rax
	jne	.L134
	vextractf128	$0x1, %ymm0, %xmm3
	vminpd	%xmm0, %xmm3, %xmm3
	movl	%esi, %eax
	andl	$-4, %eax
	vunpckhpd	%xmm3, %xmm3, %xmm0
	vminpd	%xmm3, %xmm0, %xmm0
	vextractf128	$0x1, %ymm1, %xmm3
	vminpd	%xmm1, %xmm3, %xmm3
	leal	2(%rax), %edx
	vunpckhpd	%xmm3, %xmm3, %xmm1
	vminpd	%xmm3, %xmm1, %xmm1
	vextractf128	$0x1, %ymm2, %xmm3
	vminpd	%xmm2, %xmm3, %xmm3
	vunpckhpd	%xmm3, %xmm3, %xmm2
	vminpd	%xmm3, %xmm2, %xmm2
	cmpl	%esi, %eax
	je	.L190
	vzeroupper
.L133:
	leal	-1(%rdx), %esi
	movslq	%esi, %rsi
	leaq	pos_(%rip), %rax
	vminsd	(%rax,%rsi,8), %xmm2, %xmm2
	vminsd	80000(%rax,%rsi,8), %xmm1, %xmm1
	vminsd	160000(%rax,%rsi,8), %xmm0, %xmm0
	leal	1(%rdx), %esi
	cmpl	%esi, %ecx
	jl	.L135
	movslq	%edx, %rdi
	addl	$2, %edx
	vminsd	(%rax,%rdi,8), %xmm2, %xmm2
	vminsd	80000(%rax,%rdi,8), %xmm1, %xmm1
	vminsd	160000(%rax,%rdi,8), %xmm0, %xmm0
	cmpl	%edx, %ecx
	jl	.L135
	movslq	%esi, %rdx
	vminsd	(%rax,%rdx,8), %xmm2, %xmm2
	vminsd	80000(%rax,%rdx,8), %xmm1, %xmm1
	vminsd	160000(%rax,%rdx,8), %xmm0, %xmm0
.L135:
	vmovsd	%xmm2, 208(%rsp)
	vmovsd	%xmm1, 224(%rsp)
	vmovsd	%xmm0, 240(%rsp)
	jmp	.L132
.L176:
	movq	168(%rsp), %rax
	movq	%r12, %rdi
	movq	%rax, 264(%rsp)
	leaq	.LC40(%rip), %rax
	movq	%r8, 40(%rsp)
	movq	%r10, 48(%rsp)
	movq	%r9, 32(%rsp)
	movq	%rax, 336(%rsp)
	movl	%esi, 260(%rsp)
	movl	$6576, 272(%rsp)
	movq	$27, 344(%rsp)
	movl	$4096, 256(%rsp)
	call	_gfortran_st_write@PLT
	movl	$6, %edx
	leaq	.LC37(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	104(%rsp), %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	.LC38(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$3, %edx
	leaq	.LC39(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	176(%rsp), %rsi
	movl	$2, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	152(%rsp), %rax
	movl	$4, %edx
	movl	(%rax), %eax
	movq	%r15, %rsi
	movl	%eax, 176(%rsp)
	movq	%r12, %rdi
	incl	%eax
	movl	%eax, 248(%rsp)
	call	_gfortran_transfer_integer_write@PLT
	movq	32(%rsp), %r9
	leaq	bas_(%rip), %rax
	vmovsd	(%rbx,%r9,8), %xmm0
	movl	$8, %edx
	vsubsd	160(%rsp), %xmm0, %xmm0
	movq	%r15, %rsi
	movq	%r12, %rdi
	vmulsd	(%rax), %xmm0, %xmm0
	vmovsd	%xmm0, 248(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	48(%rsp), %r10
	leaq	bas_(%rip), %rax
	vmovsd	(%rbx,%r10,8), %xmm0
	movl	$8, %edx
	vsubsd	128(%rsp), %xmm0, %xmm0
	movq	%r15, %rsi
	movq	%r12, %rdi
	vmulsd	(%rax), %xmm0, %xmm0
	vmovsd	%xmm0, 248(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	40(%rsp), %r8
	vmovsd	(%rbx,%r8,8), %xmm0
	jmp	.L183
.L190:
	vzeroupper
	jmp	.L135
.L139:
	movq	144(%rsp), %rax
	leaq	256(%rsp), %r12
	movl	(%rax), %esi
	jmp	.L161
.L165:
	movl	$2, %edx
	jmp	.L133
.L188:
	subl	$5, %eax
	jmp	.L145
.L187:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE6:
	.size	print_conformation_, .-print_conformation_
	.p2align 4
	.globl	print_conf_xyz_
	.type	print_conf_xyz_, @function
print_conf_xyz_:
.LFB7:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movq	%rdi, %r14
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	movq	%rsi, %r13
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	movq	%rdx, %r12
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	movq	%rcx, %rbp
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$584, %rsp
	.cfi_def_cfa_offset 640
	movq	%fs:40, %rax
	movq	%rax, 568(%rsp)
	leaq	.LC2(%rip), %rax
	leaq	32(%rsp), %rbx
	movl	$6613, 48(%rsp)
	movq	$30, 120(%rsp)
	movl	$4096, 32(%rsp)
	movq	%rax, 40(%rsp)
	leaq	.LC3(%rip), %rax
	movq	%rax, 112(%rsp)
	movl	(%rdi), %eax
	movq	%rbx, %rdi
	movl	%eax, 36(%rsp)
	call	_gfortran_st_write@PLT
	movl	$6, %edx
	leaq	.LC4(%rip), %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	.LC5(%rip), %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rsi
	movl	$8, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$6, %edx
	leaq	.LC6(%rip), %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_character_write@PLT
	vmovsd	0(%rbp), %xmm0
	leaq	24(%rsp), %r12
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movl	$8, %edx
	movq	%r12, %rsi
	movq	%rbx, %rdi
	vmovsd	%xmm0, 24(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	%rbx, %rdi
	call	_gfortran_st_write_done@PLT
	movl	8+bas_(%rip), %eax
	movl	%eax, 12(%rsp)
	testl	%eax, %eax
	jle	.L191
	leaq	pos_(%rip), %rbp
	movl	$1, %r15d
	leaq	bas_(%rip), %r13
	.p2align 4,,10
	.p2align 3
.L193:
	movl	(%r14), %edx
	leaq	.LC2(%rip), %rax
	movq	%rax, 40(%rsp)
	movq	%rbx, %rdi
	leaq	.LC7(%rip), %rax
	movq	%rax, 112(%rsp)
	movl	%edx, 36(%rsp)
	movl	$6617, 48(%rsp)
	movq	$7, 120(%rsp)
	movl	$4096, 32(%rsp)
	call	_gfortran_st_write@PLT
	vmovsd	0(%rbp), %xmm0
	movl	$8, %edx
	vmulsd	0(%r13), %xmm0, %xmm0
	movq	%r12, %rsi
	movq	%rbx, %rdi
	incl	%r15d
	addq	$8, %rbp
	vmovsd	%xmm0, 24(%rsp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	79992(%rbp), %xmm0
	movl	$8, %edx
	vmulsd	0(%r13), %xmm0, %xmm0
	movq	%r12, %rsi
	movq	%rbx, %rdi
	vmovsd	%xmm0, 24(%rsp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	159992(%rbp), %xmm0
	movl	$8, %edx
	vmulsd	0(%r13), %xmm0, %xmm0
	movq	%r12, %rsi
	movq	%rbx, %rdi
	vmovsd	%xmm0, 24(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	%rbx, %rdi
	call	_gfortran_st_write_done@PLT
	cmpl	%r15d, 12(%rsp)
	jge	.L193
.L191:
	movq	568(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L198
	addq	$584, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
.L198:
	.cfi_restore_state
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE7:
	.size	print_conf_xyz_, .-print_conf_xyz_
	.section	.rodata.str1.1
.LC58:
	.string	"(a"
.LC59:
	.string	",i2.2,i10.10,a)"
.LC61:
	.string	".rst"
.LC62:
	.string	"unknown"
.LC63:
	.string	"(2f18.3)"
.LC64:
	.string	"(8f14.6)"
.LC65:
	.string	"(7i10)"
.LC67:
	.string	"(2i8)"
	.text
	.p2align 4
	.globl	print_restart_
	.type	print_restart_, @function
print_restart_:
.LFB9:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	vxorps	%xmm0, %xmm0, %xmm0
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	.cfi_offset 15, -24
	leaq	88+restart_(%rip), %r15
	pushq	%r14
	.cfi_offset 14, -32
	movq	%rsi, %r14
	pushq	%r13
	.cfi_offset 13, -40
	leaq	.LC2(%rip), %r13
	pushq	%r12
	pushq	%rbx
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	leaq	-64(%r15), %rbx
	andq	$-32, %rsp
	subq	$992, %rsp
	vcvtsi2sdl	(%rdi), %xmm0, %xmm0
	leaq	448(%rsp), %r12
	movq	%fs:40, %rax
	movq	%rax, 984(%rsp)
	xorl	%eax, %eax
	movq	%r12, %rdi
	vmulsd	restart_(%rip), %xmm0, %xmm0
	movabsq	$-4294950784, %rax
	movq	%rax, 448(%rsp)
	movq	%r15, 560(%rsp)
	movq	%r13, 456(%rsp)
	vmovsd	%xmm0, 24(%rsp)
	vmovsd	%xmm0, 8(%rsp)
	movl	$6644, 464(%rsp)
	movq	$32, 568(%rsp)
	movq	$0, 520(%rsp)
	call	_gfortran_st_write@PLT
	movq	%r12, %rdi
	movl	$2, %edx
	leaq	.LC58(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	leaq	64(%r15), %rsi
	movq	%r12, %rdi
	movl	$4, %edx
	call	_gfortran_transfer_integer_write@PLT
	movl	$15, %edx
	leaq	.LC59(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movabsq	$-4294946816, %rax
	movq	%r12, %rdi
	movq	%rax, 448(%rsp)
	movq	%rbx, 560(%rsp)
	movq	%r15, 528(%rsp)
	movq	%r13, 456(%rsp)
	movl	$6645, 464(%rsp)
	movq	$64, 568(%rsp)
	movq	$0, 520(%rsp)
	movq	$32, 536(%rsp)
	call	_gfortran_st_write@PLT
	leaq	32(%r15), %rsi
	movq	%r12, %rdi
	movl	$32, %edx
	call	_gfortran_transfer_character_write@PLT
	movq	%r14, %rsi
	movq	%r12, %rdi
	movl	$4, %edx
	call	_gfortran_transfer_integer_write@PLT
	vmovsd	8(%rsp), %xmm0
	vmovsd	.LC11(%rip), %xmm2
	vmovsd	.LC60(%rip), %xmm1
	vandpd	%xmm0, %xmm2, %xmm2
	vorpd	%xmm2, %xmm1, %xmm1
	vaddsd	%xmm0, %xmm1, %xmm0
	leaq	32(%rsp), %r15
	movq	%r15, %rsi
	vcvttsd2sil	%xmm0, %eax
	movq	%r12, %rdi
	movl	$4, %edx
	movq	%r15, (%rsp)
	movl	%eax, 32(%rsp)
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	.LC61(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC62(%rip), %rax
	movq	%rax, 104(%rsp)
	movq	%r15, %rdi
	movabsq	$90211091200, %rax
	movq	%rbx, 96(%rsp)
	movq	%rax, 32(%rsp)
	movabsq	$90194317312, %rbx
	movq	%r13, 40(%rsp)
	movl	$6646, 48(%rsp)
	movq	$64, 88(%rsp)
	movq	$7, 112(%rsp)
	movl	$0, 336(%rsp)
	call	_gfortran_st_open@PLT
	leaq	.LC63(%rip), %rax
	movq	%r12, %rdi
	movq	%rax, 528(%rsp)
	movq	%r13, 456(%rsp)
	movl	$6647, 464(%rsp)
	movq	$8, 536(%rsp)
	movq	%rbx, 448(%rsp)
	call	_gfortran_st_write@PLT
	leaq	24(%rsp), %rsi
	movq	%r12, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	8+restart_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC64(%rip), %rax
	movq	%r12, %rdi
	movq	%rax, 528(%rsp)
	movq	%r13, 456(%rsp)
	movl	$6648, 464(%rsp)
	movq	$8, 536(%rsp)
	movq	%rbx, 448(%rsp)
	call	_gfortran_st_write@PLT
	movq	%r12, %rdi
	movl	$8, %edx
	leaq	8+plates_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	movl	$8, %edx
	leaq	plates_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	movl	$8, %edx
	leaq	56+plates_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	movl	$8, %edx
	leaq	64+plates_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	movl	$8, %edx
	leaq	40+plates_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	movl	$8, %edx
	leaq	48+plates_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	movl	$8, %edx
	leaq	16+restart_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	24+kier_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC65(%rip), %rax
	movq	%r12, %rdi
	movq	%rax, 528(%rsp)
	movq	%r13, 456(%rsp)
	movl	$6649, 464(%rsp)
	movq	$6, 536(%rsp)
	movq	%rbx, 448(%rsp)
	call	_gfortran_st_write@PLT
	leaq	8+wal_(%rip), %rax
	movq	%rax, 384(%rsp)
	movabsq	$1103806595072, %rax
	movq	%rax, 408(%rsp)
	vmovdqa	.LC66(%rip), %ymm0
	leaq	384(%rsp), %rax
	xorl	%ecx, %ecx
	movl	$4, %edx
	movq	%rax, %rsi
	movq	%r12, %rdi
	movq	$-1, 392(%rsp)
	movq	$4, 400(%rsp)
	movq	%rax, 8(%rsp)
	vmovdqa	%ymm0, 416(%rsp)
	vzeroupper
	call	_gfortran_transfer_array_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC67(%rip), %rax
	movq	%r12, %rdi
	movq	%rax, 528(%rsp)
	movq	%rbx, 448(%rsp)
	movq	%r13, 456(%rsp)
	movl	$6650, 464(%rsp)
	movq	$5, 536(%rsp)
	call	_gfortran_st_write@PLT
	movl	$4, %edx
	leaq	2000016+cmapi_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	2000024+cmapi_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movl	8+bas_(%rip), %r14d
	movl	$1, 20(%rsp)
	leaq	ssb_(%rip), %rbx
	movl	$1, %r15d
	testl	%r14d, %r14d
	jg	.L206
	jmp	.L204
	.p2align 4,,10
	.p2align 3
.L203:
	incl	%r15d
	movl	%r15d, 20(%rsp)
	addq	$4, %rbx
	cmpl	%r14d, %r15d
	jg	.L204
.L206:
	movl	40000(%rbx), %edx
	testl	%edx, %edx
	je	.L203
	movabsq	$90194313344, %rax
	movq	%r12, %rdi
	movq	%rax, 448(%rsp)
	movq	%r13, 456(%rsp)
	movl	$6652, 464(%rsp)
	call	_gfortran_st_write@PLT
	leaq	20(%rsp), %rsi
	movq	%r12, %rdi
	movl	$4, %edx
	call	_gfortran_transfer_integer_write@PLT
	movq	%r12, %rdi
	movl	$4, %edx
	movq	%rbx, %rsi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L203
	.p2align 4,,10
	.p2align 3
.L204:
	movabsq	$90194313344, %rbx
	movq	%r12, %rdi
	movq	%rbx, 448(%rsp)
	movq	%r13, 456(%rsp)
	movl	$6654, 464(%rsp)
	call	_gfortran_st_write@PLT
	movslq	8+bas_(%rip), %rax
	movq	8(%rsp), %rsi
	movq	%rax, 440(%rsp)
	leaq	80000+respul_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$4, %edx
	movq	%rax, 384(%rsp)
	movq	%r12, %rdi
	movabsq	$1103806595072, %rax
	movq	%rax, 408(%rsp)
	movq	$-1, 392(%rsp)
	movq	$4, 400(%rsp)
	movq	$4, 416(%rsp)
	movq	$1, 424(%rsp)
	movq	$1, 432(%rsp)
	call	_gfortran_transfer_array_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movq	%r12, %rdi
	movq	%rbx, 448(%rsp)
	movq	%r13, 456(%rsp)
	movl	$6655, 464(%rsp)
	leaq	pull_(%rip), %rbx
	call	_gfortran_st_write@PLT
	movl	$1, %r14d
	movl	$1, 20(%rsp)
	movl	8+bas_(%rip), %r15d
	testb	$1, 448(%rsp)
	je	.L209
	jmp	.L201
	.p2align 4,,10
	.p2align 3
.L224:
	movq	%rbx, %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	80000(%rbx), %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	incl	%r14d
	leaq	160000(%rbx), %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	addq	$8, %rbx
	movl	%r14d, 20(%rsp)
	testb	$1, 448(%rsp)
	jne	.L201
.L209:
	cmpl	%r14d, %r15d
	jge	.L224
.L201:
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movabsq	$90194313344, %rax
	movq	%r12, %rdi
	movq	%r13, 456(%rsp)
	movl	$6656, 464(%rsp)
	movq	%rax, 448(%rsp)
	leaq	pos_(%rip), %rbx
	call	_gfortran_st_write@PLT
	movl	$1, %r14d
	movl	$1, 20(%rsp)
	movl	8+bas_(%rip), %r15d
	testb	$1, 448(%rsp)
	je	.L212
	jmp	.L207
	.p2align 4,,10
	.p2align 3
.L225:
	movq	%rbx, %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	80000(%rbx), %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	incl	%r14d
	leaq	160000(%rbx), %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	addq	$8, %rbx
	movl	%r14d, 20(%rsp)
	testb	$1, 448(%rsp)
	jne	.L207
.L212:
	cmpl	%r14d, %r15d
	jge	.L225
.L207:
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movabsq	$90194313344, %rax
	movq	%r12, %rdi
	movq	%r13, 456(%rsp)
	movl	$6657, 464(%rsp)
	movq	%rax, 448(%rsp)
	leaq	vel_(%rip), %rbx
	call	_gfortran_st_write@PLT
	movl	$1, %r14d
	movl	$1, 20(%rsp)
	movl	8+bas_(%rip), %r15d
	testb	$1, 448(%rsp)
	je	.L215
	jmp	.L210
	.p2align 4,,10
	.p2align 3
.L226:
	movq	%rbx, %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	80000(%rbx), %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	incl	%r14d
	leaq	160000(%rbx), %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real_write@PLT
	addq	$8, %rbx
	movl	%r14d, 20(%rsp)
	testb	$1, 448(%rsp)
	jne	.L210
.L215:
	cmpl	%r14d, %r15d
	jge	.L226
.L210:
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movabsq	$90194313344, %rbx
	movq	%r12, %rdi
	movq	%r13, 456(%rsp)
	movl	$6658, 464(%rsp)
	movq	%rbx, 448(%rsp)
	call	_gfortran_st_write@PLT
	movl	$4, %edx
	leaq	8+ssb2_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	12+ssb2_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	120000+respul_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	120004+respul_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movl	60+wal_(%rip), %eax
	testl	%eax, %eax
	jne	.L227
.L214:
	movabsq	$90194313344, %rax
	movq	%r12, %rdi
	movq	%rax, 448(%rsp)
	movq	%r13, 456(%rsp)
	movl	$6663, 464(%rsp)
	call	_gfortran_st_write@PLT
	movl	$4, %edx
	leaq	48+kier_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movq	(%rsp), %rdi
	movabsq	$90194313216, %rax
	movq	%rax, 32(%rsp)
	movq	%r13, 40(%rsp)
	movl	$6664, 48(%rsp)
	call	_gfortran_st_close@PLT
	movq	984(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L228
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L227:
	.cfi_restore_state
	movq	%r12, %rdi
	movq	%r13, 456(%rsp)
	movl	$6660, 464(%rsp)
	movq	%rbx, 448(%rsp)
	call	_gfortran_st_write@PLT
	movq	8(%rsp), %r14
	movslq	8+bas_(%rip), %rax
	xorl	%ecx, %ecx
	movq	%r14, %rsi
	movl	$4, %edx
	movq	%rax, 440(%rsp)
	movabsq	$1103806595072, %r15
	leaq	120012+respul_(%rip), %rax
	movq	%r12, %rdi
	movq	%rax, 384(%rsp)
	movq	$-3, 392(%rsp)
	movq	$4, 400(%rsp)
	movq	%r15, 408(%rsp)
	movq	$4, 416(%rsp)
	movq	$2, 424(%rsp)
	movq	$1, 432(%rsp)
	call	_gfortran_transfer_array_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movq	%r12, %rdi
	movq	%r13, 456(%rsp)
	movl	$6661, 464(%rsp)
	movq	%rbx, 448(%rsp)
	call	_gfortran_st_write@PLT
	movslq	8+bas_(%rip), %rax
	movq	%r12, %rdi
	movq	%rax, 440(%rsp)
	xorl	%ecx, %ecx
	leaq	120016+respul_(%rip), %rax
	movl	$4, %edx
	movq	%r14, %rsi
	movq	%rax, 384(%rsp)
	movq	$-2, 392(%rsp)
	movq	$4, 400(%rsp)
	movq	%r15, 408(%rsp)
	movq	$4, 416(%rsp)
	movq	$2, 424(%rsp)
	movq	$1, 432(%rsp)
	call	_gfortran_transfer_array_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L214
.L228:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE9:
	.size	print_restart_, .-print_restart_
	.p2align 4
	.globl	pvector_
	.type	pvector_, @function
pvector_:
.LFB12:
	.cfi_startproc
	vmovsd	16(%rdi), %xmm1
	vmovsd	8(%rsi), %xmm0
	vmovsd	8(%rdi), %xmm3
	vmulsd	%xmm0, %xmm1, %xmm2
	vmovsd	16(%rsi), %xmm4
	vmovsd	(%rdi), %xmm5
	vmovsd	(%rsi), %xmm6
	vfmsub231sd	%xmm4, %xmm3, %xmm2
	vmulsd	%xmm5, %xmm4, %xmm4
	vmulsd	%xmm6, %xmm3, %xmm3
	vmovsd	%xmm2, (%rdx)
	vfmsub132sd	%xmm6, %xmm4, %xmm1
	vfmsub132sd	%xmm5, %xmm3, %xmm0
	vmovsd	%xmm1, 8(%rdx)
	vmulsd	%xmm1, %xmm1, %xmm1
	vmovsd	%xmm0, 16(%rdx)
	vfmadd132sd	%xmm2, %xmm1, %xmm2
	vfmadd132sd	%xmm0, %xmm2, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm0, (%rcx)
	ret
	.cfi_endproc
.LFE12:
	.size	pvector_, .-pvector_
	.p2align 4
	.globl	norma_
	.type	norma_, @function
norma_:
.LFB13:
	.cfi_startproc
	vpermilpd	$1, (%rdi), %xmm1
	vmovupd	16(%rdi), %xmm5
	vmovhpd	32(%rdi), %xmm1, %xmm1
	vmulpd	%xmm1, %xmm1, %xmm1
	vmovlpd	(%rdi), %xmm5, %xmm2
	vmovhpd	(%rdi), %xmm5, %xmm0
	vmovhps	40(%rdi), %xmm0, %xmm0
	vmovapd	.LC68(%rip), %xmm4
	vfmadd231pd	%xmm2, %xmm2, %xmm1
	vfmadd132pd	%xmm0, %xmm1, %xmm0
	vmovupd	8(%rdi), %xmm1
	vmovhps	32(%rdi), %xmm1, %xmm3
	vsqrtpd	%xmm0, %xmm0
	vdivpd	%xmm0, %xmm4, %xmm4
	vpermilpd	$1, %xmm1, %xmm0
	vmovhpd	40(%rdi), %xmm0, %xmm0
	vmulpd	%xmm4, %xmm2, %xmm2
	vmulpd	%xmm4, %xmm3, %xmm3
	vmulpd	%xmm4, %xmm0, %xmm0
	vmovsd	48(%rdi), %xmm4
	vunpcklpd	%xmm3, %xmm2, %xmm1
	vmovsd	%xmm0, %xmm2, %xmm7
	vshufpd	$1, %xmm2, %xmm3, %xmm2
	vmovsd	56(%rdi), %xmm3
	vmovsd	%xmm2, %xmm0, %xmm5
	vmulsd	%xmm3, %xmm3, %xmm0
	vmovupd	%xmm1, (%rdi)
	vmovsd	64(%rdi), %xmm1
	vmovsd	.LC8(%rip), %xmm2
	vmovupd	%xmm7, 16(%rdi)
	vfmadd231sd	%xmm4, %xmm4, %xmm0
	vmovupd	%xmm5, 32(%rdi)
	vfmadd231sd	%xmm1, %xmm1, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vdivsd	%xmm0, %xmm2, %xmm0
	vmulsd	%xmm0, %xmm4, %xmm4
	vmulsd	%xmm0, %xmm3, %xmm3
	vmulsd	%xmm0, %xmm1, %xmm1
	vmovsd	%xmm4, 48(%rdi)
	vmovsd	%xmm3, 56(%rdi)
	vmovsd	%xmm1, 64(%rdi)
	ret
	.cfi_endproc
.LFE13:
	.size	norma_, .-norma_
	.p2align 4
	.globl	eigsrt_
	.type	eigsrt_, @function
eigsrt_:
.LFB14:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movl	$0, %eax
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	movslq	(%rcx), %rbx
	movl	(%rdx), %ecx
	testq	%rbx, %rbx
	cmovs	%rax, %rbx
	movq	%rbx, %rax
	notq	%rax
	movq	%rax, -32(%rsp)
	cmpl	$1, %ecx
	jle	.L252
	leal	1(%rcx), %eax
	movq	%rax, -8(%rsp)
	leal	-1(%rcx), %eax
	movl	%eax, -24(%rsp)
	movl	%ecx, %eax
	shrl	$2, %eax
	movl	%ecx, %edx
	andl	$-4, %edx
	salq	$5, %rax
	movq	%rax, %r15
	leal	1(%rdx), %eax
	movl	%eax, -40(%rsp)
	movl	%ecx, %eax
	salq	$3, %rax
	movq	%rax, -56(%rsp)
	movl	%ecx, %eax
	subl	%edx, %eax
	movl	%edx, -36(%rsp)
	movl	%eax, -44(%rsp)
	leaq	0(,%rbx,8), %r13
	movq	%rsi, %r9
	movq	$-1, %r10
	movl	$1, %r11d
	movl	$2, %r8d
	movq	%rbx, %r14
	movq	%r13, %r12
	.p2align 4,,10
	.p2align 3
.L233:
	vmovsd	-16(%rdi,%r8,8), %xmm2
	movslq	%r11d, %rdx
	cmpl	%r8d, %ecx
	jl	.L234
	movq	%r8, %rax
	vmovsd	%xmm2, %xmm2, %xmm1
	.p2align 4,,10
	.p2align 3
.L237:
	vmovsd	-8(%rdi,%rax,8), %xmm0
	vcomisd	%xmm1, %xmm0
	jb	.L235
	vmovsd	%xmm0, %xmm0, %xmm1
	movslq	%eax, %rdx
.L235:
	incq	%rax
	cmpl	%eax, %ecx
	jge	.L237
	cmpl	%r11d, %edx
	jne	.L254
	.p2align 4,,10
	.p2align 3
.L234:
	incq	%r8
	incq	%r11
	addq	%r12, %r9
	addq	%r14, %r10
	cmpq	%r8, -8(%rsp)
	jne	.L233
	vzeroupper
.L252:
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L254:
	.cfi_restore_state
	leal	-1(%rdx), %eax
	cltq
	imulq	%r14, %rdx
	vmovsd	%xmm2, (%rdi,%rax,8)
	movq	-32(%rsp), %rax
	vmovsd	%xmm1, -16(%rdi,%r8,8)
	addq	%rdx, %rax
	movl	$3, %edx
	subq	%r10, %rdx
	addq	%rax, %rdx
	cmpq	$6, %rdx
	jbe	.L238
	cmpl	$2, -24(%rsp)
	jbe	.L246
	leaq	1(%rax), %rbx
	movq	%rbx, -16(%rsp)
	xorl	%edx, %edx
	leaq	(%rsi,%rbx,8), %rbx
	.p2align 4,,10
	.p2align 3
.L240:
	vmovupd	(%r9,%rdx), %ymm0
	vmovupd	(%rbx,%rdx), %ymm3
	vmovupd	%ymm3, (%r9,%rdx)
	vmovupd	%ymm0, (%rbx,%rdx)
	addq	$32, %rdx
	cmpq	%r15, %rdx
	jne	.L240
	movl	-36(%rsp), %ebx
	cmpl	%ebx, %ecx
	je	.L234
	movl	-44(%rsp), %edx
	cmpl	$1, %edx
	movl	%edx, -20(%rsp)
	movl	-40(%rsp), %edx
	je	.L242
.L239:
	leaq	1(%r10,%rbx), %r13
	addq	-16(%rsp), %rbx
	leaq	(%rsi,%rbx,8), %rbx
	vmovupd	(%rbx), %xmm4
	leaq	(%rsi,%r13,8), %r13
	vmovupd	0(%r13), %xmm0
	vmovupd	%xmm4, 0(%r13)
	movl	-20(%rsp), %r13d
	vmovupd	%xmm0, (%rbx)
	movl	%r13d, %ebx
	andl	$-2, %ebx
	addl	%ebx, %edx
	cmpl	%ebx, %r13d
	je	.L234
.L242:
	movslq	%edx, %rdx
	leaq	(%r10,%rdx), %rbx
	addq	%rax, %rdx
	vmovsd	(%rsi,%rbx,8), %xmm0
	vmovsd	(%rsi,%rdx,8), %xmm1
	vmovsd	%xmm1, (%rsi,%rbx,8)
	vmovsd	%xmm0, (%rsi,%rdx,8)
	jmp	.L234
.L238:
	movq	-56(%rsp), %rbx
	movq	%r9, %rdx
	addq	%r9, %rbx
	subq	%r10, %rax
	.p2align 4,,10
	.p2align 3
.L245:
	vmovsd	(%rdx), %xmm0
	vmovsd	(%rdx,%rax,8), %xmm1
	vmovsd	%xmm1, (%rdx)
	vmovsd	%xmm0, (%rdx,%rax,8)
	addq	$8, %rdx
	cmpq	%rdx, %rbx
	jne	.L245
	jmp	.L234
.L246:
	leaq	1(%rax), %r13
	movl	%ecx, -20(%rsp)
	movq	%r13, -16(%rsp)
	xorl	%ebx, %ebx
	movl	$1, %edx
	jmp	.L239
	.cfi_endproc
.LFE14:
	.size	eigsrt_, .-eigsrt_
	.section	.rodata.str1.1
.LC73:
	.string	"too many iterations in jacobi"
	.text
	.p2align 4
	.globl	jacobi_
	.type	jacobi_, @function
jacobi_:
.LFB15:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%r8, %r11
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	.cfi_offset 15, -24
	movq	%rdi, %r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$8832, %rsp
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	movq	%rcx, 232(%rsp)
	movq	%r9, 128(%rsp)
	movslq	(%rdx), %r14
	movq	%fs:40, %rax
	movq	%rax, 8824(%rsp)
	xorl	%eax, %eax
	movl	$0, %eax
	testq	%r14, %r14
	movl	%r14d, 208(%rsp)
	cmovs	%rax, %r14
	movl	(%rsi), %eax
	movq	%r14, %r13
	movl	%eax, 252(%rsp)
	notq	%r13
	testl	%eax, %eax
	jle	.L403
	leaq	1(%r14), %rbx
	leaq	0(,%rbx,8), %r10
	leal	1(%rax), %r12d
	vmovsd	.LC8(%rip), %xmm0
	leaq	-8(%r8), %r9
	movq	%r12, %rcx
	leaq	-8(%r10), %rsi
	movl	$1, %edi
.L259:
	movq	%r8, %rdx
	movl	$1, %eax
	.p2align 4,,10
	.p2align 3
.L258:
	incl	%eax
	movq	$0x000000000, (%rdx)
	addq	%rsi, %rdx
	cmpl	%ecx, %eax
	jne	.L258
	incq	%rdi
	vmovsd	%xmm0, 8(%r9)
	addq	$8, %r8
	addq	%r10, %r9
	cmpq	%rdi, %r12
	jne	.L259
	movl	252(%rsp), %eax
	cmpl	$1, %eax
	je	.L336
	leaq	800(%rsp), %rdi
	shrl	%eax
	movq	%rdi, 72(%rsp)
	movl	%eax, %ecx
	movq	232(%rsp), %rsi
	salq	$4, %rbx
	movq	%r15, %rdx
	salq	$4, %rcx
	xorl	%eax, %eax
.L261:
	vmovsd	(%rdx), %xmm0
	vmovhpd	(%rdx,%r10), %xmm0, %xmm0
	vmovapd	%xmm0, (%rdi,%rax)
	vmovupd	%xmm0, (%rsi,%rax)
	addq	$16, %rax
	addq	%rbx, %rdx
	cmpq	%rcx, %rax
	jne	.L261
	movl	252(%rsp), %ebx
	movl	%ebx, %eax
	orl	$1, %eax
	andl	$1, %ebx
	je	.L262
.L260:
	movslq	%eax, %rdx
	movq	%r14, %rcx
	imulq	%rdx, %rcx
	addq	%r13, %rdx
	movq	232(%rsp), %rbx
	addq	%rcx, %rdx
	vmovsd	(%r15,%rdx,8), %xmm0
	decl	%eax
	cltq
	vmovsd	%xmm0, 800(%rsp,%rax,8)
	vmovsd	%xmm0, (%rbx,%rax,8)
.L262:
	movl	252(%rsp), %edx
	leaq	4800(%rsp), %rax
	salq	$3, %rdx
	xorl	%esi, %esi
	movq	%rax, %rdi
	movq	%r11, 264(%rsp)
	movq	%rax, 48(%rsp)
	call	memset@PLT
	movq	264(%rsp), %r11
.L263:
	movl	252(%rsp), %edi
	movq	128(%rsp), %rax
	vxorps	%xmm0, %xmm0, %xmm0
	movl	$0, (%rax)
	movl	%edi, %eax
	imull	%edi, %eax
	vmovsd	.LC70(%rip), %xmm10
	movq	232(%rsp), %rsi
	vcvtsi2sdl	%eax, %xmm0, %xmm0
	movq	%r14, %rax
	salq	$5, %rax
	movq	%rax, 112(%rsp)
	movq	%r14, %rax
	salq	$4, %rax
	movq	%rax, 160(%rsp)
	vdivsd	%xmm0, %xmm10, %xmm10
	leal	-1(%rdi), %eax
	movl	%eax, 156(%rsp)
	movl	%edi, %eax
	shrl	$2, %eax
	salq	$5, %rax
	movq	%rax, 120(%rsp)
	movl	%edi, %eax
	andl	$-4, %eax
	movl	%eax, 152(%rsp)
	incl	%eax
	movl	%eax, 108(%rsp)
	movq	%rsi, %rax
	shrq	$3, %rax
	negq	%rax
	movl	%eax, %edx
	andl	$3, %edx
	leal	3(%rdx), %ecx
	movl	$5, %eax
	cmpl	%eax, %ecx
	cmovnb	%ecx, %eax
	movq	72(%rsp), %rcx
	movl	%eax, 60(%rsp)
	movl	%edx, %eax
	salq	$3, %rax
	addq	%rax, %rcx
	movq	%rcx, 24(%rsp)
	movq	48(%rsp), %rcx
	subl	%edx, %edi
	addq	%rax, %rcx
	addq	%rsi, %rax
	movq	%rax, 40(%rsp)
	movl	%edi, %eax
	movl	%edi, 16(%rsp)
	shrl	$2, %eax
	andl	$-4, %edi
	movl	%edx, 56(%rsp)
	salq	$5, %rax
	orl	%edi, %edx
	movq	%rcx, 32(%rsp)
	movq	%rax, 8(%rsp)
	movl	%edi, 20(%rsp)
	movl	%edx, 4(%rsp)
	movl	$1, 220(%rsp)
	movq	%r14, 264(%rsp)
	movq	%r11, 64(%rsp)
	leaq	0(,%r14,8), %rbx
	vmovq	.LC69(%rip), %xmm3
	vmovsd	.LC71(%rip), %xmm4
	vmovsd	.LC72(%rip), %xmm9
	vmovq	.LC11(%rip), %xmm8
	movq	%r13, 256(%rsp)
	vxorpd	%xmm7, %xmm7, %xmm7
	movq	%rbx, %r13
	movq	%r15, %rbx
.L257:
	cmpl	$1, 252(%rsp)
	jle	.L255
	movl	$2, %esi
	vmovsd	%xmm7, %xmm7, %xmm1
	movl	$2, %edx
	movl	$1, %ecx
	.p2align 4,,10
	.p2align 3
.L265:
	movslq	%edx, %rax
	imulq	264(%rsp), %rax
	incl	%edx
	addq	256(%rsp), %rax
	addq	%rcx, %rax
	vmovsd	(%rbx,%rax,8), %xmm0
	vandpd	%xmm3, %xmm0, %xmm0
	vaddsd	%xmm0, %xmm1, %xmm1
	cmpl	%edx, 252(%rsp)
	jge	.L265
	cmpl	252(%rsp), %esi
	jge	.L266
	leal	1(%rsi), %edx
	cmpl	%edx, 252(%rsp)
	jl	.L266
	movslq	%esi, %rcx
	movl	%edx, %esi
	jmp	.L265
.L266:
	vcomisd	%xmm7, %xmm1
	je	.L255
	cmpl	$3, 220(%rsp)
	vmovsd	%xmm7, %xmm7, %xmm5
	jle	.L404
.L272:
	leaq	16(%rbx), %rax
	movq	%rax, 88(%rsp)
	leaq	8(%rbx), %rax
	movq	%rax, 80(%rsp)
	movl	252(%rsp), %eax
	movq	64(%rsp), %r12
	incl	%eax
	movl	%eax, 104(%rsp)
	leaq	16(%r12), %rax
	movl	$1, 212(%rsp)
	movl	$2, 216(%rsp)
	movl	$0, 248(%rsp)
	movq	%rax, 96(%rsp)
	vmovsd	.LC8(%rip), %xmm6
	movl	$2, %edi
	movl	$1, %r14d
	jmp	.L273
	.p2align 4,,10
	.p2align 3
.L406:
	vandpd	%xmm3, %xmm11, %xmm1
	vaddsd	%xmm1, %xmm0, %xmm13
	vcomisd	%xmm1, %xmm13
	jne	.L277
	movq	$0x000000000, (%rbx,%r8,8)
.L280:
	cmpl	%r15d, 252(%rsp)
	jl	.L405
.L275:
	movl	%r15d, %edi
.L273:
	movq	264(%rsp), %rax
	movslq	%edi, %rdx
	imulq	%rdx, %rax
	movq	232(%rsp), %r11
	movslq	248(%rsp), %rcx
	movq	%rax, 224(%rsp)
	addq	256(%rsp), %rax
	leaq	(%rax,%r14), %r8
	vmovsd	(%rbx,%r8,8), %xmm2
	vmovsd	(%r11,%rcx,8), %xmm12
	vandpd	%xmm3, %xmm2, %xmm14
	leal	-1(%rdi), %esi
	leaq	(%r11,%rdx,8), %r9
	cmpl	$4, 220(%rsp)
	vmulsd	%xmm4, %xmm14, %xmm0
	vmovsd	-8(%r9), %xmm11
	movslq	%esi, %r10
	vandpd	%xmm3, %xmm12, %xmm13
	leal	1(%rdi), %r15d
	jle	.L277
	vaddsd	%xmm13, %xmm0, %xmm1
	vcomisd	%xmm13, %xmm1
	je	.L406
.L277:
	vcomisd	%xmm5, %xmm14
	jbe	.L280
	vsubsd	%xmm12, %xmm11, %xmm11
	vandpd	%xmm3, %xmm11, %xmm1
	vaddsd	%xmm1, %xmm0, %xmm0
	vcomisd	%xmm1, %xmm0
	jne	.L396
	vdivsd	%xmm11, %xmm2, %xmm11
	vmovsd	%xmm6, %xmm6, %xmm13
.L284:
	vmovsd	%xmm11, %xmm11, %xmm0
	vfmadd132sd	%xmm11, %xmm13, %xmm0
	vfnmadd231sd	%xmm11, %xmm2, %xmm12
	movq	$0x000000000, (%rbx,%r8,8)
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vdivsd	%xmm0, %xmm13, %xmm0
	vmulsd	%xmm0, %xmm11, %xmm1
	vaddsd	%xmm13, %xmm0, %xmm0
	vmovsd	%xmm2, %xmm2, %xmm13
	vfnmadd213sd	4800(%rsp,%rcx,8), %xmm11, %xmm13
	vdivsd	%xmm0, %xmm1, %xmm0
	vmovsd	%xmm13, 4800(%rsp,%rcx,8)
	vmovsd	%xmm2, %xmm2, %xmm13
	vfmadd213sd	4800(%rsp,%r10,8), %xmm11, %xmm13
	vmovsd	%xmm13, 4800(%rsp,%r10,8)
	movq	232(%rsp), %r10
	vmovsd	%xmm12, (%r10,%rcx,8)
	movq	264(%rsp), %rcx
	vfmadd213sd	-8(%r9), %xmm11, %xmm2
	imulq	%r14, %rcx
	movq	256(%rsp), %r10
	addq	%rcx, %r10
	cmpl	$1, 212(%rsp)
	movq	%rcx, 168(%rsp)
	movq	%r10, 240(%rsp)
	vmovsd	%xmm2, -8(%r9)
	je	.L407
	leaq	3(%r10), %rcx
	movq	%rcx, 192(%rsp)
	subq	%rax, %rcx
	cmpq	$6, %rcx
	jbe	.L290
	movl	212(%rsp), %ecx
	cmpl	$2, %ecx
	je	.L290
	subl	$2, %ecx
	cmpl	$2, %ecx
	jbe	.L291
	leaq	1(%rax), %rcx
	movq	%rcx, 200(%rsp)
	leaq	(%rbx,%rcx,8), %r8
	movl	248(%rsp), %ecx
	leaq	1(%r10), %r9
	shrl	$2, %ecx
	salq	$5, %rcx
	movq	%rcx, %r10
	leaq	(%rbx,%r9,8), %r11
	vbroadcastsd	%xmm0, %ymm13
	vbroadcastsd	%xmm1, %ymm12
	xorl	%ecx, %ecx
	.p2align 4,,10
	.p2align 3
.L293:
	vmovupd	(%r11,%rcx), %ymm2
	vmovupd	(%r8,%rcx), %ymm11
	vmovapd	%ymm2, %ymm14
	vfmadd132pd	%ymm13, %ymm11, %ymm14
	vfnmadd132pd	%ymm12, %ymm2, %ymm14
	vfnmadd231pd	%ymm13, %ymm11, %ymm2
	vmovupd	%ymm14, (%r11,%rcx)
	vfmadd132pd	%ymm12, %ymm11, %ymm2
	vmovupd	%ymm2, (%r8,%rcx)
	addq	$32, %rcx
	cmpq	%rcx, %r10
	jne	.L293
	movl	248(%rsp), %r10d
	movl	%r10d, %r8d
	andl	$-4, %r8d
	leal	1(%r8), %ecx
	cmpl	%r8d, %r10d
	je	.L294
	movl	212(%rsp), %r10d
	subl	%r8d, %r10d
	leal	-1(%r10), %r11d
	cmpl	$2, %r10d
	je	.L296
.L334:
	addq	%r8, %r9
	leaq	(%rbx,%r9,8), %r9
	addq	200(%rsp), %r8
	vmovupd	(%r9), %xmm13
	leaq	(%rbx,%r8,8), %r8
	vmovupd	(%r8), %xmm12
	vmovddup	%xmm0, %xmm2
	vmovapd	%xmm13, %xmm14
	vfmadd132pd	%xmm2, %xmm12, %xmm14
	vfnmadd132pd	%xmm12, %xmm13, %xmm2
	vmovddup	%xmm1, %xmm11
	vfnmadd132pd	%xmm11, %xmm13, %xmm14
	vfmadd132pd	%xmm11, %xmm12, %xmm2
	vmovupd	%xmm14, (%r9)
	vmovupd	%xmm2, (%r8)
	movl	%r11d, %r8d
	andl	$-2, %r8d
	addl	%r8d, %ecx
	cmpl	%r11d, %r8d
	je	.L294
.L296:
	movq	240(%rsp), %r10
	movslq	%ecx, %rcx
	leaq	(%r10,%rcx), %r8
	addq	%rax, %rcx
	vmovsd	(%rbx,%r8,8), %xmm2
	vmovsd	(%rbx,%rcx,8), %xmm11
	vmovsd	%xmm0, %xmm0, %xmm12
	vfmadd132sd	%xmm2, %xmm11, %xmm12
	vfnmadd132sd	%xmm1, %xmm2, %xmm12
	vfnmadd231sd	%xmm11, %xmm0, %xmm2
	vmovsd	%xmm12, (%rbx,%r8,8)
	vfmadd132sd	%xmm1, %xmm11, %xmm2
	vmovsd	%xmm2, (%rbx,%rcx,8)
.L294:
	cmpl	%edi, 216(%rsp)
	jge	.L304
	movslq	216(%rsp), %r10
	movq	264(%rsp), %rcx
	leaq	(%rax,%r10), %r11
	movl	%edi, %r8d
	subl	%r10d, %r8d
	movq	%r11, 200(%rsp)
	salq	$3, %r11
	imulq	%r10, %rcx
	movq	%r11, 176(%rsp)
	movl	%r8d, %r9d
	movq	264(%rsp), %r11
	decq	%r9
	movq	%r10, 136(%rsp)
	movq	256(%rsp), %r10
	imulq	%r9, %r11
	addq	%rcx, %r10
	addq	%r14, %r10
	addq	%r10, %r11
	movq	%rcx, 144(%rsp)
	leaq	0(,%r10,8), %rcx
	movq	%rcx, 184(%rsp)
	leaq	0(,%r11,8), %rcx
	movq	176(%rsp), %r11
	cmpq	%r11, %rcx
	setl	176(%rsp)
	addq	200(%rsp), %r9
	salq	$3, %r9
	cmpq	184(%rsp), %r9
	movzbl	176(%rsp), %ecx
	setl	%r9b
	orb	%r9b, %cl
	je	.L300
	movl	208(%rsp), %r9d
	cmpl	$1, %r8d
	setne	184(%rsp)
	movzbl	184(%rsp), %ecx
	testl	%r9d, %r9d
	setg	%r9b
	testb	%r9b, %cl
	je	.L300
	leal	-1(%r8), %esi
	cmpl	$2, %esi
	jbe	.L338
	movq	%r11, %rcx
	movl	%r8d, %r11d
	movq	160(%rsp), %r9
	leaq	0(,%r10,8), %rsi
	shrl	$2, %r11d
	movq	%rdx, 184(%rsp)
	addq	%rbx, %rsi
	addq	%rbx, %rcx
	salq	$5, %r11
	movq	112(%rsp), %rdx
	vbroadcastsd	%xmm0, %ymm13
	vbroadcastsd	%xmm1, %ymm12
	addq	%rsi, %r9
	addq	%rcx, %r11
	.p2align 4,,10
	.p2align 3
.L303:
	vmovsd	(%r9), %xmm2
	vmovupd	(%rcx), %ymm14
	vmovhpd	(%r9,%r13), %xmm2, %xmm11
	vmovsd	(%rsi), %xmm2
	addq	$32, %rcx
	vmovhpd	(%rsi,%r13), %xmm2, %xmm2
	vinsertf128	$0x1, %xmm11, %ymm2, %ymm2
	vmovapd	%ymm2, %ymm11
	vfmadd132pd	%ymm13, %ymm14, %ymm11
	vfnmadd132pd	%ymm12, %ymm2, %ymm11
	vfnmadd231pd	%ymm13, %ymm14, %ymm2
	vmovlpd	%xmm11, (%rsi)
	vfmadd132pd	%ymm12, %ymm14, %ymm2
	vmovhpd	%xmm11, (%rsi,%r13)
	vextractf128	$0x1, %ymm11, %xmm11
	vmovlpd	%xmm11, (%r9)
	vmovhpd	%xmm11, (%r9,%r13)
	addq	%rdx, %rsi
	vmovupd	%ymm2, -32(%rcx)
	addq	%rdx, %r9
	cmpq	%r11, %rcx
	jne	.L303
	movl	216(%rsp), %ecx
	movl	%r8d, %esi
	andl	$-4, %esi
	movq	184(%rsp), %rdx
	addl	%esi, %ecx
	cmpl	%esi, %r8d
	je	.L304
	subl	%esi, %r8d
	cmpl	$1, %r8d
	je	.L306
.L301:
	movq	264(%rsp), %r9
	vmovddup	%xmm0, %xmm11
	imulq	%rsi, %r9
	addq	200(%rsp), %rsi
	leaq	(%rbx,%rsi,8), %rsi
	addq	%r10, %r9
	leaq	(%rbx,%r9,8), %r9
	vmovsd	(%r9), %xmm14
	vmovupd	(%rsi), %xmm13
	vmovhpd	(%r9,%r13), %xmm14, %xmm14
	vmovapd	%xmm14, %xmm12
	vfmadd132pd	%xmm11, %xmm13, %xmm12
	vfnmadd132pd	%xmm13, %xmm14, %xmm11
	vmovddup	%xmm1, %xmm2
	vfnmadd132pd	%xmm2, %xmm14, %xmm12
	vfmadd132pd	%xmm11, %xmm13, %xmm2
	vmovlpd	%xmm12, (%r9)
	vmovhpd	%xmm12, (%r9,%r13)
	vmovupd	%xmm2, (%rsi)
	movl	%r8d, %esi
	andl	$-2, %esi
	addl	%esi, %ecx
	cmpl	%esi, %r8d
	je	.L304
.L306:
	movq	264(%rsp), %rsi
	movslq	%ecx, %rcx
	imulq	%rcx, %rsi
	addq	%rax, %rcx
	vmovsd	(%rbx,%rcx,8), %xmm11
	addq	256(%rsp), %rsi
	addq	%r14, %rsi
	vmovsd	(%rbx,%rsi,8), %xmm2
	vmovsd	%xmm0, %xmm0, %xmm12
	vfmadd132sd	%xmm2, %xmm11, %xmm12
	vfnmadd132sd	%xmm1, %xmm2, %xmm12
	vfnmadd231sd	%xmm11, %xmm0, %xmm2
	vmovsd	%xmm12, (%rbx,%rsi,8)
	vfmadd132sd	%xmm1, %xmm11, %xmm2
	vmovsd	%xmm2, (%rbx,%rcx,8)
.L304:
	cmpl	%r15d, 252(%rsp)
	jl	.L288
	movl	252(%rsp), %r8d
	movq	264(%rsp), %r11
	movq	224(%rsp), %r9
	subl	%edi, %r8d
	movq	256(%rsp), %rdi
	addq	%r11, %r9
	addq	%r9, %rdi
	leaq	(%r14,%rdi), %r10
	leaq	0(,%r10,8), %rsi
	addq	%rdx, %rdi
	addq	%r11, %r10
	leaq	0(,%rdi,8), %rcx
	salq	$3, %r10
	cmpq	%r10, %rcx
	setg	%r10b
	addq	%r11, %rdi
	salq	$3, %rdi
	cmpq	%rsi, %rdi
	setl	%dil
	orb	%dil, %r10b
	je	.L312
	leal	-1(%r8), %edi
	cmpl	$3, %edi
	movl	208(%rsp), %edi
	seta	%r10b
	testl	%edi, %edi
	setg	%dil
	testb	%dil, %r10b
	je	.L312
	movl	%r8d, %edi
	movq	160(%rsp), %r10
	shrl	%edi
	vmovddup	%xmm0, %xmm13
	vmovddup	%xmm1, %xmm12
	addq	%rbx, %rsi
	addq	%rbx, %rcx
	xorl	%r9d, %r9d
	.p2align 4,,10
	.p2align 3
.L313:
	vmovsd	(%rsi), %xmm2
	vmovsd	(%rcx), %xmm11
	vmovhpd	(%rsi,%r13), %xmm2, %xmm2
	vmovhpd	(%rcx,%r13), %xmm11, %xmm11
	vmovapd	%xmm2, %xmm14
	vfmadd132pd	%xmm13, %xmm11, %xmm14
	incl	%r9d
	vfnmadd132pd	%xmm12, %xmm2, %xmm14
	vfnmadd231pd	%xmm13, %xmm11, %xmm2
	vmovlpd	%xmm14, (%rsi)
	vfmadd132pd	%xmm12, %xmm11, %xmm2
	vmovhpd	%xmm14, (%rsi,%r13)
	addq	%r10, %rsi
	vmovlpd	%xmm2, (%rcx)
	vmovhpd	%xmm2, (%rcx,%r13)
	addq	%r10, %rcx
	cmpl	%r9d, %edi
	jne	.L313
	movl	%r8d, %esi
	andl	$-2, %esi
	leal	(%rsi,%r15), %ecx
	cmpl	%esi, %r8d
	je	.L288
	movslq	%ecx, %rcx
	imulq	264(%rsp), %rcx
	vmovsd	%xmm0, %xmm0, %xmm12
	addq	256(%rsp), %rcx
	leaq	(%r14,%rcx), %rsi
	addq	%rdx, %rcx
	vmovsd	(%rbx,%rsi,8), %xmm2
	vmovsd	(%rbx,%rcx,8), %xmm11
	vfmadd132sd	%xmm2, %xmm11, %xmm12
	vfnmadd132sd	%xmm1, %xmm2, %xmm12
	vfnmadd231sd	%xmm11, %xmm0, %xmm2
	vmovsd	%xmm12, (%rbx,%rsi,8)
	vfmadd132sd	%xmm1, %xmm11, %xmm2
	vmovsd	%xmm2, (%rbx,%rcx,8)
.L288:
	movq	192(%rsp), %rdx
	subq	%rax, %rdx
	cmpq	$6, %rdx
	jbe	.L408
	cmpl	$2, 156(%rsp)
	jbe	.L339
	movq	240(%rsp), %rdi
	leaq	8(%r12,%rax,8), %rcx
	leaq	8(%r12,%rdi,8), %rsi
	movq	120(%rsp), %rdi
	vbroadcastsd	%xmm0, %ymm13
	vbroadcastsd	%xmm1, %ymm12
	xorl	%edx, %edx
	.p2align 4,,10
	.p2align 3
.L324:
	vmovupd	(%rsi,%rdx), %ymm2
	vmovupd	(%rcx,%rdx), %ymm11
	vmovapd	%ymm13, %ymm14
	vfmadd132pd	%ymm2, %ymm11, %ymm14
	vfnmadd132pd	%ymm12, %ymm2, %ymm14
	vfnmadd231pd	%ymm11, %ymm13, %ymm2
	vmovupd	%ymm14, (%rsi,%rdx)
	vfmadd132pd	%ymm12, %ymm11, %ymm2
	vmovupd	%ymm2, (%rcx,%rdx)
	addq	$32, %rdx
	cmpq	%rdi, %rdx
	jne	.L324
	movl	152(%rsp), %edi
	cmpl	%edi, 252(%rsp)
	je	.L320
	movl	108(%rsp), %edx
	movl	%edi, %ecx
.L322:
	movl	252(%rsp), %esi
	subl	%ecx, %esi
	cmpl	$1, %esi
	je	.L318
	movq	240(%rsp), %rdi
	vmovddup	%xmm0, %xmm2
	leaq	1(%rcx,%rdi), %rdi
	leaq	1(%rax,%rcx), %rcx
	leaq	(%r12,%rcx,8), %rcx
	leaq	(%r12,%rdi,8), %rdi
	vmovupd	(%rcx), %xmm14
	vmovupd	(%rdi), %xmm15
	vmovapd	%xmm2, %xmm11
	vfmadd132pd	%xmm15, %xmm14, %xmm11
	vfnmadd132pd	%xmm14, %xmm15, %xmm2
	vmovddup	%xmm1, %xmm13
	vfnmadd132pd	%xmm13, %xmm15, %xmm11
	vfmadd132pd	%xmm13, %xmm14, %xmm2
	vmovupd	%xmm11, (%rdi)
	vmovupd	%xmm2, (%rcx)
	movl	%esi, %ecx
	andl	$-2, %ecx
	addl	%ecx, %edx
	cmpl	%esi, %ecx
	je	.L320
.L318:
	movq	240(%rsp), %rcx
	movslq	%edx, %rdx
	addq	%rdx, %rcx
	addq	%rax, %rdx
	vmovsd	(%r12,%rcx,8), %xmm2
	vmovsd	(%r12,%rdx,8), %xmm11
	vmovsd	%xmm0, %xmm0, %xmm12
	vfmadd132sd	%xmm2, %xmm11, %xmm12
	vfnmadd132sd	%xmm11, %xmm2, %xmm0
	vfnmadd132sd	%xmm1, %xmm2, %xmm12
	vfmadd132sd	%xmm1, %xmm11, %xmm0
	vmovsd	%xmm12, (%r12,%rcx,8)
	vmovsd	%xmm0, (%r12,%rdx,8)
.L320:
	movq	128(%rsp), %rax
	incl	(%rax)
	cmpl	%r15d, 252(%rsp)
	jge	.L275
.L405:
	movl	252(%rsp), %edi
	cmpl	%edi, 216(%rsp)
	jge	.L274
	movl	216(%rsp), %eax
	leal	1(%rax), %r15d
	cmpl	%r15d, 252(%rsp)
	jl	.L274
	movl	%eax, 212(%rsp)
	movslq	%eax, %r14
	decl	%eax
	movl	%r15d, 216(%rsp)
	movl	%eax, 248(%rsp)
	jmp	.L275
	.p2align 4,,10
	.p2align 3
.L396:
	vmulsd	%xmm9, %xmm11, %xmm11
	vmovsd	%xmm6, %xmm6, %xmm13
	vdivsd	%xmm2, %xmm11, %xmm1
	vmovsd	%xmm1, %xmm1, %xmm0
	vfmadd132sd	%xmm1, %xmm6, %xmm0
	vandpd	%xmm3, %xmm1, %xmm11
	vcmpltsd	%xmm7, %xmm1, %xmm1
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vaddsd	%xmm0, %xmm11, %xmm11
	vdivsd	%xmm11, %xmm6, %xmm11
	vmovsd	%xmm11, %xmm11, %xmm0
	vxorpd	%xmm8, %xmm11, %xmm11
	vblendvpd	%xmm1, %xmm11, %xmm0, %xmm11
	jmp	.L284
	.p2align 4,,10
	.p2align 3
.L408:
	movq	240(%rsp), %rdi
	movl	156(%rsp), %edx
	movq	224(%rsp), %rcx
	addq	%rdi, %rdx
	leaq	8(%r12,%rdi,8), %rax
	movq	96(%rsp), %rdi
	subq	168(%rsp), %rcx
	leaq	(%rdi,%rdx,8), %rdx
	.p2align 4,,10
	.p2align 3
.L321:
	vmovsd	(%rax), %xmm2
	vmovsd	(%rax,%rcx,8), %xmm11
	vmovsd	%xmm0, %xmm0, %xmm12
	vfmadd132sd	%xmm2, %xmm11, %xmm12
	vfnmadd132sd	%xmm1, %xmm2, %xmm12
	vfnmadd231sd	%xmm11, %xmm0, %xmm2
	vmovsd	%xmm12, (%rax)
	vfmadd132sd	%xmm1, %xmm11, %xmm2
	vmovsd	%xmm2, (%rax,%rcx,8)
	addq	$8, %rax
	cmpq	%rdx, %rax
	jne	.L321
	jmp	.L320
	.p2align 4,,10
	.p2align 3
.L312:
	movq	256(%rsp), %rdi
	movl	%r15d, %esi
	leaq	(%rdi,%r14), %rcx
	addq	%r9, %rcx
	movl	104(%rsp), %edi
	leaq	(%rbx,%rcx,8), %rcx
	subq	%r14, %rdx
	.p2align 4,,10
	.p2align 3
.L316:
	vmovsd	(%rcx), %xmm2
	vmovsd	(%rcx,%rdx,8), %xmm11
	vmovsd	%xmm0, %xmm0, %xmm12
	vfmadd132sd	%xmm2, %xmm11, %xmm12
	incl	%esi
	vfnmadd132sd	%xmm1, %xmm2, %xmm12
	vfnmadd231sd	%xmm11, %xmm0, %xmm2
	vmovsd	%xmm12, (%rcx)
	vfmadd132sd	%xmm1, %xmm11, %xmm2
	vmovsd	%xmm2, (%rcx,%rdx,8)
	addq	%r13, %rcx
	cmpl	%edi, %esi
	jne	.L316
	jmp	.L288
	.p2align 4,,10
	.p2align 3
.L300:
	movq	256(%rsp), %rcx
	movq	136(%rsp), %r11
	movq	80(%rsp), %r10
	addq	%rax, %r11
	addq	%r14, %rcx
	subl	216(%rsp), %esi
	addq	144(%rsp), %rcx
	addq	%r11, %rsi
	leaq	(%rbx,%rcx,8), %r8
	leaq	(%r10,%rsi,8), %rsi
	leaq	(%rbx,%r11,8), %rcx
	.p2align 4,,10
	.p2align 3
.L309:
	vmovsd	(%r8), %xmm2
	vmovsd	(%rcx), %xmm11
	vmovsd	%xmm0, %xmm0, %xmm12
	vfmadd132sd	%xmm2, %xmm11, %xmm12
	addq	$8, %rcx
	vfnmadd132sd	%xmm1, %xmm2, %xmm12
	vfnmadd231sd	%xmm11, %xmm0, %xmm2
	vmovsd	%xmm12, (%r8)
	vfmadd132sd	%xmm1, %xmm11, %xmm2
	addq	%r13, %r8
	vmovsd	%xmm2, -8(%rcx)
	cmpq	%rsi, %rcx
	jne	.L309
	jmp	.L304
	.p2align 4,,10
	.p2align 3
.L290:
	movl	212(%rsp), %r8d
	movq	240(%rsp), %r10
	subl	$2, %r8d
	addq	%r10, %r8
	leaq	8(%rbx,%r10,8), %rcx
	movq	88(%rsp), %r10
	leaq	(%r10,%r8,8), %r9
	movq	224(%rsp), %r8
	subq	168(%rsp), %r8
	.p2align 4,,10
	.p2align 3
.L299:
	vmovsd	(%rcx), %xmm2
	vmovsd	(%rcx,%r8,8), %xmm11
	vmovsd	%xmm0, %xmm0, %xmm12
	vfmadd132sd	%xmm2, %xmm11, %xmm12
	vfnmadd132sd	%xmm1, %xmm2, %xmm12
	vfnmadd231sd	%xmm11, %xmm0, %xmm2
	vmovsd	%xmm12, (%rcx)
	vfmadd132sd	%xmm1, %xmm11, %xmm2
	vmovsd	%xmm2, (%rcx,%r8,8)
	addq	$8, %rcx
	cmpq	%rcx, %r9
	jne	.L299
	jmp	.L294
	.p2align 4,,10
	.p2align 3
.L407:
	movq	%r10, %rcx
	addq	$3, %rcx
	movq	%rcx, 192(%rsp)
	jmp	.L294
.L339:
	xorl	%ecx, %ecx
	movl	$1, %edx
	jmp	.L322
.L291:
	leaq	1(%r10), %r9
	leaq	1(%rax), %r10
	movq	%r10, 200(%rsp)
	movl	248(%rsp), %r11d
	xorl	%r8d, %r8d
	movl	$1, %ecx
	jmp	.L334
.L338:
	movl	216(%rsp), %ecx
	xorl	%esi, %esi
	jmp	.L301
.L274:
	movl	60(%rsp), %edi
	cmpl	%edi, 156(%rsp)
	jb	.L340
	movl	56(%rsp), %eax
	movl	$1, %esi
	testl	%eax, %eax
	je	.L327
	vmovsd	800(%rsp), %xmm0
	movq	232(%rsp), %rdi
	vaddsd	4800(%rsp), %xmm0, %xmm0
	movl	$2, %esi
	movq	$0x000000000, 4800(%rsp)
	vmovsd	%xmm0, 800(%rsp)
	vmovsd	%xmm0, (%rdi)
	cmpl	$1, %eax
	je	.L327
	vmovsd	808(%rsp), %xmm0
	movl	$3, %esi
	vaddsd	4808(%rsp), %xmm0, %xmm0
	movq	$0x000000000, 4808(%rsp)
	vmovsd	%xmm0, 808(%rsp)
	vmovsd	%xmm0, 8(%rdi)
	cmpl	$2, %eax
	je	.L327
	vmovsd	816(%rsp), %xmm0
	movl	$4, %esi
	vaddsd	4816(%rsp), %xmm0, %xmm0
	movq	$0x000000000, 4816(%rsp)
	vmovsd	%xmm0, 816(%rsp)
	vmovsd	%xmm0, 16(%rdi)
.L327:
	movq	40(%rsp), %rdi
	movq	32(%rsp), %rdx
	movq	24(%rsp), %rcx
	movq	8(%rsp), %r8
	xorl	%eax, %eax
	vxorpd	%xmm1, %xmm1, %xmm1
	.p2align 4,,10
	.p2align 3
.L329:
	vmovupd	(%rdx,%rax), %ymm6
	vaddpd	(%rcx,%rax), %ymm6, %ymm0
	vmovupd	%ymm0, (%rcx,%rax)
	vmovapd	%ymm0, (%rdi,%rax)
	vmovupd	%ymm1, (%rdx,%rax)
	addq	$32, %rax
	cmpq	%r8, %rax
	jne	.L329
	movl	20(%rsp), %eax
	movl	16(%rsp), %edi
	addl	%eax, %esi
	cmpl	%edi, %eax
	je	.L330
	movl	4(%rsp), %eax
.L326:
	movl	252(%rsp), %edi
	subl	%eax, %edi
	cmpl	$1, %edi
	je	.L331
	movq	72(%rsp), %rdx
	salq	$3, %rax
	leaq	(%rdx,%rax), %rcx
	movq	48(%rsp), %rdx
	movl	%edi, %r8d
	addq	%rax, %rdx
	vmovupd	(%rdx), %xmm6
	addq	232(%rsp), %rax
	vaddpd	(%rcx), %xmm6, %xmm0
	shrl	%r8d
	vmovupd	%xmm0, (%rcx)
	vmovupd	%xmm0, (%rax)
	vxorpd	%xmm0, %xmm0, %xmm0
	vmovupd	%xmm0, (%rdx)
	cmpl	$1, %r8d
	je	.L332
	vmovupd	16(%rcx), %xmm6
	vaddpd	16(%rdx), %xmm6, %xmm1
	vmovupd	%xmm1, 16(%rcx)
	vmovupd	%xmm1, 16(%rax)
	vmovupd	%xmm0, 16(%rdx)
	cmpl	$2, %r8d
	je	.L332
	vmovupd	32(%rdx), %xmm6
	vaddpd	32(%rcx), %xmm6, %xmm1
	vmovupd	%xmm1, 32(%rcx)
	vmovupd	%xmm1, 32(%rax)
	vmovupd	%xmm0, 32(%rdx)
.L332:
	movl	%edi, %eax
	andl	$-2, %eax
	addl	%eax, %esi
	cmpl	%edi, %eax
	je	.L330
.L331:
	decl	%esi
	movslq	%esi, %rsi
	vmovsd	4800(%rsp,%rsi,8), %xmm0
	movq	232(%rsp), %rax
	vaddsd	800(%rsp,%rsi,8), %xmm0, %xmm0
	movq	$0x000000000, 4800(%rsp,%rsi,8)
	vmovsd	%xmm0, 800(%rsp,%rsi,8)
	vmovsd	%xmm0, (%rax,%rsi,8)
.L330:
	incl	220(%rsp)
	movl	220(%rsp), %eax
	cmpl	$51, %eax
	jne	.L257
	leaq	.LC2(%rip), %rax
	leaq	272(%rsp), %r12
	movq	%rax, 280(%rsp)
	movq	%r12, %rdi
	movabsq	$25769803904, %rax
	movl	$6154, 288(%rsp)
	movq	%rax, 272(%rsp)
	vzeroupper
	call	_gfortran_st_write@PLT
	movl	$29, %edx
	leaq	.LC73(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
.L340:
	xorl	%eax, %eax
	movl	$1, %esi
	jmp	.L326
.L255:
	movq	8824(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L409
	vzeroupper
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
.L404:
	.cfi_restore_state
	vmulsd	%xmm1, %xmm10, %xmm5
	jmp	.L272
.L336:
	leaq	800(%rsp), %rbx
	movq	%rbx, 72(%rsp)
	movl	$1, %eax
	jmp	.L260
.L403:
	leaq	800(%rsp), %rax
	movq	%rax, 72(%rsp)
	leaq	4800(%rsp), %rax
	movq	%rax, 48(%rsp)
	jmp	.L263
.L409:
	vzeroupper
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE15:
	.size	jacobi_, .-jacobi_
	.section	.rodata
	.align 4
.LC75:
	.long	3
	.text
	.p2align 4
	.globl	kabsch_
	.type	kabsch_, @function
kabsch_:
.LFB11:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	vxorpd	%xmm7, %xmm7, %xmm7
	movq	%rsi, %r11
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	movq	%rsi, %r9
	movl	$10000, %r10d
	pushq	%r14
	pushq	%r13
	pushq	%r12
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	leaq	qk.32(%rip), %r12
	movq	%r12, %r13
	pushq	%rbx
	.cfi_offset 3, -56
	movq	%rdx, %rbx
	andq	$-32, %rsp
	subq	$544, %rsp
	movq	%rdi, 8(%rsp)
	movl	(%rdi), %edi
	vmovsd	.LC8(%rip), %xmm0
	vcvtsi2sdl	%edi, %xmm7, %xmm4
	movq	%rcx, (%rsp)
	movl	%edi, %ecx
	andl	$-4, %ecx
	vdivsd	%xmm4, %xmm0, %xmm4
	movq	%fs:40, %rax
	movq	%rax, 536(%rsp)
	xorl	%eax, %eax
	leal	-1(%rdi), %eax
	movl	%eax, 144(%rsp)
	movl	%edi, %eax
	movl	%ecx, 168(%rsp)
	shrl	$2, %eax
	incl	%ecx
	movl	%ecx, 160(%rsp)
	salq	$5, %rax
	movq	%rdx, %rcx
.L413:
	testl	%edi, %edi
	jle	.L423
	cmpl	$2, 144(%rsp)
	jbe	.L446
	vxorpd	%xmm1, %xmm1, %xmm1
	xorl	%esi, %esi
	vmovapd	%ymm1, %ymm0
	.p2align 4,,10
	.p2align 3
.L415:
	vaddpd	(%rcx,%rsi), %ymm0, %ymm0
	vaddpd	(%r9,%rsi), %ymm1, %ymm1
	addq	$32, %rsi
	cmpq	%rax, %rsi
	jne	.L415
	vextractf128	$0x1, %ymm1, %xmm2
	vextractf128	$0x1, %ymm0, %xmm3
	vaddpd	%xmm1, %xmm2, %xmm2
	vaddpd	%xmm0, %xmm3, %xmm3
	vunpckhpd	%xmm2, %xmm2, %xmm1
	vunpckhpd	%xmm3, %xmm3, %xmm0
	vaddpd	%xmm2, %xmm1, %xmm1
	vaddpd	%xmm3, %xmm0, %xmm0
	cmpl	168(%rsp), %edi
	je	.L416
	movl	160(%rsp), %esi
.L414:
	movslq	%esi, %r8
	leaq	-10001(%r10,%r8), %r8
	vaddsd	(%rbx,%r8,8), %xmm0, %xmm0
	vaddsd	(%r11,%r8,8), %xmm1, %xmm1
	leal	1(%rsi), %r8d
	cmpl	%edi, %r8d
	jg	.L417
	movslq	%r8d, %r8
	leaq	-10001(%r10,%r8), %r8
	addl	$2, %esi
	vaddsd	(%rbx,%r8,8), %xmm0, %xmm0
	vaddsd	(%r11,%r8,8), %xmm1, %xmm1
	cmpl	%esi, %edi
	jl	.L417
	movslq	%esi, %rsi
	leaq	-10001(%r10,%rsi), %rsi
	vaddsd	(%rbx,%rsi,8), %xmm0, %xmm0
	vaddsd	(%r11,%rsi,8), %xmm1, %xmm1
.L417:
	cmpl	$2, 144(%rsp)
	vmulsd	%xmm0, %xmm4, %xmm3
	vmulsd	%xmm1, %xmm4, %xmm2
	jbe	.L452
.L444:
	vbroadcastsd	%xmm2, %ymm5
	vbroadcastsd	%xmm3, %ymm1
	xorl	%esi, %esi
	.p2align 4,,10
	.p2align 3
.L422:
	vmovupd	(%r9,%rsi), %ymm6
	vsubpd	%ymm5, %ymm6, %ymm0
	vmovapd	%ymm0, 0(%r13,%rsi)
	vmovupd	(%rcx,%rsi), %ymm6
	vsubpd	%ymm1, %ymm6, %ymm0
	vmovupd	%ymm0, (%rcx,%rsi)
	addq	$32, %rsi
	cmpq	%rsi, %rax
	jne	.L422
	movl	168(%rsp), %esi
	cmpl	%esi, %edi
	je	.L423
	movl	%esi, %r8d
	movl	160(%rsp), %esi
.L442:
	movl	%edi, %r14d
	subl	%r8d, %r14d
	cmpl	$1, %r14d
	je	.L419
	addq	%r10, %r8
	salq	$3, %r8
	vmovupd	-80000(%r11,%r8), %xmm6
	vmovddup	%xmm2, %xmm0
	vsubpd	%xmm0, %xmm6, %xmm0
	leaq	-80000(%rbx,%r8), %r15
	vmovupd	(%r15), %xmm7
	vmovapd	%xmm0, -80000(%r12,%r8)
	vmovddup	%xmm3, %xmm0
	vsubpd	%xmm0, %xmm7, %xmm0
	movl	%r14d, %r8d
	andl	$-2, %r8d
	vmovupd	%xmm0, (%r15)
	addl	%r8d, %esi
	cmpl	%r8d, %r14d
	je	.L423
.L419:
	movslq	%esi, %rsi
	leaq	-10001(%r10,%rsi), %rsi
	vmovsd	(%rbx,%rsi,8), %xmm0
	vmovsd	(%r11,%rsi,8), %xmm1
	vsubsd	%xmm3, %xmm0, %xmm0
	vsubsd	%xmm2, %xmm1, %xmm1
	vmovsd	%xmm0, (%rbx,%rsi,8)
	vmovsd	%xmm1, (%r12,%rsi,8)
.L423:
	addq	$10000, %r10
	addq	$80000, %rcx
	addq	$80000, %r9
	addq	$80000, %r13
	cmpq	$40000, %r10
	jne	.L413
	vxorps	%xmm5, %xmm5, %xmm5
	vcvtsi2ssl	%edi, %xmm5, %xmm2
	vmovsd	.LC74(%rip), %xmm0
	movl	144(%rsp), %r14d
	leaq	392(%rsp), %r13
	vcvtss2sd	%xmm2, %xmm2, %xmm2
	vdivsd	%xmm2, %xmm0, %xmm2
	movl	$10000, %r11d
.L429:
	movq	%r12, %rcx
	movq	%r13, %r9
	movl	$10000, %r8d
.L428:
	movq	$0x000000000, -8(%r9)
	testl	%edi, %edi
	jle	.L447
	cmpl	$2, %r14d
	jbe	.L448
	xorl	%esi, %esi
	vxorpd	%xmm0, %xmm0, %xmm0
	.p2align 4,,10
	.p2align 3
.L426:
	vmovupd	(%rdx,%rsi), %ymm7
	vfmadd231pd	(%rcx,%rsi), %ymm7, %ymm0
	addq	$32, %rsi
	cmpq	%rsi, %rax
	jne	.L426
	vextractf128	$0x1, %ymm0, %xmm1
	vaddpd	%xmm0, %xmm1, %xmm1
	vunpckhpd	%xmm1, %xmm1, %xmm0
	vaddpd	%xmm1, %xmm0, %xmm0
	cmpl	168(%rsp), %edi
	je	.L427
	movl	160(%rsp), %esi
.L425:
	movslq	%esi, %r10
	leaq	-10001(%r10,%r11), %r15
	vmovsd	(%rbx,%r15,8), %xmm5
	leaq	-10001(%r10,%r8), %r10
	vfmadd231sd	(%r12,%r10,8), %xmm5, %xmm0
	leal	1(%rsi), %r10d
	cmpl	%edi, %r10d
	jg	.L427
	movslq	%r10d, %r10
	leaq	-10001(%r10,%r11), %r15
	vmovsd	(%rbx,%r15,8), %xmm5
	leaq	-10001(%r8,%r10), %r10
	addl	$2, %esi
	vfmadd231sd	(%r12,%r10,8), %xmm5, %xmm0
	cmpl	%esi, %edi
	jl	.L427
	movslq	%esi, %rsi
	leaq	-10001(%r8,%rsi), %r10
	vmovsd	(%r12,%r10,8), %xmm5
	leaq	-10001(%r11,%rsi), %rsi
	vfmadd231sd	(%rbx,%rsi,8), %xmm5, %xmm0
.L427:
	vmulsd	%xmm0, %xmm2, %xmm0
.L424:
	addq	$10000, %r8
	vmovsd	%xmm0, -8(%r9)
	addq	$80000, %rcx
	addq	$24, %r9
	cmpq	$40000, %r8
	jne	.L428
	addq	$10000, %r11
	addq	$8, %r13
	addq	$80000, %rdx
	cmpq	$40000, %r11
	jne	.L429
	vmovapd	384(%rsp), %xmm2
	vmovsd	424(%rsp), %xmm5
	vmovsd	440(%rsp), %xmm3
	vmovsd	400(%rsp), %xmm15
	vmovsd	%xmm5, 160(%rsp)
	vmovddup	%xmm5, %xmm10
	vpermilpd	$1, %xmm2, %xmm5
	vmovhpd	416(%rsp), %xmm5, %xmm5
	vmovddup	%xmm3, %xmm8
	vmovsd	%xmm15, 168(%rsp)
	vmovddup	%xmm15, %xmm13
	vmovddup	416(%rsp), %xmm12
	vmovddup	392(%rsp), %xmm15
	vmulpd	%xmm12, %xmm5, %xmm12
	vmulpd	%xmm5, %xmm15, %xmm15
	vmulpd	%xmm5, %xmm8, %xmm5
	vmovsd	432(%rsp), %xmm1
	vmovhps	408(%rsp), %xmm2, %xmm9
	vmovddup	%xmm1, %xmm7
	vmovapd	400(%rsp), %xmm4
	vfmadd132pd	%xmm9, %xmm5, %xmm7
	vmovddup	408(%rsp), %xmm11
	vmovddup	384(%rsp), %xmm14
	vfmadd231pd	%xmm9, %xmm11, %xmm12
	vfmadd132pd	%xmm9, %xmm15, %xmm14
	vmovsd	448(%rsp), %xmm0
	vunpcklpd	%xmm2, %xmm4, %xmm4
	vmovhps	424(%rsp), %xmm4, %xmm4
	vmovddup	%xmm0, %xmm6
	vfmadd231pd	%xmm4, %xmm13, %xmm14
	vfmadd231pd	%xmm10, %xmm4, %xmm12
	vfmadd132pd	%xmm6, %xmm7, %xmm4
	leaq	224(%rsp), %r14
	leaq	192(%rsp), %r13
	leaq	.LC75(%rip), %rdx
	leaq	464(%rsp), %rdi
	vmovapd	%xmm4, 512(%rsp)
	vmulsd	392(%rsp), %xmm3, %xmm4
	leaq	188(%rsp), %r9
	movq	%r14, %r8
	movq	%r13, %rcx
	movq	%rdx, %rsi
	vfmadd231sd	384(%rsp), %xmm1, %xmm4
	vmovapd	%xmm2, 80(%rsp)
	vmovapd	%xmm14, 464(%rsp)
	vmovupd	%xmm12, 488(%rsp)
	vmovsd	%xmm0, 16(%rsp)
	vfmadd231sd	168(%rsp), %xmm0, %xmm4
	vmovsd	%xmm4, 480(%rsp)
	vmulsd	416(%rsp), %xmm3, %xmm4
	vmulsd	%xmm3, %xmm3, %xmm3
	vfmadd231sd	408(%rsp), %xmm1, %xmm4
	vfmadd132sd	%xmm1, %xmm3, %xmm1
	vfmadd231sd	160(%rsp), %xmm0, %xmm4
	vfmadd231sd	%xmm0, %xmm0, %xmm1
	vmovsd	%xmm4, 504(%rsp)
	vmovsd	%xmm1, 528(%rsp)
	vzeroupper
	call	jacobi_
	leaq	.LC75(%rip), %rcx
	movq	%rcx, %rdx
	movq	%r14, %rsi
	movq	%r13, %rdi
	call	eigsrt_
	vmovsd	224(%rsp), %xmm7
	vmovsd	264(%rsp), %xmm10
	vmovsd	256(%rsp), %xmm6
	vmulsd	%xmm10, %xmm7, %xmm9
	vmovsd	248(%rsp), %xmm8
	vmulsd	240(%rsp), %xmm6, %xmm5
	vmulsd	232(%rsp), %xmm8, %xmm13
	vmovddup	%xmm10, %xmm2
	vfmsub231sd	240(%rsp), %xmm8, %xmm9
	vmovddup	232(%rsp), %xmm4
	vfmsub231sd	232(%rsp), %xmm10, %xmm5
	vfmsub231sd	%xmm6, %xmm7, %xmm13
	vmovapd	%xmm4, 96(%rsp)
	vmovddup	%xmm9, %xmm12
	vmovapd	%xmm12, 112(%rsp)
	vmovupd	408(%rsp), %xmm12
	vmovapd	%xmm2, %xmm15
	vmulpd	%xmm4, %xmm12, %xmm4
	vmovddup	%xmm5, %xmm2
	vmovddup	%xmm8, %xmm3
	vmovapd	%xmm2, 128(%rsp)
	vmovddup	%xmm13, %xmm2
	vmovapd	%xmm3, 144(%rsp)
	vmovapd	%xmm2, %xmm3
	vmovapd	80(%rsp), %xmm2
	vmovddup	%xmm7, %xmm14
	vfmadd231pd	%xmm14, %xmm2, %xmm4
	vmovapd	432(%rsp), %xmm11
	vmovddup	%xmm6, %xmm0
	vmovddup	240(%rsp), %xmm1
	vmovapd	%xmm1, 80(%rsp)
	vfmadd231pd	%xmm1, %xmm11, %xmm4
	vmulpd	%xmm0, %xmm12, %xmm1
	vmulpd	112(%rsp), %xmm12, %xmm12
	vmovsd	%xmm5, 272(%rsp)
	vmovapd	%xmm0, 64(%rsp)
	vmovapd	%xmm4, 304(%rsp)
	vfmadd231pd	144(%rsp), %xmm2, %xmm1
	vfmadd231pd	128(%rsp), %xmm2, %xmm12
	vmovapd	%xmm3, 32(%rsp)
	vmovsd	%xmm9, 280(%rsp)
	vmovsd	%xmm13, 288(%rsp)
	vfmadd231pd	%xmm15, %xmm11, %xmm1
	vfmadd231pd	%xmm3, %xmm11, %xmm12
	vmovsd	160(%rsp), %xmm11
	vmovapd	%xmm15, 48(%rsp)
	vmulsd	232(%rsp), %xmm11, %xmm2
	vmovupd	%xmm1, 328(%rsp)
	vmovapd	%xmm12, 352(%rsp)
	vmovsd	168(%rsp), %xmm15
	vmovsd	16(%rsp), %xmm0
	vfmadd231sd	%xmm15, %xmm7, %xmm2
	vfmadd231sd	240(%rsp), %xmm0, %xmm2
	vmovsd	%xmm2, 320(%rsp)
	vmulsd	%xmm11, %xmm6, %xmm2
	vmovapd	320(%rsp), %xmm3
	vfmadd231sd	%xmm15, %xmm8, %xmm2
	vfmadd132sd	%xmm10, %xmm2, %xmm0
	vmovhps	328(%rsp), %xmm4, %xmm2
	vmovsd	%xmm0, 344(%rsp)
	vpermilpd	$1, %xmm4, %xmm0
	vmovhpd	336(%rsp), %xmm0, %xmm0
	vmulpd	%xmm0, %xmm0, %xmm0
	vunpcklpd	%xmm4, %xmm3, %xmm4
	vmovhps	344(%rsp), %xmm4, %xmm4
	vfmadd231pd	%xmm2, %xmm2, %xmm0
	vfmadd132pd	%xmm4, %xmm0, %xmm4
	vmovapd	.LC68(%rip), %xmm0
	vsqrtpd	%xmm4, %xmm4
	vdivpd	%xmm4, %xmm0, %xmm4
	vmovlpd	312(%rsp), %xmm1, %xmm0
	vpermilpd	$1, 312(%rsp), %xmm1
	vmovhpd	344(%rsp), %xmm1, %xmm1
	vmulpd	%xmm2, %xmm4, %xmm2
	vmulpd	%xmm4, %xmm1, %xmm1
	vmulpd	%xmm4, %xmm0, %xmm0
	vmovsd	%xmm2, %xmm2, %xmm15
	vmovsd	%xmm1, %xmm2, %xmm3
	vunpcklpd	%xmm0, %xmm2, %xmm12
	vmovsd	%xmm0, %xmm0, %xmm11
	vshufpd	$1, %xmm2, %xmm0, %xmm4
	vmovapd	%xmm3, 320(%rsp)
	vunpckhpd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm4, %xmm1, %xmm3
	vmovsd	%xmm1, %xmm1, %xmm4
	vmovapd	%xmm3, 336(%rsp)
	vmulsd	%xmm4, %xmm0, %xmm3
	vunpckhpd	%xmm1, %xmm1, %xmm1
	vunpckhpd	%xmm2, %xmm2, %xmm2
	vmulsd	%xmm8, %xmm1, %xmm8
	vmulsd	%xmm6, %xmm1, %xmm6
	vfmsub231sd	%xmm1, %xmm11, %xmm3
	vmulsd	%xmm10, %xmm1, %xmm10
	vfmadd132sd	%xmm4, %xmm8, %xmm7
	vmovq	%xmm3, %rdx
	vmulsd	%xmm15, %xmm1, %xmm3
	movq	%rdx, 352(%rsp)
	vfmsub231sd	%xmm2, %xmm4, %xmm3
	vmulsd	%xmm2, %xmm11, %xmm2
	vmovsd	%xmm3, 360(%rsp)
	vfmsub132sd	%xmm0, %xmm2, %xmm15
	vmovupd	328(%rsp), %xmm2
	vmovapd	352(%rsp), %xmm11
	vmulpd	144(%rsp), %xmm2, %xmm3
	vmulpd	64(%rsp), %xmm2, %xmm0
	vmulpd	48(%rsp), %xmm2, %xmm2
	vfmadd231sd	%xmm15, %xmm5, %xmm7
	vmovsd	%xmm6, %xmm6, %xmm5
	vfmadd132pd	%xmm12, %xmm3, %xmm14
	vfmadd231pd	96(%rsp), %xmm12, %xmm0
	vfmadd231pd	80(%rsp), %xmm12, %xmm2
	vfmadd231sd	232(%rsp), %xmm4, %xmm5
	vfmadd132sd	240(%rsp), %xmm10, %xmm4
	vmovapd	%xmm14, %xmm3
	vfmadd231pd	128(%rsp), %xmm11, %xmm3
	vfmadd231pd	112(%rsp), %xmm11, %xmm0
	vfmadd132pd	32(%rsp), %xmm2, %xmm11
	vfmadd231sd	%xmm15, %xmm9, %xmm5
	vfmadd132sd	%xmm13, %xmm4, %xmm15
	vmovapd	%xmm3, 16(%rsp)
	vmovapd	%xmm0, 64(%rsp)
	vmovapd	%xmm11, 80(%rsp)
	movq	8(%rsp), %rax
	movl	(%rax), %ecx
	testl	%ecx, %ecx
	jle	.L449
	vunpckhpd	%xmm3, %xmm3, %xmm4
	vmovsd	%xmm3, %xmm3, %xmm8
	vmovsd	%xmm3, 168(%rsp)
	vunpckhpd	%xmm11, %xmm11, %xmm6
	vunpckhpd	%xmm0, %xmm0, %xmm3
	leal	-1(%rcx), %edi
	vmovsd	%xmm0, 160(%rsp)
	vmovsd	%xmm11, 144(%rsp)
	vmovsd	%xmm4, 128(%rsp)
	vmovsd	%xmm3, 112(%rsp)
	vmovsd	%xmm6, 96(%rsp)
	cmpl	$2, %edi
	jbe	.L450
	movl	%ecx, %r10d
	shrl	$2, %r10d
	leaq	160000+qkk.31(%rip), %rax
	salq	$5, %r10
	vbroadcastsd	%xmm8, %ymm9
	vbroadcastsd	%xmm0, %ymm13
	vbroadcastsd	%xmm6, %ymm12
	vbroadcastsd	%xmm11, %ymm11
	vbroadcastsd	%xmm4, %ymm0
	vbroadcastsd	%xmm3, %ymm14
	vbroadcastsd	%xmm7, %ymm10
	vbroadcastsd	%xmm5, %ymm8
	vbroadcastsd	%xmm15, %ymm6
	leaq	160000+qk.32(%rip), %rdx
	addq	%rax, %r10
	.p2align 4,,10
	.p2align 3
.L432:
	vmovapd	-80000(%rdx), %ymm3
	vmovapd	-160000(%rdx), %ymm2
	vmulpd	%ymm3, %ymm13, %ymm4
	vmovapd	(%rdx), %ymm1
	addq	$32, %rax
	addq	$32, %rdx
	vfmadd231pd	%ymm2, %ymm9, %ymm4
	vfmadd231pd	%ymm1, %ymm11, %ymm4
	vmovapd	%ymm4, -160032(%rax)
	vmulpd	%ymm3, %ymm14, %ymm4
	vmulpd	%ymm3, %ymm8, %ymm3
	vfmadd231pd	%ymm2, %ymm0, %ymm4
	vfmadd132pd	%ymm10, %ymm3, %ymm2
	vfmadd231pd	%ymm1, %ymm12, %ymm4
	vfmadd132pd	%ymm6, %ymm2, %ymm1
	vmovapd	%ymm4, -80032(%rax)
	vmovapd	%ymm1, -32(%rax)
	cmpq	%rax, %r10
	jne	.L432
	movl	%ecx, %edx
	andl	$-4, %edx
	leal	1(%rdx), %eax
	cmpl	%ecx, %edx
	je	.L472
.L431:
	movl	%ecx, %r11d
	subl	%edx, %r11d
	cmpl	$1, %r11d
	je	.L473
	leal	20000(%rdx), %r14d
	vmovapd	80(%rsp), %xmm9
	vmovapd	(%r12,%r14,8), %xmm10
	vpermilpd	$3, %xmm9, %xmm4
	vpermilpd	$0, %xmm9, %xmm11
	vmulpd	%xmm10, %xmm11, %xmm11
	vmulpd	%xmm10, %xmm4, %xmm4
	vmovddup	%xmm15, %xmm3
	leal	10000(%rdx), %r10d
	vmovapd	64(%rsp), %xmm0
	vmulpd	%xmm10, %xmm3, %xmm10
	vmovapd	(%r12,%r10,8), %xmm8
	vpermilpd	$3, %xmm0, %xmm14
	vpermilpd	$0, %xmm0, %xmm0
	vfmadd132pd	%xmm8, %xmm11, %xmm0
	vfmadd231pd	%xmm14, %xmm8, %xmm4
	vmovapd	16(%rsp), %xmm6
	vmovddup	%xmm5, %xmm2
	movl	%edx, %r13d
	vfmadd132pd	%xmm2, %xmm10, %xmm8
	vpermilpd	$0, %xmm6, %xmm12
	vpermilpd	$3, %xmm6, %xmm13
	vmovapd	(%r12,%r13,8), %xmm6
	vmovddup	%xmm7, %xmm1
	vfmadd132pd	%xmm6, %xmm0, %xmm12
	vfmadd231pd	%xmm13, %xmm6, %xmm4
	vfmadd132pd	%xmm1, %xmm8, %xmm6
	leaq	qkk.31(%rip), %rdx
	vmovapd	%xmm12, (%rdx,%r13,8)
	vmovapd	%xmm4, (%rdx,%r10,8)
	movl	%r11d, %r10d
	andl	$-2, %r10d
	vmovapd	%xmm6, (%rdx,%r14,8)
	addl	%r10d, %eax
	cmpl	%r10d, %r11d
	je	.L435
.L434:
	leal	9999(%rax), %r10d
	movslq	%r10d, %r10
	vmovsd	(%r12,%r10,8), %xmm6
	leal	-1(%rax), %r11d
	vmulsd	160(%rsp), %xmm6, %xmm0
	movslq	%r11d, %r11
	vmovsd	(%r12,%r11,8), %xmm3
	addl	$19999, %eax
	cltq
	vfmadd231sd	168(%rsp), %xmm3, %xmm0
	vmovsd	(%r12,%rax,8), %xmm1
	vfmadd231sd	144(%rsp), %xmm1, %xmm0
	vmovsd	%xmm0, (%rdx,%r11,8)
	vmulsd	112(%rsp), %xmm6, %xmm0
	vmulsd	%xmm5, %xmm6, %xmm6
	vfmadd231sd	128(%rsp), %xmm3, %xmm0
	vfmadd132sd	%xmm7, %xmm6, %xmm3
	vfmadd231sd	96(%rsp), %xmm1, %xmm0
	vfmadd132sd	%xmm15, %xmm3, %xmm1
	vmovsd	%xmm0, (%rdx,%r10,8)
	vmovsd	%xmm1, (%rdx,%rax,8)
.L435:
	movq	(%rsp), %rax
	movq	$0x000000000, (%rax)
	cmpl	$2, %edi
	jbe	.L451
.L443:
	movl	%ecx, %esi
	shrl	$2, %esi
	salq	$5, %rsi
	leaq	160000+qkk.31(%rip), %rdx
	addq	%rbx, %rsi
	movq	%rbx, %rax
	vxorpd	%xmm1, %xmm1, %xmm1
	.p2align 4,,10
	.p2align 3
.L440:
	vmovupd	80000(%rax), %ymm6
	vmovupd	(%rax), %ymm5
	vsubpd	-80000(%rdx), %ymm6, %ymm3
	vmovupd	160000(%rax), %ymm7
	vsubpd	-160000(%rdx), %ymm5, %ymm2
	vmulpd	%ymm3, %ymm3, %ymm3
	vsubpd	(%rdx), %ymm7, %ymm0
	addq	$32, %rax
	addq	$32, %rdx
	vfmadd132pd	%ymm0, %ymm1, %ymm0
	vfmadd132pd	%ymm2, %ymm3, %ymm2
	vaddpd	%ymm0, %ymm2, %ymm1
	cmpq	%rsi, %rax
	jne	.L440
	vextractf128	$0x1, %ymm1, %xmm0
	vaddpd	%xmm1, %xmm0, %xmm1
	movl	%ecx, %esi
	andl	$-4, %esi
	vunpckhpd	%xmm1, %xmm1, %xmm3
	vaddpd	%xmm1, %xmm3, %xmm1
	leal	1(%rsi), %eax
	leaq	qkk.31(%rip), %rdx
	vmovsd	%xmm1, %xmm1, %xmm3
	cmpl	%esi, %ecx
	je	.L469
.L441:
	movl	%ecx, %r8d
	subl	%esi, %r8d
	cmpl	$1, %r8d
	je	.L437
	movl	%esi, %r9d
	vmovupd	(%rbx,%r9,8), %xmm5
	leal	10000(%rsi), %edi
	vsubpd	(%rdx,%r9,8), %xmm5, %xmm0
	vmovupd	(%rbx,%rdi,8), %xmm5
	addl	$20000, %esi
	vsubpd	(%rdx,%rdi,8), %xmm5, %xmm1
	vmovupd	(%rbx,%rsi,8), %xmm5
	vmulpd	%xmm1, %xmm1, %xmm1
	vfmadd231pd	%xmm0, %xmm0, %xmm1
	vsubpd	(%rdx,%rsi,8), %xmm5, %xmm0
	movl	%r8d, %esi
	andl	$-2, %esi
	addl	%esi, %eax
	vfmadd132pd	%xmm0, %xmm1, %xmm0
	vunpckhpd	%xmm0, %xmm0, %xmm1
	vaddpd	%xmm0, %xmm1, %xmm0
	vaddsd	%xmm0, %xmm3, %xmm3
	cmpl	%r8d, %esi
	je	.L469
.L437:
	movslq	%eax, %rsi
	leaq	(%rbx,%rsi,8), %rsi
	vmovsd	-8(%rsi), %xmm1
	leal	-1(%rax), %edi
	movslq	%edi, %rdi
	vsubsd	(%rdx,%rdi,8), %xmm1, %xmm1
	vmovsd	79992(%rsi), %xmm2
	leal	9999(%rax), %edi
	movslq	%edi, %rdi
	vsubsd	(%rdx,%rdi,8), %xmm2, %xmm2
	vmovsd	159992(%rsi), %xmm0
	addl	$19999, %eax
	vmulsd	%xmm2, %xmm2, %xmm2
	cltq
	vsubsd	(%rdx,%rax,8), %xmm0, %xmm0
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vfmadd132sd	%xmm0, %xmm3, %xmm0
	vaddsd	%xmm0, %xmm1, %xmm3
	vzeroupper
.L430:
	vxorpd	%xmm7, %xmm7, %xmm7
	vcvtsi2sdl	%ecx, %xmm7, %xmm0
	movq	(%rsp), %rax
	vdivsd	%xmm0, %xmm3, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm0, (%rax)
	movq	536(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L474
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L447:
	.cfi_restore_state
	vxorpd	%xmm0, %xmm0, %xmm0
	jmp	.L424
.L448:
	vxorpd	%xmm0, %xmm0, %xmm0
	movl	$1, %esi
	jmp	.L425
.L469:
	vzeroupper
	jmp	.L430
.L416:
	vmulsd	%xmm0, %xmm4, %xmm3
	vmulsd	%xmm1, %xmm4, %xmm2
	jmp	.L444
.L449:
	vxorpd	%xmm3, %xmm3, %xmm3
	jmp	.L430
.L452:
	xorl	%r8d, %r8d
	movl	$1, %esi
	jmp	.L442
.L446:
	vxorpd	%xmm1, %xmm1, %xmm1
	vmovsd	%xmm1, %xmm1, %xmm0
	movl	$1, %esi
	jmp	.L414
.L472:
	movq	(%rsp), %rax
	movq	$0x000000000, (%rax)
	jmp	.L443
.L450:
	xorl	%edx, %edx
	movl	$1, %eax
	jmp	.L431
.L451:
	xorl	%esi, %esi
	vxorpd	%xmm3, %xmm3, %xmm3
	movl	$1, %eax
	jmp	.L441
.L473:
	leaq	qkk.31(%rip), %rdx
	jmp	.L434
.L474:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE11:
	.size	kabsch_, .-kabsch_
	.p2align 4
	.globl	compute_rmsd_
	.type	compute_rmsd_, @function
compute_rmsd_:
.LFB4:
	.cfi_startproc
	pushq	%r13
	.cfi_def_cfa_offset 16
	.cfi_offset 13, -16
	movq	%rdi, %r13
	pushq	%r12
	.cfi_def_cfa_offset 24
	.cfi_offset 12, -24
	subq	$8, %rsp
	.cfi_def_cfa_offset 32
	movslq	8+bas_(%rip), %r12
	testl	%r12d, %r12d
	jle	.L476
	salq	$3, %r12
	movq	%r12, %rdx
	leaq	pos_(%rip), %rsi
	leaq	r.34(%rip), %rdi
	call	memcpy@PLT
	movq	%r12, %rdx
	leaq	80000+pos_(%rip), %rsi
	leaq	80000+r.34(%rip), %rdi
	call	memcpy@PLT
	movq	%r12, %rdx
	leaq	160000+pos_(%rip), %rsi
	leaq	160000+r.34(%rip), %rdi
	call	memcpy@PLT
	movq	%r12, %rdx
	leaq	nat_(%rip), %rsi
	leaq	rn.33(%rip), %rdi
	call	memcpy@PLT
	movq	%r12, %rdx
	leaq	80000+nat_(%rip), %rsi
	leaq	80000+rn.33(%rip), %rdi
	call	memcpy@PLT
	movq	%r12, %rdx
	leaq	160000+nat_(%rip), %rsi
	leaq	160000+rn.33(%rip), %rdi
	call	memcpy@PLT
.L476:
	addq	$8, %rsp
	.cfi_def_cfa_offset 24
	popq	%r12
	.cfi_def_cfa_offset 16
	movq	%r13, %rcx
	leaq	rn.33(%rip), %rdx
	leaq	r.34(%rip), %rsi
	leaq	8+bas_(%rip), %rdi
	popq	%r13
	.cfi_def_cfa_offset 8
	jmp	kabsch_
	.cfi_endproc
.LFE4:
	.size	compute_rmsd_, .-compute_rmsd_
	.p2align 4
	.globl	kmt_
	.type	kmt_, @function
kmt_:
.LFB16:
	.cfi_startproc
	leaq	8(%rsp), %r10
	.cfi_def_cfa 10, 0
	andq	$-32, %rsp
	pushq	-8(%r10)
	pushq	%rbp
	.cfi_escape 0x10,0x6,0x2,0x76,0
	movq	%rsp, %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%r10
	.cfi_escape 0xf,0x3,0x76,0x58,0x6
	.cfi_escape 0x10,0xf,0x2,0x76,0x78
	.cfi_escape 0x10,0xe,0x2,0x76,0x70
	.cfi_escape 0x10,0xd,0x2,0x76,0x68
	.cfi_escape 0x10,0xc,0x2,0x76,0x60
	pushq	%rbx
	subq	$256, %rsp
	.cfi_escape 0x10,0x3,0x2,0x76,0x50
	movq	%rsi, -280(%rbp)
	movq	%rdi, -272(%rbp)
	movl	(%rdx), %r12d
	movq	%fs:40, %rax
	movq	%rax, -56(%rbp)
	xorl	%eax, %eax
	movl	(%rcx), %eax
	subl	%r12d, %eax
	leal	1(%rax), %esi
	movslq	%esi, %rdx
	testq	%rdx, %rdx
	movl	%eax, -192(%rbp)
	movl	$0, %eax
	cmovs	%rax, %rdx
	movl	%esi, -180(%rbp)
	leaq	15(,%rdx,4), %rax
	shrq	$4, %rax
	salq	$4, %rax
	subq	%rax, %rsp
	movq	%rsp, -200(%rbp)
	subq	%rax, %rsp
	leaq	15(,%rdx,8), %rax
	shrq	$4, %rax
	salq	$4, %rax
	movq	%rsp, %r13
	subq	%rax, %rsp
	movq	%rsp, %r9
	subq	%rax, %rsp
	movq	%rsp, %rbx
	subq	%rax, %rsp
	movq	%rsp, %r10
	testl	%esi, %esi
	jle	.L610
	movl	-192(%rbp), %eax
	movslq	%r12d, %rsi
	leaq	8(,%rax,8), %r14
	leaq	-8(,%rsi,8), %r15
	leaq	pos_(%rip), %rax
	movq	%r9, %rdi
	movq	%rsi, -264(%rbp)
	movq	%r14, %rdx
	leaq	(%rax,%r15), %rsi
	movq	%r9, -80(%rbp)
	movq	%r10, -72(%rbp)
	movq	%rax, -256(%rbp)
	call	memcpy@PLT
	movq	-256(%rbp), %rax
	movq	%r14, %rdx
	leaq	80000(%rax,%r15), %rsi
	movq	%rbx, %rdi
	call	memcpy@PLT
	movq	-72(%rbp), %r10
	movq	-256(%rbp), %rax
	movq	%r10, %rdi
	leaq	160000(%rax,%r15), %rsi
	movq	%r14, %rdx
	call	memcpy@PLT
	cmpl	$6, -192(%rbp)
	movq	-72(%rbp), %r10
	movq	-80(%rbp), %r9
	jbe	.L534
	movl	-180(%rbp), %edx
	movq	-200(%rbp), %rsi
	vmovdqa	.LC76(%rip), %ymm1
	shrl	$3, %edx
	vmovd	%r12d, %xmm4
	salq	$5, %rdx
	vmovdqa	.LC77(%rip), %ymm3
	vpbroadcastd	%xmm4, %ymm4
	movq	%rsi, %rax
	addq	%rsi, %rdx
	vmovdqa	%ymm1, %ymm2
	vpcmpeqd	%ymm5, %ymm5, %ymm5
.L482:
	vmovdqa	%ymm2, %ymm0
	vpaddd	%ymm4, %ymm0, %ymm0
	vpaddd	%ymm5, %ymm0, %ymm0
	vmovdqu	%ymm0, (%rax)
	addq	$32, %rax
	vpaddd	%ymm3, %ymm2, %ymm2
	cmpq	%rax, %rdx
	jne	.L482
	movl	-180(%rbp), %esi
	movl	%esi, %edx
	andl	$-8, %edx
	leal	1(%rdx), %eax
	cmpl	%edx, %esi
	je	.L483
.L481:
	movl	-192(%rbp), %esi
	movl	-180(%rbp), %ecx
	subl	%edx, %esi
	subl	%edx, %ecx
	cmpl	$2, %esi
	jbe	.L484
	vmovd	%eax, %xmm0
	vpshufd	$0, %xmm0, %xmm0
	vpaddd	.LC78(%rip), %xmm0, %xmm0
	vmovd	%r12d, %xmm3
	vpshufd	$0, %xmm3, %xmm1
	vpaddd	%xmm1, %xmm0, %xmm0
	movq	-200(%rbp), %rsi
	vpcmpeqd	%xmm1, %xmm1, %xmm1
	vpaddd	%xmm1, %xmm0, %xmm0
	vmovdqu	%xmm0, (%rsi,%rdx,4)
	movl	%ecx, %edx
	andl	$-4, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L485
.L484:
	movq	-200(%rbp), %rdi
	leal	-1(%rax), %edx
	movl	-192(%rbp), %r8d
	movslq	%edx, %rdx
	leal	-1(%r12,%rax), %ecx
	movl	%ecx, (%rdi,%rdx,4)
	leal	1(%rax), %edx
	cmpl	%eax, %r8d
	jl	.L485
	movslq	%eax, %rcx
	leal	-1(%r12,%rdx), %esi
	movl	%esi, (%rdi,%rcx,4)
	addl	$2, %eax
	cmpl	%edx, %r8d
	jl	.L485
	movslq	%edx, %rdx
	leal	-1(%r12,%rax), %eax
	movl	%eax, (%rdi,%rdx,4)
.L485:
	cmpl	$6, -192(%rbp)
	jbe	.L535
	vmovd	%r12d, %xmm4
	vmovdqa	.LC76(%rip), %ymm1
	vmovdqa	.LC77(%rip), %ymm3
	vpbroadcastd	%xmm4, %ymm4
.L483:
	movl	-180(%rbp), %edx
	movq	%r13, %rax
	shrl	$3, %edx
	salq	$5, %rdx
	addq	%r13, %rdx
	vpcmpeqd	%ymm2, %ymm2, %ymm2
.L488:
	vmovdqa	%ymm1, %ymm0
	vpaddd	%ymm4, %ymm0, %ymm0
	vpaddd	%ymm2, %ymm0, %ymm0
	vmovdqu	%ymm0, (%rax)
	addq	$32, %rax
	vpaddd	%ymm3, %ymm1, %ymm1
	cmpq	%rax, %rdx
	jne	.L488
	movl	-180(%rbp), %esi
	movl	%esi, %edx
	andl	$-8, %edx
	leal	1(%rdx), %eax
	cmpl	%esi, %edx
	je	.L597
.L486:
	movl	-192(%rbp), %esi
	movl	-180(%rbp), %ecx
	subl	%edx, %esi
	subl	%edx, %ecx
	cmpl	$2, %esi
	jbe	.L491
	vmovd	%eax, %xmm0
	vpshufd	$0, %xmm0, %xmm0
	vpaddd	.LC78(%rip), %xmm0, %xmm0
	vmovd	%r12d, %xmm3
	vpshufd	$0, %xmm3, %xmm1
	vpaddd	%xmm1, %xmm0, %xmm0
	vpcmpeqd	%xmm1, %xmm1, %xmm1
	vpaddd	%xmm1, %xmm0, %xmm0
	vmovdqu	%xmm0, 0(%r13,%rdx,4)
	movl	%ecx, %edx
	andl	$-4, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L597
.L491:
	leal	-1(%rax), %edx
	movl	-192(%rbp), %edi
	movslq	%edx, %rdx
	leal	-1(%r12,%rax), %ecx
	movl	%ecx, 0(%r13,%rdx,4)
	leal	1(%rax), %edx
	cmpl	%eax, %edi
	jl	.L597
	movslq	%eax, %rcx
	leal	-1(%r12,%rdx), %esi
	movl	%esi, 0(%r13,%rcx,4)
	addl	$2, %eax
	cmpl	%edx, %edi
	jl	.L597
	movslq	%edx, %rdx
	leal	-1(%r12,%rax), %eax
	movl	%eax, 0(%r13,%rdx,4)
	vzeroupper
	jmp	.L489
.L597:
	vzeroupper
.L489:
	movq	-264(%rbp), %rcx
	movq	-256(%rbp), %rsi
	leaq	0(,%rcx,8), %rax
	leaq	(%rsi,%rax), %rdi
	leaq	-8(%rsi,%rcx,8), %rcx
	movq	%rdi, -232(%rbp)
	leaq	80000(%rsi,%rax), %rdi
	movq	%rdi, -240(%rbp)
	movq	%rcx, -208(%rbp)
	leaq	160000(%rsi,%rax), %rdi
	leaq	79992(%rsi,%rax), %rcx
	movl	-180(%rbp), %r11d
	leaq	159992(%rsi,%rax), %rax
	movq	%rdi, -248(%rbp)
	movq	%rcx, -216(%rbp)
	movl	$0, -164(%rbp)
	movl	$0, -188(%rbp)
	movl	$0, -184(%rbp)
	movl	$0, -168(%rbp)
	movl	$0, -172(%rbp)
	movl	$0, -176(%rbp)
	movq	%rax, -224(%rbp)
	movl	$2, %eax
	movq	%rbx, %r13
	movq	%r10, %r12
	movl	%eax, %ebx
	movq	%r9, %r10
	movl	%r11d, %r9d
	.p2align 4,,10
	.p2align 3
.L480:
	cmpl	$1, %r9d
	jle	.L518
.L493:
	leal	-2(%rbx), %eax
	cmpl	$1, %eax
	jle	.L536
	cmpl	%eax, %r9d
	cmovle	%r9d, %eax
	movslq	%ebx, %rcx
	salq	$3, %rcx
	leaq	(%r10,%rcx), %r8
	movl	%eax, %r11d
	movq	%r10, %rdi
	movq	%r13, %rax
	leaq	0(%r13,%rcx), %rsi
	movl	%ebx, %r10d
	movl	%r9d, %r13d
	movl	$1, %edx
	movq	%r8, %r9
	addq	%r12, %rcx
	movl	%r11d, %r8d
	movq	%rdi, %rbx
	movq	%rax, %r11
.L496:
	movq	(%rsi), %rax
	vmovsd	-16(%r9), %xmm0
	vmovsd	-16(%rsi), %xmm1
	vmovsd	-8(%r9), %xmm4
	vmovq	%rax, %xmm3
	vsubsd	%xmm0, %xmm4, %xmm2
	vmovsd	-8(%rsi), %xmm7
	vmovsd	(%rcx), %xmm5
	vsubsd	%xmm1, %xmm3, %xmm3
	movq	-8(%r12,%rdx,8), %r14
	vmovsd	(%r9), %xmm15
	vsubsd	%xmm1, %xmm7, %xmm13
	movq	-8(%r11,%rdx,8), %rdi
	vmovsd	%xmm7, -128(%rbp)
	vmovsd	%xmm5, -136(%rbp)
	vmovsd	%xmm5, %xmm5, %xmm7
	vmovsd	-16(%rcx), %xmm5
	vmulsd	%xmm2, %xmm3, %xmm12
	vmovsd	%xmm2, -96(%rbp)
	vmovq	%r14, %xmm2
	vsubsd	%xmm5, %xmm2, %xmm10
	vsubsd	%xmm15, %xmm0, %xmm9
	vmovq	%rdi, %xmm2
	vsubsd	%xmm1, %xmm2, %xmm14
	vmovsd	-8(%rcx), %xmm2
	vsubsd	%xmm0, %xmm15, %xmm8
	vsubsd	%xmm5, %xmm2, %xmm2
	vmovsd	-8(%rbx,%rdx,8), %xmm6
	vmovsd	%xmm9, -72(%rbp)
	vmulsd	%xmm9, %xmm10, %xmm9
	vsubsd	%xmm5, %xmm7, %xmm7
	vsubsd	%xmm0, %xmm6, %xmm11
	vmulsd	%xmm2, %xmm8, %xmm8
	vmulsd	%xmm2, %xmm3, %xmm3
	vfmadd132sd	%xmm7, %xmm9, %xmm11
	vmovsd	%xmm4, -120(%rbp)
	vsubsd	%xmm6, %xmm0, %xmm9
	vsubsd	%xmm4, %xmm0, %xmm4
	vmovsd	%xmm15, -88(%rbp)
	vmulsd	%xmm3, %xmm9, %xmm9
	vmovsd	%xmm4, -104(%rbp)
	vfmadd132sd	%xmm7, %xmm8, %xmm4
	vmovsd	(%r11,%rdx,8), %xmm15
	vmovsd	%xmm8, -112(%rbp)
	vfmadd231sd	%xmm13, %xmm11, %xmm9
	vmulsd	%xmm4, %xmm14, %xmm11
	vfmadd231sd	%xmm10, %xmm12, %xmm11
	vmovsd	(%r12,%rdx,8), %xmm10
	vsubsd	%xmm5, %xmm10, %xmm10
	vaddsd	%xmm9, %xmm11, %xmm14
	vmovsd	(%rbx,%rdx,8), %xmm11
	vsubsd	%xmm0, %xmm11, %xmm9
	vmovsd	%xmm14, -80(%rbp)
	vsubsd	%xmm1, %xmm15, %xmm14
	vmovq	%xmm9, %r15
	vmulsd	-72(%rbp), %xmm10, %xmm9
	vmovq	%r15, %xmm8
	vmulsd	%xmm4, %xmm14, %xmm14
	vxorpd	%xmm4, %xmm4, %xmm4
	vfmadd231sd	%xmm7, %xmm8, %xmm9
	vsubsd	%xmm11, %xmm0, %xmm8
	vfmadd231sd	%xmm10, %xmm12, %xmm14
	vmulsd	%xmm3, %xmm8, %xmm8
	vfmadd132sd	%xmm13, %xmm8, %xmm9
	vaddsd	%xmm14, %xmm9, %xmm9
	vmulsd	-80(%rbp), %xmm9, %xmm9
	vcomisd	%xmm4, %xmm9
	jbe	.L587
.L606:
	leal	1(%rdx), %eax
	incq	%rdx
	cmpl	%edx, %r8d
	jg	.L496
	movq	%rbx, %rsi
	movl	%r13d, %r9d
	movl	%r10d, %ebx
	movq	%r11, %r13
	movq	%rsi, %r10
	cmpl	%eax, %r9d
	jle	.L512
.L601:
	xorl	%edi, %edi
.L495:
	movslq	%ebx, %rdx
	salq	$3, %rdx
	leaq	0(%r13,%rdx), %r15
	leal	1(%rbx), %r14d
	leaq	(%r10,%rdx), %r11
	addq	%r12, %rdx
	movq	%rdx, %rcx
	cltq
	movl	%r9d, %edx
	movq	%r10, %r9
	movq	%r15, %r10
	movl	%r14d, %r15d
	movq	%r12, %r14
	movl	%edi, %r12d
	movq	%r13, %rdi
.L517:
	cmpl	%eax, %r15d
	jl	.L611
.L507:
	incq	%rax
	cmpl	%eax, %edx
	jg	.L517
	movq	%r9, %r10
	movq	%rdi, %r13
	movl	%edx, %r9d
	movl	%r12d, %edi
	movq	%r14, %r12
.L516:
	testl	%edi, %edi
	je	.L512
	leal	1(%rbx), %r14d
.L509:
	movl	%r14d, %ebx
.L494:
	cmpl	%r9d, %ebx
	jl	.L480
	jne	.L520
	movl	-164(%rbp), %r8d
	testl	%r8d, %r8d
	jle	.L520
	cmpl	$2, %r9d
	je	.L521
.L545:
	movl	$0, -164(%rbp)
	movl	$2, %ebx
	cmpl	$1, %r9d
	jg	.L493
	.p2align 4,,10
	.p2align 3
.L518:
	movslq	%r9d, %rax
	decq	%rax
	incl	-164(%rbp)
	movq	$0x000000000, (%r10,%rax,8)
	movq	$0x000000000, 0(%r13,%rax,8)
	movq	$0x000000000, (%r12,%rax,8)
	decl	%r9d
	jmp	.L494
	.p2align 4,,10
	.p2align 3
.L611:
	cmpl	$1, %r12d
	je	.L612
	movl	%r15d, %esi
	movl	%r12d, %r13d
	movq	%r9, %r15
	movq	%rdi, %r9
.L508:
	vmovsd	-16(%r10), %xmm4
	vmovsd	-8(%r10), %xmm6
	vmovsd	-16(%r11), %xmm0
	vmovsd	-8(%r11), %xmm15
	vsubsd	%xmm4, %xmm6, %xmm9
	leal	-1(%rax), %edi
	vmovsd	%xmm6, -144(%rbp)
	vmovsd	(%r10), %xmm6
	movslq	%edi, %rdi
	vsubsd	%xmm0, %xmm15, %xmm5
	movq	(%r14,%rdi,8), %r12
	vmovsd	%xmm6, -104(%rbp)
	vsubsd	%xmm4, %xmm6, %xmm6
	vmovsd	-16(%rcx), %xmm7
	vmovsd	(%r15,%rdi,8), %xmm8
	vmovsd	(%r11), %xmm2
	movq	(%r9,%rdi,8), %rdi
	vmovsd	(%rcx), %xmm3
	vmovq	%r12, %xmm1
	vmulsd	%xmm5, %xmm6, %xmm14
	vsubsd	%xmm7, %xmm1, %xmm11
	vmovsd	%xmm5, -120(%rbp)
	vsubsd	%xmm0, %xmm2, %xmm1
	vmovq	%rdi, %xmm5
	vmovsd	%xmm2, -96(%rbp)
	vsubsd	%xmm2, %xmm0, %xmm2
	vsubsd	%xmm7, %xmm3, %xmm13
	vmovsd	%xmm3, -136(%rbp)
	vsubsd	%xmm4, %xmm5, %xmm3
	vmovsd	-8(%rcx), %xmm5
	vmovsd	%xmm2, -72(%rbp)
	vsubsd	%xmm7, %xmm5, %xmm5
	vmulsd	%xmm2, %xmm11, %xmm2
	vsubsd	%xmm0, %xmm8, %xmm10
	vmulsd	%xmm6, %xmm5, %xmm6
	vmulsd	%xmm5, %xmm1, %xmm1
	vsubsd	%xmm15, %xmm0, %xmm12
	vfmadd132sd	%xmm13, %xmm2, %xmm10
	vsubsd	%xmm8, %xmm0, %xmm2
	vmovsd	%xmm15, -128(%rbp)
	vmovsd	%xmm12, -88(%rbp)
	vmulsd	%xmm6, %xmm2, %xmm2
	vmovsd	%xmm1, -112(%rbp)
	vfmadd132sd	%xmm9, %xmm2, %xmm10
	vmovsd	%xmm1, %xmm1, %xmm2
	vfmadd231sd	%xmm12, %xmm13, %xmm2
	vmulsd	%xmm3, %xmm2, %xmm3
	vfmadd231sd	%xmm14, %xmm11, %xmm3
	vmovsd	(%r14,%rax,8), %xmm11
	vsubsd	%xmm7, %xmm11, %xmm11
	vaddsd	%xmm3, %xmm10, %xmm3
	vmovsd	(%r15,%rax,8), %xmm10
	vsubsd	%xmm0, %xmm10, %xmm15
	vmovsd	%xmm3, %xmm3, %xmm12
	vmovsd	%xmm3, -160(%rbp)
	vmovsd	(%r9,%rax,8), %xmm3
	vmovq	%xmm15, %r8
	vmulsd	-72(%rbp), %xmm11, %xmm15
	vsubsd	%xmm4, %xmm3, %xmm1
	vmovsd	%xmm1, -80(%rbp)
	vmovq	%r8, %xmm1
	vfmadd231sd	%xmm1, %xmm13, %xmm15
	vsubsd	%xmm10, %xmm0, %xmm1
	vmulsd	-80(%rbp), %xmm2, %xmm2
	vmovsd	%xmm1, -152(%rbp)
	vmulsd	%xmm1, %xmm6, %xmm1
	vfmadd231sd	%xmm11, %xmm14, %xmm2
	vfmadd132sd	%xmm9, %xmm1, %xmm15
	vxorpd	%xmm1, %xmm1, %xmm1
	vaddsd	%xmm15, %xmm2, %xmm15
	vmulsd	%xmm12, %xmm15, %xmm15
	vcomisd	%xmm1, %xmm15
	jbe	.L589
.L609:
	incq	%rax
	cmpl	%eax, %edx
	jle	.L594
	cmpl	%eax, %esi
	jl	.L508
	movq	%r9, %rdi
	movl	%r13d, %r12d
	movq	%r15, %r9
	movl	%esi, %r15d
	jmp	.L507
	.p2align 4,,10
	.p2align 3
.L612:
	incq	%rax
	cmpl	%eax, %edx
	jg	.L507
	movq	%r9, %r10
	movq	%r14, %r12
	movl	%edx, %r9d
	movq	%rdi, %r13
	movl	%r15d, %r14d
	jmp	.L509
	.p2align 4,,10
	.p2align 3
.L587:
	vmovsd	-72(%rbp), %xmm8
	vmovq	%rdi, %xmm4
	vfmadd132sd	%xmm13, %xmm12, %xmm8
	vsubsd	%xmm4, %xmm15, %xmm15
	vmovq	%r14, %xmm9
	vsubsd	%xmm9, %xmm10, %xmm10
	vsubsd	%xmm6, %xmm11, %xmm14
	vmovq	%xmm8, %r15
	vaddsd	%xmm6, %xmm0, %xmm8
	vsubsd	%xmm1, %xmm15, %xmm9
	vsubsd	%xmm0, %xmm14, %xmm4
	vsubsd	%xmm11, %xmm8, %xmm8
	vmovq	%r15, %xmm11
	vmulsd	-72(%rbp), %xmm2, %xmm2
	vmulsd	%xmm3, %xmm8, %xmm8
	vmulsd	%xmm0, %xmm3, %xmm3
	vmulsd	%xmm1, %xmm2, %xmm2
	vfmadd132sd	%xmm11, %xmm8, %xmm10
	vmovsd	-104(%rbp), %xmm11
	vmulsd	%xmm11, %xmm9, %xmm8
	vfmadd231sd	%xmm13, %xmm4, %xmm8
	vmovsd	%xmm8, %xmm8, %xmm4
	vfmadd132sd	%xmm7, %xmm10, %xmm4
	vmovsd	-128(%rbp), %xmm8
	vsubsd	%xmm8, %xmm1, %xmm10
	vmovq	%xmm4, %r14
	vsubsd	-136(%rbp), %xmm5, %xmm4
	vmulsd	%xmm7, %xmm10, %xmm7
	vmulsd	-72(%rbp), %xmm10, %xmm10
	vmulsd	%xmm11, %xmm4, %xmm4
	vfmadd132sd	%xmm0, %xmm2, %xmm7
	vfmadd132sd	%xmm5, %xmm3, %xmm10
	vmulsd	%xmm1, %xmm4, %xmm4
	vmovq	%r14, %xmm3
	vaddsd	%xmm7, %xmm10, %xmm10
	vfmsub231sd	%xmm5, %xmm12, %xmm4
	vmovsd	-80(%rbp), %xmm7
	vfmadd231sd	-112(%rbp), %xmm9, %xmm4
	vsubsd	%xmm10, %xmm4, %xmm10
	vmovq	%rdi, %xmm4
	vaddsd	%xmm3, %xmm10, %xmm10
	vmovsd	-88(%rbp), %xmm3
	vdivsd	%xmm10, %xmm7, %xmm10
	vmovsd	-120(%rbp), %xmm7
	vfmsub231sd	%xmm10, %xmm15, %xmm4
	vfnmadd132sd	%xmm10, %xmm6, %xmm14
	vmovq	%rax, %xmm6
	vsubsd	%xmm8, %xmm6, %xmm6
	vaddsd	%xmm1, %xmm4, %xmm2
	vsubsd	%xmm0, %xmm14, %xmm0
	vsubsd	%xmm7, %xmm14, %xmm5
	vmulsd	-96(%rbp), %xmm2, %xmm2
	vfmadd132sd	%xmm13, %xmm2, %xmm0
	vsubsd	%xmm7, %xmm3, %xmm2
	vaddsd	%xmm8, %xmm4, %xmm3
	vmulsd	%xmm3, %xmm2, %xmm2
	vfmadd231sd	%xmm6, %xmm5, %xmm2
	vxorpd	%xmm6, %xmm6, %xmm6
	vmulsd	%xmm2, %xmm0, %xmm0
	vcomisd	%xmm0, %xmm6
	jnb	.L606
	vmovq	%rax, %xmm0
	vsubsd	%xmm0, %xmm1, %xmm1
	vsubsd	-88(%rbp), %xmm14, %xmm14
	vaddsd	%xmm4, %xmm0, %xmm4
	vxorpd	%xmm0, %xmm0, %xmm0
	vmulsd	%xmm14, %xmm1, %xmm1
	xorl	%edi, %edi
	leal	1(%rdx), %eax
	vfmadd231sd	-72(%rbp), %xmm4, %xmm1
	vmulsd	%xmm2, %xmm1, %xmm1
	vcomisd	%xmm0, %xmm1
	seta	%dil
	incq	%rdx
	cmpl	%edx, %r8d
	jle	.L613
	vcomisd	%xmm1, %xmm0
	jnb	.L496
	movq	%rbx, %rax
	movl	%r13d, %r9d
	movl	%r10d, %ebx
	movq	%r11, %r13
	movq	%rax, %r10
	movl	%r8d, %r11d
	.p2align 4,,10
	.p2align 3
.L499:
	leaq	1(%rdx), %rcx
	leal	1(%rdx), %eax
	cmpl	%ecx, %r11d
	jle	.L537
	addq	$2, %rdx
	leal	1(%rcx), %eax
	cmpl	%edx, %r11d
	jg	.L499
.L537:
	movl	$1, %edi
.L498:
	cmpl	%eax, %r9d
	jg	.L495
	jmp	.L516
	.p2align 4,,10
	.p2align 3
.L589:
	vmovq	%rdi, %xmm1
	vsubsd	%xmm1, %xmm3, %xmm3
	vmovq	%r12, %xmm1
	vsubsd	%xmm1, %xmm11, %xmm11
	vmovsd	-72(%rbp), %xmm1
	vsubsd	%xmm8, %xmm10, %xmm15
	vfmadd132sd	%xmm9, %xmm14, %xmm1
	vsubsd	%xmm4, %xmm3, %xmm10
	vsubsd	%xmm0, %xmm15, %xmm2
	vmovq	%xmm1, %r12
	vaddsd	-152(%rbp), %xmm8, %xmm1
	vmulsd	%xmm6, %xmm1, %xmm1
	vmulsd	%xmm0, %xmm6, %xmm6
	vmovq	%xmm1, %r8
	vmovq	%r8, %xmm12
	vmovq	%r12, %xmm1
	vfmadd132sd	%xmm1, %xmm12, %xmm11
	vmulsd	-88(%rbp), %xmm10, %xmm1
	vmovsd	-144(%rbp), %xmm12
	vfmadd132sd	%xmm9, %xmm1, %xmm2
	vmovsd	-72(%rbp), %xmm1
	vmulsd	%xmm1, %xmm5, %xmm5
	vfmadd231sd	%xmm2, %xmm13, %xmm11
	vsubsd	%xmm12, %xmm4, %xmm2
	vmulsd	%xmm4, %xmm5, %xmm5
	vmulsd	%xmm2, %xmm13, %xmm13
	vmulsd	%xmm1, %xmm2, %xmm2
	vfmadd132sd	%xmm0, %xmm5, %xmm13
	vsubsd	-136(%rbp), %xmm7, %xmm5
	vfmadd132sd	%xmm7, %xmm6, %xmm2
	vmovsd	-112(%rbp), %xmm6
	vmulsd	-88(%rbp), %xmm5, %xmm5
	vaddsd	%xmm13, %xmm2, %xmm13
	vmovsd	-96(%rbp), %xmm2
	vmulsd	%xmm4, %xmm5, %xmm5
	vfmsub231sd	%xmm7, %xmm14, %xmm5
	vxorpd	%xmm7, %xmm7, %xmm7
	vfmadd132sd	%xmm10, %xmm5, %xmm6
	vmovsd	-128(%rbp), %xmm5
	vsubsd	%xmm5, %xmm2, %xmm2
	vsubsd	%xmm13, %xmm6, %xmm13
	vmovsd	-160(%rbp), %xmm6
	vaddsd	%xmm11, %xmm13, %xmm11
	vdivsd	%xmm11, %xmm6, %xmm11
	vmovq	%rdi, %xmm6
	vfmsub132sd	%xmm11, %xmm6, %xmm3
	vfnmadd132sd	%xmm11, %xmm8, %xmm15
	vmovsd	-104(%rbp), %xmm6
	vsubsd	%xmm12, %xmm6, %xmm6
	vaddsd	%xmm3, %xmm4, %xmm1
	vsubsd	%xmm0, %xmm15, %xmm0
	vmulsd	-120(%rbp), %xmm1, %xmm1
	vfmadd132sd	%xmm9, %xmm1, %xmm0
	vsubsd	%xmm5, %xmm15, %xmm1
	vaddsd	%xmm12, %xmm3, %xmm5
	vmulsd	%xmm5, %xmm2, %xmm2
	vfmadd132sd	%xmm6, %xmm2, %xmm1
	vmulsd	%xmm1, %xmm0, %xmm0
	vcomisd	%xmm0, %xmm7
	jnb	.L609
	vmovsd	-104(%rbp), %xmm0
	vsubsd	-96(%rbp), %xmm15, %xmm15
	vsubsd	%xmm0, %xmm4, %xmm4
	vaddsd	%xmm0, %xmm3, %xmm3
	vxorpd	%xmm0, %xmm0, %xmm0
	vmulsd	%xmm15, %xmm4, %xmm4
	xorl	%r12d, %r12d
	movq	%r9, %rdi
	movq	%r15, %r9
	movl	%esi, %r15d
	vfmadd231sd	-72(%rbp), %xmm3, %xmm4
	vmulsd	%xmm4, %xmm1, %xmm1
	vcomisd	%xmm0, %xmm1
	seta	%r12b
	jmp	.L507
	.p2align 4,,10
	.p2align 3
.L536:
	movl	$1, %eax
	jmp	.L601
	.p2align 4,,10
	.p2align 3
.L594:
	movq	%r9, %r13
	movq	%r15, %r10
	movl	%edx, %r9d
	movq	%r14, %r12
.L512:
	cmpl	%r9d, %ebx
	jge	.L518
	movl	%r9d, %eax
	subl	%ebx, %eax
	decl	%eax
	leaq	1(%rax), %rcx
	leal	-1(%rbx), %eax
	movslq	%eax, %r8
	leaq	0(,%r8,8), %r14
	leaq	0(,%rcx,8), %r15
	leaq	8(%r14), %rax
	leaq	(%r10,%rax), %rsi
	leaq	(%r10,%r14), %rdi
	movq	%r15, %rdx
	movl	%r9d, -104(%rbp)
	movq	%r10, -80(%rbp)
	movq	%rcx, -96(%rbp)
	movq	%r8, -88(%rbp)
	movq	%rax, -72(%rbp)
	call	memmove@PLT
	movq	-72(%rbp), %rax
	leaq	0(%r13,%r14), %rdi
	leaq	0(%r13,%rax), %rsi
	movq	%r15, %rdx
	call	memmove@PLT
	movq	-72(%rbp), %rax
	leaq	(%r12,%r14), %rdi
	leaq	(%r12,%rax), %rsi
	movq	%r15, %rdx
	call	memmove@PLT
	movq	-96(%rbp), %rcx
	movq	-88(%rbp), %r8
	leaq	0(,%rcx,4), %rdx
	movq	-200(%rbp), %rcx
	leaq	0(,%r8,4), %rax
	leaq	4(%rcx,%rax), %rsi
	leaq	(%rcx,%rax), %rdi
	call	memmove@PLT
	movq	-80(%rbp), %r10
	movl	-104(%rbp), %r9d
	jmp	.L518
	.p2align 4,,10
	.p2align 3
.L520:
	cmpl	$2, %ebx
	je	.L521
	movl	-168(%rbp), %eax
	movl	-176(%rbp), %esi
	xorl	$1, %eax
	cmpl	$199, %esi
	jg	.L585
	testl	%eax, %eax
	jne	.L614
	cmpl	$199, -176(%rbp)
	jg	.L585
.L529:
	movl	-184(%rbp), %edx
	movl	-172(%rbp), %esi
	xorl	%eax, %eax
	testl	%edx, %edx
	sete	%al
	cmpl	$199, %esi
	jg	.L586
	testl	%eax, %eax
	jne	.L615
	cmpl	$199, -172(%rbp)
	jg	.L586
.L531:
	cmpl	$1, -188(%rbp)
	jg	.L616
	movl	-188(%rbp), %esi
	movl	-180(%rbp), %eax
	leal	(%rsi,%rsi), %edx
	subl	%edx, %eax
	incl	%esi
	movl	%esi, -188(%rbp)
	leal	-2(%rax), %r9d
	cmpl	$3, %eax
	jle	.L545
	movq	-256(%rbp), %r15
	subl	$4, %eax
	movslq	%esi, %rbx
	addq	-264(%rbp), %rbx
	leaq	8(,%rax,8), %r14
	movq	%r10, %rdi
	leaq	(%r15,%rbx,8), %rsi
	movq	%r14, %rdx
	movl	%r9d, -80(%rbp)
	movq	%r10, -72(%rbp)
	call	memcpy@PLT
	leaq	80000(%r15,%rbx,8), %rsi
	movq	%r14, %rdx
	movq	%r13, %rdi
	call	memcpy@PLT
	leaq	160000(%r15,%rbx,8), %rsi
	movq	%r14, %rdx
	movq	%r12, %rdi
	call	memcpy@PLT
	movl	$2, %ebx
	movl	$0, -164(%rbp)
	movq	-72(%rbp), %r10
	movl	-80(%rbp), %r9d
	jmp	.L480
	.p2align 4,,10
	.p2align 3
.L521:
	movl	-176(%rbp), %eax
	movl	-172(%rbp), %esi
	orl	%esi, %eax
	je	.L539
	movl	-168(%rbp), %edi
	movl	-180(%rbp), %eax
	testl	%edi, %edi
	jne	.L524
	subl	%esi, %eax
	cmpl	$1, %eax
	jle	.L617
	decl	%eax
	leaq	0(,%rax,8), %r14
	movq	-208(%rbp), %rsi
	movq	%r10, %rdi
	movq	%r14, %rdx
	movq	%r10, -72(%rbp)
	movq	%rax, %rbx
	call	memcpy@PLT
	movq	-216(%rbp), %rsi
	movq	%r14, %rdx
	movq	%r13, %rdi
	call	memcpy@PLT
	movq	-224(%rbp), %rsi
	movq	%r14, %rdx
	movq	%r12, %rdi
	call	memcpy@PLT
	movq	-72(%rbp), %r10
.L526:
	incl	-172(%rbp)
	movl	%ebx, %r9d
.L600:
	movl	$0, -164(%rbp)
	movl	$1, -168(%rbp)
	movl	$2, %ebx
	jmp	.L480
	.p2align 4,,10
	.p2align 3
.L613:
	movq	%rbx, %rsi
	movl	%r13d, %r9d
	movl	%r10d, %ebx
	movq	%r11, %r13
	movq	%rsi, %r10
	jmp	.L498
	.p2align 4,,10
	.p2align 3
.L524:
	movl	-184(%rbp), %ecx
	testl	%ecx, %ecx
	jne	.L603
	movl	-188(%rbp), %esi
	subl	%esi, %eax
	leal	-2(%rax), %r9d
	incl	%esi
	movl	%esi, -188(%rbp)
	testl	%r9d, %r9d
	jle	.L540
	subl	$3, %eax
	leaq	8(,%rax,8), %r14
	movq	-232(%rbp), %rsi
	movq	%r10, %rdi
	movq	%r14, %rdx
	movl	%r9d, -80(%rbp)
	movq	%r10, -72(%rbp)
	call	memcpy@PLT
	movq	-240(%rbp), %rsi
	movq	%r14, %rdx
	movq	%r13, %rdi
	call	memcpy@PLT
	movq	-248(%rbp), %rsi
	movq	%r14, %rdx
	movq	%r12, %rdi
	call	memcpy@PLT
	movl	-168(%rbp), %eax
	movl	$0, -164(%rbp)
	movl	%eax, -184(%rbp)
	movq	-72(%rbp), %r10
	movl	-80(%rbp), %r9d
	movl	$2, %ebx
	jmp	.L480
.L585:
	testl	%eax, %eax
	je	.L529
	movl	-172(%rbp), %esi
	movl	-180(%rbp), %eax
	subl	%esi, %eax
	leal	-1(%rax), %r9d
	incl	%esi
	movl	%esi, -172(%rbp)
	testl	%r9d, %r9d
	jle	.L600
	subl	$2, %eax
	leaq	8(,%rax,8), %r14
	movq	-208(%rbp), %rsi
	movq	%r10, %rdi
	movq	%r14, %rdx
	movl	%r9d, -80(%rbp)
	movq	%r10, -72(%rbp)
	call	memcpy@PLT
	movq	-216(%rbp), %rsi
	movq	%r14, %rdx
	movq	%r13, %rdi
	call	memcpy@PLT
	movq	-224(%rbp), %rsi
	movq	%r14, %rdx
	movq	%r12, %rdi
	call	memcpy@PLT
	movl	$2, %ebx
	movl	$0, -164(%rbp)
	movl	$1, -168(%rbp)
	movq	-72(%rbp), %r10
	movl	-80(%rbp), %r9d
	jmp	.L480
.L586:
	testl	%eax, %eax
	je	.L531
	movl	-188(%rbp), %esi
	movl	-180(%rbp), %eax
	subl	%esi, %eax
	leal	-2(%rax), %r9d
	incl	%esi
	movl	%esi, -188(%rbp)
	testl	%r9d, %r9d
	jle	.L544
	subl	$3, %eax
	leaq	8(,%rax,8), %r14
	movq	-232(%rbp), %rsi
	movq	%r10, %rdi
	movq	%r14, %rdx
	movl	%r9d, -80(%rbp)
	movq	%r10, -72(%rbp)
	call	memcpy@PLT
	movq	-240(%rbp), %rsi
	movq	%r14, %rdx
	movq	%r13, %rdi
	call	memcpy@PLT
	movq	-248(%rbp), %rsi
	movq	%r14, %rdx
	movq	%r12, %rdi
	call	memcpy@PLT
	movl	$2, %ebx
	movl	$0, -164(%rbp)
	movl	$1, -184(%rbp)
	movq	-72(%rbp), %r10
	movl	-80(%rbp), %r9d
	jmp	.L480
.L614:
	movl	-180(%rbp), %eax
	subl	%esi, %eax
	leal	-1(%rax), %r9d
	incl	%esi
	movl	%esi, -176(%rbp)
	testl	%r9d, %r9d
	jle	.L541
	movq	-256(%rbp), %r15
	subl	$2, %eax
	movslq	%esi, %rbx
	addq	-264(%rbp), %rbx
	leaq	8(,%rax,8), %r14
	movq	%r10, %rdi
	leaq	-8(%r15,%rbx,8), %rsi
	movq	%r14, %rdx
	movl	%r9d, -80(%rbp)
	movq	%r10, -72(%rbp)
	call	memcpy@PLT
	leaq	79992(%r15,%rbx,8), %rsi
	movq	%r14, %rdx
	movq	%r13, %rdi
	call	memcpy@PLT
	leaq	159992(%r15,%rbx,8), %rsi
	movq	%r14, %rdx
	movq	%r12, %rdi
	call	memcpy@PLT
	movl	$2, %ebx
	movl	$0, -164(%rbp)
	movl	$0, -168(%rbp)
	movq	-72(%rbp), %r10
	movl	-80(%rbp), %r9d
	jmp	.L480
.L615:
	movl	-180(%rbp), %eax
	subl	%esi, %eax
	leal	-1(%rax), %r9d
	incl	%esi
	movl	%esi, -172(%rbp)
	testl	%r9d, %r9d
	jle	.L543
	subl	$2, %eax
	leaq	8(,%rax,8), %r14
	movq	-208(%rbp), %rsi
	movq	%r10, %rdi
	movq	%r14, %rdx
	movl	%r9d, -80(%rbp)
	movq	%r10, -72(%rbp)
	call	memcpy@PLT
	movq	-216(%rbp), %rsi
	movq	%r14, %rdx
	movq	%r13, %rdi
	call	memcpy@PLT
	movq	-224(%rbp), %rsi
	movq	%r14, %rdx
	movq	%r12, %rdi
	call	memcpy@PLT
	movl	$2, %ebx
	movl	$0, -164(%rbp)
	movl	$0, -184(%rbp)
	movq	-72(%rbp), %r10
	movl	-80(%rbp), %r9d
	jmp	.L480
.L540:
	movl	-168(%rbp), %eax
	movl	$0, -164(%rbp)
	movl	%eax, -184(%rbp)
	movl	$2, %ebx
	jmp	.L480
.L617:
	leal	-1(%rax), %ebx
	jmp	.L526
.L539:
	movl	$-1, %eax
.L523:
	movq	-280(%rbp), %rsi
	movl	-192(%rbp), %ebx
	movl	%ebx, (%rsi)
	movq	-272(%rbp), %rsi
	movl	%eax, (%rsi)
	movq	-56(%rbp), %rax
	subq	%fs:40, %rax
	jne	.L618
	leaq	-48(%rbp), %rsp
	popq	%rbx
	popq	%r10
	.cfi_remember_state
	.cfi_def_cfa 10, 0
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	leaq	-8(%r10), %rsp
	.cfi_def_cfa 7, 8
	ret
.L541:
	.cfi_restore_state
	movl	$0, -164(%rbp)
	movl	$0, -168(%rbp)
	movl	$2, %ebx
	jmp	.L480
.L616:
	movl	-180(%rbp), %eax
.L603:
	subl	-172(%rbp), %eax
	decl	%eax
	movl	%eax, -192(%rbp)
	movl	-176(%rbp), %eax
	decl	%eax
	jmp	.L523
.L544:
	movl	$0, -164(%rbp)
	movl	$1, -184(%rbp)
	movl	$2, %ebx
	jmp	.L480
.L543:
	movl	$0, -164(%rbp)
	movl	$0, -184(%rbp)
	movl	$2, %ebx
	jmp	.L480
.L610:
	movslq	%r12d, %rax
	movq	%rax, -264(%rbp)
	leaq	pos_(%rip), %rax
	movq	%rax, -256(%rbp)
	jmp	.L489
.L535:
	xorl	%edx, %edx
	movl	$1, %eax
	jmp	.L486
.L534:
	xorl	%edx, %edx
	movl	$1, %eax
	jmp	.L481
.L618:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE16:
	.size	kmt_, .-kmt_
	.p2align 4
	.globl	cgyration_
	.type	cgyration_, @function
cgyration_:
.LFB8:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$320, %rsp
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	movq	%fs:40, %rax
	movq	%rax, 312(%rsp)
	movl	160000+bon_(%rip), %eax
	movl	%eax, 32(%rsp)
	testl	%eax, %eax
	jle	.L619
	leaq	120(%rsp), %rax
	movq	%rax, 16(%rsp)
	leaq	240(%rsp), %rax
	movq	%rax, 24(%rsp)
	leaq	128(%rsp), %rax
	movq	%rax, 8(%rsp)
	leaq	160(%rsp), %rax
	movl	$1, 36(%rsp)
	movq	%rax, (%rsp)
	leaq	gyr_(%rip), %r13
	leaq	160000(%r13), %r14
	leaq	120004+bon_(%rip), %r12
	leaq	pos_(%rip), %rbx
	.p2align 4,,10
	.p2align 3
.L636:
	movl	-4(%r12), %edx
	movl	32+bas_(%rip), %ecx
	movl	$0, 112(%rsp)
	movl	$0, 116(%rsp)
	leal	1(%rdx), %eax
	testl	%ecx, %ecx
	jne	.L648
	xorl	%r8d, %r8d
	xorl	%ecx, %ecx
	xorl	%r9d, %r9d
.L621:
	movl	(%r12), %edi
	vxorpd	%xmm6, %xmm6, %xmm6
	movl	%edi, %esi
	subl	%edx, %esi
	vcvtsi2sdl	%esi, %xmm6, %xmm0
	incl	36(%rsp)
	vmovsd	%xmm0, 40(%rsp)
	cmpl	%r8d, %esi
	je	.L649
	vmovd	%ecx, %xmm6
	vpinsrd	$1, %r9d, %xmm6, %xmm0
	vmovq	%xmm0, 480000(%r13)
.L625:
	vmovsd	.LC8(%rip), %xmm7
	vxorpd	%xmm0, %xmm0, %xmm0
	vdivsd	40(%rsp), %xmm7, %xmm6
	movq	$0x000000000, 224(%rsp)
	vmovsd	%xmm6, 104(%rsp)
	vmovapd	%ymm0, 160(%rsp)
	vmovapd	%ymm0, 192(%rsp)
	cmpl	%eax, %edi
	jl	.L650
	movl	%edi, %r8d
	subl	%eax, %r8d
	leal	1(%r8), %ecx
	cmpl	$2, %r8d
	jbe	.L642
	movslq	%eax, %r9
	movl	%ecx, %esi
	leaq	0(,%r9,8), %rdx
	vxorpd	%xmm2, %xmm2, %xmm2
	shrl	$2, %esi
	leaq	-8(%rbx,%rdx), %r15
	leaq	79992(%rbx,%rdx), %r11
	leaq	159992(%rbx,%rdx), %r10
	salq	$5, %rsi
	xorl	%edx, %edx
	vmovapd	%ymm2, %ymm1
	vmovapd	%ymm2, %ymm0
	.p2align 4,,10
	.p2align 3
.L627:
	vaddpd	(%r15,%rdx), %ymm0, %ymm0
	vaddpd	(%r11,%rdx), %ymm1, %ymm1
	vaddpd	(%r10,%rdx), %ymm2, %ymm2
	addq	$32, %rdx
	cmpq	%rsi, %rdx
	jne	.L627
	vextractf128	$0x1, %ymm2, %xmm3
	vaddpd	%xmm2, %xmm3, %xmm2
	movl	%ecx, %edx
	andl	$-4, %edx
	vunpckhpd	%xmm2, %xmm2, %xmm3
	vaddpd	%xmm2, %xmm3, %xmm2
	vextractf128	$0x1, %ymm1, %xmm3
	vaddpd	%xmm1, %xmm3, %xmm3
	leal	(%rdx,%rax), %esi
	vunpckhpd	%xmm3, %xmm3, %xmm1
	vaddpd	%xmm3, %xmm1, %xmm1
	vextractf128	$0x1, %ymm0, %xmm3
	vaddpd	%xmm0, %xmm3, %xmm3
	vunpckhpd	%xmm3, %xmm3, %xmm0
	vaddpd	%xmm3, %xmm0, %xmm0
	cmpl	%edx, %ecx
	je	.L651
.L626:
	movslq	%esi, %rdx
	leal	1(%rsi), %r9d
	vaddsd	-8(%rbx,%rdx,8), %xmm0, %xmm0
	vaddsd	79992(%rbx,%rdx,8), %xmm1, %xmm1
	vaddsd	159992(%rbx,%rdx,8), %xmm2, %xmm2
	cmpl	%r9d, %edi
	jl	.L629
	addl	$2, %esi
	vaddsd	(%rbx,%rdx,8), %xmm0, %xmm0
	vaddsd	80000(%rbx,%rdx,8), %xmm1, %xmm1
	vaddsd	160000(%rbx,%rdx,8), %xmm2, %xmm2
	movslq	%r9d, %r9
	cmpl	%esi, %edi
	jl	.L629
	vaddsd	(%rbx,%r9,8), %xmm0, %xmm0
	vaddsd	80000(%rbx,%r9,8), %xmm1, %xmm1
	vaddsd	160000(%rbx,%r9,8), %xmm2, %xmm2
.L629:
	vmovsd	104(%rsp), %xmm7
	vmulsd	%xmm7, %xmm0, %xmm6
	vmulsd	%xmm7, %xmm1, %xmm5
	vmulsd	%xmm7, %xmm2, %xmm7
	vmovsd	%xmm6, 56(%rsp)
	vunpcklpd	%xmm5, %xmm6, %xmm0
	vmovsd	%xmm5, 48(%rsp)
	vmovsd	%xmm7, 96(%rsp)
	vmovupd	%xmm0, (%r14)
	vmovsd	%xmm7, 16(%r14)
	cmpl	$2, %r8d
	jbe	.L643
	movslq	%eax, %r9
.L639:
	vbroadcastsd	96(%rsp), %ymm6
	movl	%ecx, %esi
	vxorpd	%xmm12, %xmm12, %xmm12
	salq	$3, %r9
	shrl	$2, %esi
	vbroadcastsd	56(%rsp), %ymm15
	vbroadcastsd	48(%rsp), %ymm14
	leaq	-8(%rbx,%r9), %r11
	leaq	79992(%rbx,%r9), %r10
	vmovapd	%ymm6, 64(%rsp)
	leaq	159992(%rbx,%r9), %r9
	salq	$5, %rsi
	xorl	%edx, %edx
	vmovapd	%ymm12, %ymm11
	vmovapd	%ymm12, %ymm10
	vmovapd	%ymm12, %ymm9
	vmovapd	%ymm12, %ymm8
	vmovapd	%ymm12, %ymm7
	vmovapd	%ymm12, %ymm6
	.p2align 4,,10
	.p2align 3
.L634:
	vmovupd	(%r10,%rdx), %ymm4
	vmovupd	(%r11,%rdx), %ymm5
	vsubpd	%ymm14, %ymm4, %ymm2
	vsubpd	%ymm15, %ymm5, %ymm0
	vmovupd	(%r9,%rdx), %ymm5
	vmulpd	%ymm2, %ymm2, %ymm4
	vsubpd	64(%rsp), %ymm5, %ymm1
	vmovapd	%ymm0, %ymm5
	addq	$32, %rdx
	vmulpd	%ymm1, %ymm1, %ymm3
	vfmadd132pd	%ymm0, %ymm4, %ymm5
	vfnmadd231pd	%ymm0, %ymm2, %ymm10
	vfnmadd231pd	%ymm2, %ymm1, %ymm11
	vfnmadd231pd	%ymm0, %ymm1, %ymm12
	vaddpd	%ymm4, %ymm3, %ymm4
	vaddpd	%ymm5, %ymm3, %ymm13
	vfmadd231pd	%ymm0, %ymm0, %ymm3
	vaddpd	%ymm4, %ymm7, %ymm7
	vaddpd	%ymm13, %ymm6, %ymm6
	vaddpd	%ymm5, %ymm9, %ymm9
	vaddpd	%ymm3, %ymm8, %ymm8
	cmpq	%rsi, %rdx
	jne	.L634
	vextractf128	$0x1, %ymm12, %xmm0
	vaddpd	%xmm12, %xmm0, %xmm12
	movl	%ecx, %edx
	andl	$-4, %edx
	vunpckhpd	%xmm12, %xmm12, %xmm0
	vaddpd	%xmm12, %xmm0, %xmm12
	vextractf128	$0x1, %ymm11, %xmm0
	vaddpd	%xmm11, %xmm0, %xmm11
	leal	(%rdx,%rax), %esi
	vunpckhpd	%xmm11, %xmm11, %xmm0
	vaddpd	%xmm11, %xmm0, %xmm11
	vextractf128	$0x1, %ymm10, %xmm0
	vaddpd	%xmm10, %xmm0, %xmm10
	vunpckhpd	%xmm10, %xmm10, %xmm0
	vaddpd	%xmm10, %xmm0, %xmm10
	vextractf128	$0x1, %ymm9, %xmm0
	vaddpd	%xmm9, %xmm0, %xmm9
	vunpckhpd	%xmm9, %xmm9, %xmm0
	vaddpd	%xmm9, %xmm0, %xmm9
	vextractf128	$0x1, %ymm8, %xmm0
	vaddpd	%xmm8, %xmm0, %xmm8
	vunpckhpd	%xmm8, %xmm8, %xmm0
	vaddpd	%xmm8, %xmm0, %xmm8
	vextractf128	$0x1, %ymm7, %xmm0
	vaddpd	%xmm7, %xmm0, %xmm7
	vunpckhpd	%xmm7, %xmm7, %xmm0
	vaddpd	%xmm7, %xmm0, %xmm7
	vextractf128	$0x1, %ymm6, %xmm0
	vaddpd	%xmm6, %xmm0, %xmm6
	vunpckhpd	%xmm6, %xmm6, %xmm0
	vaddpd	%xmm6, %xmm0, %xmm6
	cmpl	%ecx, %edx
	je	.L630
.L637:
	movl	%r8d, %ecx
	subl	%edx, %ecx
	leal	1(%rcx), %r8d
	cmpl	$1, %ecx
	jbe	.L631
	cltq
	addq	%rdx, %rax
	leaq	-8+pos_(%rip), %rcx
	vmovupd	(%rcx,%rax,8), %xmm5
	addq	$80000, %rcx
	vmovupd	(%rcx,%rax,8), %xmm4
	addq	$80000, %rcx
	vmovupd	(%rcx,%rax,8), %xmm2
	vmovddup	56(%rsp), %xmm14
	vmovddup	96(%rsp), %xmm1
	vsubpd	%xmm14, %xmm5, %xmm14
	vsubpd	%xmm1, %xmm2, %xmm1
	vmovddup	48(%rsp), %xmm0
	vsubpd	%xmm0, %xmm4, %xmm0
	vmulpd	%xmm1, %xmm14, %xmm2
	vmulpd	%xmm1, %xmm1, %xmm3
	vmulpd	%xmm1, %xmm0, %xmm1
	vmovapd	%xmm4, 64(%rsp)
	vmulpd	%xmm0, %xmm0, %xmm4
	vxorpd	.LC79(%rip), %xmm2, %xmm2
	vmulpd	%xmm0, %xmm14, %xmm0
	vunpckhpd	%xmm2, %xmm2, %xmm15
	vaddpd	%xmm2, %xmm15, %xmm2
	vxorpd	.LC79(%rip), %xmm1, %xmm1
	vmovapd	%xmm14, %xmm5
	vaddsd	%xmm2, %xmm12, %xmm12
	vunpckhpd	%xmm1, %xmm1, %xmm2
	vaddpd	%xmm1, %xmm2, %xmm1
	vfmadd132pd	%xmm14, %xmm4, %xmm5
	vxorpd	.LC79(%rip), %xmm0, %xmm0
	vaddsd	%xmm1, %xmm11, %xmm11
	vunpckhpd	%xmm0, %xmm0, %xmm1
	vaddpd	%xmm0, %xmm1, %xmm0
	vaddpd	%xmm3, %xmm5, %xmm13
	vaddpd	%xmm3, %xmm4, %xmm4
	vfmadd231pd	%xmm14, %xmm14, %xmm3
	vaddsd	%xmm0, %xmm10, %xmm10
	vunpckhpd	%xmm5, %xmm5, %xmm0
	vaddpd	%xmm5, %xmm0, %xmm0
	movl	%r8d, %eax
	andl	$-2, %eax
	vaddsd	%xmm0, %xmm9, %xmm9
	vunpckhpd	%xmm3, %xmm3, %xmm0
	vaddpd	%xmm3, %xmm0, %xmm3
	vunpckhpd	%xmm4, %xmm4, %xmm0
	vaddpd	%xmm4, %xmm0, %xmm4
	vunpckhpd	%xmm13, %xmm13, %xmm0
	vaddpd	%xmm13, %xmm0, %xmm13
	vaddsd	%xmm3, %xmm8, %xmm8
	vaddsd	%xmm4, %xmm7, %xmm7
	vaddsd	%xmm13, %xmm6, %xmm6
	addl	%eax, %esi
	cmpl	%eax, %r8d
	je	.L630
.L631:
	movslq	%esi, %rax
	vmovsd	79992(%rbx,%rax,8), %xmm2
	vmovsd	48(%rsp), %xmm14
	vmovsd	159992(%rbx,%rax,8), %xmm1
	vmovsd	96(%rsp), %xmm13
	vsubsd	%xmm14, %xmm2, %xmm2
	vsubsd	%xmm13, %xmm1, %xmm1
	vmovsd	-8(%rbx,%rax,8), %xmm0
	vmovsd	56(%rsp), %xmm15
	vmulsd	%xmm1, %xmm1, %xmm3
	vmulsd	%xmm2, %xmm2, %xmm4
	vsubsd	%xmm15, %xmm0, %xmm0
	vfnmadd231sd	%xmm1, %xmm2, %xmm11
	vmovsd	%xmm0, %xmm0, %xmm5
	vfmadd132sd	%xmm0, %xmm4, %xmm5
	vaddsd	%xmm6, %xmm3, %xmm6
	vaddsd	%xmm3, %xmm4, %xmm4
	vfmadd231sd	%xmm0, %xmm0, %xmm3
	vfnmadd231sd	%xmm2, %xmm0, %xmm10
	vfnmadd231sd	%xmm1, %xmm0, %xmm12
	vaddsd	%xmm6, %xmm5, %xmm6
	vaddsd	%xmm4, %xmm7, %xmm7
	vaddsd	%xmm3, %xmm8, %xmm8
	vaddsd	%xmm5, %xmm9, %xmm9
	cmpl	%esi, %edi
	jle	.L630
	vmovsd	80000(%rbx,%rax,8), %xmm2
	vmovsd	(%rbx,%rax,8), %xmm0
	vsubsd	%xmm14, %xmm2, %xmm2
	vmovsd	160000(%rbx,%rax,8), %xmm1
	vsubsd	%xmm15, %xmm0, %xmm0
	vmulsd	%xmm2, %xmm2, %xmm4
	vsubsd	%xmm13, %xmm1, %xmm1
	vmovsd	%xmm0, %xmm0, %xmm5
	vfnmadd231sd	%xmm2, %xmm0, %xmm10
	vmulsd	%xmm1, %xmm1, %xmm3
	vfmadd132sd	%xmm0, %xmm4, %xmm5
	vfnmadd231sd	%xmm1, %xmm2, %xmm11
	vfnmadd231sd	%xmm1, %xmm0, %xmm12
	vaddsd	%xmm3, %xmm4, %xmm4
	vaddsd	%xmm3, %xmm5, %xmm13
	vfmadd231sd	%xmm0, %xmm0, %xmm3
	vaddsd	%xmm4, %xmm7, %xmm7
	vaddsd	%xmm13, %xmm6, %xmm6
	vaddsd	%xmm5, %xmm9, %xmm9
	vaddsd	%xmm3, %xmm8, %xmm8
.L630:
	vmulsd	104(%rsp), %xmm6, %xmm6
	vunpcklpd	%xmm9, %xmm11, %xmm9
	vunpcklpd	%xmm10, %xmm12, %xmm0
	vmovsd	%xmm7, 160(%rsp)
	vmovsd	%xmm8, 192(%rsp)
	vmovupd	%xmm9, 216(%rsp)
	vmovapd	%xmm0, 176(%rsp)
.L638:
	vsqrtsd	%xmm6, %xmm6, %xmm6
	movq	8(%rsp), %r15
	leaq	.LC75(%rip), %rdx
	movq	16(%rsp), %r9
	movq	24(%rsp), %r8
	movq	(%rsp), %rdi
	vunpcklpd	%xmm12, %xmm11, %xmm11
	movq	%r15, %rcx
	movq	%rdx, %rsi
	vmovddup	40(%rsp), %xmm7
	vmovsd	%xmm10, 168(%rsp)
	vmovapd	%xmm7, 64(%rsp)
	vmovupd	%xmm11, 200(%rsp)
	vmovsd	%xmm6, 0(%r13)
	vzeroupper
	call	jacobi_
	vmovapd	128(%rsp), %xmm6
	leaq	.LC75(%rip), %rdi
	vdivpd	64(%rsp), %xmm6, %xmm0
	vmovsd	104(%rsp), %xmm6
	vsqrtpd	%xmm0, %xmm0
	vmovapd	%xmm0, 128(%rsp)
	vmulsd	144(%rsp), %xmm6, %xmm0
	movq	%r15, %rsi
	addq	$8, %r13
	addq	$24, %r14
	addq	$4, %r12
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm0, 144(%rsp)
	call	sort_
	vmovsd	128(%rsp), %xmm0
	vmovsd	136(%rsp), %xmm1
	vaddsd	144(%rsp), %xmm0, %xmm0
	movslq	-8(%r12), %rdx
	movslq	-4(%r12), %rax
	vmulsd	.LC72(%rip), %xmm0, %xmm0
	vmovsd	80000(%rbx,%rdx,8), %xmm3
	vmovsd	(%rbx,%rdx,8), %xmm2
	vsubsd	79992(%rbx,%rax,8), %xmm3, %xmm3
	vsubsd	-8(%rbx,%rax,8), %xmm2, %xmm2
	vsubsd	%xmm0, %xmm1, %xmm1
	vmulsd	%xmm3, %xmm3, %xmm3
	movl	32(%rsp), %edi
	vdivsd	%xmm0, %xmm1, %xmm0
	vfmadd132sd	%xmm2, %xmm3, %xmm2
	vmovsd	%xmm0, 399992(%r13)
	vmovsd	160000(%rbx,%rdx,8), %xmm0
	vsubsd	159992(%rbx,%rax,8), %xmm0, %xmm0
	vfmadd132sd	%xmm0, %xmm2, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm0, 79992(%r13)
	cmpl	%edi, 36(%rsp)
	jle	.L636
.L619:
	movq	312(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L652
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L649:
	.cfi_restore_state
	movl	$0, 480000(%r13)
	movl	$0, 480004(%r13)
	jmp	.L625
	.p2align 4,,10
	.p2align 3
.L648:
	leaq	124(%rsp), %rdx
	movq	%r12, %rcx
	leaq	116(%rsp), %rsi
	leaq	112(%rsp), %rdi
	movl	%eax, 124(%rsp)
	call	kmt_
	movl	116(%rsp), %r9d
	movl	-4(%r12), %edx
	movl	112(%rsp), %ecx
	movl	%r9d, %r8d
	subl	%ecx, %r8d
	leal	1(%rdx), %eax
	jmp	.L621
	.p2align 4,,10
	.p2align 3
.L651:
	vmovsd	104(%rsp), %xmm7
	vmulsd	%xmm7, %xmm0, %xmm6
	vmulsd	%xmm7, %xmm1, %xmm3
	vmulsd	%xmm7, %xmm2, %xmm7
	vmovsd	%xmm6, 56(%rsp)
	vunpcklpd	%xmm3, %xmm6, %xmm0
	vmovsd	%xmm3, 48(%rsp)
	vmovsd	%xmm7, 96(%rsp)
	vmovupd	%xmm0, (%r14)
	vmovsd	%xmm7, 16(%r14)
	jmp	.L639
.L650:
	vxorpd	%xmm6, %xmm6, %xmm6
	movq	$0x000000000, (%r14)
	movq	$0x000000000, 8(%r14)
	movq	$0x000000000, 16(%r14)
	vmovsd	%xmm6, %xmm6, %xmm12
	vmovsd	%xmm6, %xmm6, %xmm11
	vmovsd	%xmm6, %xmm6, %xmm10
	jmp	.L638
.L642:
	vxorpd	%xmm2, %xmm2, %xmm2
	movl	%eax, %esi
	vmovsd	%xmm2, %xmm2, %xmm1
	vmovsd	%xmm2, %xmm2, %xmm0
	jmp	.L626
.L643:
	vxorpd	%xmm12, %xmm12, %xmm12
	movl	%eax, %esi
	xorl	%edx, %edx
	vmovsd	%xmm12, %xmm12, %xmm11
	vmovsd	%xmm12, %xmm12, %xmm10
	vmovsd	%xmm12, %xmm12, %xmm9
	vmovsd	%xmm12, %xmm12, %xmm8
	vmovsd	%xmm12, %xmm12, %xmm7
	vmovsd	%xmm12, %xmm12, %xmm6
	jmp	.L637
.L652:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE8:
	.size	cgyration_, .-cgyration_
	.section	.rodata.str1.1
.LC81:
	.string	"BROKEN PBC. PLS CHECK!"
	.text
	.p2align 4
	.globl	update_verlet_list_
	.type	update_verlet_list_, @function
update_verlet_list_:
.LFB17:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	movq	%rdi, %r8
	leaq	verl_(%rip), %rcx
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	vxorps	%xmm3, %xmm3, %xmm3
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$776, %rsp
	.cfi_def_cfa_offset 832
	movq	%rsi, 160(%rsp)
	vmovsd	(%r8), %xmm0
	leaq	cmp2_(%rip), %rsi
	vaddsd	7924016+sig_(%rip), %xmm0, %xmm8
	vaddsd	7924008+sig_(%rip), %xmm0, %xmm0
	movq	%fs:40, %rax
	movq	%rax, 760(%rsp)
	xorl	%eax, %eax
	movl	60000004(%rsi), %eax
	movl	540000008(%rsi), %r11d
	vmulsd	%xmm0, %xmm0, %xmm6
	movl	%eax, 216(%rsp)
	movl	$3, %eax
	subl	%r11d, %eax
	movslq	%eax, %rdx
	movl	$0, 60000004(%rsi)
	movl	%edx, 540000008(%rsi)
	movl	36+kier_(%rip), %r9d
	movl	8+bas_(%rip), %esi
	movl	120240016(%rcx), %edi
	vmulsd	%xmm8, %xmm8, %xmm7
	movl	$0, cmap_(%rip)
	movl	$0, cmp2_(%rip)
	movl	$0, 120240016(%rcx)
	movl	%r11d, 120(%rsp)
	movl	%edx, 96(%rsp)
	movl	%esi, 28(%rsp)
	movl	%r9d, 12(%rsp)
	vmovsd	%xmm6, 104(%rsp)
	testl	%esi, %esi
	jle	.L654
	imulq	$15000000, %rdx, %rdx
	movl	120240020(%rcx), %ebx
	vmovsd	plates_(%rip), %xmm6
	movq	%rdx, 48(%rsp)
	movslq	%r11d, %rdx
	imulq	$15000000, %rdx, %rdx
	movl	%ebx, %eax
	vmovsd	%xmm6, 72(%rsp)
	shrl	$31, %eax
	vmovsd	24+kier_(%rip), %xmm6
	addl	%ebx, %eax
	sarl	%eax
	movq	%rdx, 64(%rsp)
	vmovsd	%xmm6, 88(%rsp)
	leal	1(%rsi), %edx
	vmovsd	240000+for_(%rip), %xmm6
	leal	(%rax,%rsi), %r15d
	addl	%edx, %eax
	leaq	pos_(%rip), %r10
	movl	%edx, 24(%rsp)
	movl	%eax, 124(%rsp)
	movl	%eax, %edx
	vmovsd	%xmm6, 16(%rsp)
	movslq	%esi, %rax
	vmovsd	240032+for_(%rip), %xmm6
	leaq	(%r10,%rax,8), %rax
	movl	36+bas_(%rip), %r14d
	movq	%rax, 136(%rsp)
	vmovsd	%xmm6, 32(%rsp)
	movslq	%edx, %rax
	vmovsd	8+plates_(%rip), %xmm6
	leaq	(%r10,%rax,8), %rax
	movl	%ebx, 100(%rsp)
	addl	%esi, %ebx
	movl	%r15d, 200(%rsp)
	movq	%rax, 128(%rsp)
	movl	%r14d, 40(%rsp)
	movl	%ebx, 112(%rsp)
	vmovsd	240024+for_(%rip), %xmm10
	movl	40+kier_(%rip), %r15d
	vmovsd	240008+for_(%rip), %xmm13
	vmovsd	.LC11(%rip), %xmm14
	vmovsd	%xmm6, 80(%rsp)
	movq	%rcx, %r11
	xorl	%r13d, %r13d
	movl	$1, %eax
	movl	$1, %esi
	movl	%r9d, %r14d
	jmp	.L675
	.p2align 4,,10
	.p2align 3
.L656:
	vmovsd	80(%rsp), %xmm6
	vsubsd	%xmm4, %xmm6, %xmm0
	vcomisd	%xmm0, %xmm8
	ja	.L906
.L655:
	incl	%esi
	addq	$8, %r10
	addq	$24, %r11
	cmpl	24(%rsp), %esi
	je	.L907
.L675:
	vmovsd	(%r10), %xmm9
	vmovsd	80000(%r10), %xmm5
	vmovsd	160000(%r10), %xmm4
	movl	40(%rsp), %ebx
	vmovsd	%xmm9, (%r11)
	vmovsd	%xmm5, 8(%r11)
	vmovsd	%xmm4, 16(%r11)
	testl	%ebx, %ebx
	je	.L655
	vsubsd	72(%rsp), %xmm4, %xmm0
	vcomisd	%xmm0, %xmm8
	jbe	.L656
	cmpl	$1, 100(%rsp)
	movl	24(%rsp), %r9d
	jle	.L656
	vmovsd	.LC11(%rip), %xmm6
	movq	%r10, 144(%rsp)
	vsubsd	88(%rsp), %xmm9, %xmm11
	movq	136(%rsp), %r8
	movl	200(%rsp), %r10d
	vmovsd	%xmm6, 56(%rsp)
	jmp	.L665
	.p2align 4,,10
	.p2align 3
.L660:
	incl	%r9d
	addq	$8, %r8
	cmpl	%r9d, %r10d
	jl	.L908
.L665:
	vsubsd	(%r8), %xmm11, %xmm1
	vsubsd	80000(%r8), %xmm5, %xmm0
	vsubsd	160000(%r8), %xmm4, %xmm12
	testl	%r14d, %r14d
	je	.L658
	vmulsd	%xmm1, %xmm10, %xmm15
	vmovsd	56(%rsp), %xmm2
	vmovsd	.LC60(%rip), %xmm6
	vandpd	%xmm15, %xmm2, %xmm2
	vorpd	%xmm2, %xmm6, %xmm6
	vaddsd	%xmm15, %xmm6, %xmm6
	vcvttsd2sil	%xmm6, %edx
	vcvtsi2sdl	%edx, %xmm3, %xmm6
	vfnmadd231sd	16(%rsp), %xmm6, %xmm1
.L658:
	testl	%r15d, %r15d
	je	.L659
	vmulsd	32(%rsp), %xmm0, %xmm15
	vmovsd	.LC60(%rip), %xmm6
	vandpd	%xmm15, %xmm14, %xmm2
	vorpd	%xmm2, %xmm6, %xmm6
	vaddsd	%xmm15, %xmm6, %xmm6
	vcvttsd2sil	%xmm6, %edx
	vcvtsi2sdl	%edx, %xmm3, %xmm6
	vfnmadd231sd	%xmm13, %xmm6, %xmm0
.L659:
	vmulsd	%xmm12, %xmm12, %xmm12
	vfmadd132sd	%xmm1, %xmm12, %xmm1
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vcomisd	%xmm0, %xmm7
	jbe	.L660
	incl	%r13d
	movslq	%r13d, %rdx
	leaq	(%rdx,%rdx,2), %rdx
	addq	48(%rsp), %rdx
	movl	%esi, -59759996(%rcx,%rdx,4)
	movl	%r9d, -59759992(%rcx,%rdx,4)
	movl	$0, -59759988(%rcx,%rdx,4)
	leaq	-15000001(%rdx), %r12
	cmpl	%eax, %edi
	jl	.L660
	movslq	%eax, %rdx
	leaq	(%rdx,%rdx,2), %rdx
	addq	64(%rsp), %rdx
	jmp	.L664
	.p2align 4,,10
	.p2align 3
.L909:
	testl	%ebp, %ebp
	je	.L663
.L662:
	incl	%eax
	addq	$3, %rdx
	cmpl	%eax, %edi
	jl	.L660
.L664:
	leaq	0(,%rdx,4), %rbx
	cmpl	%esi, -59759996(%rcx,%rdx,4)
	jl	.L662
	movl	-59759992(%rcx,%rbx), %ebx
	sete	%bpl
	movzbl	%bpl, %ebp
	cmpl	%r9d, %ebx
	jl	.L909
.L663:
	cmpl	%r9d, %ebx
	jne	.L660
	testl	%ebp, %ebp
	je	.L660
	movl	-59759988(%rcx,%rdx,4), %edx
	incl	%r9d
	movl	%edx, 240016(%rcx,%r12,4)
	incl	%eax
	addq	$8, %r8
	cmpl	%r9d, %r10d
	jge	.L665
.L908:
	vmovsd	80(%rsp), %xmm6
	movq	144(%rsp), %r10
	vsubsd	%xmm4, %xmm6, %xmm0
	vcomisd	%xmm0, %xmm8
	jbe	.L655
.L906:
	movl	124(%rsp), %r9d
	movl	112(%rsp), %edx
	cmpl	%edx, %r9d
	jg	.L655
	vaddsd	88(%rsp), %xmm9, %xmm9
	movq	%r10, 56(%rsp)
	movq	128(%rsp), %r8
	leal	1(%rdx), %r12d
	jmp	.L674
	.p2align 4,,10
	.p2align 3
.L669:
	incl	%r9d
	addq	$8, %r8
	cmpl	%r12d, %r9d
	je	.L910
.L674:
	vsubsd	-8(%r8), %xmm9, %xmm1
	vsubsd	79992(%r8), %xmm5, %xmm0
	vsubsd	159992(%r8), %xmm4, %xmm2
	testl	%r14d, %r14d
	je	.L667
	vmulsd	%xmm1, %xmm10, %xmm11
	vmovsd	.LC60(%rip), %xmm6
	vandpd	%xmm11, %xmm14, %xmm12
	vorpd	%xmm12, %xmm6, %xmm6
	vaddsd	%xmm11, %xmm6, %xmm6
	vcvttsd2sil	%xmm6, %edx
	vcvtsi2sdl	%edx, %xmm3, %xmm11
	vfnmadd231sd	16(%rsp), %xmm11, %xmm1
.L667:
	testl	%r15d, %r15d
	je	.L668
	vmulsd	32(%rsp), %xmm0, %xmm11
	vmovsd	.LC60(%rip), %xmm6
	vandpd	%xmm11, %xmm14, %xmm12
	vorpd	%xmm12, %xmm6, %xmm6
	vaddsd	%xmm11, %xmm6, %xmm6
	vcvttsd2sil	%xmm6, %edx
	vcvtsi2sdl	%edx, %xmm3, %xmm11
	vfnmadd231sd	%xmm11, %xmm13, %xmm0
.L668:
	vmulsd	%xmm2, %xmm2, %xmm2
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vcomisd	%xmm0, %xmm7
	jbe	.L669
	incl	%r13d
	movslq	%r13d, %rdx
	leaq	(%rdx,%rdx,2), %rdx
	addq	48(%rsp), %rdx
	movl	%esi, -59759996(%rcx,%rdx,4)
	movl	%r9d, -59759992(%rcx,%rdx,4)
	movl	$0, -59759988(%rcx,%rdx,4)
	leaq	-15000001(%rdx), %rbp
	cmpl	%eax, %edi
	jl	.L669
	movslq	%eax, %rdx
	leaq	(%rdx,%rdx,2), %rdx
	addq	64(%rsp), %rdx
	jmp	.L673
	.p2align 4,,10
	.p2align 3
.L911:
	testl	%ebx, %ebx
	je	.L672
.L671:
	incl	%eax
	addq	$3, %rdx
	cmpl	%eax, %edi
	jl	.L669
.L673:
	leaq	0(,%rdx,4), %r10
	cmpl	%esi, -59759996(%rcx,%rdx,4)
	jl	.L671
	movl	-59759992(%rcx,%r10), %r10d
	sete	%bl
	movzbl	%bl, %ebx
	cmpl	%r9d, %r10d
	jl	.L911
.L672:
	cmpl	%r9d, %r10d
	jne	.L669
	testl	%ebx, %ebx
	je	.L669
	movl	-59759988(%rcx,%rdx,4), %edx
	incl	%r9d
	movl	%edx, 240016(%rcx,%rbp,4)
	incl	%eax
	addq	$8, %r8
	cmpl	%r12d, %r9d
	jne	.L674
.L910:
	movq	56(%rsp), %r10
	incl	%esi
	addq	$8, %r10
	addq	$24, %r11
	cmpl	24(%rsp), %esi
	jne	.L675
.L907:
	movl	%r13d, 120240016(%rcx)
.L654:
	movl	12(%rsp), %r9d
	testl	%r9d, %r9d
	je	.L676
	vmovsd	.LC80(%rip), %xmm0
	vcomisd	240000+for_(%rip), %xmm0
	ja	.L677
.L676:
	movl	40+kier_(%rip), %eax
	movl	%eax, 24(%rsp)
	testl	%eax, %eax
	je	.L678
	vmovsd	.LC80(%rip), %xmm0
	vcomisd	240008+for_(%rip), %xmm0
	ja	.L677
.L678:
	movl	44+kier_(%rip), %eax
	movl	%eax, 16(%rsp)
	testl	%eax, %eax
	jne	.L679
.L682:
	movl	28(%rsp), %r8d
	testl	%r8d, %r8d
	jle	.L653
	leaq	cmap_(%rip), %rax
	movl	60000004(%rax), %r13d
	movl	66000008(%rax), %eax
	vmovsd	240040+for_(%rip), %xmm6
	movl	%eax, 144(%rsp)
	movl	160004+bon_(%rip), %eax
	vmovsd	%xmm6, 32(%rsp)
	movl	%eax, 220(%rsp)
	movl	80032+ssb_(%rip), %eax
	movq	$1, 40(%rsp)
	movl	%eax, 124(%rsp)
	movl	10004072+nmapi_(%rip), %eax
	movl	$0, 100(%rsp)
	movl	%eax, 128(%rsp)
	movslq	120(%rsp), %rax
	movl	$0, 72(%rsp)
	imulq	$15000000, %rax, %rax
	movl	$1, 192(%rsp)
	vmovsd	240024+for_(%rip), %xmm11
	movq	%rax, 208(%rsp)
	movslq	96(%rsp), %rax
	vmovsd	240000+for_(%rip), %xmm10
	imulq	$15000000, %rax, %rax
	movl	$0, 96(%rsp)
	vmovsd	240032+for_(%rip), %xmm9
	movq	%rax, 136(%rsp)
	movl	32+ssb2_(%rip), %eax
	vmovsd	240008+for_(%rip), %xmm8
	movl	%eax, 204(%rsp)
	movl	80032+misc_(%rip), %eax
	vmovsd	240016+for_(%rip), %xmm6
	movl	%eax, 200(%rsp)
	leaq	40000+sequence_(%rip), %rax
	movq	%rax, 64(%rsp)
	movl	28(%rsp), %eax
	leaq	pos_(%rip), %r11
	incl	%eax
	movq	%rax, 152(%rsp)
	movl	$2, 120(%rsp)
	vmovsd	.LC11(%rip), %xmm13
	movl	$1, %ebx
	.p2align 4,,10
	.p2align 3
.L743:
	movl	120(%rsp), %edi
	movq	40(%rsp), %rsi
	leal	-1(%rdi), %ecx
	movslq	%ecx, %rax
	leaq	bon_(%rip), %r15
	movl	%esi, 80(%rsp)
	movl	%esi, %r14d
	movl	%esi, %edx
	cmpl	%esi, 120000(%r15,%rax,4)
	jge	.L684
	leal	1(%rdi), %eax
	movl	%eax, 120(%rsp)
	movl	%edi, %ecx
.L684:
	movq	40(%rsp), %r15
	movl	80(%rsp), %esi
	leaq	79996+bon_(%rip), %rdi
	movl	(%rdi,%r15,4), %edi
	leal	1(%rsi), %eax
	movl	%eax, 56(%rsp)
	testl	%edi, %edi
	je	.L685
	movl	%esi, %edi
	leal	2(%rsi), %eax
	leaq	80000+bon_(%rip), %rsi
	movl	(%rsi,%r15,4), %r12d
	testl	%r12d, %r12d
	je	.L685
	leal	3(%rdi), %eax
.L685:
	cmpl	28(%rsp), %eax
	jg	.L687
	movslq	%ecx, %rcx
	leaq	bon_(%rip), %rsi
	movl	120000(%rsi,%rcx,4), %esi
	movq	160(%rsp), %rdi
	movl	%esi, 48(%rsp)
	movl	(%rdi), %r12d
	cmpl	%eax, %esi
	jge	.L901
	leaq	sequence_(%rip), %rbp
.L688:
	cltq
	leaq	pos_(%rip), %rdi
	leaq	0(%rbp,%rax,4), %rsi
	leaq	(%rdi,%rax,8), %rcx
	jmp	.L742
	.p2align 4,,10
	.p2align 3
.L715:
	incq	%rax
	addq	$4, %rsi
	addq	$8, %rcx
	cmpl	%eax, 28(%rsp)
	jl	.L687
.L742:
	cmpl	%eax, %r14d
	movl	%eax, %r8d
	cmovge	%r14d, %r8d
	movl	%eax, %r9d
	movl	%eax, %edi
	cmpl	%r8d, %r12d
	jg	.L715
	vmovsd	(%r11), %xmm1
	vmovsd	80000(%r11), %xmm2
	vmovsd	160000(%r11), %xmm0
	movl	12(%rsp), %r15d
	vsubsd	-8(%rcx), %xmm1, %xmm1
	vsubsd	79992(%rcx), %xmm2, %xmm2
	vsubsd	159992(%rcx), %xmm0, %xmm0
	testl	%r15d, %r15d
	je	.L716
	vmulsd	%xmm1, %xmm11, %xmm5
	vmovsd	.LC60(%rip), %xmm4
	vandpd	%xmm5, %xmm13, %xmm12
	vorpd	%xmm12, %xmm4, %xmm4
	vaddsd	%xmm5, %xmm4, %xmm4
	vcvttsd2sil	%xmm4, %r8d
	vcvtsi2sdl	%r8d, %xmm3, %xmm4
	vfnmadd231sd	%xmm4, %xmm10, %xmm1
.L716:
	movl	24(%rsp), %ebp
	testl	%ebp, %ebp
	je	.L717
	vmulsd	%xmm2, %xmm9, %xmm5
	vmovsd	.LC60(%rip), %xmm4
	vandpd	%xmm5, %xmm13, %xmm12
	vorpd	%xmm12, %xmm4, %xmm4
	vaddsd	%xmm5, %xmm4, %xmm4
	vcvttsd2sil	%xmm4, %r8d
	vcvtsi2sdl	%r8d, %xmm3, %xmm4
	vfnmadd231sd	%xmm4, %xmm8, %xmm2
.L717:
	movl	16(%rsp), %r10d
	testl	%r10d, %r10d
	je	.L718
	vmulsd	32(%rsp), %xmm0, %xmm5
	vmovsd	.LC60(%rip), %xmm4
	vandpd	%xmm5, %xmm13, %xmm12
	vorpd	%xmm12, %xmm4, %xmm4
	vaddsd	%xmm5, %xmm4, %xmm4
	vcvttsd2sil	%xmm4, %r8d
	vcvtsi2sdl	%r8d, %xmm3, %xmm4
	vfnmadd231sd	%xmm4, %xmm6, %xmm0
.L718:
	vmulsd	%xmm2, %xmm2, %xmm2
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vcomisd	%xmm0, %xmm7
	jbe	.L715
	cmpl	%ebx, %r13d
	jl	.L739
	movslq	%ebx, %r8
	leaq	cmap_(%rip), %r15
	leaq	(%r8,%r8,2), %r8
	leaq	(%r15,%r8,4), %r8
	movl	%eax, %r15d
	.p2align 4,,10
	.p2align 3
.L740:
	cmpl	%edx, 59999996(%r8)
	jl	.L737
	movl	60000000(%r8), %r10d
	sete	%bpl
	movzbl	%bpl, %ebp
	cmpl	%eax, %r10d
	jge	.L755
	testl	%ebp, %ebp
	je	.L755
.L737:
	incl	%ebx
	addq	$12, %r8
	cmpl	%ebx, %r13d
	jge	.L740
.L739:
	movl	%eax, %r15d
	cmpl	%eax, 56(%rsp)
	je	.L721
	movq	64(%rsp), %r10
	movl	39996(%rsi), %r8d
	movl	(%r10), %r10d
	movl	%r8d, 88(%rsp)
	cmpl	%eax, 48(%rsp)
	jl	.L722
	movl	144(%rsp), %r8d
	testl	%r8d, %r8d
	je	.L723
	subl	80(%rsp), %r9d
	movl	%r9d, %r8d
	sarl	$31, %r8d
	xorl	%r8d, %r9d
	subl	%r8d, %r9d
	cmpl	$4, %r9d
	je	.L912
.L722:
	xorl	%r9d, %r9d
	cmpl	$4, 88(%rsp)
	sete	%r9b
	xorl	%r8d, %r8d
	cmpl	$4, %r10d
	sete	%r8b
	andl	%r9d, %r8d
	je	.L725
	movl	124(%rsp), %r9d
	testl	%r9d, %r9d
	jne	.L721
.L725:
	incl	72(%rsp)
	movq	136(%rsp), %rbp
	movslq	72(%rsp), %r9
	leaq	-15000001(%rbp,%r9), %r9
	salq	$2, %r9
	leaq	1(%r9), %rbp
	movq	%rbp, 176(%rsp)
	leaq	2(%r9), %rbp
	movq	%rbp, 168(%rsp)
	leaq	3(%r9), %rbp
	movq	%rbp, 112(%rsp)
	movl	128(%rsp), %ebp
	testl	%ebp, %ebp
	je	.L913
	leaq	cmp2_(%rip), %rbp
	movl	%r14d, 60000008(%rbp,%r9,4)
	movl	%edi, 60000012(%rbp,%r9,4)
	movl	$0, 60000016(%rbp,%r9,4)
	leal	(%r10,%r10,4), %ebp
	leal	(%r10,%rbp,4), %r10d
	addl	88(%rsp), %r10d
	negl	%r10d
	leaq	cmp2_(%rip), %rbp
	movl	%r10d, 60000020(%rbp,%r9,4)
	movl	204(%rsp), %r10d
	testl	%r10d, %r10d
	je	.L721
.L724:
	testl	%r8d, %r8d
	je	.L731
	movl	124(%rsp), %ebp
	testl	%ebp, %ebp
	je	.L731
	movslq	96(%rsp), %r8
	vmovd	%r14d, %xmm5
	vpinsrd	$1, %edi, %xmm5, %xmm0
	leal	1(%r8), %r9d
	leaq	cmp2_(%rip), %rdi
	leaq	(%r8,%r8,2), %r8
	vmovq	%xmm0, 4(%rdi,%r8,4)
	cmpl	%r15d, 48(%rsp)
	jl	.L735
	movl	$-3, 12(%rdi,%r8,4)
	movl	%r9d, 96(%rsp)
	jmp	.L715
	.p2align 4,,10
	.p2align 3
.L915:
	movq	112(%rsp), %rbp
	cmpl	%eax, 28(%rsp)
	jge	.L688
	.p2align 4,,10
	.p2align 3
.L687:
	incq	40(%rsp)
	addq	$4, 64(%rsp)
	addq	$8, %r11
	movq	40(%rsp), %rax
	cmpq	152(%rsp), %rax
	jne	.L743
	movl	96(%rsp), %eax
	movl	72(%rsp), %esi
	movl	%eax, cmp2_(%rip)
	leaq	cmp2_(%rip), %rax
	movl	%esi, 60000004(%rax)
	movl	100(%rsp), %eax
	movl	%eax, cmap_(%rip)
.L653:
	movq	760(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L914
	addq	$776, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L901:
	.cfi_restore_state
	movl	28(%rsp), %r15d
	movslq	%eax, %rcx
	cmpl	%r15d, %esi
	vmovsd	.LC11(%rip), %xmm12
	cmovle	%esi, %r15d
	leaq	sequence_(%rip), %rbp
	leaq	0(,%rcx,4), %rsi
	leaq	sdch_(%rip), %r8
	leaq	pos_(%rip), %r10
	leaq	0(%rbp,%rsi), %rdi
	movq	%rbp, 112(%rsp)
	addq	%r8, %rsi
	leaq	(%r10,%rcx,8), %rcx
	vmovsd	%xmm12, %xmm12, %xmm5
	jmp	.L714
	.p2align 4,,10
	.p2align 3
.L689:
	incl	%eax
	addq	$4, %rdi
	addq	$4, %rsi
	addq	$8, %rcx
	cmpl	%r15d, %eax
	jg	.L915
.L714:
	cmpl	%r14d, %eax
	movl	%r14d, %r8d
	cmovge	%eax, %r8d
	cmpl	%r12d, %r8d
	jl	.L689
	vmovsd	(%r11), %xmm1
	vmovsd	80000(%r11), %xmm2
	vmovsd	160000(%r11), %xmm0
	movl	12(%rsp), %ebp
	vsubsd	-8(%rcx), %xmm1, %xmm1
	vsubsd	79992(%rcx), %xmm2, %xmm2
	vsubsd	159992(%rcx), %xmm0, %xmm0
	testl	%ebp, %ebp
	je	.L690
	vmulsd	%xmm1, %xmm11, %xmm14
	vmovsd	.LC60(%rip), %xmm4
	vandpd	%xmm14, %xmm5, %xmm15
	vorpd	%xmm15, %xmm4, %xmm4
	vaddsd	%xmm14, %xmm4, %xmm4
	vcvttsd2sil	%xmm4, %r8d
	vcvtsi2sdl	%r8d, %xmm3, %xmm4
	vfnmadd231sd	%xmm10, %xmm4, %xmm1
.L690:
	movl	24(%rsp), %r10d
	testl	%r10d, %r10d
	je	.L691
	vmulsd	%xmm2, %xmm9, %xmm14
	vmovsd	.LC60(%rip), %xmm4
	vandpd	%xmm14, %xmm5, %xmm15
	vorpd	%xmm15, %xmm4, %xmm4
	vaddsd	%xmm14, %xmm4, %xmm4
	vcvttsd2sil	%xmm4, %r8d
	vcvtsi2sdl	%r8d, %xmm3, %xmm4
	vfnmadd231sd	%xmm8, %xmm4, %xmm2
.L691:
	movl	16(%rsp), %r9d
	testl	%r9d, %r9d
	je	.L692
	vmulsd	32(%rsp), %xmm0, %xmm14
	vmovsd	.LC60(%rip), %xmm4
	vandpd	%xmm14, %xmm12, %xmm15
	vorpd	%xmm15, %xmm4, %xmm4
	vaddsd	%xmm14, %xmm4, %xmm4
	vcvttsd2sil	%xmm4, %r8d
	vcvtsi2sdl	%r8d, %xmm3, %xmm4
	vfnmadd231sd	%xmm6, %xmm4, %xmm0
.L692:
	vmulsd	%xmm2, %xmm2, %xmm2
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vcomisd	%xmm0, %xmm7
	jbe	.L689
	cmpl	%ebx, %r13d
	jl	.L694
	movslq	%ebx, %r8
	leaq	(%r8,%r8,2), %r8
	leaq	cmap_(%rip), %r10
	leaq	(%r10,%r8,4), %r8
	.p2align 4,,10
	.p2align 3
.L697:
	cmpl	%edx, 59999996(%r8)
	jl	.L695
	movl	60000000(%r8), %r9d
	sete	%r10b
	movzbl	%r10b, %r10d
	cmpl	%eax, %r9d
	jge	.L696
	testl	%r10d, %r10d
	je	.L696
.L695:
	incl	%ebx
	addq	$12, %r8
	cmpl	%ebx, %r13d
	jge	.L697
.L694:
	cmpl	%eax, 56(%rsp)
	je	.L698
	movq	64(%rsp), %r10
	movl	39996(%rdi), %r9d
	movl	(%r10), %r10d
	movl	%r9d, 88(%rsp)
	cmpl	%eax, 48(%rsp)
	jl	.L699
	movl	144(%rsp), %r8d
	testl	%r8d, %r8d
	je	.L700
	movl	%eax, %r8d
	subl	80(%rsp), %r8d
	movl	%r8d, %r9d
	sarl	$31, %r9d
	xorl	%r9d, %r8d
	subl	%r9d, %r8d
	cmpl	$4, %r8d
	je	.L916
.L699:
	xorl	%r9d, %r9d
	cmpl	$4, %r10d
	sete	%r9b
	xorl	%r8d, %r8d
	cmpl	$4, 88(%rsp)
	sete	%r8b
	andl	%r9d, %r8d
	je	.L701
	movl	124(%rsp), %r9d
	testl	%r9d, %r9d
	jne	.L698
.L701:
	incl	72(%rsp)
	movq	136(%rsp), %rbp
	movslq	72(%rsp), %r9
	leaq	-15000001(%rbp,%r9), %r9
	salq	$2, %r9
	leaq	1(%r9), %rbp
	movq	%rbp, 184(%rsp)
	leaq	2(%r9), %rbp
	movq	%rbp, 168(%rsp)
	leaq	3(%r9), %rbp
	movq	%rbp, 176(%rsp)
	movl	128(%rsp), %ebp
	testl	%ebp, %ebp
	je	.L917
	leaq	cmp2_(%rip), %rbp
	movl	%r14d, 60000008(%rbp,%r9,4)
	movl	%eax, 60000012(%rbp,%r9,4)
	movl	$0, 60000016(%rbp,%r9,4)
	leal	(%r10,%r10,4), %ebp
	leal	(%r10,%rbp,4), %r10d
	addl	88(%rsp), %r10d
	leaq	cmp2_(%rip), %rbp
	movl	%r10d, 60000020(%rbp,%r9,4)
	movl	204(%rsp), %r9d
	testl	%r9d, %r9d
	je	.L698
.L709:
	testl	%r8d, %r8d
	je	.L707
	movl	124(%rsp), %r8d
	testl	%r8d, %r8d
	je	.L707
	movslq	96(%rsp), %r8
	vmovd	%r14d, %xmm1
	leal	1(%r8), %r9d
	vpinsrd	$1, %eax, %xmm1, %xmm0
	leaq	(%r8,%r8,2), %r8
	leaq	cmp2_(%rip), %r10
	vmovq	%xmm0, 4(%r10,%r8,4)
	cmpl	%eax, 48(%rsp)
	jge	.L712
	movl	$-2, 12(%r10,%r8,4)
	movl	%r9d, 96(%rsp)
	jmp	.L689
	.p2align 4,,10
	.p2align 3
.L707:
	vmovsd	104(%rsp), %xmm2
	vcomisd	%xmm0, %xmm2
	jbe	.L689
	movslq	100(%rsp), %r8
	leaq	cmap_(%rip), %r10
	movq	%r8, %r9
	leaq	(%r8,%r8,2), %r8
	movl	%r14d, 4(%r10,%r8,4)
	movl	%eax, 8(%r10,%r8,4)
	movl	$0, 12(%r10,%r8,4)
	leal	1(%r9), %r10d
	movl	%r10d, 100(%rsp)
	jmp	.L689
	.p2align 4,,10
	.p2align 3
.L731:
	vmovsd	104(%rsp), %xmm5
	vcomisd	%xmm0, %xmm5
	jbe	.L715
	movslq	100(%rsp), %r8
	leaq	cmap_(%rip), %r15
	movq	%r8, %r10
	leaq	(%r8,%r8,2), %r8
	movl	%edi, 8(%r15,%r8,4)
	leal	1(%r10), %edi
	movl	%r14d, 4(%r15,%r8,4)
	movl	$0, 12(%r15,%r8,4)
	movl	%edi, 100(%rsp)
	jmp	.L715
.L912:
	movl	220(%rsp), %ebp
	testl	%ebp, %ebp
	jne	.L722
	.p2align 4,,10
	.p2align 3
.L721:
	movl	200(%rsp), %r8d
	testl	%r8d, %r8d
	je	.L731
	movq	40(%rsp), %r9
	leaq	356+sdch_(%rip), %r10
	cmpl	$2, (%r10,%r9,4)
	jle	.L905
	leaq	356+sdch_(%rip), %r9
	cmpl	$2, (%r9,%rax,4)
	jle	.L905
	movslq	96(%rsp), %r8
	vmovd	%r14d, %xmm5
	vpinsrd	$1, %edi, %xmm5, %xmm0
	leal	1(%r8), %r9d
	leaq	cmp2_(%rip), %rdi
	leaq	(%r8,%r8,2), %r8
	vmovq	%xmm0, 4(%rdi,%r8,4)
	cmpl	%r15d, 48(%rsp)
	jl	.L734
	movl	$-5, 12(%rdi,%r8,4)
	movl	%r9d, 96(%rsp)
	jmp	.L715
.L916:
	movl	220(%rsp), %ebp
	testl	%ebp, %ebp
	jne	.L699
	.p2align 4,,10
	.p2align 3
.L698:
	movl	200(%rsp), %r9d
	testl	%r9d, %r9d
	je	.L707
	movq	40(%rsp), %r9
	leaq	356+sdch_(%rip), %r10
	cmpl	$2, (%r10,%r9,4)
	jle	.L904
	cmpl	$2, 356(%rsi)
	jle	.L904
	movslq	96(%rsp), %r8
	vmovd	%r14d, %xmm2
	leal	1(%r8), %r9d
	vpinsrd	$1, %eax, %xmm2, %xmm0
	leaq	(%r8,%r8,2), %r8
	leaq	cmp2_(%rip), %r10
	vmovq	%xmm0, 4(%r10,%r8,4)
	cmpl	%eax, 48(%rsp)
	jl	.L918
	leaq	cmp2_(%rip), %r10
	movl	$-5, 12(%r10,%r8,4)
	movl	%r9d, 96(%rsp)
	jmp	.L689
	.p2align 4,,10
	.p2align 3
.L755:
	cmpl	%r10d, %r15d
	jne	.L739
	testl	%ebp, %ebp
	je	.L739
	movslq	96(%rsp), %r8
	vmovd	%r14d, %xmm5
	movq	%r8, %r15
	vpinsrd	$1, %edi, %xmm5, %xmm0
	leaq	(%r8,%r8,2), %r8
	leaq	cmp2_(%rip), %rdi
	movl	%ebx, 12(%rdi,%r8,4)
	vmovq	%xmm0, 4(%rdi,%r8,4)
	leal	1(%r15), %edi
	movl	%edi, 96(%rsp)
	incl	%ebx
	jmp	.L715
	.p2align 4,,10
	.p2align 3
.L696:
	cmpl	%eax, %r9d
	jne	.L694
	testl	%r10d, %r10d
	je	.L694
	movslq	96(%rsp), %r8
	vmovd	%r14d, %xmm2
	leaq	cmp2_(%rip), %r9
	movq	%r8, %r10
	vpinsrd	$1, %eax, %xmm2, %xmm0
	leaq	(%r8,%r8,2), %r8
	movl	%ebx, 12(%r9,%r8,4)
	vmovq	%xmm0, 4(%r9,%r8,4)
	leal	1(%r10), %r9d
	movl	%r9d, 96(%rsp)
	incl	%ebx
	jmp	.L689
	.p2align 4,,10
	.p2align 3
.L723:
	xorl	%r8d, %r8d
	cmpl	$4, 88(%rsp)
	sete	%r8b
	xorl	%r9d, %r9d
	cmpl	$4, %r10d
	sete	%r9b
	andl	%r9d, %r8d
	jmp	.L724
	.p2align 4,,10
	.p2align 3
.L700:
	xorl	%r8d, %r8d
	cmpl	$4, %r10d
	sete	%r8b
	xorl	%r9d, %r9d
	cmpl	$4, 88(%rsp)
	sete	%r9b
	andl	%r9d, %r8d
	jmp	.L709
	.p2align 4,,10
	.p2align 3
.L904:
	movq	64(%rsp), %r9
	cmpl	$4, (%r9)
	sete	%r9b
	xorl	%r8d, %r8d
	cmpl	$4, 39996(%rdi)
	movzbl	%r9b, %r9d
	sete	%r8b
	andl	%r9d, %r8d
	jmp	.L709
	.p2align 4,,10
	.p2align 3
.L905:
	movq	64(%rsp), %r10
	xorl	%r9d, %r9d
	cmpl	$4, 39996(%rsi)
	sete	%r9b
	xorl	%r8d, %r8d
	cmpl	$4, (%r10)
	sete	%r8b
	andl	%r9d, %r8d
	jmp	.L724
.L917:
	movl	216(%rsp), %ebp
	movl	192(%rsp), %r10d
	cmpl	%r10d, %ebp
	jl	.L703
	movslq	%r10d, %r8
	addq	208(%rsp), %r8
	movl	%r13d, 88(%rsp)
	movq	%rcx, 192(%rsp)
	salq	$2, %r8
	movl	%ebp, %ecx
	movl	%r10d, %r13d
	.p2align 4,,10
	.p2align 3
.L706:
	leaq	cmp2_(%rip), %rbp
	leaq	0(,%r8,4), %r10
	cmpl	%edx, -180000008(%rbp,%r8,4)
	jl	.L704
	movl	-180000004(%rbp,%r10), %r10d
	sete	%bpl
	movzbl	%bpl, %ebp
	cmpl	%eax, %r10d
	jge	.L705
	testl	%ebp, %ebp
	je	.L705
.L704:
	incl	%r13d
	addq	$4, %r8
	cmpl	%r13d, %ecx
	jge	.L706
	movq	192(%rsp), %rcx
	movl	%r13d, 192(%rsp)
	movl	88(%rsp), %r13d
.L703:
	leaq	cmp2_(%rip), %r10
	movl	%r14d, 60000008(%r10,%r9,4)
	movq	184(%rsp), %r9
	movl	%eax, 60000008(%r10,%r9,4)
	movq	168(%rsp), %r9
	movl	$0, 60000008(%r10,%r9,4)
	movq	176(%rsp), %r9
	movl	$1, 60000008(%r10,%r9,4)
	jmp	.L689
.L913:
	movl	216(%rsp), %ebp
	movl	192(%rsp), %r10d
	cmpl	%r10d, %ebp
	jl	.L727
	movslq	%r10d, %r8
	addq	208(%rsp), %r8
	movl	%r13d, 88(%rsp)
	movq	%rax, 184(%rsp)
	salq	$2, %r8
	movl	%r10d, %r13d
	movl	%ebp, %eax
	.p2align 4,,10
	.p2align 3
.L730:
	leaq	cmp2_(%rip), %rbp
	leaq	0(,%r8,4), %r10
	cmpl	%edx, -180000008(%rbp,%r8,4)
	jl	.L728
	movl	-180000004(%rbp,%r10), %r10d
	sete	%bpl
	movzbl	%bpl, %ebp
	cmpl	%r10d, %r15d
	jle	.L753
	testl	%ebp, %ebp
	je	.L753
.L728:
	incl	%r13d
	addq	$4, %r8
	cmpl	%r13d, %eax
	jge	.L730
	movl	%r13d, 192(%rsp)
	movq	184(%rsp), %rax
	movl	88(%rsp), %r13d
.L727:
	leaq	cmp2_(%rip), %r15
	movl	%r14d, 60000008(%r15,%r9,4)
	movq	176(%rsp), %r9
	movl	%edi, 60000008(%r15,%r9,4)
	movq	168(%rsp), %rdi
	movl	$0, 60000008(%r15,%rdi,4)
	movq	112(%rsp), %rdi
	movl	$-1, 60000008(%r15,%rdi,4)
	jmp	.L715
.L735:
	leaq	cmp2_(%rip), %rdi
	movl	$-2, 12(%rdi,%r8,4)
	movl	%r9d, 96(%rsp)
	jmp	.L715
.L712:
	leaq	cmp2_(%rip), %r10
	movl	$-3, 12(%r10,%r8,4)
	movl	%r9d, 96(%rsp)
	jmp	.L689
.L679:
	vmovsd	.LC80(%rip), %xmm0
	vcomisd	240016+for_(%rip), %xmm0
	jbe	.L682
.L677:
	leaq	.LC2(%rip), %rax
	leaq	224(%rsp), %rbp
	movq	%rax, 232(%rsp)
	movl	$33554433, %eax
	salq	$7, %rax
	movq	%rbp, %rdi
	movq	%rax, 224(%rsp)
	movl	$4264, 240(%rsp)
	call	_gfortran_st_write@PLT
	movl	$22, %edx
	leaq	.LC81(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
	.p2align 4,,10
	.p2align 3
.L918:
	movl	$-4, 12(%r10,%r8,4)
	movl	%r9d, 96(%rsp)
	jmp	.L689
.L734:
	leaq	cmp2_(%rip), %rdi
	movl	$-4, 12(%rdi,%r8,4)
	movl	%r9d, 96(%rsp)
	jmp	.L715
.L705:
	movq	192(%rsp), %rcx
	movl	%r13d, 192(%rsp)
	movl	88(%rsp), %r13d
	cmpl	%eax, %r10d
	jne	.L703
	testl	%ebp, %ebp
	je	.L703
	vmovd	%r14d, %xmm2
	leaq	cmp2_(%rip), %r10
	vpinsrd	$1, %eax, %xmm2, %xmm0
	vmovq	%xmm0, 60000008(%r10,%r9,4)
	movl	-180000000(%r10,%r8,4), %r9d
	movq	168(%rsp), %rbp
	incl	192(%rsp)
	movl	%r9d, 60000008(%r10,%rbp,4)
	movq	176(%rsp), %rbp
	movl	-179999996(%r10,%r8,4), %r8d
	movl	%r8d, 60000008(%r10,%rbp,4)
	jmp	.L689
.L753:
	movl	%r13d, 192(%rsp)
	movq	184(%rsp), %rax
	movl	88(%rsp), %r13d
	cmpl	%r10d, %r15d
	jne	.L727
	testl	%ebp, %ebp
	je	.L727
	vmovd	%r14d, %xmm5
	leaq	cmp2_(%rip), %r15
	vpinsrd	$1, %edi, %xmm5, %xmm0
	vmovq	%xmm0, 60000008(%r15,%r9,4)
	movl	-180000000(%r15,%r8,4), %edi
	movq	168(%rsp), %r9
	incl	192(%rsp)
	movl	%edi, 60000008(%r15,%r9,4)
	movq	112(%rsp), %r9
	movl	-179999996(%r15,%r8,4), %edi
	movl	%edi, 60000008(%r15,%r9,4)
	jmp	.L715
.L914:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE17:
	.size	update_verlet_list_, .-update_verlet_list_
	.p2align 4
	.globl	vafm_
	.type	vafm_, @function
vafm_:
.LFB18:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	movl	60+wal_(%rip), %r9d
	movq	%rdi, %r11
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	movq	%rsi, %r12
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	movq	%rdx, %rbp
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	movq	$0x000000000, (%rdi)
	movq	$0x000000000, (%rsi)
	testl	%r9d, %r9d
	je	.L920
	movl	36+bas_(%rip), %r8d
	vxorps	%xmm12, %xmm12, %xmm12
	testl	%r8d, %r8d
	je	.L921
	leaq	verl_(%rip), %rcx
	movl	120240016(%rcx), %edx
	testl	%edx, %edx
	jle	.L989
	vmovsd	240008+for_(%rip), %xmm4
	vmovsd	80000+misc_(%rip), %xmm6
	vmovsd	%xmm4, -40(%rsp)
	vmovsd	wal_(%rip), %xmm4
	vcvttsd2sil	%xmm6, %r14d
	vmovsd	%xmm4, -96(%rsp)
	vmovsd	.LC8(%rip), %xmm4
	vmovsd	24+kier_(%rip), %xmm7
	vdivsd	%xmm6, %xmm4, %xmm6
	vmovq	.LC11(%rip), %xmm11
	movl	120240020(%rcx), %eax
	vxorpd	%xmm11, %xmm7, %xmm5
	vmovsd	%xmm5, -32(%rsp)
	vmovsd	240024+for_(%rip), %xmm5
	movl	%eax, %r10d
	vmovsd	%xmm5, -64(%rsp)
	vmovsd	240000+for_(%rip), %xmm5
	shrl	$31, %r10d
	addl	%eax, %r10d
	vmovsd	%xmm5, -56(%rsp)
	movl	48+wal_(%rip), %eax
	vmovsd	240032+for_(%rip), %xmm5
	movl	%eax, -24(%rsp)
	vmovsd	%xmm5, -48(%rsp)
	movl	44+wal_(%rip), %eax
	vmovsd	64+sig_(%rip), %xmm5
	movl	%eax, -16(%rsp)
	vmovsd	%xmm5, -88(%rsp)
	leaq	cmp2_(%rip), %rax
	vmulsd	cmapi_(%rip), %xmm5, %xmm5
	movslq	540000008(%rax), %rax
	decl	%edx
	imulq	$15000000, %rax, %rax
	vmovsd	0(%rbp), %xmm15
	movl	40+kier_(%rip), %r8d
	vmovsd	%xmm5, -104(%rsp)
	leaq	(%rdx,%rdx,2), %rdx
	vmovsd	.LC83(%rip), %xmm5
	leaq	(%rcx,%rax,4), %rsi
	vxorpd	%xmm13, %xmm13, %xmm13
	addq	%rdx, %rax
	sarl	%r10d
	leaq	12(%rcx), %rdx
	vmulsd	240024+pull_(%rip), %xmm5, %xmm5
	movl	36+kier_(%rip), %r13d
	addl	8+bas_(%rip), %r10d
	vmovsd	%xmm6, -80(%rsp)
	vmovsd	%xmm15, %xmm15, %xmm9
	vmovsd	%xmm7, -72(%rsp)
	movq	%r12, %r15
	movq	%rbp, -8(%rsp)
	leaq	(%rdx,%rax,4), %rbx
	vmovsd	%xmm13, %xmm13, %xmm14
	leaq	pos_(%rip), %rcx
	leaq	for_(%rip), %rdi
	vmovsd	%xmm13, %xmm13, %xmm15
	movq	%r11, %r9
	movl	%r8d, %r12d
	jmp	.L937
	.p2align 4,,10
	.p2align 3
.L992:
	movl	%r11d, %ebp
	sarl	$31, %ebp
	xorl	%ebp, %r11d
	subl	%ebp, %r11d
	incl	%r11d
	cmpl	%r14d, %r11d
	movl	%r11d, %edx
	cmovg	%r14d, %edx
	movl	%edx, -59759976(%rsi)
	cmpl	%r8d, %r10d
	jle	.L929
	incl	-16(%rsp)
.L930:
	vdivsd	%xmm0, %xmm4, %xmm8
	vmovsd	-96(%rsp), %xmm7
	vcomisd	%xmm0, %xmm7
	vmulsd	-88(%rsp), %xmm8, %xmm1
	vmulsd	%xmm1, %xmm1, %xmm10
	vmulsd	%xmm1, %xmm10, %xmm1
	vmulsd	%xmm1, %xmm1, %xmm1
	vmulsd	-80(%rsp), %xmm1, %xmm10
	vmulsd	%xmm5, %xmm10, %xmm10
	jb	.L986
	vmulsd	%xmm1, %xmm5, %xmm10
.L934:
	vmovsd	.LC84(%rip), %xmm0
	vsubsd	%xmm13, %xmm3, %xmm3
	vfnmadd213sd	.LC85(%rip), %xmm1, %xmm0
	vsubsd	%xmm4, %xmm1, %xmm1
	vfmadd231sd	%xmm10, %xmm1, %xmm9
	vmulsd	%xmm8, %xmm0, %xmm0
	vmulsd	%xmm10, %xmm0, %xmm0
	vminsd	.LC82(%rip), %xmm0, %xmm0
	vmaxsd	.LC86(%rip), %xmm0, %xmm0
	vmulsd	%xmm8, %xmm0, %xmm8
	vxorpd	%xmm11, %xmm8, %xmm0
	vmulsd	%xmm2, %xmm0, %xmm2
	vmulsd	%xmm8, %xmm3, %xmm3
	vfnmadd213sd	80000(%rdi,%rax,8), %xmm6, %xmm8
	vaddsd	(%rdi,%rax,8), %xmm2, %xmm0
	vmovsd	%xmm8, 80000(%rdi,%rax,8)
	vmovsd	%xmm0, (%rdi,%rax,8)
	vaddsd	160000(%rdi,%rax,8), %xmm3, %xmm0
	vmovsd	%xmm0, 160000(%rdi,%rax,8)
	cmpl	%r8d, %r10d
	jle	.L935
	addq	$12, %rsi
	vaddsd	%xmm3, %xmm15, %xmm15
	vaddsd	%xmm2, %xmm14, %xmm14
	cmpq	%rsi, %rbx
	je	.L991
.L937:
	movl	-59759980(%rsi), %r8d
	movslq	-59759984(%rsi), %r11
	vmovsd	-72(%rsp), %xmm1
	cmpl	%r8d, %r10d
	jg	.L924
	vmovsd	-32(%rsp), %xmm1
.L924:
	leaq	-1(%r11), %rax
	vmovsd	(%rcx,%rax,8), %xmm0
	movslq	%r8d, %rdx
	vsubsd	-8(%rcx,%rdx,8), %xmm0, %xmm2
	vmovsd	79992(%rcx,%r11,8), %xmm6
	vmovsd	159992(%rcx,%r11,8), %xmm13
	vmovsd	159992(%rcx,%rdx,8), %xmm3
	vsubsd	%xmm1, %xmm2, %xmm2
	vsubsd	79992(%rcx,%rdx,8), %xmm6, %xmm6
	vsubsd	%xmm3, %xmm13, %xmm0
	testl	%r13d, %r13d
	je	.L925
	vmulsd	-64(%rsp), %xmm2, %xmm8
	vmovsd	.LC90(%rip), %xmm7
	vmovsd	.LC60(%rip), %xmm1
	vandpd	%xmm8, %xmm7, %xmm10
	vorpd	%xmm10, %xmm1, %xmm1
	vaddsd	%xmm8, %xmm1, %xmm1
	vcvttsd2sil	%xmm1, %edx
	vcvtsi2sdl	%edx, %xmm12, %xmm1
	vfnmadd231sd	-56(%rsp), %xmm1, %xmm2
.L925:
	testl	%r12d, %r12d
	je	.L926
	vmulsd	-48(%rsp), %xmm6, %xmm8
	vmovsd	.LC90(%rip), %xmm7
	vmovsd	.LC60(%rip), %xmm1
	vandpd	%xmm8, %xmm7, %xmm10
	vorpd	%xmm10, %xmm1, %xmm1
	vaddsd	%xmm8, %xmm1, %xmm1
	vcvttsd2sil	%xmm1, %edx
	vcvtsi2sdl	%edx, %xmm12, %xmm1
	vfnmadd231sd	-40(%rsp), %xmm1, %xmm6
.L926:
	vmulsd	%xmm0, %xmm0, %xmm0
	vmovsd	-104(%rsp), %xmm1
	movl	-59759976(%rsi), %r11d
	vfmadd231sd	%xmm2, %xmm2, %xmm0
	vfmadd231sd	%xmm6, %xmm6, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vcomisd	%xmm0, %xmm1
	jnb	.L992
	testl	%r11d, %r11d
	js	.L993
	movl	$1, %edx
	subl	%r11d, %edx
	cmpl	$0, %edx
	movl	$0, %r11d
	cmovg	%r11d, %edx
	movl	%edx, -59759976(%rsi)
	jmp	.L930
	.p2align 4,,10
	.p2align 3
.L921:
	movl	120004+respul_(%rip), %esi
	leaq	respul_(%rip), %r14
	addl	120000+respul_(%rip), %esi
	testl	%esi, %esi
	jle	.L989
	vmovsd	8+plates_(%rip), %xmm4
	vmovsd	hhar_(%rip), %xmm6
	vmovsd	%xmm4, -96(%rsp)
	vmovsd	plates_(%rip), %xmm4
	vcvtsi2sdl	4+equil_(%rip), %xmm12, %xmm0
	vmovsd	%xmm4, -32(%rsp)
	vaddsd	%xmm6, %xmm6, %xmm4
	vmovsd	24+kier_(%rip), %xmm10
	vmovq	.LC11(%rip), %xmm11
	vmovsd	%xmm4, -64(%rsp)
	vmovsd	.LC8(%rip), %xmm4
	vxorpd	%xmm11, %xmm10, %xmm5
	vdivsd	%xmm0, %xmm4, %xmm3
	vmovsd	%xmm5, -88(%rsp)
	vmovsd	8+hhar_(%rip), %xmm5
	movslq	16+equil_(%rip), %rcx
	vmovsd	%xmm5, -72(%rsp)
	vmovsd	240024+pull_(%rip), %xmm5
	leal	-1(%rsi), %edi
	vmovsd	%xmm5, -48(%rsp)
	movl	44+wal_(%rip), %r15d
	leaq	8(%r14), %rsi
	leaq	(%rsi,%rdi,8), %r10
	leaq	1(%rcx), %rdi
	movl	52+wal_(%rip), %eax
	movq	%rdi, -8(%rsp)
	movl	%r15d, -104(%rsp)
	movl	48+wal_(%rip), %r13d
	movl	56+wal_(%rip), %ebx
	movl	%eax, -56(%rsp)
	leaq	pull_(%rip), %rdx
	movq	%r14, %rax
	leaq	pos_(%rip), %r8
	leaq	for_(%rip), %r9
	vmovsd	%xmm3, -16(%rsp)
	vmovsd	80000+misc_(%rip), %xmm3
	vdivsd	%xmm3, %xmm4, %xmm7
	vmulsd	%xmm5, %xmm7, %xmm5
	vmovsd	%xmm7, -24(%rsp)
	vmovsd	%xmm5, -40(%rsp)
	vmovsd	64+sig_(%rip), %xmm5
	vmulsd	.LC87(%rip), %xmm5, %xmm7
	vmovsd	%xmm7, -80(%rsp)
	.p2align 4,,10
	.p2align 3
.L957:
	movl	120012(%rax), %esi
	testl	%esi, %esi
	je	.L939
	js	.L994
	vmovsd	-96(%rsp), %xmm7
	vmovsd	-88(%rsp), %xmm2
	vaddsd	160000(%rdx), %xmm7, %xmm0
	incl	%r13d
.L941:
	movslq	120016(%rax), %rdi
	vmovsd	159992(%r8,%rdi,8), %xmm8
	vmovsd	79992(%r8,%rdi,8), %xmm9
	vsubsd	%xmm0, %xmm8, %xmm8
	leaq	-1(%rdi), %rcx
	vsubsd	80000(%rdx), %xmm9, %xmm9
	vmulsd	%xmm8, %xmm8, %xmm7
	vmovsd	(%r8,%rcx,8), %xmm1
	vsubsd	(%rdx), %xmm1, %xmm1
	vfmadd231sd	%xmm9, %xmm9, %xmm7
	vsubsd	%xmm2, %xmm1, %xmm1
	vfmadd231sd	%xmm1, %xmm1, %xmm7
	vsqrtsd	%xmm7, %xmm7, %xmm14
	testl	%ebx, %ebx
	je	.L942
	vdivsd	%xmm14, %xmm5, %xmm0
	vmovsd	(%r14,%rcx,8), %xmm15
	vcomisd	-80(%rsp), %xmm14
	vmulsd	%xmm0, %xmm0, %xmm13
	vmulsd	%xmm0, %xmm13, %xmm13
	vmulsd	%xmm13, %xmm13, %xmm13
	vmulsd	%xmm13, %xmm15, %xmm0
	vsubsd	%xmm4, %xmm13, %xmm2
	vfnmadd132sd	.LC74(%rip), %xmm4, %xmm13
	vmulsd	-40(%rsp), %xmm0, %xmm0
	vmulsd	%xmm0, %xmm2, %xmm2
	vmulsd	.LC88(%rip), %xmm0, %xmm0
	vmulsd	.LC83(%rip), %xmm2, %xmm2
	vmulsd	%xmm13, %xmm0, %xmm0
	vdivsd	%xmm14, %xmm0, %xmm0
	jbe	.L987
	vxorpd	%xmm13, %xmm13, %xmm13
	vcomisd	%xmm13, %xmm15
	jbe	.L988
	vsubsd	%xmm4, %xmm15, %xmm15
	vmovsd	%xmm15, (%r14,%rcx,8)
	jmp	.L947
	.p2align 4,,10
	.p2align 3
.L942:
	vmulsd	-72(%rsp), %xmm7, %xmm0
	vmovsd	.LC83(%rip), %xmm15
	movl	-56(%rsp), %edi
	vaddsd	%xmm6, %xmm0, %xmm2
	vfmadd213sd	-64(%rsp), %xmm15, %xmm0
	vmulsd	%xmm7, %xmm2, %xmm2
	vmulsd	%xmm14, %xmm0, %xmm15
	testl	%edi, %edi
	je	.L949
	vmovsd	(%rax), %xmm0
	vcomisd	%xmm0, %xmm3
	jbe	.L950
	vaddsd	%xmm4, %xmm0, %xmm0
	vmovsd	%xmm0, (%rax)
.L950:
	vmovsd	-24(%rsp), %xmm13
	vmulsd	-48(%rsp), %xmm0, %xmm0
	vmulsd	%xmm13, %xmm2, %xmm2
	vmulsd	%xmm13, %xmm15, %xmm15
	vmulsd	%xmm0, %xmm2, %xmm2
	vmulsd	%xmm15, %xmm0, %xmm0
.L947:
	vcomisd	.LC89(%rip), %xmm7
	jbe	.L953
	vdivsd	%xmm14, %xmm0, %xmm0
	vmovsd	.LC86(%rip), %xmm15
	vmovsd	.LC82(%rip), %xmm7
	vcomisd	%xmm0, %xmm15
	ja	.L954
	vxorpd	%xmm11, %xmm0, %xmm7
	vmaxsd	%xmm15, %xmm7, %xmm7
.L954:
	vmulsd	%xmm7, %xmm1, %xmm1
	vmulsd	%xmm7, %xmm8, %xmm8
	vfmadd213sd	80000(%r9,%rcx,8), %xmm9, %xmm7
	vaddsd	(%r9,%rcx,8), %xmm1, %xmm0
	vmovsd	%xmm7, 80000(%r9,%rcx,8)
	vmovsd	%xmm0, (%r9,%rcx,8)
	vaddsd	160000(%r9,%rcx,8), %xmm8, %xmm0
	vmovsd	%xmm0, 160000(%r9,%rcx,8)
	testl	%esi, %esi
	jle	.L955
	vmovsd	(%r11), %xmm0
	vsubsd	%xmm8, %xmm0, %xmm8
	vmovsd	(%r12), %xmm0
	vsubsd	%xmm1, %xmm0, %xmm1
	vmovsd	%xmm8, (%r11)
	vmovsd	%xmm1, (%r12)
.L953:
	vaddsd	0(%rbp), %xmm2, %xmm2
	vmovsd	%xmm2, 0(%rbp)
.L939:
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%r10, %rax
	jne	.L957
	movl	-104(%rsp), %r15d
	vmovd	%r15d, %xmm6
	vpinsrd	$1, %r13d, %xmm6, %xmm0
	vmovq	%xmm0, 44+wal_(%rip)
.L989:
	popq	%rbx
	.cfi_remember_state
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L935:
	.cfi_restore_state
	addq	$12, %rsi
	vsubsd	%xmm3, %xmm15, %xmm15
	vsubsd	%xmm2, %xmm14, %xmm14
	cmpq	%rsi, %rbx
	jne	.L937
.L991:
	movq	-8(%rsp), %rbp
	vmovd	-16(%rsp), %xmm5
	vmovsd	%xmm14, %xmm14, %xmm13
	vmovsd	%xmm9, 0(%rbp)
	vmovsd	%xmm15, (%r9)
	vmovsd	%xmm13, (%r15)
	vpinsrd	$1, -24(%rsp), %xmm5, %xmm0
	popq	%rbx
	.cfi_remember_state
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	vmovq	%xmm0, 44+wal_(%rip)
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L986:
	.cfi_restore_state
	movl	%edx, %r11d
	sarl	$31, %r11d
	xorl	%r11d, %edx
	subl	%r11d, %edx
	vcvtsi2sdl	%edx, %xmm12, %xmm0
	vmulsd	%xmm10, %xmm0, %xmm10
	jmp	.L934
	.p2align 4,,10
	.p2align 3
.L929:
	incl	-24(%rsp)
	jmp	.L930
	.p2align 4,,10
	.p2align 3
.L920:
	movslq	120000+respul_(%rip), %rax
	leaq	pos_(%rip), %rcx
	leaq	nat_(%rip), %rdi
	leaq	9999(%rax), %rdx
	vmovsd	(%rcx,%rdx,8), %xmm15
	vmovsd	(%rdi,%rdx,8), %xmm3
	leaq	-1(%rax), %rsi
	vsubsd	%xmm3, %xmm15, %xmm2
	vmovsd	(%rcx,%rsi,8), %xmm13
	vmovsd	(%rdi,%rsi,8), %xmm11
	vmulsd	%xmm2, %xmm2, %xmm2
	vsubsd	%xmm11, %xmm13, %xmm1
	addq	$19999, %rax
	vmovsd	(%rcx,%rax,8), %xmm14
	vmovsd	(%rdi,%rax,8), %xmm12
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vsubsd	%xmm12, %xmm14, %xmm0
	vmovsd	8+hhar_(%rip), %xmm8
	vmovsd	240024+pull_(%rip), %xmm5
	vmovsd	hhar_(%rip), %xmm7
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vmovsd	.LC89(%rip), %xmm6
	vaddsd	%xmm7, %xmm7, %xmm9
	vmulsd	%xmm0, %xmm8, %xmm1
	vmulsd	%xmm0, %xmm5, %xmm10
	vcomisd	%xmm6, %xmm0
	vaddsd	%xmm7, %xmm1, %xmm4
	vfmadd213sd	0(%rbp), %xmm4, %xmm10
	vmovsd	%xmm10, 0(%rbp)
	jbe	.L958
	vfmadd132sd	.LC83(%rip), %xmm9, %xmm1
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vsubsd	%xmm15, %xmm3, %xmm3
	vsubsd	%xmm14, %xmm12, %xmm12
	vsubsd	%xmm13, %xmm11, %xmm11
	vmulsd	%xmm5, %xmm1, %xmm1
	leaq	for_(%rip), %rdi
	vmulsd	%xmm0, %xmm1, %xmm1
	vdivsd	%xmm0, %xmm1, %xmm0
	vfmadd213sd	(%rdi,%rsi,8), %xmm0, %xmm11
	vfmadd213sd	(%rdi,%rdx,8), %xmm0, %xmm3
	vfmadd213sd	(%rdi,%rax,8), %xmm12, %xmm0
	vmovsd	%xmm11, (%rdi,%rsi,8)
	vmovsd	%xmm3, (%rdi,%rdx,8)
	vmovsd	%xmm0, (%rdi,%rax,8)
.L958:
	movslq	120004+respul_(%rip), %rax
	vmovsd	80000+pull_(%rip), %xmm1
	leaq	9999(%rax), %rdx
	vaddsd	240008+pull_(%rip), %xmm1, %xmm1
	vmovsd	(%rcx,%rdx,8), %xmm12
	vmovsd	pull_(%rip), %xmm0
	vsubsd	%xmm1, %xmm12, %xmm14
	vaddsd	240000+pull_(%rip), %xmm0, %xmm0
	leaq	-1(%rax), %rsi
	vmulsd	%xmm14, %xmm14, %xmm14
	vmovsd	(%rcx,%rsi,8), %xmm13
	vmovsd	160000+pull_(%rip), %xmm2
	vsubsd	%xmm0, %xmm13, %xmm4
	vaddsd	240016+pull_(%rip), %xmm2, %xmm2
	addq	$19999, %rax
	vfmadd132sd	%xmm4, %xmm14, %xmm4
	vmovsd	(%rcx,%rax,8), %xmm11
	vmovsd	%xmm0, pull_(%rip)
	vsubsd	%xmm2, %xmm11, %xmm3
	vmovsd	%xmm1, 80000+pull_(%rip)
	vmovsd	%xmm2, 160000+pull_(%rip)
	vfmadd132sd	%xmm3, %xmm4, %xmm3
	vmulsd	%xmm3, %xmm8, %xmm8
	vcomisd	%xmm6, %xmm3
	vaddsd	%xmm8, %xmm7, %xmm4
	vmulsd	%xmm3, %xmm5, %xmm7
	vfmadd132sd	%xmm7, %xmm10, %xmm4
	vmovsd	%xmm4, 0(%rbp)
	jbe	.L989
	vfmadd132sd	.LC83(%rip), %xmm9, %xmm8
	vsqrtsd	%xmm3, %xmm3, %xmm3
	vsubsd	%xmm13, %xmm0, %xmm0
	vsubsd	%xmm12, %xmm1, %xmm1
	vsubsd	%xmm11, %xmm2, %xmm2
	vmulsd	%xmm8, %xmm5, %xmm5
	leaq	for_(%rip), %rcx
	vmovsd	16+kier_(%rip), %xmm4
	vmulsd	%xmm3, %xmm5, %xmm5
	vdivsd	%xmm3, %xmm5, %xmm3
	vmovsd	kier_(%rip), %xmm5
	vmulsd	%xmm3, %xmm0, %xmm0
	vmulsd	%xmm3, %xmm1, %xmm1
	vmulsd	%xmm3, %xmm2, %xmm3
	vaddsd	(%rcx,%rsi,8), %xmm0, %xmm2
	vmovsd	%xmm2, (%rcx,%rsi,8)
	vaddsd	(%rcx,%rdx,8), %xmm1, %xmm2
	vmulsd	8+kier_(%rip), %xmm1, %xmm1
	vmovsd	%xmm2, (%rcx,%rdx,8)
	vaddsd	(%rcx,%rax,8), %xmm3, %xmm2
	vfmadd231sd	%xmm0, %xmm5, %xmm1
	vmovsd	%xmm2, (%rcx,%rax,8)
	vmulsd	%xmm0, %xmm4, %xmm0
	vdivsd	%xmm5, %xmm4, %xmm2
	vfmadd231sd	%xmm3, %xmm4, %xmm1
	vmulsd	%xmm4, %xmm4, %xmm4
	vmovsd	%xmm1, (%r11)
	vdivsd	%xmm5, %xmm4, %xmm1
	vfmadd213sd	.LC8(%rip), %xmm2, %xmm2
	vdivsd	%xmm2, %xmm3, %xmm3
	vaddsd	%xmm5, %xmm1, %xmm1
	vdivsd	%xmm1, %xmm0, %xmm1
	vsubsd	%xmm3, %xmm1, %xmm1
	vmovsd	%xmm1, (%r12)
	popq	%rbx
	.cfi_remember_state
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L994:
	.cfi_restore_state
	vmovsd	-32(%rsp), %xmm7
	incl	-104(%rsp)
	vaddsd	160000(%rdx), %xmm7, %xmm0
	vmovsd	%xmm10, %xmm10, %xmm2
	jmp	.L941
	.p2align 4,,10
	.p2align 3
.L993:
	leal	1(%r11), %edx
	movl	%edx, -59759976(%rsi)
	jmp	.L930
	.p2align 4,,10
	.p2align 3
.L949:
	movq	-8(%rsp), %r15
	leaq	wal_(%rip), %rdi
	vcvtsi2ssl	(%rdi,%r15,4), %xmm12, %xmm13
	vcvtss2sd	%xmm13, %xmm13, %xmm0
	vmulsd	-48(%rsp), %xmm0, %xmm0
	vmulsd	-16(%rsp), %xmm0, %xmm0
	vmulsd	%xmm0, %xmm2, %xmm2
	vmulsd	%xmm0, %xmm15, %xmm0
	jmp	.L947
	.p2align 4,,10
	.p2align 3
.L987:
	vcomisd	%xmm15, %xmm3
	jbe	.L947
	vaddsd	%xmm4, %xmm15, %xmm13
	vmovsd	%xmm13, (%r14,%rcx,8)
	jmp	.L947
	.p2align 4,,10
	.p2align 3
.L955:
	je	.L953
	vaddsd	(%r11), %xmm8, %xmm8
	vaddsd	(%r12), %xmm1, %xmm1
	vmovsd	%xmm8, (%r11)
	vmovsd	%xmm1, (%r12)
	jmp	.L953
	.p2align 4,,10
	.p2align 3
.L988:
	movq	$0x000000000, (%r14,%rcx,8)
	xorl	%esi, %esi
	movl	$0, 120012(%rax)
	jmp	.L947
	.cfi_endproc
.LFE18:
	.size	vafm_, .-vafm_
	.p2align 4
	.globl	afm_
	.type	afm_, @function
afm_:
.LFB19:
	.cfi_startproc
	movslq	120000+respul_(%rip), %rax
	leaq	pos_(%rip), %rcx
	leaq	-1(%rax), %r8
	leaq	nat_(%rip), %rdx
	vmovsd	(%rcx,%r8,8), %xmm7
	vmovsd	(%rdx,%r8,8), %xmm4
	leaq	9999(%rax), %r8
	vmovsd	(%rcx,%r8,8), %xmm9
	vmovsd	(%rdx,%r8,8), %xmm3
	vsubsd	%xmm4, %xmm7, %xmm1
	vsubsd	%xmm3, %xmm9, %xmm2
	addq	$19999, %rax
	vmovsd	(%rcx,%rax,8), %xmm8
	vmulsd	%xmm2, %xmm2, %xmm2
	vmovsd	(%rdx,%rax,8), %xmm6
	vsubsd	%xmm6, %xmm8, %xmm0
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vmovsd	hhar_(%rip), %xmm2
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vmulsd	8+hhar_(%rip), %xmm0, %xmm1
	vcomisd	.LC89(%rip), %xmm0
	vaddsd	%xmm2, %xmm1, %xmm5
	vfmadd213sd	(%rsi), %xmm0, %xmm5
	vmovsd	%xmm5, (%rsi)
	jbe	.L996
	vaddsd	%xmm2, %xmm2, %xmm2
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vsubsd	%xmm9, %xmm3, %xmm3
	vfmadd132sd	.LC83(%rip), %xmm2, %xmm1
	vsubsd	%xmm8, %xmm6, %xmm6
	vsubsd	%xmm7, %xmm4, %xmm4
	vmulsd	%xmm0, %xmm1, %xmm1
	vdivsd	%xmm0, %xmm1, %xmm0
	vfmadd213sd	for_(%rip), %xmm0, %xmm4
	vfmadd213sd	80000+for_(%rip), %xmm0, %xmm3
	vfmadd213sd	160000+for_(%rip), %xmm6, %xmm0
	vmovsd	%xmm4, for_(%rip)
	vmovsd	%xmm3, 80000+for_(%rip)
	vmovsd	%xmm0, 160000+for_(%rip)
.L996:
	movslq	120004+respul_(%rip), %rdx
	vmovsd	(%rdi), %xmm0
	vmovsd	kier_(%rip), %xmm1
	leaq	for_(%rip), %rax
	vfmadd213sd	-8(%rax,%rdx,8), %xmm0, %xmm1
	vmovsd	159992(%rax,%rdx,8), %xmm7
	vmovsd	%xmm1, -8(%rax,%rdx,8)
	vmovsd	8+kier_(%rip), %xmm1
	vfmadd213sd	79992(%rax,%rdx,8), %xmm0, %xmm1
	vfmadd132sd	16+kier_(%rip), %xmm7, %xmm0
	vmovsd	%xmm1, 79992(%rax,%rdx,8)
	vmovsd	%xmm0, 159992(%rax,%rdx,8)
	ret
	.cfi_endproc
.LFE19:
	.size	afm_, .-afm_
	.p2align 4
	.globl	make_fcc_
	.type	make_fcc_, @function
make_fcc_:
.LFB20:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	vmovsd	240008+verl_(%rip), %xmm10
	vmovsd	48+plates_(%rip), %xmm4
	vmulsd	.LC91(%rip), %xmm10, %xmm6
	vmovsd	40+plates_(%rip), %xmm0
	vmovsd	%xmm4, -16(%rsp)
	vsubsd	%xmm4, %xmm0, %xmm0
	vmovsd	%xmm6, -24(%rsp)
	vdivsd	%xmm6, %xmm0, %xmm0
	vmovsd	64+plates_(%rip), %xmm6
	vmovsd	%xmm6, -8(%rsp)
	vcvttsd2sil	%xmm0, %eax
	vmovsd	56+plates_(%rip), %xmm0
	vsubsd	%xmm6, %xmm0, %xmm0
	movl	%eax, -68(%rsp)
	vdivsd	%xmm10, %xmm0, %xmm0
	testl	%eax, %eax
	jle	.L1021
	vcvttsd2sil	%xmm0, %edi
	incl	%eax
	vmovsd	plates_(%rip), %xmm14
	movl	%eax, -72(%rsp)
	movl	%edi, %r14d
	leal	-1(%rdi), %eax
	andl	$-8, %r14d
	vmovddup	%xmm10, %xmm5
	movl	%eax, -28(%rsp)
	leal	1(%r14), %eax
	vmovddup	%xmm14, %xmm13
	movslq	8+bas_(%rip), %r15
	leaq	verl_(%rip), %rsi
	movl	%edi, %ecx
	vmovapd	%xmm5, -48(%rsp)
	movl	%eax, -32(%rsp)
	vmovddup	%xmm6, %xmm5
	shrl	$3, %ecx
	vmovapd	%xmm5, -64(%rsp)
	movl	120240020(%rsi), %esi
	vmovapd	%xmm13, %xmm5
	vmovdqa	.LC77(%rip), %ymm12
	vmovsd	%xmm14, %xmm14, %xmm13
	vxorps	%xmm9, %xmm9, %xmm9
	vmovsd	%xmm10, %xmm10, %xmm14
	movq	%r15, %r9
	salq	$6, %rcx
	movl	$1, %r11d
	leaq	pos_(%rip), %rdx
	vpcmpeqd	%ymm11, %ymm11, %ymm11
	vmovapd	%xmm5, %xmm10
	.p2align 4,,10
	.p2align 3
.L1008:
	testl	%edi, %edi
	jle	.L1001
	leal	-1(%r11), %eax
	vcvtsi2sdl	%eax, %xmm9, %xmm0
	movl	%r11d, %eax
	andl	$1, %eax
	vcvtsi2ssl	%eax, %xmm9, %xmm8
	vmovsd	-24(%rsp), %xmm15
	cmpl	$6, -28(%rsp)
	vfmadd213sd	-16(%rsp), %xmm0, %xmm15
	vmulss	.LC92(%rip), %xmm8, %xmm8
	vcvtss2sd	%xmm8, %xmm8, %xmm8
	jbe	.L1017
	movslq	%esi, %rax
	addq	%r15, %rax
	salq	$3, %rax
	vbroadcastsd	-8(%rsp), %ymm4
	vmovdqa	.LC76(%rip), %ymm2
	leaq	(%rdx,%rax), %rbx
	leaq	80000(%rdx,%rax), %r10
	leaq	160000(%rdx,%rax), %r8
	vbroadcastsd	%xmm15, %ymm7
	vbroadcastsd	%xmm8, %ymm6
	vbroadcastsd	%xmm14, %ymm5
	vbroadcastsd	%xmm13, %ymm3
	xorl	%eax, %eax
	.p2align 4,,10
	.p2align 3
.L1004:
	vmovdqa	%ymm2, %ymm0
	vpaddd	%ymm11, %ymm0, %ymm0
	vextracti128	$0x1, %ymm0, %xmm1
	vcvtdq2pd	%xmm1, %ymm1
	vcvtdq2pd	%xmm0, %ymm0
	vaddpd	%ymm6, %ymm1, %ymm1
	vaddpd	%ymm6, %ymm0, %ymm0
	vmovupd	%ymm7, (%rbx,%rax)
	vfmadd132pd	%ymm5, %ymm4, %ymm1
	vfmadd132pd	%ymm5, %ymm4, %ymm0
	vmovupd	%ymm7, 32(%rbx,%rax)
	vpaddd	%ymm12, %ymm2, %ymm2
	vmovupd	%ymm1, 32(%r10,%rax)
	vmovupd	%ymm0, (%r10,%rax)
	vmovupd	%ymm3, (%r8,%rax)
	vmovupd	%ymm3, 32(%r8,%rax)
	addq	$64, %rax
	cmpq	%rcx, %rax
	jne	.L1004
	leal	(%rsi,%r14), %r10d
	cmpl	%r14d, %edi
	je	.L1005
	movl	-32(%rsp), %r8d
	movl	%r14d, %r12d
.L1002:
	movl	%edi, %ebx
	subl	%r12d, %ebx
	leal	-1(%rbx), %eax
	cmpl	$2, %eax
	jbe	.L1006
	movslq	%esi, %rax
	addq	%r15, %rax
	addq	%r12, %rax
	salq	$3, %rax
	vmovddup	%xmm15, %xmm0
	leaq	(%rdx,%rax), %r13
	vmovd	%r8d, %xmm7
	vmovupd	%xmm0, 0(%r13)
	vmovupd	%xmm0, 16(%r13)
	vpshufd	$0, %xmm7, %xmm0
	vpaddd	.LC93(%rip), %xmm0, %xmm0
	vmovddup	%xmm8, %xmm2
	vpshufd	$238, %xmm0, %xmm1
	vcvtdq2pd	%xmm1, %xmm1
	vcvtdq2pd	%xmm0, %xmm0
	vaddpd	%xmm2, %xmm1, %xmm1
	vaddpd	%xmm2, %xmm0, %xmm0
	vmovapd	-48(%rsp), %xmm3
	vmovapd	-64(%rsp), %xmm4
	leaq	80000(%rdx,%rax), %r12
	vfmadd132pd	%xmm3, %xmm4, %xmm0
	vfmadd132pd	%xmm3, %xmm4, %xmm1
	leaq	160000(%rdx,%rax), %rax
	vmovupd	%xmm0, (%r12)
	vmovupd	%xmm1, 16(%r12)
	vmovupd	%xmm10, (%rax)
	vmovupd	%xmm10, 16(%rax)
	movl	%ebx, %eax
	andl	$-4, %eax
	addl	%eax, %r8d
	addl	%eax, %r10d
	cmpl	%eax, %ebx
	je	.L1005
.L1006:
	leal	-1(%r8), %ebx
	vcvtsi2sdl	%ebx, %xmm9, %xmm0
	vmovsd	-8(%rsp), %xmm7
	leal	1(%r9,%r10), %eax
	cltq
	vaddsd	%xmm8, %xmm0, %xmm0
	leal	1(%r8), %ebx
	vmovsd	%xmm15, -8(%rdx,%rax,8)
	vfmadd132sd	%xmm14, %xmm7, %xmm0
	vmovsd	%xmm13, 159992(%rdx,%rax,8)
	vmovsd	%xmm0, 79992(%rdx,%rax,8)
	cmpl	%ebx, %edi
	jl	.L1005
	vcvtsi2sdl	%r8d, %xmm9, %xmm0
	leal	2(%r9,%r10), %eax
	cltq
	addl	$2, %r8d
	vaddsd	%xmm8, %xmm0, %xmm0
	vmovsd	%xmm15, -8(%rdx,%rax,8)
	vmovsd	%xmm13, 159992(%rdx,%rax,8)
	vfmadd132sd	%xmm14, %xmm7, %xmm0
	vmovsd	%xmm0, 79992(%rdx,%rax,8)
	cmpl	%r8d, %edi
	jl	.L1005
	vcvtsi2sdl	%ebx, %xmm9, %xmm0
	leal	3(%r9,%r10), %eax
	cltq
	vmovsd	%xmm15, -8(%rdx,%rax,8)
	vaddsd	%xmm8, %xmm0, %xmm8
	vmovsd	%xmm13, 159992(%rdx,%rax,8)
	vfmadd132sd	%xmm14, %xmm7, %xmm8
	vmovsd	%xmm8, 79992(%rdx,%rax,8)
.L1005:
	addl	%edi, %esi
.L1001:
	incl	%r11d
	cmpl	-72(%rsp), %r11d
	jne	.L1008
	vmovsd	%xmm14, %xmm14, %xmm10
	leaq	verl_(%rip), %rax
	vmovsd	8+plates_(%rip), %xmm14
	movl	%esi, 120240020(%rax)
	vmovddup	%xmm10, %xmm5
	vmovddup	-8(%rsp), %xmm6
	vmovdqa	.LC77(%rip), %ymm12
	vmovapd	%xmm6, -64(%rsp)
	vmovsd	%xmm14, %xmm14, %xmm6
	vmovddup	%xmm14, %xmm13
	xorl	%r11d, %r11d
	vmovsd	%xmm10, %xmm10, %xmm14
	movslq	%r9d, %r15
	vmovapd	%xmm5, -48(%rsp)
	leaq	pos_(%rip), %rdx
	vpcmpeqd	%ymm11, %ymm11, %ymm11
	vmovsd	%xmm6, %xmm6, %xmm10
	.p2align 4,,10
	.p2align 3
.L1016:
	testl	%edi, %edi
	jle	.L1009
	movl	%r11d, %eax
	andl	$1, %eax
	vcvtsi2ssl	%eax, %xmm9, %xmm8
	vcvtsi2sdl	%r11d, %xmm9, %xmm0
	vmovsd	-24(%rsp), %xmm15
	cmpl	$6, -28(%rsp)
	vmulss	.LC92(%rip), %xmm8, %xmm8
	vfmadd213sd	-16(%rsp), %xmm0, %xmm15
	vcvtss2sd	%xmm8, %xmm8, %xmm8
	jbe	.L1018
	movslq	%esi, %rax
	addq	%r15, %rax
	salq	$3, %rax
	vbroadcastsd	-8(%rsp), %ymm4
	vmovdqa	.LC76(%rip), %ymm2
	leaq	(%rdx,%rax), %rbx
	leaq	80000(%rdx,%rax), %r10
	leaq	160000(%rdx,%rax), %r8
	vbroadcastsd	%xmm15, %ymm7
	vbroadcastsd	%xmm8, %ymm6
	vbroadcastsd	%xmm14, %ymm5
	vbroadcastsd	%xmm10, %ymm3
	xorl	%eax, %eax
	.p2align 4,,10
	.p2align 3
.L1012:
	vmovdqa	%ymm2, %ymm0
	vpaddd	%ymm11, %ymm0, %ymm0
	vextracti128	$0x1, %ymm0, %xmm1
	vcvtdq2pd	%xmm1, %ymm1
	vcvtdq2pd	%xmm0, %ymm0
	vaddpd	%ymm6, %ymm1, %ymm1
	vaddpd	%ymm6, %ymm0, %ymm0
	vmovupd	%ymm7, (%rbx,%rax)
	vfmadd132pd	%ymm5, %ymm4, %ymm1
	vfmadd132pd	%ymm5, %ymm4, %ymm0
	vmovupd	%ymm7, 32(%rbx,%rax)
	vpaddd	%ymm12, %ymm2, %ymm2
	vmovupd	%ymm1, 32(%r10,%rax)
	vmovupd	%ymm0, (%r10,%rax)
	vmovupd	%ymm3, (%r8,%rax)
	vmovupd	%ymm3, 32(%r8,%rax)
	addq	$64, %rax
	cmpq	%rcx, %rax
	jne	.L1012
	leal	(%rsi,%r14), %r10d
	cmpl	%r14d, %edi
	je	.L1013
	movl	-32(%rsp), %r8d
	movl	%r14d, %r12d
.L1010:
	movl	%edi, %ebx
	subl	%r12d, %ebx
	leal	-1(%rbx), %eax
	cmpl	$2, %eax
	jbe	.L1014
	movslq	%esi, %rax
	addq	%r15, %rax
	addq	%r12, %rax
	salq	$3, %rax
	vmovddup	%xmm15, %xmm0
	leaq	(%rdx,%rax), %r13
	vmovd	%r8d, %xmm7
	vmovupd	%xmm0, 0(%r13)
	vmovupd	%xmm0, 16(%r13)
	vpshufd	$0, %xmm7, %xmm0
	vpaddd	.LC93(%rip), %xmm0, %xmm0
	vmovddup	%xmm8, %xmm2
	vpshufd	$238, %xmm0, %xmm1
	vcvtdq2pd	%xmm1, %xmm1
	vcvtdq2pd	%xmm0, %xmm0
	vaddpd	%xmm2, %xmm1, %xmm1
	vaddpd	%xmm2, %xmm0, %xmm0
	vmovapd	-48(%rsp), %xmm5
	vmovapd	-64(%rsp), %xmm6
	leaq	80000(%rdx,%rax), %r12
	vfmadd132pd	%xmm5, %xmm6, %xmm0
	vfmadd132pd	%xmm5, %xmm6, %xmm1
	leaq	160000(%rdx,%rax), %rax
	vmovupd	%xmm0, (%r12)
	vmovupd	%xmm1, 16(%r12)
	vmovupd	%xmm13, (%rax)
	vmovupd	%xmm13, 16(%rax)
	movl	%ebx, %eax
	andl	$-4, %eax
	addl	%eax, %r8d
	addl	%eax, %r10d
	cmpl	%eax, %ebx
	je	.L1013
.L1014:
	leal	-1(%r8), %ebx
	vcvtsi2sdl	%ebx, %xmm9, %xmm0
	vmovsd	-8(%rsp), %xmm3
	leal	1(%r9,%r10), %eax
	cltq
	vaddsd	%xmm8, %xmm0, %xmm0
	leal	1(%r8), %ebx
	vmovsd	%xmm15, -8(%rdx,%rax,8)
	vfmadd132sd	%xmm14, %xmm3, %xmm0
	vmovsd	%xmm10, 159992(%rdx,%rax,8)
	vmovsd	%xmm0, 79992(%rdx,%rax,8)
	cmpl	%ebx, %edi
	jl	.L1013
	vcvtsi2sdl	%r8d, %xmm9, %xmm0
	leal	2(%r9,%r10), %eax
	cltq
	addl	$2, %r8d
	vaddsd	%xmm8, %xmm0, %xmm0
	vmovsd	%xmm15, -8(%rdx,%rax,8)
	vmovsd	%xmm10, 159992(%rdx,%rax,8)
	vfmadd132sd	%xmm14, %xmm3, %xmm0
	vmovsd	%xmm0, 79992(%rdx,%rax,8)
	cmpl	%edi, %r8d
	jg	.L1013
	vcvtsi2sdl	%ebx, %xmm9, %xmm0
	leal	3(%r9,%r10), %eax
	cltq
	vmovsd	%xmm15, -8(%rdx,%rax,8)
	vaddsd	%xmm8, %xmm0, %xmm8
	vmovsd	%xmm10, 159992(%rdx,%rax,8)
	vfmadd132sd	%xmm14, %xmm3, %xmm8
	vmovsd	%xmm8, 79992(%rdx,%rax,8)
.L1013:
	addl	%edi, %esi
.L1009:
	incl	%r11d
	cmpl	-68(%rsp), %r11d
	jne	.L1016
	leaq	verl_(%rip), %rax
	movl	%esi, 120240020(%rax)
	vzeroupper
.L1021:
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
.L1018:
	.cfi_restore_state
	movl	%esi, %r10d
	xorl	%r12d, %r12d
	movl	$1, %r8d
	jmp	.L1010
.L1017:
	movl	%esi, %r10d
	xorl	%r12d, %r12d
	movl	$1, %r8d
	jmp	.L1002
	.cfi_endproc
.LFE20:
	.size	make_fcc_, .-make_fcc_
	.p2align 4
	.globl	connect_to_wal_
	.type	connect_to_wal_, @function
connect_to_wal_:
.LFB21:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	leaq	respul_(%rip), %r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$96, %rsp
	.cfi_offset 3, -56
	movl	8+bas_(%rip), %ebx
	testl	%ebx, %ebx
	jle	.L1024
	movl	%ebx, %edx
	salq	$3, %rdx
	leaq	160000+pos_(%rip), %rsi
	movq	%r12, %rdi
	call	memcpy@PLT
	leal	-1(%rbx), %eax
	cmpl	$6, %eax
	jbe	.L1034
	movl	%ebx, %edx
	shrl	$3, %edx
	leaq	80000(%r12), %rax
	salq	$5, %rdx
	vmovdqa	.LC76(%rip), %ymm0
	vmovdqa	.LC77(%rip), %ymm2
	addq	%rax, %rdx
	.p2align 4,,10
	.p2align 3
.L1026:
	vmovdqa	%ymm0, %ymm1
	vmovdqa	%ymm1, (%rax)
	addq	$32, %rax
	vpaddd	%ymm2, %ymm0, %ymm0
	cmpq	%rdx, %rax
	jne	.L1026
	movl	%ebx, %edx
	andl	$-8, %edx
	leal	1(%rdx), %eax
	leaq	respul_(%rip), %r12
	cmpl	%edx, %ebx
	je	.L1044
	vzeroupper
.L1025:
	leal	-1(%rax), %edx
	movslq	%edx, %rdx
	leaq	respul_(%rip), %r12
	movl	%eax, 80000(%r12,%rdx,4)
	leal	1(%rax), %edx
	cmpl	%edx, %ebx
	jl	.L1024
	movslq	%eax, %rcx
	movl	%edx, 80000(%r12,%rcx,4)
	leal	2(%rax), %ecx
	cmpl	%ecx, %ebx
	jl	.L1024
	movslq	%edx, %rdx
	movl	%ecx, 80000(%r12,%rdx,4)
	leal	3(%rax), %edx
	cmpl	%edx, %ebx
	jl	.L1024
	movslq	%ecx, %rcx
	movl	%edx, 80000(%r12,%rcx,4)
	leal	4(%rax), %ecx
	cmpl	%ecx, %ebx
	jl	.L1024
	movslq	%edx, %rdx
	movl	%ecx, 80000(%r12,%rdx,4)
	leal	5(%rax), %edx
	cmpl	%edx, %ebx
	jl	.L1024
	movslq	%ecx, %rcx
	addl	$6, %eax
	movl	%edx, 80000(%r12,%rcx,4)
	cmpl	%eax, %ebx
	jl	.L1024
	movslq	%edx, %rdx
	movl	%eax, 80000(%r12,%rdx,4)
.L1024:
	leaq	80000+respul_(%rip), %rdx
	leaq	-80000(%rdx), %rsi
	leaq	8+bas_(%rip), %rdi
	call	sort2_
	movl	120008+respul_(%rip), %eax
	movl	%eax, %esi
	shrl	$31, %esi
	addl	%eax, %esi
	sarl	%esi
	movl	%esi, 120000+respul_(%rip)
	movl	%esi, 120004+respul_(%rip)
	cmpl	$1, %eax
	jle	.L1042
	movl	8+bas_(%rip), %edi
	vmovsd	plates_(%rip), %xmm1
	vmovsd	8+plates_(%rip), %xmm0
	leal	1(%rdi), %ebx
	movl	%edi, 12(%rsp)
	movl	%ebx, 8(%rsp)
	vmovsd	%xmm1, 24(%rsp)
	vmovsd	%xmm0, 16(%rsp)
	cmpl	$15, %eax
	jle	.L1035
	movslq	%edi, %rax
	movl	%esi, %edx
	vbroadcastsd	%xmm0, %ymm0
	leaq	79968(%r12,%rax,4), %rcx
	leaq	-8+pos_(%rip), %r10
	shrl	$3, %edx
	salq	$5, %rdx
	leaq	80000(%r10), %r9
	vbroadcastsd	%xmm1, %ymm1
	vmovapd	%ymm0, 32(%rsp)
	leaq	80000+respul_(%rip), %r11
	leaq	pull_(%rip), %rdi
	movq	%rcx, %rbx
	vmovapd	.LC94(%rip), %ymm0
	vmovdqa	.LC96(%rip), %ymm12
	subq	%rdx, %rbx
	leaq	80000(%r9), %r8
	vmovapd	%ymm1, 64(%rsp)
	movq	%rdi, %rax
	leaq	40012(%r11), %rdx
	.p2align 4,,10
	.p2align 3
.L1030:
	vmovdqa	(%r11), %ymm1
	vmovapd	%ymm0, %ymm4
	vmovapd	%ymm0, %ymm3
	vgatherdpd	%ymm4, (%r10,%xmm1,8), %ymm7
	vgatherdpd	%ymm3, (%r9,%xmm1,8), %ymm5
	vperm2i128	$17, %ymm1, %ymm1, %ymm8
	vmovapd	%ymm0, %ymm4
	vmovapd	%ymm0, %ymm3
	vmovapd	%ymm0, %ymm14
	vgatherdpd	%ymm4, (%r10,%xmm8,8), %ymm6
	vgatherdpd	%ymm3, (%r9,%xmm8,8), %ymm4
	vgatherdpd	%ymm14, (%r8,%xmm1,8), %ymm3
	vmovdqa	.LC95(%rip), %ymm14
	vmovapd	%ymm0, %ymm13
	vgatherdpd	%ymm13, (%r8,%xmm8,8), %ymm2
	vpermd	(%rcx), %ymm14, %ymm8
	vmovapd	64(%rsp), %ymm15
	vmovapd	%ymm0, %ymm9
	vgatherdpd	%ymm9, (%r10,%xmm8,8), %ymm11
	vmovapd	%ymm0, %ymm14
	vperm2i128	$17, %ymm8, %ymm8, %ymm9
	vgatherdpd	%ymm14, (%r10,%xmm9,8), %ymm10
	vsubpd	%ymm15, %ymm3, %ymm3
	vsubpd	%ymm15, %ymm2, %ymm2
	vpermpd	$68, %ymm7, %ymm14
	vpermpd	$68, %ymm11, %ymm15
	vpermpd	$238, %ymm7, %ymm7
	vpermpd	$238, %ymm11, %ymm11
	vshufpd	$12, %ymm11, %ymm7, %ymm7
	vpermpd	$68, %ymm10, %ymm11
	vmovapd	%ymm7, 32(%rax)
	vpermpd	$238, %ymm10, %ymm10
	vpermpd	$68, %ymm6, %ymm7
	vpermpd	$238, %ymm6, %ymm6
	vshufpd	$12, %ymm11, %ymm7, %ymm7
	vshufpd	$12, %ymm10, %ymm6, %ymm6
	vmovapd	%ymm7, 64(%rax)
	vmovapd	%ymm6, 96(%rax)
	vshufpd	$12, %ymm15, %ymm14, %ymm14
	vmovapd	%ymm0, %ymm6
	vmovapd	%ymm14, (%rax)
	vgatherdpd	%ymm6, (%r9,%xmm8,8), %ymm7
	vmovapd	%ymm0, %ymm15
	vgatherdpd	%ymm15, (%r9,%xmm9,8), %ymm6
	vpermpd	$68, %ymm5, %ymm10
	vpermpd	$68, %ymm7, %ymm11
	vpermpd	$238, %ymm5, %ymm5
	vpermpd	$238, %ymm7, %ymm7
	vshufpd	$12, %ymm7, %ymm5, %ymm5
	vpermpd	$68, %ymm6, %ymm7
	vmovapd	%ymm5, 80032(%rax)
	vpermpd	$238, %ymm6, %ymm6
	vpermpd	$68, %ymm4, %ymm5
	vpermpd	$238, %ymm4, %ymm4
	vshufpd	$12, %ymm7, %ymm5, %ymm5
	vshufpd	$12, %ymm6, %ymm4, %ymm4
	vmovapd	%ymm5, 80064(%rax)
	vmovapd	%ymm4, 80096(%rax)
	vmovapd	%ymm0, %ymm7
	vshufpd	$12, %ymm11, %ymm10, %ymm10
	vmovapd	%ymm10, 80000(%rax)
	vgatherdpd	%ymm7, (%r8,%xmm8,8), %ymm5
	vmovapd	32(%rsp), %ymm6
	vmovapd	%ymm0, %ymm7
	vgatherdpd	%ymm7, (%r8,%xmm9,8), %ymm4
	vsubpd	%ymm6, %ymm5, %ymm5
	vsubpd	%ymm6, %ymm4, %ymm4
	vpermpd	$68, %ymm3, %ymm6
	vpermpd	$68, %ymm5, %ymm7
	vpermpd	$238, %ymm3, %ymm3
	vpermpd	$238, %ymm5, %ymm5
	vshufpd	$12, %ymm5, %ymm3, %ymm3
	vpermpd	$68, %ymm4, %ymm5
	vmovapd	%ymm3, 160032(%rax)
	vpermpd	$238, %ymm4, %ymm4
	vpermpd	$68, %ymm2, %ymm3
	vpermpd	$238, %ymm2, %ymm2
	vshufpd	$12, %ymm4, %ymm2, %ymm2
	vmovapd	%ymm2, 160096(%rax)
	vpunpckldq	%ymm8, %ymm1, %ymm2
	vpunpckhdq	%ymm8, %ymm1, %ymm1
	vshufpd	$12, %ymm5, %ymm3, %ymm3
	vmovapd	%ymm3, 160064(%rax)
	vperm2i128	$32, %ymm1, %ymm2, %ymm3
	vpunpckldq	%ymm3, %ymm12, %ymm4
	vperm2i128	$49, %ymm1, %ymm2, %ymm1
	vpunpckhdq	%ymm3, %ymm12, %ymm2
	vperm2i128	$32, %ymm2, %ymm4, %ymm3
	vperm2i128	$49, %ymm2, %ymm4, %ymm2
	vshufpd	$12, %ymm7, %ymm6, %ymm6
	vmovapd	%ymm6, 160000(%rax)
	vmovdqu	%ymm2, 32(%rdx)
	vpunpckldq	%ymm1, %ymm12, %ymm2
	vpunpckhdq	%ymm1, %ymm12, %ymm1
	vmovdqu	%ymm3, (%rdx)
	subq	$32, %rcx
	vperm2i128	$32, %ymm1, %ymm2, %ymm3
	vperm2i128	$49, %ymm1, %ymm2, %ymm1
	vmovdqu	%ymm3, 64(%rdx)
	vmovdqu	%ymm1, 96(%rdx)
	addq	$32, %r11
	subq	$-128, %rdx
	subq	$-128, %rax
	cmpq	%rcx, %rbx
	jne	.L1030
	movl	%esi, %eax
	andl	$-8, %eax
	leal	1(%rax,%rax), %r8d
	leal	1(%rax), %r9d
	cmpl	%eax, %esi
	je	.L1045
	vzeroupper
.L1029:
	movl	%esi, %ebx
	leal	-1(%rsi), %edx
	subl	%eax, %ebx
	subl	%eax, %edx
	movl	%ebx, 64(%rsp)
	cmpl	$2, %edx
	jbe	.L1032
	vmovapd	.LC97(%rip), %xmm0
	vmovdqa	80000(%r12,%rax,4), %xmm1
	leaq	-8+pos_(%rip), %r14
	vmovapd	%xmm0, %xmm4
	vgatherdpd	%xmm4, (%r14,%xmm1,8), %xmm8
	leaq	80000(%r14), %rbx
	vmovapd	%xmm0, %xmm4
	movslq	12(%rsp), %r15
	vgatherdpd	%xmm4, (%rbx,%xmm1,8), %xmm6
	vpshufd	$238, %xmm1, %xmm10
	leaq	160000(%r14), %r11
	vmovapd	%xmm0, %xmm5
	vmovapd	%xmm0, %xmm4
	vmovapd	%xmm0, %xmm3
	vmovapd	%xmm0, %xmm12
	vgatherdpd	%xmm5, (%r14,%xmm10,8), %xmm7
	vmovapd	%xmm0, %xmm13
	vgatherdpd	%xmm4, (%rbx,%xmm10,8), %xmm5
	movq	%rax, %r10
	vgatherdpd	%xmm3, (%r11,%xmm1,8), %xmm4
	leaq	5000(%rax), %rcx
	vgatherdpd	%xmm12, (%r11,%xmm10,8), %xmm3
	leaq	10000(%rax), %rdx
	subq	%rax, %r15
	leaq	79984+respul_(%rip), %rax
	vmovddup	24(%rsp), %xmm2
	salq	$4, %r10
	vsubpd	%xmm2, %xmm4, %xmm4
	vsubpd	%xmm2, %xmm3, %xmm3
	vpshufd	$27, (%rax,%r15,4), %xmm2
	vgatherdpd	%xmm13, (%r14,%xmm2,8), %xmm12
	vpshufd	$238, %xmm2, %xmm10
	vmovapd	%xmm0, %xmm13
	vgatherdpd	%xmm13, (%r14,%xmm10,8), %xmm11
	leaq	(%rdi,%r10), %r13
	vunpcklpd	%xmm12, %xmm8, %xmm13
	vunpckhpd	%xmm12, %xmm8, %xmm8
	vmovapd	%xmm8, 16(%r13)
	vunpcklpd	%xmm11, %xmm7, %xmm8
	vunpckhpd	%xmm11, %xmm7, %xmm7
	vmovapd	%xmm7, 48(%r13)
	vmovapd	%xmm13, 0(%r13)
	vmovapd	%xmm8, 32(%r13)
	vmovapd	%xmm0, %xmm7
	vgatherdpd	%xmm7, (%rbx,%xmm2,8), %xmm8
	vmovapd	%xmm0, %xmm12
	salq	$4, %rcx
	vgatherdpd	%xmm12, (%rbx,%xmm10,8), %xmm7
	addq	%rdi, %rcx
	vunpcklpd	%xmm8, %xmm6, %xmm11
	vunpckhpd	%xmm8, %xmm6, %xmm6
	vmovapd	%xmm6, 16(%rcx)
	vunpcklpd	%xmm7, %xmm5, %xmm6
	vunpckhpd	%xmm7, %xmm5, %xmm5
	vmovddup	16(%rsp), %xmm9
	vmovapd	%xmm11, (%rcx)
	vmovapd	%xmm6, 32(%rcx)
	vmovapd	%xmm5, 48(%rcx)
	vmovapd	%xmm0, %xmm5
	vgatherdpd	%xmm5, (%r11,%xmm2,8), %xmm6
	vsubpd	%xmm9, %xmm6, %xmm6
	vgatherdpd	%xmm0, (%r11,%xmm10,8), %xmm5
	vsubpd	%xmm9, %xmm5, %xmm0
	salq	$4, %rdx
	addq	%rdi, %rdx
	vunpcklpd	%xmm6, %xmm4, %xmm5
	vunpckhpd	%xmm6, %xmm4, %xmm4
	vmovapd	%xmm4, 16(%rdx)
	movl	64(%rsp), %ebx
	vunpcklpd	%xmm0, %xmm3, %xmm4
	vunpckhpd	%xmm0, %xmm3, %xmm3
	vmovdqa	.LC98(%rip), %xmm0
	vmovapd	%xmm3, 48(%rdx)
	vpunpckldq	%xmm2, %xmm1, %xmm3
	leaq	120012(%r12,%r10), %r10
	vpunpckhdq	%xmm2, %xmm1, %xmm1
	movl	%ebx, %eax
	vpunpckldq	%xmm3, %xmm0, %xmm2
	vmovapd	%xmm5, (%rdx)
	vmovapd	%xmm4, 32(%rdx)
	andl	$-4, %eax
	vmovdqu	%xmm2, (%r10)
	vpunpckhdq	%xmm3, %xmm0, %xmm3
	vpunpckldq	%xmm1, %xmm0, %xmm2
	vpunpckhdq	%xmm1, %xmm0, %xmm1
	vmovdqu	%xmm3, 16(%r10)
	vmovdqu	%xmm2, 32(%r10)
	vmovdqu	%xmm1, 48(%r10)
	leal	(%r8,%rax,2), %r8d
	addl	%eax, %r9d
	cmpl	%eax, %ebx
	je	.L1042
.L1032:
	movl	8(%rsp), %r14d
	leal	-1(%r9), %eax
	cltq
	movl	%r14d, %ecx
	movslq	80000(%r12,%rax,4), %rbx
	subl	%r9d, %ecx
	leaq	pos_(%rip), %rax
	movslq	%ecx, %rcx
	movslq	79996(%r12,%rcx,4), %r11
	vmovsd	-8(%rax,%rbx,8), %xmm1
	leal	-1(%r8), %edx
	movslq	%edx, %rdx
	vmovhpd	-8(%rax,%r11,8), %xmm1, %xmm1
	leaq	(%rdx,%rdx), %r10
	vmovsd	159992(%rax,%rbx,8), %xmm0
	movl	$-1, 120012(%r12,%r10,4)
	movl	%ebx, 120016(%r12,%r10,4)
	vmovupd	%xmm1, (%rdi,%rdx,8)
	vmovsd	79992(%rax,%rbx,8), %xmm1
	vmovsd	24(%rsp), %xmm5
	vmovhpd	79992(%rax,%r11,8), %xmm1, %xmm1
	vmovupd	%xmm1, 80000(%rdi,%rdx,8)
	vmovsd	159992(%rax,%r11,8), %xmm1
	vmovsd	16(%rsp), %xmm4
	vsubsd	%xmm5, %xmm0, %xmm0
	vsubsd	%xmm4, %xmm1, %xmm1
	leal	1(%r8), %ecx
	movslq	%ecx, %rcx
	vunpcklpd	%xmm1, %xmm0, %xmm0
	vmovupd	%xmm0, 160000(%rdi,%rdx,8)
	movl	%r11d, 120024(%r12,%r10,4)
	leal	1(%r9), %r11d
	movl	$1, 120020(%r12,%r10,4)
	cmpl	%r11d, %esi
	jl	.L1042
	movslq	%r9d, %rdx
	movslq	80000(%r12,%rdx,4), %rbx
	movl	12(%rsp), %edx
	vmovsd	-8(%rax,%rbx,8), %xmm1
	subl	%r9d, %edx
	movslq	%edx, %rdx
	movslq	79996(%r12,%rdx,4), %r13
	leaq	(%rcx,%rcx), %r10
	vmovhpd	-8(%rax,%r13,8), %xmm1, %xmm1
	vmovsd	159992(%rax,%rbx,8), %xmm0
	movl	$-1, 120012(%r12,%r10,4)
	movl	%ebx, 120016(%r12,%r10,4)
	vmovupd	%xmm1, (%rdi,%rcx,8)
	vmovsd	79992(%rax,%rbx,8), %xmm1
	vsubsd	%xmm5, %xmm0, %xmm0
	vmovhpd	79992(%rax,%r13,8), %xmm1, %xmm1
	vmovupd	%xmm1, 80000(%rdi,%rcx,8)
	vmovsd	159992(%rax,%r13,8), %xmm1
	addl	$2, %r9d
	vsubsd	%xmm4, %xmm1, %xmm1
	vunpcklpd	%xmm1, %xmm0, %xmm0
	vmovupd	%xmm0, 160000(%rdi,%rcx,8)
	movl	$1, 120020(%r12,%r10,4)
	movl	%r13d, 120024(%r12,%r10,4)
	cmpl	%r9d, %esi
	jl	.L1042
	movslq	%r11d, %r11
	movslq	80000(%r12,%r11,4), %rsi
	movl	%r14d, %edx
	vmovsd	159992(%rax,%rsi,8), %xmm0
	subl	%r9d, %edx
	movslq	%edx, %rdx
	movslq	79996(%r12,%rdx,4), %rdx
	vsubsd	%xmm5, %xmm0, %xmm0
	addl	$3, %r8d
	vmovsd	-8(%rax,%rsi,8), %xmm5
	movslq	%r8d, %r8
	leaq	(%r8,%r8), %rcx
	vmovhpd	-8(%rax,%rdx,8), %xmm5, %xmm1
	movl	$-1, 120012(%r12,%rcx,4)
	movl	%esi, 120016(%r12,%rcx,4)
	vmovupd	%xmm1, (%rdi,%r8,8)
	vmovsd	79992(%rax,%rsi,8), %xmm1
	vmovhpd	79992(%rax,%rdx,8), %xmm1, %xmm1
	vmovupd	%xmm1, 80000(%rdi,%r8,8)
	vmovsd	159992(%rax,%rdx,8), %xmm1
	vsubsd	%xmm4, %xmm1, %xmm1
	vunpcklpd	%xmm1, %xmm0, %xmm0
	vmovupd	%xmm0, 160000(%rdi,%r8,8)
	movl	$1, 120020(%r12,%rcx,4)
	movl	%edx, 120024(%r12,%rcx,4)
.L1042:
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L1044:
	.cfi_restore_state
	vzeroupper
	jmp	.L1024
	.p2align 4,,10
	.p2align 3
.L1045:
	vzeroupper
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
.L1035:
	.cfi_restore_state
	xorl	%eax, %eax
	movl	$1, %r9d
	movl	$1, %r8d
	leaq	pull_(%rip), %rdi
	jmp	.L1029
.L1034:
	movl	$1, %eax
	jmp	.L1025
	.cfi_endproc
.LFE21:
	.size	connect_to_wal_, .-connect_to_wal_
	.p2align 4
	.globl	connect_to_wal_one_by_one_
	.type	connect_to_wal_one_by_one_, @function
connect_to_wal_one_by_one_:
.LFB22:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	movslq	120000+respul_(%rip), %rdi
	movslq	120004+respul_(%rip), %rcx
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movl	8+bas_(%rip), %edx
	leal	1(%rdi), %r14d
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	subl	%ecx, %edx
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	cmpl	%edx, %r14d
	jg	.L1062
	vmovsd	wal_(%rip), %xmm1
	vmovsd	plates_(%rip), %xmm4
	vmovsd	8+plates_(%rip), %xmm3
	vaddsd	%xmm1, %xmm4, %xmm2
	vsubsd	%xmm1, %xmm3, %xmm1
	movslq	%r14d, %rax
	leaq	79996+respul_(%rip), %rbx
	leaq	pos_(%rip), %r10
	.p2align 4,,10
	.p2align 3
.L1053:
	movslq	(%rbx,%rax,4), %r9
	leaq	-1(%rax), %rbp
	leaq	19999(%r9), %r11
	vmovsd	(%r10,%r11,8), %xmm0
	movq	%r9, %rsi
	vcomisd	%xmm0, %xmm2
	leaq	-1(%r9), %r8
	jbe	.L1059
	leaq	respul_(%rip), %rdx
	leaq	20000(%rdi), %r12
	addq	%rdi, %rdi
	vcomisd	%xmm1, %xmm0
	movl	(%rdx,%r12,4), %r15d
	movl	%r14d, %r13d
	movl	%r15d, (%rbx,%rax,4)
	movl	%r9d, (%rdx,%r12,4)
	movl	$-1, 120012(%rdx,%rdi,4)
	movl	%r9d, 120016(%rdx,%rdi,4)
	jbe	.L1064
.L1054:
	leal	1(%rcx), %eax
	movl	%eax, 120004+respul_(%rip)
	leaq	20000(%rcx), %rax
	movl	(%rdx,%rax,4), %edi
	addq	%rcx, %rcx
	vmovsd	(%r10,%r8,8), %xmm1
	movl	%edi, 80000(%rdx,%rbp,4)
	movl	$1, 120012(%rdx,%rcx,4)
	movl	%esi, (%rdx,%rax,4)
	movl	%esi, 120016(%rdx,%rcx,4)
	leaq	pull_(%rip), %rax
	leaq	10000(%r8), %rcx
	vsubsd	%xmm3, %xmm0, %xmm0
	vmovsd	%xmm1, (%rax,%r8,8)
	movl	%r13d, 120000+respul_(%rip)
	vmovsd	(%r10,%rcx,8), %xmm1
	vmovsd	%xmm0, 160000(%rax,%r8,8)
	vmovsd	%xmm1, (%rax,%rcx,8)
.L1052:
	movq	$0x000000000, (%rdx,%r8,8)
.L1062:
	popq	%rbx
	.cfi_remember_state
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L1059:
	.cfi_restore_state
	vcomisd	%xmm1, %xmm0
	ja	.L1065
	incq	%rax
	cmpl	%eax, %edx
	jge	.L1053
	popq	%rbx
	.cfi_remember_state
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	movl	%edi, 120000+respul_(%rip)
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
.L1065:
	.cfi_restore_state
	movl	%edi, %r13d
	leaq	respul_(%rip), %rdx
	jmp	.L1054
.L1064:
	vmovsd	(%r10,%r8,8), %xmm1
	leaq	pull_(%rip), %rax
	addq	$9999, %r9
	vsubsd	%xmm4, %xmm0, %xmm0
	vmovsd	%xmm1, (%rax,%r8,8)
	vmovsd	(%r10,%r9,8), %xmm1
	movl	%r14d, 120000+respul_(%rip)
	vmovsd	%xmm1, (%rax,%r9,8)
	vmovsd	%xmm0, (%rax,%r11,8)
	jmp	.L1052
	.cfi_endproc
.LFE22:
	.size	connect_to_wal_one_by_one_, .-connect_to_wal_one_by_one_
	.p2align 4
	.globl	evalangles_
	.type	evalangles_, @function
evalangles_:
.LFB23:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$280, %rsp
	.cfi_def_cfa_offset 336
	movl	8+bas_(%rip), %r14d
	movq	%rdi, 24(%rsp)
	movq	%rsi, 104(%rsp)
	movq	%rdx, 128(%rsp)
	cmpl	$2, %r14d
	jle	.L1102
	vmovsd	.LC8(%rip), %xmm3
	movl	80020+chiral_(%rip), %eax
	vdivsd	2592144+mr_(%rip), %xmm3, %xmm6
	vmovsd	ang_(%rip), %xmm3
	movl	%eax, 4(%rsp)
	vmovsd	%xmm3, 136(%rsp)
	vmulsd	.LC99(%rip), %xmm6, %xmm3
	movl	2592152+mr_(%rip), %eax
	leal	-2(%r14), %r12d
	movl	%eax, 96(%rsp)
	leaq	80000+bon_(%rip), %r13
	leaq	240000+pos_(%rip), %rax
	movl	%r14d, 16(%rsp)
	vmovq	.LC11(%rip), %xmm9
	movq	%r12, %r14
	vmovsd	%xmm6, 112(%rsp)
	leaq	for_(%rip), %rbp
	xorl	%ebx, %ebx
	leaq	4(%r13), %r15
	vmovsd	%xmm3, 120(%rsp)
	movq	%rax, %r12
	jmp	.L1078
	.p2align 4,,10
	.p2align 3
.L1071:
	incq	%rbx
	addq	$8, %rbp
	addq	$48, %r12
	cmpq	%r14, %rbx
	je	.L1104
.L1078:
	movl	0(%r13,%rbx,4), %r8d
	testl	%r8d, %r8d
	je	.L1071
	movl	(%r15,%rbx,4), %edi
	testl	%edi, %edi
	je	.L1071
	vmovsd	8(%r12), %xmm7
	vmovsd	56(%r12), %xmm11
	vmulsd	%xmm7, %xmm7, %xmm8
	vmulsd	%xmm11, %xmm11, %xmm5
	vmovsd	(%r12), %xmm12
	vmovsd	48(%r12), %xmm10
	vmulsd	%xmm7, %xmm11, %xmm1
	vfmadd231sd	%xmm12, %xmm12, %xmm8
	vfmadd231sd	%xmm10, %xmm10, %xmm5
	vmovsd	16(%r12), %xmm4
	vmovsd	64(%r12), %xmm3
	vfmadd231sd	%xmm12, %xmm10, %xmm1
	vfmadd231sd	%xmm4, %xmm4, %xmm8
	vfmadd231sd	%xmm3, %xmm3, %xmm5
	vmovsd	%xmm4, 56(%rsp)
	vmovsd	%xmm7, 88(%rsp)
	vfmadd231sd	%xmm4, %xmm3, %xmm1
	vsqrtsd	%xmm8, %xmm8, %xmm8
	vsqrtsd	%xmm5, %xmm5, %xmm5
	vmovsd	%xmm12, 80(%rsp)
	vmovsd	%xmm11, 72(%rsp)
	vmulsd	%xmm8, %xmm5, %xmm0
	vxorpd	%xmm9, %xmm1, %xmm1
	vmovsd	%xmm10, 64(%rsp)
	vmovsd	%xmm3, 48(%rsp)
	vmovsd	%xmm8, 40(%rsp)
	vdivsd	%xmm0, %xmm1, %xmm1
	vmovsd	%xmm5, 32(%rsp)
	vminsd	.LC8(%rip), %xmm1, %xmm1
	vmaxsd	.LC9(%rip), %xmm1, %xmm1
	vmovsd	%xmm1, %xmm1, %xmm0
	vmovsd	%xmm1, 8(%rsp)
	call	acos@PLT
	vmovsd	8(%rsp), %xmm1
	vxorpd	%xmm4, %xmm4, %xmm4
	vcomisd	%xmm4, %xmm1
	vmovq	.LC11(%rip), %xmm9
	vmovsd	%xmm0, %xmm0, %xmm6
	je	.L1089
	vmovsd	.LC8(%rip), %xmm4
	vmovsd	40(%rsp), %xmm8
	vmovsd	32(%rsp), %xmm5
	vdivsd	%xmm8, %xmm4, %xmm8
	vmovsd	80(%rsp), %xmm12
	vmovsd	72(%rsp), %xmm11
	vmovsd	48(%rsp), %xmm3
	vmovsd	480048(%r12), %xmm13
	vmovsd	480056(%r12), %xmm15
	vmovsd	64(%rsp), %xmm10
	vmovsd	88(%rsp), %xmm7
	vdivsd	%xmm5, %xmm4, %xmm5
	vmovsd	56(%rsp), %xmm4
	vmulsd	%xmm8, %xmm12, %xmm12
	vmulsd	%xmm8, %xmm4, %xmm4
	vmulsd	%xmm8, %xmm7, %xmm7
	vmulsd	%xmm4, %xmm15, %xmm1
	vmulsd	%xmm5, %xmm11, %xmm2
	vmovsd	480064(%r12), %xmm11
	vmulsd	%xmm5, %xmm3, %xmm3
	vmulsd	%xmm12, %xmm11, %xmm0
	vmulsd	%xmm5, %xmm10, %xmm10
	vfnmadd231sd	%xmm11, %xmm7, %xmm1
	vmulsd	%xmm7, %xmm13, %xmm7
	vfnmadd132sd	%xmm13, %xmm0, %xmm4
	vmulsd	%xmm3, %xmm15, %xmm0
	vmulsd	%xmm1, %xmm8, %xmm1
	vfnmadd132sd	%xmm15, %xmm7, %xmm12
	vmulsd	%xmm4, %xmm8, %xmm4
	vfmsub231sd	%xmm2, %xmm11, %xmm0
	vmulsd	%xmm11, %xmm10, %xmm11
	vmulsd	%xmm2, %xmm13, %xmm2
	vmulsd	%xmm12, %xmm8, %xmm12
	vmulsd	%xmm0, %xmm5, %xmm0
	vfmsub132sd	%xmm13, %xmm11, %xmm3
	vfmsub132sd	%xmm10, %xmm2, %xmm15
	vxorpd	%xmm9, %xmm0, %xmm7
	vmulsd	%xmm3, %xmm5, %xmm3
	vmulsd	%xmm15, %xmm5, %xmm15
	vsubsd	%xmm1, %xmm0, %xmm0
	vxorpd	%xmm9, %xmm3, %xmm2
	vxorpd	%xmm9, %xmm15, %xmm11
	vsubsd	%xmm4, %xmm3, %xmm3
	vsubsd	%xmm12, %xmm15, %xmm15
.L1073:
	movl	4(%rsp), %esi
	leaq	8+angtemp_(%rip), %rax
	vmovsd	%xmm6, (%rax,%rbx,8)
	testl	%esi, %esi
	je	.L1071
	leaq	160000+angnat_(%rip), %rax
	movl	(%rax,%rbx,4), %ecx
	testl	%ecx, %ecx
	jne	.L1105
.L1074:
	vmovdqa	.LC101(%rip), %xmm5
	leaq	40008+sequence_(%rip), %rax
	vmovd	(%rax,%rbx,4), %xmm8
	subq	$4, %rax
	vmovdqa	%xmm5, %xmm13
	vpminsd	%xmm5, %xmm8, %xmm8
	vmovd	(%rax,%rbx,4), %xmm5
	vpminsd	%xmm13, %xmm5, %xmm5
	movl	96(%rsp), %eax
	vmovd	%xmm8, %esi
	vmovd	%xmm5, %edx
	movslq	%esi, %rsi
	movslq	%edx, %rdx
	testl	%eax, %eax
	je	.L1075
	vmulsd	112(%rsp), %xmm6, %xmm6
	imulq	$54003, %rsi, %rsi
	imulq	$18001, %rdx, %rdx
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvttsd2sil	%xmm6, %ecx
	addq	%rsi, %rdx
	leaq	mr_(%rip), %rsi
	vcvtsi2sdl	%ecx, %xmm5, %xmm5
	movslq	%ecx, %rdi
	incl	%ecx
	movslq	%ecx, %rcx
	addq	%rdx, %rdi
	addq	%rdx, %rcx
	vsubsd	%xmm5, %xmm6, %xmm6
	vmovsd	-576040(%rsi,%rdi,8), %xmm13
	vmovsd	-576040(%rsi,%rcx,8), %xmm5
	vmovsd	720032(%rsi,%rcx,8), %xmm14
	vsubsd	%xmm13, %xmm5, %xmm5
	vfmadd231sd	%xmm6, %xmm5, %xmm13
	vmovsd	720032(%rsi,%rdi,8), %xmm5
	vsubsd	%xmm5, %xmm14, %xmm14
	vfmadd132sd	%xmm6, %xmm5, %xmm14
	vmulsd	120(%rsp), %xmm14, %xmm14
.L1076:
	vfnmadd213sd	0(%rbp), %xmm14, %xmm1
	vfnmadd213sd	80000(%rbp), %xmm14, %xmm4
	vfnmadd213sd	160000(%rbp), %xmm14, %xmm12
	vfnmadd213sd	8(%rbp), %xmm14, %xmm0
	vfnmadd213sd	80008(%rbp), %xmm14, %xmm3
	vfnmadd213sd	160008(%rbp), %xmm14, %xmm15
	vfnmadd213sd	16(%rbp), %xmm14, %xmm7
	vfnmadd213sd	80016(%rbp), %xmm14, %xmm2
	movq	24(%rsp), %rax
	vfnmadd213sd	160016(%rbp), %xmm11, %xmm14
	vaddsd	(%rax), %xmm13, %xmm13
	incq	%rbx
	vmovsd	%xmm1, 0(%rbp)
	vmovsd	%xmm4, 80000(%rbp)
	vmovsd	%xmm12, 160000(%rbp)
	vmovsd	%xmm0, 8(%rbp)
	vmovsd	%xmm3, 80008(%rbp)
	vmovsd	%xmm15, 160008(%rbp)
	vmovsd	%xmm7, 16(%rbp)
	vmovsd	%xmm2, 80016(%rbp)
	vmovsd	%xmm14, 160016(%rbp)
	vmovsd	%xmm13, (%rax)
	addq	$8, %rbp
	addq	$48, %r12
	cmpq	%r14, %rbx
	jne	.L1078
	.p2align 4,,10
	.p2align 3
.L1104:
	movl	16(%rsp), %r14d
	cmpl	$3, %r14d
	jle	.L1102
	vmovsd	8+ang_(%rip), %xmm2
	movl	102432+ang_(%rip), %eax
	vmovsd	.LC100(%rip), %xmm3
	vmovsd	%xmm2, 64(%rsp)
	vmovsd	16+ang_(%rip), %xmm2
	movl	%eax, 8(%rsp)
	movl	240000+angtemp_(%rip), %eax
	vmulsd	%xmm2, %xmm3, %xmm6
	movl	%eax, 40(%rsp)
	movl	80024+chiral_(%rip), %eax
	vmovsd	%xmm2, 72(%rsp)
	movl	%eax, 48(%rsp)
	vmovsd	80008+chiral_(%rip), %xmm2
	vmovsd	%xmm6, 80(%rsp)
	vmovsd	%xmm2, 56(%rsp)
	leaq	80000+bon_(%rip), %r12
	leaq	for_(%rip), %rbp
	leaq	240000+pos_(%rip), %r15
	leal	-3(%r14), %r13d
	xorl	%ebx, %ebx
	.p2align 4,,10
	.p2align 3
.L1088:
	movl	(%r12), %r14d
	testl	%r14d, %r14d
	je	.L1080
	movl	4(%r12), %r11d
	testl	%r11d, %r11d
	je	.L1080
	movl	8(%r12), %r10d
	testl	%r10d, %r10d
	jne	.L1106
	.p2align 4,,10
	.p2align 3
.L1080:
	incq	%rbx
	addq	$4, %r12
	addq	$8, %rbp
	addq	$48, %r15
	cmpq	%rbx, %r13
	jne	.L1088
.L1102:
	addq	$280, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L1089:
	.cfi_restore_state
	vmovsd	%xmm1, %xmm1, %xmm11
	vmovsd	%xmm1, %xmm1, %xmm2
	vmovsd	%xmm1, %xmm1, %xmm7
	vmovsd	%xmm1, %xmm1, %xmm15
	vmovsd	%xmm1, %xmm1, %xmm3
	vmovsd	%xmm1, %xmm1, %xmm0
	vmovsd	%xmm1, %xmm1, %xmm12
	vmovsd	%xmm1, %xmm1, %xmm4
	jmp	.L1073
	.p2align 4,,10
	.p2align 3
.L1106:
	vmovsd	480056(%r15), %xmm3
	vmovsd	480104(%r15), %xmm7
	leaq	1200008+pos_(%rip), %rax
	vmulsd	%xmm3, %xmm7, %xmm1
	vmovsd	(%rax,%rbx,8), %xmm6
	vmovsd	48(%r15), %xmm0
	vmovsd	480048(%r15), %xmm5
	vmovsd	%xmm6, 152(%rsp)
	vmovsd	480096(%r15), %xmm6
	vmovsd	%xmm0, 32(%rsp)
	vmovsd	56(%r15), %xmm0
	vfmadd231sd	%xmm5, %xmm6, %xmm1
	vmovsd	%xmm0, 184(%rsp)
	vmovsd	64(%r15), %xmm0
	vmovsd	480112(%r15), %xmm4
	vmovsd	480064(%r15), %xmm2
	vmovsd	%xmm0, 192(%rsp)
	vmovsd	8(%r15), %xmm0
	vfmadd231sd	%xmm2, %xmm4, %xmm1
	vmovsd	%xmm2, 112(%rsp)
	vmulsd	%xmm7, %xmm0, %xmm2
	vmovsd	%xmm5, 88(%rsp)
	vmovsd	(%r15), %xmm5
	vmovsd	%xmm7, 136(%rsp)
	vminsd	.LC8(%rip), %xmm1, %xmm1
	vfmadd231sd	%xmm6, %xmm5, %xmm2
	vmovsd	16(%r15), %xmm7
	vmaxsd	.LC9(%rip), %xmm1, %xmm1
	addq	$8, %rax
	vmovsd	%xmm0, 168(%rsp)
	vfmadd231sd	%xmm4, %xmm7, %xmm2
	vmovsd	%xmm1, %xmm1, %xmm0
	movq	(%rax,%rbx,8), %r14
	vmovsd	%xmm3, 96(%rsp)
	vmovsd	%xmm4, 144(%rsp)
	vmovsd	%xmm5, 160(%rsp)
	vmovsd	%xmm7, 176(%rsp)
	vmovsd	%xmm2, 16(%rsp)
	vmovsd	%xmm6, 120(%rsp)
	vmovsd	%xmm1, 200(%rsp)
	call	acos@PLT
	vmovsd	16(%rsp), %xmm2
	vxorpd	%xmm7, %xmm7, %xmm7
	vcmpltsd	%xmm2, %xmm7, %xmm2
	vmovsd	%xmm0, %xmm0, %xmm3
	movl	4(%rsp), %r9d
	vxorpd	.LC11(%rip), %xmm0, %xmm0
	leaq	80016+angtemp_(%rip), %rax
	vblendvpd	%xmm2, %xmm0, %xmm3, %xmm0
	testl	%r9d, %r9d
	vmovsd	96(%r15), %xmm5
	vmovsd	104(%r15), %xmm3
	vmovsd	112(%r15), %xmm2
	vmovq	.LC11(%rip), %xmm4
	vmovsd	%xmm0, (%rax,%rbx,8)
	je	.L1080
	movl	8(%rsp), %r8d
	testl	%r8d, %r8d
	je	.L1080
	leaq	160000+angnat_(%rip), %rax
	movl	(%rax,%rbx,4), %edi
	vmovsd	200(%rsp), %xmm1
	testl	%edi, %edi
	je	.L1084
	addq	$12, %rax
	movl	(%rax,%rbx,4), %esi
	testl	%esi, %esi
	jne	.L1107
.L1084:
	vmovsd	%xmm2, 216(%rsp)
	vmovsd	%xmm3, 208(%rsp)
	vmovsd	%xmm5, 200(%rsp)
	vmovsd	%xmm1, 16(%rsp)
	call	sin@PLT
	vmovsd	16(%rsp), %xmm1
	leaq	40008+sequence_(%rip), %rax
	vmulsd	%xmm0, %xmm0, %xmm11
	vmulsd	%xmm0, %xmm1, %xmm12
	vmovsd	%xmm0, %xmm0, %xmm10
	vmovd	(%rax,%rbx,4), %xmm0
	vmovdqa	%xmm0, %xmm8
	vmovdqa	.LC101(%rip), %xmm0
	vmulsd	%xmm1, %xmm1, %xmm9
	vmovdqa	%xmm0, %xmm7
	vpminsd	%xmm0, %xmm8, %xmm0
	vmovd	%xmm0, %eax
	cltq
	leaq	(%rax,%rax,4), %rdx
	leaq	40004+sequence_(%rip), %rax
	vmovd	(%rax,%rbx,4), %xmm0
	vpminsd	%xmm7, %xmm0, %xmm0
	vmovd	%xmm0, %eax
	cltq
	leaq	-21(%rax,%rdx,4), %rax
	salq	$4, %rax
	leaq	ang_(%rip), %rdx
	vmovsd	51264(%rdx,%rax,8), %xmm14
	vmovsd	51240(%rdx,%rax,8), %xmm13
	vmulsd	%xmm9, %xmm14, %xmm0
	vmovsd	51248(%rdx,%rax,8), %xmm7
	vmovsd	%xmm13, %xmm13, %xmm8
	vfmadd213sd	51232(%rdx,%rax,8), %xmm10, %xmm8
	vmovsd	51256(%rdx,%rax,8), %xmm6
	vfmadd231sd	%xmm1, %xmm7, %xmm0
	vsubsd	%xmm11, %xmm9, %xmm9
	vmovq	.LC11(%rip), %xmm4
	vmovsd	216(%rsp), %xmm2
	vmovsd	208(%rsp), %xmm3
	vaddsd	%xmm8, %xmm0, %xmm0
	vmovsd	51272(%rdx,%rax,8), %xmm8
	vmovsd	200(%rsp), %xmm5
	vmulsd	%xmm12, %xmm8, %xmm15
	vmulsd	%xmm8, %xmm9, %xmm9
	vfmadd231sd	%xmm11, %xmm6, %xmm15
	vsubsd	%xmm14, %xmm6, %xmm6
	vfmadd231sd	%xmm1, %xmm13, %xmm9
	vmovapd	%xmm4, %xmm14
	vaddsd	%xmm6, %xmm6, %xmm6
	vaddsd	%xmm15, %xmm0, %xmm0
	vmulsd	%xmm12, %xmm6, %xmm6
	vfnmadd132sd	%xmm10, %xmm6, %xmm7
	vaddsd	%xmm9, %xmm7, %xmm7
.L1086:
	movq	104(%rsp), %rax
	movl	(%rax), %eax
	testl	%eax, %eax
	je	.L1087
	movq	128(%rsp), %rax
	vmovsd	(%rax), %xmm1
	vmulsd	%xmm1, %xmm7, %xmm7
	vmulsd	%xmm1, %xmm0, %xmm0
.L1087:
	vmovsd	.LC8(%rip), %xmm1
	vmovq	%r14, %xmm9
	vdivsd	%xmm9, %xmm1, %xmm11
	vmovsd	184(%rsp), %xmm4
	vmovsd	192(%rsp), %xmm12
	vmulsd	%xmm4, %xmm4, %xmm10
	vmovsd	32(%rsp), %xmm6
	vdivsd	152(%rsp), %xmm1, %xmm15
	vmulsd	88(%rsp), %xmm15, %xmm13
	vmulsd	96(%rsp), %xmm15, %xmm9
	vfmadd231sd	%xmm12, %xmm12, %xmm10
	vmulsd	112(%rsp), %xmm15, %xmm15
	vfmadd231sd	%xmm6, %xmm6, %xmm10
	vsqrtsd	%xmm10, %xmm10, %xmm8
	vmovq	%xmm10, %rax
	vmovsd	32(%rsp), %xmm10
	vmulsd	%xmm8, %xmm13, %xmm13
	vmulsd	%xmm8, %xmm9, %xmm9
	vmulsd	%xmm8, %xmm15, %xmm15
	vmulsd	%xmm10, %xmm5, %xmm5
	vmulsd	120(%rsp), %xmm11, %xmm1
	vmulsd	136(%rsp), %xmm11, %xmm6
	vmulsd	144(%rsp), %xmm11, %xmm11
	vfmadd132sd	%xmm4, %xmm5, %xmm3
	vmulsd	%xmm8, %xmm1, %xmm1
	vmulsd	%xmm8, %xmm6, %xmm6
	vmulsd	%xmm8, %xmm11, %xmm8
	vmovsd	168(%rsp), %xmm11
	vmulsd	%xmm4, %xmm11, %xmm11
	vmovq	%rax, %xmm4
	movq	24(%rsp), %rax
	vaddsd	(%rax), %xmm0, %xmm0
	vfmadd231sd	176(%rsp), %xmm12, %xmm11
	vfmadd132sd	%xmm2, %xmm3, %xmm12
	vmovsd	.LC8(%rip), %xmm2
	vmovsd	%xmm0, (%rax)
	vmovsd	%xmm7, %xmm7, %xmm0
	vfmadd231sd	160(%rsp), %xmm10, %xmm11
	vdivsd	%xmm4, %xmm2, %xmm10
	vfnmadd213sd	0(%rbp), %xmm13, %xmm0
	vxorpd	%xmm14, %xmm11, %xmm11
	vmulsd	%xmm13, %xmm11, %xmm3
	vmulsd	%xmm9, %xmm11, %xmm2
	vmulsd	%xmm15, %xmm11, %xmm11
	vmovsd	%xmm0, 0(%rbp)
	vmovsd	%xmm7, %xmm7, %xmm0
	vfnmadd213sd	80000(%rbp), %xmm9, %xmm0
	vfnmadd231sd	%xmm12, %xmm1, %xmm3
	vfnmadd231sd	%xmm12, %xmm6, %xmm2
	vfnmadd132sd	%xmm8, %xmm11, %xmm12
	vmovsd	%xmm0, 80000(%rbp)
	vmovsd	%xmm7, %xmm7, %xmm0
	vfnmadd213sd	160000(%rbp), %xmm15, %xmm0
	vmovsd	%xmm0, 160000(%rbp)
	vfmsub231sd	%xmm10, %xmm3, %xmm13
	vfmsub231sd	%xmm10, %xmm2, %xmm9
	vfmsub231sd	%xmm10, %xmm12, %xmm15
	vfnmadd132sd	%xmm10, %xmm1, %xmm3
	vfnmadd132sd	%xmm10, %xmm6, %xmm2
	vfnmadd213sd	8(%rbp), %xmm7, %xmm13
	vfnmadd213sd	80008(%rbp), %xmm7, %xmm9
	vfnmadd213sd	160008(%rbp), %xmm7, %xmm15
	vfnmadd132sd	%xmm10, %xmm8, %xmm12
	vfnmadd213sd	16(%rbp), %xmm7, %xmm3
	vmovsd	%xmm13, 8(%rbp)
	vmovsd	%xmm9, 80008(%rbp)
	vmovsd	%xmm15, 160008(%rbp)
	vmovsd	%xmm3, 16(%rbp)
	vfnmadd213sd	80016(%rbp), %xmm7, %xmm2
	vfnmadd213sd	160016(%rbp), %xmm7, %xmm12
	vfmadd213sd	24(%rbp), %xmm7, %xmm1
	vfmadd213sd	80024(%rbp), %xmm7, %xmm6
	vfmadd213sd	160024(%rbp), %xmm7, %xmm8
	vmovsd	%xmm2, 80016(%rbp)
	vmovsd	%xmm12, 160016(%rbp)
	vmovsd	%xmm1, 24(%rbp)
	vmovsd	%xmm6, 80024(%rbp)
	vmovsd	%xmm8, 160024(%rbp)
	jmp	.L1080
	.p2align 4,,10
	.p2align 3
.L1105:
	leaq	8(%rax), %rdx
	movl	(%rdx,%rbx,4), %edx
	testl	%edx, %edx
	je	.L1074
	leaq	-159992(%rax), %rdx
	vsubsd	(%rdx,%rbx,8), %xmm6, %xmm13
	vmulsd	136(%rsp), %xmm13, %xmm14
	vmulsd	%xmm13, %xmm14, %xmm13
	vaddsd	%xmm14, %xmm14, %xmm14
	jmp	.L1076
	.p2align 4,,10
	.p2align 3
.L1075:
	vmulsd	%xmm6, %xmm6, %xmm8
	leaq	(%rsi,%rsi,4), %rcx
	leaq	-21(%rdx,%rcx,4), %rdx
	salq	$4, %rdx
	leaq	ang_(%rip), %rcx
	vmulsd	%xmm6, %xmm8, %xmm14
	vmovsd	40(%rcx,%rdx,8), %xmm13
	vfmadd213sd	32(%rcx,%rdx,8), %xmm6, %xmm13
	vmulsd	%xmm6, %xmm14, %xmm10
	vmulsd	%xmm6, %xmm10, %xmm5
	vmovq	%xmm5, %rax
	vmulsd	64(%rcx,%rdx,8), %xmm10, %xmm5
	vfmadd231sd	48(%rcx,%rdx,8), %xmm8, %xmm5
	vaddsd	%xmm5, %xmm13, %xmm5
	vmovsd	80(%rcx,%rdx,8), %xmm13
	vfmadd213sd	56(%rcx,%rdx,8), %xmm14, %xmm13
	vmovq	%xmm5, %rsi
	vmovq	%rax, %xmm5
	vmulsd	%xmm14, %xmm13, %xmm13
	vmulsd	120(%rcx,%rdx,8), %xmm14, %xmm14
	vfmadd231sd	72(%rcx,%rdx,8), %xmm5, %xmm13
	vmovq	%rsi, %xmm5
	vfmadd231sd	112(%rcx,%rdx,8), %xmm8, %xmm14
	vaddsd	%xmm5, %xmm13, %xmm13
	vmovsd	96(%rcx,%rdx,8), %xmm5
	vfmadd132sd	104(%rcx,%rdx,8), %xmm5, %xmm6
	vaddsd	%xmm6, %xmm14, %xmm14
	vmovq	%rax, %xmm6
	vmulsd	136(%rcx,%rdx,8), %xmm6, %xmm5
	vfmadd132sd	128(%rcx,%rdx,8), %xmm5, %xmm10
	vaddsd	%xmm10, %xmm14, %xmm14
	jmp	.L1076
.L1107:
	movl	40(%rsp), %ecx
	testl	%ecx, %ecx
	jne	.L1084
	movl	48(%rsp), %edx
	subq	$79996, %rax
	vsubsd	(%rax,%rbx,8), %xmm0, %xmm0
	testl	%edx, %edx
	je	.L1085
	vmulsd	56(%rsp), %xmm0, %xmm7
	vmulsd	.LC72(%rip), %xmm0, %xmm0
	vmovapd	%xmm4, %xmm14
	vmulsd	%xmm7, %xmm0, %xmm0
	vxorpd	%xmm4, %xmm7, %xmm7
	jmp	.L1086
.L1085:
	leaq	264(%rsp), %rdi
	leaq	256(%rsp), %rsi
	vmovsd	%xmm2, 248(%rsp)
	vmovsd	%xmm3, 240(%rsp)
	vmovsd	%xmm5, 232(%rsp)
	movq	%rsi, 224(%rsp)
	movq	%rdi, 216(%rsp)
	vmovsd	%xmm0, 208(%rsp)
	call	sincos@PLT
	vmovsd	208(%rsp), %xmm0
	vmovsd	256(%rsp), %xmm6
	vmulsd	.LC100(%rip), %xmm0, %xmm0
	vmovsd	264(%rsp), %xmm4
	movq	224(%rsp), %rsi
	movq	216(%rsp), %rdi
	vmovsd	%xmm6, 16(%rsp)
	vmovsd	%xmm4, 200(%rsp)
	call	sincos@PLT
	vmovsd	.LC8(%rip), %xmm7
	vmovsd	64(%rsp), %xmm6
	vsubsd	256(%rsp), %xmm7, %xmm0
	vsubsd	16(%rsp), %xmm7, %xmm1
	vmovsd	80(%rsp), %xmm7
	vmulsd	72(%rsp), %xmm0, %xmm0
	vmulsd	264(%rsp), %xmm7, %xmm7
	vmovq	.LC11(%rip), %xmm4
	vmovsd	232(%rsp), %xmm5
	vmovsd	240(%rsp), %xmm3
	vfmadd231sd	%xmm6, %xmm1, %xmm0
	vfmadd231sd	200(%rsp), %xmm6, %xmm7
	vmovsd	248(%rsp), %xmm2
	vmovapd	%xmm4, %xmm14
	jmp	.L1086
	.cfi_endproc
.LFE23:
	.size	evalangles_, .-evalangles_
	.p2align 4
	.globl	eval_chirality_
	.type	eval_chirality_, @function
eval_chirality_:
.LFB24:
	.cfi_startproc
	movl	8+bas_(%rip), %r9d
	movq	%rdi, %r10
	cmpl	$1, %r9d
	jle	.L1109
	leaq	240000+pos_(%rip), %rdx
	leal	-1(%r9), %r8d
	xorl	%eax, %eax
	leaq	xs.30(%rip), %rdi
	leaq	ys.29(%rip), %rcx
	leaq	zs.28(%rip), %rsi
	.p2align 4,,10
	.p2align 3
.L1113:
	vmovsd	(%rdx), %xmm0
	addq	$48, %rdx
	vmovsd	%xmm0, (%rdi,%rax,8)
	vmovsd	-40(%rdx), %xmm0
	vmovsd	%xmm0, (%rcx,%rax,8)
	vmovsd	-32(%rdx), %xmm0
	vmovsd	%xmm0, (%rsi,%rax,8)
	incq	%rax
	cmpq	%r8, %rax
	jne	.L1113
	cmpl	$3, %r9d
	jle	.L1109
	pushq	%r14
	.cfi_def_cfa_offset 16
	.cfi_offset 14, -16
	leal	-4(%r9), %r8d
	leaq	79992+bon_(%rip), %r9
	pushq	%r13
	.cfi_def_cfa_offset 24
	.cfi_offset 13, -24
	vmovq	.LC11(%rip), %xmm1
	leaq	720048+pos_(%rip), %rdx
	pushq	%r12
	.cfi_def_cfa_offset 32
	.cfi_offset 12, -32
	leaq	3(%r8), %r11
	movl	$2, %eax
	pushq	%rbp
	.cfi_def_cfa_offset 40
	.cfi_offset 6, -40
	leaq	159984+angtemp_(%rip), %r12
	pushq	%rbx
	.cfi_def_cfa_offset 48
	.cfi_offset 3, -48
	leaq	4(%r9), %rbx
	leaq	-79988(%rbx), %rbp
	.p2align 4,,10
	.p2align 3
.L1116:
	movl	(%r9,%rax,4), %r13d
	testl	%r13d, %r13d
	je	.L1114
	movl	(%rbx,%rax,4), %r14d
	testl	%r14d, %r14d
	je	.L1114
	vmovsd	16(%rdx), %xmm0
	vmovsd	8(%rdx), %xmm7
	vmulsd	(%rsi,%rax,8), %xmm0, %xmm0
	vfmadd231sd	(%rcx,%rax,8), %xmm7, %xmm0
	vmovsd	(%rdx), %xmm7
	vfmadd231sd	(%rdi,%rax,8), %xmm7, %xmm0
	vxorpd	%xmm1, %xmm0, %xmm0
	vdivsd	0(%rbp,%rax,8), %xmm0, %xmm0
	vmovsd	%xmm0, (%r12,%rax,8)
.L1114:
	incq	%rax
	addq	$48, %rdx
	cmpq	%r11, %rax
	jne	.L1116
	vmovsd	bon_(%rip), %xmm0
	leaq	80000+bon_(%rip), %r11
	vmulsd	%xmm0, %xmm0, %xmm12
	movq	$0x000000000, (%r10)
	vmovsd	80000+chiral_(%rip), %xmm13
	leaq	ys.29(%rip), %rdi
	leaq	zs.28(%rip), %rsi
	vmulsd	%xmm0, %xmm12, %xmm12
	vmovsd	.LC8(%rip), %xmm0
	leaq	xs.30(%rip), %rcx
	leaq	for_(%rip), %rdx
	xorl	%eax, %eax
	vdivsd	%xmm12, %xmm0, %xmm12
	leaq	4(%r11), %rbx
	leaq	160000+angtemp_(%rip), %r12
	leaq	chiral_(%rip), %rbp
	jmp	.L1118
	.p2align 4,,10
	.p2align 3
.L1120:
	movq	%r9, %rax
.L1118:
	movl	(%r11,%rax,4), %r13d
	testl	%r13d, %r13d
	je	.L1117
	movl	(%rbx,%rax,4), %r9d
	testl	%r9d, %r9d
	je	.L1117
	vmovsd	(%r12,%rax,8), %xmm1
	vxorpd	%xmm6, %xmm6, %xmm6
	vmulsd	0(%rbp,%rax,8), %xmm1, %xmm0
	vcomisd	%xmm6, %xmm0
	ja	.L1117
	vmulsd	%xmm1, %xmm13, %xmm0
	vmulsd	.LC72(%rip), %xmm1, %xmm1
	vmovsd	8(%rdi), %xmm7
	vmovsd	16(%rsi), %xmm2
	vmovsd	8(%rsi), %xmm11
	vmulsd	%xmm2, %xmm7, %xmm6
	vfmadd213sd	(%r10), %xmm0, %xmm1
	vmovsd	16(%rdi), %xmm3
	vmulsd	%xmm0, %xmm12, %xmm0
	vmovsd	8(%rcx), %xmm8
	vfnmadd231sd	%xmm3, %xmm11, %xmm6
	vmovsd	%xmm1, (%r10)
	vmovsd	16(%rcx), %xmm1
	vmulsd	%xmm3, %xmm8, %xmm4
	vmulsd	%xmm11, %xmm1, %xmm5
	vfmadd213sd	(%rdx), %xmm0, %xmm6
	vfnmadd231sd	%xmm7, %xmm1, %xmm4
	vfnmadd231sd	%xmm2, %xmm8, %xmm5
	vmovsd	%xmm6, (%rdx)
	vmovsd	(%rcx), %xmm6
	vaddsd	%xmm8, %xmm6, %xmm9
	vfmadd213sd	80000(%rdx), %xmm0, %xmm5
	vfmadd213sd	160000(%rdx), %xmm0, %xmm4
	vmulsd	%xmm2, %xmm9, %xmm15
	vmovsd	%xmm5, 80000(%rdx)
	vmovsd	(%rdi), %xmm5
	vmovsd	%xmm4, 160000(%rdx)
	vaddsd	%xmm7, %xmm5, %xmm14
	vmovsd	(%rsi), %xmm4
	vmovq	%xmm15, %r9
	vmulsd	%xmm1, %xmm14, %xmm15
	vaddsd	%xmm11, %xmm4, %xmm10
	vmovq	%xmm15, %r14
	vmulsd	%xmm3, %xmm10, %xmm15
	vfnmadd132sd	%xmm2, %xmm15, %xmm14
	vmovq	%r9, %xmm15
	vfnmadd132sd	%xmm1, %xmm15, %xmm10
	vmovq	%r14, %xmm15
	vfnmadd132sd	%xmm3, %xmm15, %xmm9
	vfmadd213sd	8(%rdx), %xmm0, %xmm14
	vaddsd	%xmm11, %xmm2, %xmm2
	vfmadd213sd	80008(%rdx), %xmm0, %xmm10
	vaddsd	%xmm8, %xmm1, %xmm1
	vfmadd213sd	160008(%rdx), %xmm0, %xmm9
	vmovsd	%xmm14, 8(%rdx)
	vmulsd	%xmm5, %xmm2, %xmm14
	vaddsd	%xmm3, %xmm7, %xmm3
	vmovsd	%xmm10, 80008(%rdx)
	vmovsd	%xmm9, 160008(%rdx)
	vmulsd	%xmm4, %xmm1, %xmm10
	vmulsd	%xmm6, %xmm3, %xmm9
	vfnmadd132sd	%xmm4, %xmm14, %xmm3
	vfnmadd132sd	%xmm6, %xmm10, %xmm2
	vfnmadd132sd	%xmm5, %xmm9, %xmm1
	vfmadd213sd	16(%rdx), %xmm0, %xmm3
	vfmadd213sd	80016(%rdx), %xmm0, %xmm2
	vfmadd213sd	160016(%rdx), %xmm0, %xmm1
	vmovsd	%xmm3, 16(%rdx)
	vmulsd	%xmm7, %xmm4, %xmm3
	vmovsd	%xmm2, 80016(%rdx)
	vmovsd	%xmm1, 160016(%rdx)
	vmulsd	%xmm11, %xmm6, %xmm2
	vmulsd	%xmm8, %xmm5, %xmm1
	vfnmadd132sd	%xmm11, %xmm3, %xmm5
	vfnmadd132sd	%xmm8, %xmm2, %xmm4
	vfnmadd132sd	%xmm7, %xmm1, %xmm6
	vfmadd213sd	24(%rdx), %xmm0, %xmm5
	vmovsd	%xmm5, 24(%rdx)
	vfmadd213sd	80024(%rdx), %xmm0, %xmm4
	vfmadd213sd	160024(%rdx), %xmm6, %xmm0
	vmovsd	%xmm4, 80024(%rdx)
	vmovsd	%xmm0, 160024(%rdx)
	.p2align 4,,10
	.p2align 3
.L1117:
	leaq	1(%rax), %r9
	addq	$8, %rdi
	addq	$8, %rsi
	addq	$8, %rcx
	addq	$8, %rdx
	cmpq	%rax, %r8
	jne	.L1120
	popq	%rbx
	.cfi_def_cfa_offset 40
	popq	%rbp
	.cfi_def_cfa_offset 32
	popq	%r12
	.cfi_def_cfa_offset 24
	popq	%r13
	.cfi_def_cfa_offset 16
	popq	%r14
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L1109:
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
	movq	$0x000000000, (%r10)
	ret
	.cfi_endproc
.LFE24:
	.size	eval_chirality_, .-eval_chirality_
	.p2align 4
	.globl	evalcpot_
	.type	evalcpot_, @function
evalcpot_:
.LFB25:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	leaq	cmp2_(%rip), %rdx
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$536, %rsp
	.cfi_def_cfa_offset 592
	movl	60000004(%rdx), %eax
	movq	%rdi, 144(%rsp)
	testl	%eax, %eax
	jle	.L1397
	vmovsd	240024+for_(%rip), %xmm4
	movl	36+kier_(%rip), %ecx
	vmovsd	%xmm4, 96(%rsp)
	vmovsd	240000+for_(%rip), %xmm4
	movl	%ecx, 48(%rsp)
	vmovsd	%xmm4, 104(%rsp)
	movl	40+kier_(%rip), %ecx
	vmovsd	240032+for_(%rip), %xmm4
	vmovsd	240008+for_(%rip), %xmm1
	movl	80024+misc_(%rip), %esi
	movl	%ecx, 52(%rsp)
	vmovsd	%xmm4, 112(%rsp)
	movl	44+kier_(%rip), %ecx
	vmovsd	240040+for_(%rip), %xmm4
	vmovsd	80000+misc_(%rip), %xmm2
	movl	%ecx, 80(%rsp)
	movl	%esi, 196(%rsp)
	movl	80032+misc_(%rip), %ecx
	movl	2000012+cmapi_(%rip), %esi
	movl	2000020+cmapi_(%rip), %ebx
	vmovsd	%xmm1, 120(%rsp)
	vmovsd	%xmm4, 128(%rsp)
	vmovsd	240016+for_(%rip), %xmm1
	vmovsd	cmapi_(%rip), %xmm4
	movl	%ecx, 24(%rsp)
	movl	%esi, 252(%rsp)
	vmovsd	%xmm1, 136(%rsp)
	vmovsd	%xmm4, 160(%rsp)
	vmovsd	%xmm2, 152(%rsp)
	movl	%ebx, 224(%rsp)
	vmovsd	80008+neigh_(%rip), %xmm13
	vmovsd	7924024+sig_(%rip), %xmm11
	movl	80036+ssb_(%rip), %ebx
	movl	32+restr_(%rip), %esi
	vmovsd	40+sig_(%rip), %xmm1
	movl	%esi, 228(%rsp)
	movl	80036+misc_(%rip), %esi
	vmovsd	24+restr_(%rip), %xmm4
	movl	%esi, 436(%rsp)
	movl	%ecx, %esi
	movl	80024+neigh_(%rip), %ecx
	vmovsd	%xmm1, 200(%rsp)
	movl	%ecx, 420(%rsp)
	vmovsd	8+restr_(%rip), %xmm1
	movl	2000024+cmapi_(%rip), %ecx
	movl	%ebx, 192(%rsp)
	movl	%ecx, 272(%rsp)
	movl	80020+neigh_(%rip), %ebx
	movl	2000016+cmapi_(%rip), %ecx
	vmovsd	%xmm4, 168(%rsp)
	vmovsd	%xmm1, 184(%rsp)
	vmovsd	restr_(%rip), %xmm4
	vmovsd	16+restr_(%rip), %xmm1
	movl	%ebx, 248(%rsp)
	movl	%ecx, 268(%rsp)
	movl	248008+nat_(%rip), %ebx
	movl	12+ssb2_(%rip), %ecx
	vmovsd	%xmm4, 352(%rsp)
	vmovsd	%xmm1, 280(%rsp)
	vmovsd	4000+sig_(%rip), %xmm4
	vmovsd	7924008+sig_(%rip), %xmm1
	andl	$1, %esi
	movb	%sil, 403(%rsp)
	movl	%ecx, 276(%rsp)
	vmovsd	%xmm1, 88(%rsp)
	movl	%ebx, 432(%rsp)
	vmovsd	%xmm4, 232(%rsp)
	vmovsd	72+pid_(%rip), %xmm5
	vmovsd	.LC8(%rip), %xmm15
	movl	28+bas_(%rip), %ecx
	vdivsd	%xmm2, %xmm15, %xmm4
	vmovsd	.LC85(%rip), %xmm0
	movl	%ecx, 256(%rsp)
	movl	%ecx, %esi
	movl	8+ssb2_(%rip), %ecx
	vmovsd	32+hhar_(%rip), %xmm7
	movl	%ecx, 264(%rsp)
	movl	28+ssb2_(%rip), %ecx
	decl	%eax
	movl	%ecx, 260(%rsp)
	movl	36+restr_(%rip), %ecx
	andl	$1, %esi
	movl	%ecx, 316(%rsp)
	movslq	540000008(%rdx), %rcx
	movb	%sil, 315(%rsp)
	imulq	$15000000, %rcx, %rcx
	vmovsd	%xmm5, 304(%rsp)
	vmovsd	%xmm7, 368(%rsp)
	addq	%rcx, %rax
	movq	%rcx, %rsi
	vdivsd	%xmm5, %xmm1, %xmm2
	salq	$4, %rax
	leaq	-179999976(%rdx,%rax), %rax
	salq	$4, %rsi
	movq	%rax, 56(%rsp)
	leaq	-179999992(%rdx,%rsi), %r14
	leaq	240016+nat_(%rip), %rax
	leal	-1(%rbx), %edx
	vmovsd	%xmm4, 472(%rsp)
	leaq	(%rax,%rdx,8), %rax
	vxorps	%xmm12, %xmm12, %xmm12
	leaq	sdch_(%rip), %r15
	leaq	pos_(%rip), %r10
	vmovsd	%xmm2, 376(%rsp)
	vdivsd	bas_(%rip), %xmm0, %xmm2
	vmovsd	%xmm2, 440(%rsp)
	vmovsd	24+hhar_(%rip), %xmm2
	vmovsd	%xmm2, 448(%rsp)
	vmovsd	16+hhar_(%rip), %xmm2
	vaddsd	%xmm2, %xmm2, %xmm1
	vmovsd	%xmm2, 456(%rsp)
	vdivsd	48+hhar_(%rip), %xmm15, %xmm2
	vmovsd	%xmm1, 464(%rsp)
	vmulsd	56+hhar_(%rip), %xmm4, %xmm1
	vmulsd	%xmm7, %xmm4, %xmm4
	vmovsd	%xmm2, 336(%rsp)
	vmovsd	32+sig_(%rip), %xmm2
	vmovsd	%xmm1, 344(%rsp)
	vmovsd	%xmm2, 480(%rsp)
	vmovsd	48+sig_(%rip), %xmm5
	vmovq	.LC11(%rip), %xmm0
	vmovsd	24+sig_(%rip), %xmm1
	movq	%rax, 424(%rsp)
	vmovsd	%xmm5, 360(%rsp)
	vmovsd	%xmm1, 392(%rsp)
	vmovsd	%xmm0, %xmm0, %xmm14
	vmovapd	%xmm0, 320(%rsp)
	vmovsd	%xmm4, 296(%rsp)
	jmp	.L1225
	.p2align 4,,10
	.p2align 3
.L1403:
	cmpl	$2, %edi
	setg	314(%rsp)
	movl	%edi, %r11d
.L1129:
	movslq	(%r14), %r12
	decl	%edi
	movslq	%edi, %rdi
	leaq	sig_(%rip), %rbx
	vmovsd	(%rbx,%rdi,8), %xmm0
	movl	4(%r14), %edi
	movl	356(%r15,%r12,4), %ebx
	leaq	-1(%r12), %rbp
	movl	%ebx, 16(%rsp)
	movslq	%edi, %rbx
	movl	%edi, 28(%rsp)
	movl	356(%r15,%rbx,4), %r8d
	vmovsd	(%r10,%rbp,8), %xmm1
	vmovsd	79992(%r10,%r12,8), %xmm2
	vmovsd	159992(%r10,%r12,8), %xmm4
	movl	48(%rsp), %edi
	movl	%r12d, 40(%rsp)
	movl	%r8d, 12(%rsp)
	vsubsd	-8(%r10,%rbx,8), %xmm1, %xmm1
	vsubsd	79992(%r10,%rbx,8), %xmm2, %xmm2
	vsubsd	159992(%r10,%rbx,8), %xmm4, %xmm4
	leaq	-1(%rbx), %r13
	testl	%edi, %edi
	je	.L1130
	vmulsd	96(%rsp), %xmm1, %xmm5
	vmovsd	.LC60(%rip), %xmm3
	vandpd	%xmm5, %xmm14, %xmm6
	vorpd	%xmm6, %xmm3, %xmm3
	vaddsd	%xmm5, %xmm3, %xmm3
	vcvttsd2sil	%xmm3, %r8d
	vcvtsi2sdl	%r8d, %xmm12, %xmm3
	vfnmadd231sd	104(%rsp), %xmm3, %xmm1
.L1130:
	movl	52(%rsp), %r9d
	testl	%r9d, %r9d
	je	.L1131
	vmulsd	112(%rsp), %xmm2, %xmm5
	vmovsd	.LC60(%rip), %xmm3
	vandpd	%xmm5, %xmm14, %xmm6
	vorpd	%xmm6, %xmm3, %xmm3
	vaddsd	%xmm5, %xmm3, %xmm3
	vcvttsd2sil	%xmm3, %r8d
	vcvtsi2sdl	%r8d, %xmm12, %xmm3
	vfnmadd231sd	120(%rsp), %xmm3, %xmm2
.L1131:
	movl	80(%rsp), %r8d
	testl	%r8d, %r8d
	je	.L1132
	vmulsd	128(%rsp), %xmm4, %xmm5
	vmovsd	.LC60(%rip), %xmm3
	vandpd	%xmm5, %xmm14, %xmm6
	vorpd	%xmm6, %xmm3, %xmm3
	vaddsd	%xmm5, %xmm3, %xmm3
	vcvttsd2sil	%xmm3, %r8d
	vcvtsi2sdl	%r8d, %xmm12, %xmm3
	vfnmadd231sd	136(%rsp), %xmm3, %xmm4
.L1132:
	vmulsd	%xmm2, %xmm2, %xmm3
	vfmadd231sd	%xmm1, %xmm1, %xmm3
	vfmadd231sd	%xmm4, %xmm4, %xmm3
	vcomisd	%xmm3, %xmm13
	jbe	.L1133
	leaq	neigh_(%rip), %r8
	incl	(%r8,%rbp,8)
	incl	(%r8,%r13,8)
.L1133:
	vcomisd	%xmm11, %xmm3
	jbe	.L1389
	testl	%eax, %eax
	je	.L1137
	decl	%ecx
	xorl	%ecx, %eax
	sarl	$31, %eax
	leal	(%rcx,%rax), %edx
	xorl	%eax, %edx
	movl	%edx, 8(%r14)
.L1137:
	testl	%edx, %edx
	jne	.L1220
	cmpb	$0, 314(%rsp)
	jne	.L1401
.L1220:
	addq	$16, %r14
	cmpq	56(%rsp), %r14
	je	.L1402
.L1225:
	movl	12(%r14), %esi
	movl	8(%r14), %eax
	movl	%esi, %r8d
	sarl	$31, %r8d
	movl	%eax, %r9d
	movl	%r8d, %edi
	sarl	$31, %r9d
	xorl	%esi, %edi
	movl	%r9d, %ecx
	subl	%r8d, %edi
	xorl	%eax, %ecx
	orl	$1, %r8d
	movl	%r8d, 20(%rsp)
	movl	%eax, %edx
	subl	%r9d, %ecx
	cmpl	$8, %edi
	jle	.L1403
	movb	$1, 314(%rsp)
	movl	$5, %r11d
	jmp	.L1129
	.p2align 4,,10
	.p2align 3
.L1389:
	movl	24(%rsp), %edi
	vsqrtsd	%xmm3, %xmm3, %xmm5
	movl	$0, 32(%rsp)
	testl	%edi, %edi
	je	.L1138
	movl	16(%rsp), %r8d
	xorl	%edi, %edi
	addl	12(%rsp), %r8d
	cmpl	$7, %r8d
	setg	%dil
	movl	%edi, 32(%rsp)
.L1138:
	cmpl	$1, %r11d
	jle	.L1404
	vmulsd	160(%rsp), %xmm0, %xmm6
	vcomisd	%xmm5, %xmm6
	jb	.L1391
	movl	$6, %esi
	addl	$2, 196(%rsp)
	cmpl	%esi, %r11d
	cmovle	%r11d, %esi
	cmpl	$1, 20(%rsp)
	movl	%esi, %r8d
	je	.L1405
	leal	-4(%rsi), %esi
	movslq	%esi, %rsi
	incl	224(%rsp)
	incl	(%r15,%rsi,4)
.L1176:
	vcvtsi2sdl	%ecx, %xmm12, %xmm6
	vmovsd	152(%rsp), %xmm7
	movl	%eax, %esi
	vcomisd	%xmm6, %xmm7
	jbe	.L1177
	leal	1(%rcx), %esi
	movl	%esi, 8(%r14)
.L1177:
	movl	192(%rsp), %eax
	testl	%eax, %eax
	je	.L1180
	leaq	sequence_(%rip), %rax
	leaq	10000(%rbp), %rdi
	cmpl	$4, 40000(%rax,%rbp,4)
	movq	%rdi, 64(%rsp)
	je	.L1406
	movl	24(%rsp), %eax
	testl	%eax, %eax
	jne	.L1186
	.p2align 4,,10
	.p2align 3
.L1185:
	vcomisd	88(%rsp), %xmm5
	jbe	.L1396
	movl	32(%rsp), %eax
	movl	%esi, %edx
	testl	%eax, %eax
	je	.L1137
	movl	24(%rsp), %ecx
	leaq	10000(%rbp), %rax
	movq	%rax, 64(%rsp)
	vxorpd	%xmm6, %xmm6, %xmm6
	leaq	10000(%r13), %rax
	testl	%ecx, %ecx
	movq	%rax, 72(%rsp)
	vmovsd	%xmm6, %xmm6, %xmm7
	jne	.L1207
	.p2align 4,,10
	.p2align 3
.L1209:
	vdivsd	%xmm5, %xmm6, %xmm6
	movq	144(%rsp), %rax
	movq	64(%rsp), %rsi
	vaddsd	(%rax), %xmm7, %xmm7
	movq	72(%rsp), %rcx
	vmovsd	%xmm7, (%rax)
	leaq	for_(%rip), %rax
	vmovsd	%xmm6, %xmm6, %xmm0
	vfnmadd213sd	(%rax,%rbp,8), %xmm1, %xmm0
	vmovsd	%xmm0, (%rax,%rbp,8)
	vmovsd	%xmm6, %xmm6, %xmm0
	vfnmadd213sd	(%rax,%rsi,8), %xmm2, %xmm0
	vfmadd213sd	(%rax,%r13,8), %xmm6, %xmm1
	vmovsd	%xmm0, (%rax,%rsi,8)
	vmovsd	%xmm6, %xmm6, %xmm0
	vfnmadd213sd	160000(%rax,%rbp,8), %xmm4, %xmm0
	vfmadd213sd	(%rax,%rcx,8), %xmm6, %xmm2
	vmovsd	%xmm1, (%rax,%r13,8)
	vmovsd	%xmm0, 160000(%rax,%rbp,8)
	vfmadd213sd	160000(%rax,%r13,8), %xmm4, %xmm6
	vmovsd	%xmm2, (%rax,%rcx,8)
	vmovsd	%xmm6, 160000(%rax,%r13,8)
	jmp	.L1137
	.p2align 4,,10
	.p2align 3
.L1180:
	movl	24(%rsp), %r9d
	testl	%r9d, %r9d
	je	.L1185
	leaq	sequence_(%rip), %rax
	leaq	10000(%rbp), %rdi
	cmpl	$4, 40000(%rax,%rbp,4)
	movq	%rdi, 64(%rsp)
	je	.L1407
.L1186:
	movl	256(%rsp), %eax
	testl	%eax, %eax
	je	.L1197
	vmulsd	304(%rsp), %xmm0, %xmm6
	vcomisd	%xmm5, %xmm6
	jnb	.L1408
	movl	32(%rsp), %eax
	testl	%eax, %eax
	jne	.L1197
	testl	%edx, %edx
	movl	%esi, %edx
	je	.L1137
	.p2align 4,,10
	.p2align 3
.L1197:
	vcvtsi2sdl	%ecx, %xmm12, %xmm7
	vmulsd	296(%rsp), %xmm7, %xmm7
.L1200:
	cmpl	$4, %r11d
	jne	.L1203
	vaddsd	%xmm7, %xmm7, %xmm7
.L1203:
	vdivsd	%xmm5, %xmm0, %xmm0
	vmovsd	.LC83(%rip), %xmm9
	vmovsd	.LC74(%rip), %xmm8
	vcomisd	88(%rsp), %xmm5
	vmulsd	%xmm0, %xmm0, %xmm6
	vmulsd	%xmm0, %xmm6, %xmm6
	vmulsd	%xmm6, %xmm6, %xmm6
	vmulsd	%xmm6, %xmm7, %xmm0
	vsubsd	%xmm15, %xmm6, %xmm7
	vfnmadd132sd	%xmm8, %xmm15, %xmm6
	vmulsd	%xmm9, %xmm7, %xmm7
	vmulsd	%xmm0, %xmm7, %xmm7
	vmulsd	%xmm6, %xmm0, %xmm0
	vmulsd	.LC88(%rip), %xmm0, %xmm6
	vdivsd	%xmm5, %xmm6, %xmm6
	jnb	.L1255
	cmpb	$0, 315(%rsp)
	je	.L1409
.L1255:
	leaq	10000(%r13), %rax
	movq	%rax, 72(%rsp)
	movl	%esi, %edx
	jmp	.L1188
	.p2align 4,,10
	.p2align 3
.L1207:
	movl	12(%rsp), %ecx
	leaq	misc_(%rip), %rax
	vmovsd	(%rax,%rbp,8), %xmm0
	cmpl	%ecx, 16(%rsp)
	je	.L1272
	cmpl	$5, %r11d
	jne	.L1272
	cmpl	$1, %r8d
	je	.L1213
	vaddsd	%xmm15, %xmm0, %xmm0
	vmovsd	152(%rsp), %xmm10
	vminsd	%xmm10, %xmm0, %xmm0
	vmovsd	%xmm0, (%rax,%rbp,8)
	vaddsd	(%rax,%r13,8), %xmm15, %xmm9
	vminsd	%xmm10, %xmm9, %xmm9
	vmovsd	%xmm9, (%rax,%r13,8)
	vmovsd	(%rax,%rbp,8), %xmm0
.L1212:
	movl	260(%rsp), %r8d
	vxorpd	%xmm8, %xmm8, %xmm8
	testl	%r8d, %r8d
	jne	.L1214
	vmaxsd	%xmm0, %xmm9, %xmm8
.L1214:
	vmovsd	152(%rsp), %xmm0
	vcomisd	%xmm8, %xmm0
	jbe	.L1399
	vmulsd	336(%rsp), %xmm5, %xmm9
	movl	%r11d, 408(%rsp)
	movl	%edx, 84(%rsp)
	vmovsd	%xmm11, 504(%rsp)
	vmovsd	%xmm13, 496(%rsp)
	vxorpd	320(%rsp), %xmm9, %xmm0
	vmovsd	%xmm3, 488(%rsp)
	vmovsd	%xmm6, 384(%rsp)
	vmovsd	%xmm7, 288(%rsp)
	vmovsd	%xmm4, 240(%rsp)
	vmovsd	%xmm2, 216(%rsp)
	vmovsd	%xmm1, 208(%rsp)
	vmovsd	%xmm8, 176(%rsp)
	vmovsd	%xmm5, 40(%rsp)
	vmovsd	%xmm9, 32(%rsp)
	call	exp@PLT
	movq	.LC8(%rip), %rax
	movl	12(%rsp), %edx
	vmovq	%rax, %xmm15
	movq	.LC90(%rip), %rax
	cmpl	%edx, 16(%rsp)
	vmovsd	32(%rsp), %xmm9
	vmovsd	40(%rsp), %xmm5
	movl	84(%rsp), %edx
	vmovsd	176(%rsp), %xmm8
	vmovsd	208(%rsp), %xmm1
	vmovsd	216(%rsp), %xmm2
	vmovsd	240(%rsp), %xmm4
	vmovsd	288(%rsp), %xmm7
	vmovsd	384(%rsp), %xmm6
	movl	408(%rsp), %r11d
	vmovsd	488(%rsp), %xmm3
	vmovsd	496(%rsp), %xmm13
	vmovsd	504(%rsp), %xmm11
	vmovsd	%xmm0, %xmm0, %xmm10
	leaq	pos_(%rip), %r10
	vmovq	%rax, %xmm14
	vxorps	%xmm12, %xmm12, %xmm12
	je	.L1410
	movl	260(%rsp), %edi
	vxorpd	%xmm0, %xmm0, %xmm0
	testl	%edi, %edi
	je	.L1411
	movl	316(%rsp), %esi
	testl	%esi, %esi
	jne	.L1412
.L1218:
	vdivsd	%xmm3, %xmm0, %xmm0
	vmovsd	.LC103(%rip), %xmm8
	vsubsd	%xmm9, %xmm8, %xmm8
	vmulsd	%xmm0, %xmm8, %xmm8
	vdivsd	%xmm5, %xmm8, %xmm8
	vaddsd	%xmm6, %xmm8, %xmm6
.L1219:
	vaddsd	%xmm0, %xmm7, %xmm7
	jmp	.L1399
	.p2align 4,,10
	.p2align 3
.L1401:
	movl	20(%rsp), %eax
	movl	%eax, 12(%r14)
	cmpl	$5, %r11d
	je	.L1413
	cmpl	$7, %r11d
	je	.L1414
	cmpl	$6, %r11d
	je	.L1415
	cmpl	$4, %r11d
	jne	.L1220
	leaq	10090(,%rbp,4), %rax
	decl	(%r15,%rax,4)
	addq	$16, %r14
	leaq	10090(,%r13,4), %rax
	decl	(%r15,%rax,4)
	cmpq	56(%rsp), %r14
	jne	.L1225
	.p2align 4,,10
	.p2align 3
.L1402:
	vmovd	264(%rsp), %xmm4
	vmovd	224(%rsp), %xmm2
	vpinsrd	$1, 276(%rsp), %xmm4, %xmm0
	vmovd	252(%rsp), %xmm5
	movl	196(%rsp), %eax
	vpinsrd	$1, 272(%rsp), %xmm2, %xmm1
	vmovq	%xmm0, 8+ssb2_(%rip)
	vpinsrd	$1, 268(%rsp), %xmm5, %xmm0
	movl	%eax, 80024+misc_(%rip)
	vpunpcklqdq	%xmm1, %xmm0, %xmm0
	vmovdqu	%xmm0, 2000012+cmapi_(%rip)
.L1397:
	addq	$536, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L1404:
	.cfi_restore_state
	leaq	sequence_(%rip), %r8
	leaq	10000(%rbp), %rdi
	movq	%rdi, 64(%rsp)
	movl	(%r8,%rdi,4), %edi
	movl	%edi, 84(%rsp)
	leaq	10000(%r13), %rdi
	movl	(%r8,%rdi,4), %r8d
	movq	%rdi, 72(%rsp)
	movl	84(%rsp), %edi
	movl	%r8d, %r9d
	movl	%r8d, 176(%rsp)
	leal	(%rdi,%rdi,4), %r8d
	leal	(%rdi,%r8,4), %r8d
	addl	%r9d, %r8d
	movl	%r8d, 208(%rsp)
	leaq	sig_(%rip), %rdi
	movslq	%r8d, %r8
	vmovsd	-8(%rdi,%r8,8), %xmm9
	vmaxsd	200(%rsp), %xmm9, %xmm6
	vmulsd	168(%rsp), %xmm6, %xmm6
	vcomisd	%xmm5, %xmm6
	jbe	.L1140
	cmpl	$2, 84(%rsp)
	leaq	0(,%rbp,4), %rdi
	movl	$1, %r8d
	movq	%rdi, 216(%rsp)
	cmovne	228(%rsp), %r8d
	addq	$10090, %rdi
	movq	%rdi, 408(%rsp)
	movl	(%r15,%rdi,4), %edi
	movq	.LC10(%rip), %r9
	movl	%edi, 488(%rsp)
	cmpl	%r8d, %edi
	jge	.L1143
	leaq	0(%rbp,%rbp,2), %r8
	addq	%r8, %r8
	vmulsd	720008(%r10,%r8,8), %xmm2, %xmm6
	vfmadd231sd	720000(%r10,%r8,8), %xmm1, %xmm6
	vfmadd231sd	720016(%r10,%r8,8), %xmm4, %xmm6
	vdivsd	%xmm5, %xmm6, %xmm6
	vandpd	.LC69(%rip), %xmm6, %xmm7
	vmovq	%xmm7, %r9
.L1143:
	cmpl	$2, 176(%rsp)
	movl	$1, %r8d
	cmovne	228(%rsp), %r8d
	leaq	0(,%r13,4), %rdi
	movl	%r8d, 288(%rsp)
	leaq	10090(%rdi), %r8
	movq	%r8, 384(%rsp)
	movl	288(%rsp), %r8d
	movq	%rdi, 240(%rsp)
	vxorpd	%xmm6, %xmm6, %xmm6
	cmpl	%r8d, 40360(%r15,%rdi,4)
	jl	.L1416
.L1145:
	vmovsd	184(%rsp), %xmm7
	vcomisd	%xmm7, %xmm6
	jbe	.L1146
	vmovq	%r9, %xmm10
	vcomisd	%xmm7, %xmm10
	ja	.L1417
.L1146:
	movq	216(%rsp), %rdi
	vmovsd	%xmm15, %xmm15, %xmm7
	leaq	4(%rdi), %r8
	movl	248(%rsp), %edi
	movq	%r8, 288(%rsp)
	leaq	neigh_(%rip), %r8
	cmpl	%edi, -4(%r8,%r12,8)
	setl	%r8b
	movq	216(%rsp), %rdi
	movzbl	%r8b, %r8d
	addl	40364(%r15,%rdi,4), %r8d
	cmpl	$1, 40(%rsp)
	jle	.L1150
	movslq	84(%rsp), %rdi
	cmpl	%r8d, 104(%r15,%rdi,4)
	jle	.L1150
	leaq	-6(%r12,%r12,2), %r8
	addq	%r8, %r8
	vmovsd	240008(%r10,%r8,8), %xmm10
	vmovsd	240000(%r10,%r8,8), %xmm7
	vmovsd	240048(%r10,%r8,8), %xmm8
	vmovsd	%xmm10, 496(%rsp)
	vmovq	%xmm7, %rdi
	vmovsd	240056(%r10,%r8,8), %xmm10
	vmovsd	%xmm8, 504(%rsp)
	vsubsd	%xmm8, %xmm7, %xmm8
	vmovsd	496(%rsp), %xmm7
	vmovsd	%xmm10, 512(%rsp)
	vsubsd	%xmm10, %xmm7, %xmm7
	vmovsd	240016(%r10,%r8,8), %xmm10
	movq	240064(%r10,%r8,8), %r8
	vmulsd	%xmm2, %xmm7, %xmm7
	vmovsd	%xmm10, 520(%rsp)
	vfmadd231sd	%xmm1, %xmm8, %xmm7
	vmovq	%r8, %xmm8
	vsubsd	%xmm8, %xmm10, %xmm8
	vfmadd132sd	%xmm4, %xmm7, %xmm8
	vxorpd	%xmm7, %xmm7, %xmm7
	vcomisd	%xmm8, %xmm7
	jbe	.L1418
	.p2align 4,,10
	.p2align 3
.L1150:
	vcomisd	184(%rsp), %xmm6
	jbe	.L1151
	vmovsd	280(%rsp), %xmm6
	vcomisd	%xmm7, %xmm6
	jbe	.L1151
	movl	$7, 208(%rsp)
	vmovsd	360(%rsp), %xmm9
	movl	$7, %r8d
.L1148:
	vmulsd	168(%rsp), %xmm9, %xmm6
	vcomisd	%xmm5, %xmm6
	jb	.L1140
	movl	208(%rsp), %edi
	vcvtsi2sdl	%ecx, %xmm12, %xmm6
	xorl	%edi, %esi
	sarl	$31, %esi
	vmovsd	152(%rsp), %xmm7
	addl	%esi, %edi
	xorl	%edi, %esi
	vcomisd	%xmm6, %xmm7
	movl	%esi, 208(%rsp)
	movl	%esi, 12(%r14)
	jbe	.L1158
	leal	1(%rcx), %eax
	movl	%eax, 8(%r14)
.L1158:
	cmpl	$5, %r8d
	je	.L1419
	movl	%eax, %esi
	cmpl	$7, %r8d
	je	.L1420
	cmpl	$6, %r8d
	je	.L1421
	cmpl	$4, %r8d
	je	.L1422
	movl	$5, %r8d
	jmp	.L1161
	.p2align 4,,10
	.p2align 3
.L1151:
	movq	240(%rsp), %rdi
	vmovsd	%xmm15, %xmm15, %xmm6
	leaq	4(%rdi), %r8
	movl	248(%rsp), %edi
	movq	%r8, 496(%rsp)
	leaq	neigh_(%rip), %r8
	cmpl	-4(%r8,%rbx,8), %edi
	setg	%r8b
	movq	240(%rsp), %rdi
	movzbl	%r8b, %r8d
	addl	40364(%r15,%rdi,4), %r8d
	cmpl	$1, 28(%rsp)
	jle	.L1154
	movslq	176(%rsp), %rdi
	cmpl	%r8d, 104(%r15,%rdi,4)
	jle	.L1154
	leaq	0(%r13,%r13,2), %r8
	addq	%r8, %r8
	vmovsd	240008(%r10,%r8,8), %xmm8
	vmovsd	240000(%r10,%r8,8), %xmm6
	vsubsd	239960(%r10,%r8,8), %xmm8, %xmm10
	vsubsd	239952(%r10,%r8,8), %xmm6, %xmm6
	vmulsd	%xmm10, %xmm2, %xmm8
	vmovq	%xmm6, %rdi
	vfmadd231sd	%xmm6, %xmm1, %xmm8
	vmovsd	240016(%r10,%r8,8), %xmm6
	vsubsd	239968(%r10,%r8,8), %xmm6, %xmm6
	vfmadd231sd	%xmm4, %xmm6, %xmm8
	vmovq	%xmm6, %r8
	vxorpd	%xmm6, %xmm6, %xmm6
	vcomisd	%xmm8, %xmm6
	ja	.L1154
	vmulsd	%xmm10, %xmm10, %xmm6
	vmovq	%rdi, %xmm10
	vmulsd	%xmm8, %xmm8, %xmm8
	vfmadd132sd	%xmm10, %xmm6, %xmm10
	vmovsd	%xmm10, %xmm10, %xmm6
	vmovq	%r8, %xmm10
	vfmadd132sd	%xmm10, %xmm6, %xmm10
	vmulsd	%xmm10, %xmm3, %xmm6
	vdivsd	%xmm6, %xmm8, %xmm6
	.p2align 4,,10
	.p2align 3
.L1154:
	vmovq	%r9, %xmm10
	vcomisd	184(%rsp), %xmm10
	ja	.L1423
	vmovsd	280(%rsp), %xmm10
	vcomisd	%xmm6, %xmm10
	jbe	.L1140
	vcomisd	%xmm7, %xmm10
	jbe	.L1140
	movl	16(%rsp), %edi
	movl	$2, %r8d
	cmpl	%r8d, %edi
	movl	%edi, %r9d
	cmovg	%r8d, %r9d
	addl	$2, %r9d
	movl	%r9d, 404(%rsp)
	movl	12(%rsp), %r9d
	cmpl	%r8d, %r9d
	cmovle	%r9d, %r8d
	movq	288(%rsp), %r9
	addl	$2, %r8d
	movl	%r8d, 416(%rsp)
	movslq	%r8d, %r8
	leaq	10085(%r9,%r8), %r9
	movq	%r9, 288(%rsp)
	leaq	(%r8,%r8,4), %r9
	leaq	(%r8,%r9,4), %r8
	movslq	84(%rsp), %r9
	leaq	-16(%r9,%r8), %r8
	movl	(%r15,%r8,4), %r8d
	movq	288(%rsp), %r9
	cmpl	%r8d, (%r15,%r9,4)
	setl	%r9b
	movzbl	%r9b, %r9d
	movl	%r9d, 288(%rsp)
	movl	12(%rsp), %r9d
	xorl	%r8d, %r8d
	cmpl	%r9d, %edi
	movl	32(%rsp), %r9d
	setne	%r8b
	xorl	$1, %r9d
	orl	%r9d, %r8d
	cmpl	$20, 84(%rsp)
	jne	.L1157
	cmpl	$20, 176(%rsp)
	jne	.L1157
	movl	28(%rsp), %r9d
	subl	40(%rsp), %r9d
	movl	%r9d, %edi
	sarl	$31, %edi
	xorl	%edi, %r9d
	subl	%edi, %r9d
	cmpl	$3, %r9d
	je	.L1140
.L1157:
	movl	288(%rsp), %r9d
	testl	%r9d, %r9d
	je	.L1140
	testl	%r8d, %r8d
	je	.L1140
	movslq	404(%rsp), %r8
	movq	496(%rsp), %rdi
	leaq	(%r8,%r8,4), %r9
	leaq	10085(%rdi,%r8), %rdi
	leaq	(%r8,%r9,4), %r8
	movslq	176(%rsp), %r9
	leaq	-16(%r9,%r8), %r8
	movl	(%r15,%r8,4), %r9d
	cmpl	%r9d, (%r15,%rdi,4)
	jge	.L1140
	movl	436(%rsp), %edi
	testl	%edi, %edi
	je	.L1400
	movl	$5, 208(%rsp)
	vmovsd	480(%rsp), %xmm9
.L1400:
	movl	$5, %r8d
	jmp	.L1148
	.p2align 4,,10
	.p2align 3
.L1396:
	vmovsd	232(%rsp), %xmm7
	leaq	10000(%rbp), %rax
	vdivsd	%xmm5, %xmm7, %xmm6
	movq	%rax, 64(%rsp)
	leaq	10000(%r13), %rax
	movq	%rax, 72(%rsp)
	movl	%esi, %edx
	vmulsd	%xmm6, %xmm6, %xmm0
	vmulsd	%xmm6, %xmm0, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm0, %xmm0, %xmm8
	vmulsd	.LC83(%rip), %xmm0, %xmm6
	vsubsd	%xmm15, %xmm0, %xmm7
	vfnmadd132sd	.LC74(%rip), %xmm15, %xmm8
	vmulsd	.LC88(%rip), %xmm0, %xmm0
	vfmadd132sd	%xmm6, %xmm15, %xmm7
	vmulsd	%xmm8, %xmm0, %xmm0
	vdivsd	%xmm5, %xmm0, %xmm6
.L1188:
	movl	24(%rsp), %eax
	testl	%eax, %eax
	je	.L1399
	movl	32(%rsp), %r9d
	testl	%r9d, %r9d
	jne	.L1207
.L1399:
	vminsd	.LC82(%rip), %xmm6, %xmm6
	vmaxsd	.LC86(%rip), %xmm6, %xmm6
	jmp	.L1209
	.p2align 4,,10
	.p2align 3
.L1391:
	testl	%eax, %eax
	jle	.L1179
	movl	$1, %esi
	subl	%eax, %esi
	movl	%esi, 8(%r14)
	movl	$1, %r8d
	jmp	.L1177
	.p2align 4,,10
	.p2align 3
.L1423:
	vmovsd	280(%rsp), %xmm7
	vcomisd	%xmm6, %xmm7
	ja	.L1244
	.p2align 4,,10
	.p2align 3
.L1140:
	testl	%eax, %eax
	je	.L1247
	leal	-1(%rcx), %edi
	xorl	%edi, %eax
	sarl	$31, %eax
	leal	(%rdi,%rax), %esi
	xorl	%eax, %esi
	movl	%esi, 8(%r14)
	movl	$1, %r8d
.L1161:
	movl	192(%rsp), %eax
	testl	%eax, %eax
	je	.L1185
	cmpl	$4, 84(%rsp)
	jne	.L1185
.L1182:
	cmpl	$1, %r11d
	jle	.L1185
	cmpb	$0, 403(%rsp)
	je	.L1185
	jmp	.L1186
	.p2align 4,,10
	.p2align 3
.L1413:
	movl	28(%rsp), %edx
	leaq	ssb_(%rip), %rax
	cmpl	%edx, (%rax,%rbp,4)
	je	.L1424
.L1222:
	salq	$2, %r12
	decl	40348(%r15,%r12,4)
	movl	16(%rsp), %eax
	movl	$2, %r8d
	salq	$2, %rbx
	decl	40348(%r15,%rbx,4)
	movl	%eax, %r9d
	cmpl	%r8d, %eax
	movl	12(%rsp), %eax
	cmovg	%r8d, %r9d
	cmpl	%r8d, %eax
	cmovle	%eax, %r8d
	leal	2(%r9), %edx
	leal	2(%r8), %eax
	movl	%eax, 416(%rsp)
	cltq
	leaq	10085(%r12,%rax), %rax
	decl	(%r15,%rax,4)
	movslq	%edx, %rax
	leaq	10085(%rbx,%rax), %rax
	movl	%edx, 404(%rsp)
	decl	(%r15,%rax,4)
	jmp	.L1220
	.p2align 4,,10
	.p2align 3
.L1247:
	xorl	%esi, %esi
	movl	$1, %r8d
	jmp	.L1161
	.p2align 4,,10
	.p2align 3
.L1416:
	leaq	0(%r13,%r13,2), %r8
	addq	%r8, %r8
	vmulsd	720008(%r10,%r8,8), %xmm2, %xmm6
	vfmadd231sd	720000(%r10,%r8,8), %xmm1, %xmm6
	vfmadd231sd	720016(%r10,%r8,8), %xmm4, %xmm6
	vdivsd	%xmm5, %xmm6, %xmm6
	vandpd	.LC69(%rip), %xmm6, %xmm6
	jmp	.L1145
	.p2align 4,,10
	.p2align 3
.L1408:
	vmovsd	88(%rsp), %xmm7
	vcomisd	%xmm5, %xmm7
	jb	.L1395
	vmovsd	368(%rsp), %xmm7
	vmovsd	376(%rsp), %xmm0
	jmp	.L1200
	.p2align 4,,10
	.p2align 3
.L1409:
	vmovsd	232(%rsp), %xmm6
	leaq	10000(%r13), %rax
	vdivsd	%xmm5, %xmm6, %xmm6
	movq	%rax, 72(%rsp)
	movl	%esi, %edx
	vmulsd	%xmm6, %xmm6, %xmm10
	vmulsd	%xmm6, %xmm10, %xmm10
	vmulsd	%xmm10, %xmm10, %xmm10
	vfnmadd132sd	%xmm10, %xmm15, %xmm8
	vmulsd	%xmm9, %xmm10, %xmm9
	vsubsd	%xmm15, %xmm10, %xmm6
	vfmadd132sd	%xmm10, %xmm0, %xmm8
	vfmadd132sd	%xmm6, %xmm15, %xmm9
	vmulsd	.LC88(%rip), %xmm8, %xmm8
	vaddsd	%xmm9, %xmm7, %xmm7
	vdivsd	%xmm5, %xmm8, %xmm6
	jmp	.L1188
	.p2align 4,,10
	.p2align 3
.L1424:
	movl	$0, 40000(%rax,%rbp,4)
	movl	$0, (%rax,%rbp,4)
	movl	$0, 40000(%rax,%r13,4)
	movl	$0, (%rax,%r13,4)
	jmp	.L1222
	.p2align 4,,10
	.p2align 3
.L1417:
	movl	28(%rsp), %r8d
	subl	40(%rsp), %r8d
	movl	%r8d, %edi
	sarl	$31, %edi
	xorl	%edi, %r8d
	subl	%edi, %r8d
	cmpl	$4, %r8d
	jne	.L1262
	cmpl	$1, 20(%rsp)
	je	.L1146
.L1262:
	leaq	0(%rbp,%rbp,2), %r8
	leaq	(%r8,%r8), %rdi
	vmovsd	720008(%r10,%rdi,8), %xmm7
	leaq	0(%r13,%r13,2), %r8
	addq	%r8, %r8
	vmulsd	720008(%r10,%r8,8), %xmm7, %xmm7
	vmovsd	720000(%r10,%rdi,8), %xmm10
	vfmadd231sd	720000(%r10,%r8,8), %xmm10, %xmm7
	vmovsd	720016(%r10,%rdi,8), %xmm10
	vfmadd231sd	720016(%r10,%r8,8), %xmm10, %xmm7
	vandpd	.LC69(%rip), %xmm7, %xmm7
	vcomisd	352(%rsp), %xmm7
	jbe	.L1146
	movl	$4, 208(%rsp)
	vmovsd	392(%rsp), %xmm9
	movl	$4, %r8d
	jmp	.L1148
	.p2align 4,,10
	.p2align 3
.L1272:
	vmovsd	(%rax,%r13,8), %xmm9
	jmp	.L1212
	.p2align 4,,10
	.p2align 3
.L1179:
	je	.L1249
	leal	1(%rax), %esi
	movl	%esi, 8(%r14)
	movl	$1, %r8d
	jmp	.L1177
	.p2align 4,,10
	.p2align 3
.L1414:
	leaq	10087(,%r12,4), %rax
	decl	(%r15,%rax,4)
	leaq	10090(,%r13,4), %rax
	decl	(%r15,%rax,4)
	jmp	.L1220
	.p2align 4,,10
	.p2align 3
.L1405:
	leal	-1(%rsi), %esi
	movslq	%esi, %rsi
	incl	252(%rsp)
	incl	(%r15,%rsi,4)
	jmp	.L1176
	.p2align 4,,10
	.p2align 3
.L1406:
	leaq	10000(%r13), %rdi
	cmpl	$4, 40000(%rax,%r13,4)
	movq	%rdi, 72(%rsp)
	jne	.L1182
	cmpl	$5, %r11d
	jne	.L1182
	movl	28(%rsp), %edi
	leaq	ssb_(%rip), %rax
	cmpl	%edi, (%rax,%rbp,4)
	je	.L1183
	movl	24(%rsp), %r9d
	testl	%r9d, %r9d
	je	.L1185
.L1183:
	cmpl	%edi, (%rax,%rbp,4)
	jne	.L1186
	vmovsd	%xmm15, %xmm15, %xmm0
	testl	%esi, %esi
	jns	.L1187
	vcvtsi2sdl	%esi, %xmm12, %xmm0
	vmulsd	472(%rsp), %xmm0, %xmm0
	vxorpd	.LC11(%rip), %xmm0, %xmm0
.L1187:
	vsubsd	440(%rsp), %xmm5, %xmm9
	vmovsd	464(%rsp), %xmm6
	leaq	neigh_(%rip), %rax
	vmulsd	%xmm9, %xmm9, %xmm10
	movl	-4(%rax,%rbx,8), %edx
	addl	-4(%rax,%r12,8), %edx
	vmulsd	448(%rsp), %xmm10, %xmm8
	vaddsd	456(%rsp), %xmm8, %xmm7
	vfmadd132sd	.LC83(%rip), %xmm6, %xmm8
	vmulsd	%xmm10, %xmm7, %xmm7
	vmulsd	%xmm9, %xmm8, %xmm8
	vmulsd	%xmm0, %xmm7, %xmm7
	vmulsd	%xmm0, %xmm8, %xmm6
	cmpl	%edx, 420(%rsp)
	jle	.L1251
	vcomisd	.LC102(%rip), %xmm10
	jbe	.L1251
	movl	12(%r14), %edi
	testl	%edi, %edi
	jle	.L1189
	decl	268(%rsp)
.L1190:
	testl	%esi, %esi
	jle	.L1191
	movl	$1, %edx
	subl	%esi, %edx
	movl	%edx, 8(%r14)
.L1192:
	movl	192(%rsp), %ecx
	testl	%ecx, %ecx
	je	.L1188
	movl	432(%rsp), %eax
	testl	%eax, %eax
	jle	.L1193
	movl	40(%rsp), %edi
	movl	28(%rsp), %r9d
	leaq	240008+nat_(%rip), %rsi
	xorl	%eax, %eax
	jmp	.L1196
.L1194:
	cmpl	%ecx, %edi
	jne	.L1195
	cmpl	28(%rsp), %r9d
	je	.L1425
.L1195:
	addq	$8, %rsi
	cmpq	%rsi, 424(%rsp)
	je	.L1426
.L1196:
	movl	(%rsi), %ecx
	movl	%ecx, 28(%rsp)
	movl	4(%rsi), %ecx
	cmpl	28(%rsp), %edi
	jne	.L1194
	cmpl	%ecx, %r9d
	jne	.L1194
	decl	264(%rsp)
	movl	$1, %eax
	jmp	.L1194
	.p2align 4,,10
	.p2align 3
.L1415:
	leaq	10090(,%rbp,4), %rax
	decl	(%r15,%rax,4)
	leaq	10087(,%rbx,4), %rax
	decl	(%r15,%rax,4)
	jmp	.L1220
	.p2align 4,,10
	.p2align 3
.L1249:
	xorl	%esi, %esi
	movl	$1, %r8d
	jmp	.L1177
	.p2align 4,,10
	.p2align 3
.L1412:
	vdivsd	%xmm5, %xmm0, %xmm0
	vmovsd	.LC9(%rip), %xmm3
	vsubsd	%xmm9, %xmm3, %xmm8
	vmulsd	%xmm0, %xmm8, %xmm8
	vdivsd	%xmm5, %xmm8, %xmm8
	vaddsd	%xmm6, %xmm8, %xmm6
	jmp	.L1219
	.p2align 4,,10
	.p2align 3
.L1407:
	leaq	10000(%r13), %rdi
	cmpl	$4, 40000(%rax,%r13,4)
	movq	%rdi, 72(%rsp)
	jne	.L1186
	cmpl	$5, %r11d
	jne	.L1186
	movl	28(%rsp), %edi
	leaq	ssb_(%rip), %rax
	jmp	.L1183
	.p2align 4,,10
	.p2align 3
.L1395:
	vxorpd	%xmm7, %xmm7, %xmm7
	jmp	.L1200
	.p2align 4,,10
	.p2align 3
.L1244:
	movl	$6, 208(%rsp)
	vmovsd	200(%rsp), %xmm9
	movl	$6, %r8d
	jmp	.L1148
	.p2align 4,,10
	.p2align 3
.L1411:
	vsubsd	152(%rsp), %xmm8, %xmm8
	movl	316(%rsp), %esi
	vmulsd	%xmm10, %xmm8, %xmm8
	vmulsd	344(%rsp), %xmm8, %xmm0
	testl	%esi, %esi
	je	.L1218
	jmp	.L1412
.L1418:
	vmovsd	504(%rsp), %xmm7
	vmovq	%rdi, %xmm10
	vsubsd	%xmm10, %xmm7, %xmm7
	vmovsd	512(%rsp), %xmm10
	vmulsd	%xmm8, %xmm8, %xmm8
	vsubsd	496(%rsp), %xmm10, %xmm10
	vmulsd	%xmm10, %xmm10, %xmm10
	vfmadd132sd	%xmm7, %xmm10, %xmm7
	vmovsd	%xmm7, %xmm7, %xmm10
	vmovq	%r8, %xmm7
	vsubsd	520(%rsp), %xmm7, %xmm7
	vfmadd132sd	%xmm7, %xmm10, %xmm7
	vmulsd	%xmm7, %xmm3, %xmm7
	vdivsd	%xmm7, %xmm8, %xmm7
	jmp	.L1150
	.p2align 4,,10
	.p2align 3
.L1419:
	movq	216(%rsp), %rdi
	movq	240(%rsp), %r9
	incl	40364(%r15,%rdi,4)
	movslq	416(%rsp), %rsi
	leaq	10089(%rdi,%rsi), %rsi
	incl	40364(%r15,%r9,4)
	incl	(%r15,%rsi,4)
	movslq	404(%rsp), %rsi
	leaq	10089(%r9,%rsi), %rsi
	incl	(%r15,%rsi,4)
	cmpl	$4, 176(%rsp)
	movl	%eax, %esi
	jne	.L1161
	cmpl	$4, 84(%rsp)
	jne	.L1161
	leaq	neigh_(%rip), %rax
	movl	-4(%rax,%r12,8), %edi
	addl	-4(%rax,%rbx,8), %edi
	cmpl	420(%rsp), %edi
	jge	.L1185
	movq	64(%rsp), %rdi
	leaq	ssb_(%rip), %rax
	movl	(%rax,%rdi,4), %r9d
	testl	%r9d, %r9d
	jne	.L1185
	movq	72(%rsp), %r9
	cmpl	$0, (%rax,%r9,4)
	jne	.L1185
	movl	$1, (%rax,%rdi,4)
	movl	28(%rsp), %edi
	movl	$1, (%rax,%r9,4)
	movl	%edi, (%rax,%rbp,4)
	movl	40(%rsp), %edi
	movl	%edi, (%rax,%r13,4)
	movl	208(%rsp), %eax
	testl	%eax, %eax
	jle	.L1163
	incl	268(%rsp)
.L1164:
	movl	192(%rsp), %eax
	testl	%eax, %eax
	je	.L1185
	cmpl	$0, 432(%rsp)
	jle	.L1166
	movl	$0, 72(%rsp)
	movl	%edx, 84(%rsp)
	movl	40(%rsp), %edi
	movl	28(%rsp), %r9d
	leaq	240008+nat_(%rip), %rax
	jmp	.L1169
.L1167:
	cmpl	28(%rsp), %edi
	jne	.L1168
	cmpl	40(%rsp), %r9d
	je	.L1427
.L1168:
	addq	$8, %rax
	cmpq	%rax, 424(%rsp)
	je	.L1428
.L1169:
	movl	(%rax), %edx
	movl	%edx, 40(%rsp)
	movl	4(%rax), %edx
	movl	%edx, 28(%rsp)
	cmpl	40(%rsp), %edi
	jne	.L1167
	cmpl	%edx, %r9d
	jne	.L1167
	incl	264(%rsp)
	movl	$1, 72(%rsp)
	jmp	.L1167
	.p2align 4,,10
	.p2align 3
.L1410:
	vmovsd	152(%rsp), %xmm0
	movl	316(%rsp), %esi
	vsubsd	%xmm8, %xmm0, %xmm8
	vmulsd	%xmm10, %xmm8, %xmm8
	vmulsd	344(%rsp), %xmm8, %xmm0
	testl	%esi, %esi
	je	.L1218
	jmp	.L1412
	.p2align 4,,10
	.p2align 3
.L1213:
	vsubsd	%xmm15, %xmm0, %xmm0
	vxorpd	%xmm8, %xmm8, %xmm8
	vmaxsd	%xmm8, %xmm0, %xmm0
	vmovsd	%xmm0, (%rax,%rbp,8)
	vmovsd	(%rax,%r13,8), %xmm9
	vsubsd	%xmm15, %xmm9, %xmm9
	vmaxsd	%xmm8, %xmm9, %xmm9
	vmovsd	%xmm9, (%rax,%r13,8)
	vmovsd	(%rax,%rbp,8), %xmm0
	jmp	.L1212
	.p2align 4,,10
	.p2align 3
.L1420:
	movq	216(%rsp), %rax
	incl	40364(%r15,%rax,4)
	movq	384(%rsp), %rax
	incl	(%r15,%rax,4)
	jmp	.L1161
.L1421:
	movq	240(%rsp), %rax
	incl	40364(%r15,%rax,4)
	movq	408(%rsp), %rax
	incl	(%r15,%rax,4)
	jmp	.L1161
.L1422:
	movl	488(%rsp), %eax
	movq	408(%rsp), %rdi
	incl	%eax
	movl	%eax, (%r15,%rdi,4)
	movq	384(%rsp), %rax
	incl	(%r15,%rax,4)
	jmp	.L1161
.L1251:
	movl	%esi, %edx
	jmp	.L1188
.L1191:
	movl	$0, %edx
	je	.L1192
	leal	1(%rsi), %edx
	movl	%edx, 8(%r14)
	jmp	.L1192
.L1189:
	decl	272(%rsp)
	jmp	.L1190
.L1425:
	decl	264(%rsp)
	movl	$1, %eax
	jmp	.L1195
.L1426:
	movl	%r9d, 28(%rsp)
	testl	%eax, %eax
	jne	.L1188
.L1193:
	decl	276(%rsp)
	jmp	.L1188
.L1163:
	incl	272(%rsp)
	jmp	.L1164
.L1427:
	incl	264(%rsp)
	movl	$1, 72(%rsp)
	jmp	.L1168
.L1428:
	cmpl	$0, 72(%rsp)
	movl	%r9d, 28(%rsp)
	movl	84(%rsp), %edx
	jne	.L1182
.L1166:
	incl	276(%rsp)
	jmp	.L1182
	.cfi_endproc
.LFE25:
	.size	evalcpot_, .-evalcpot_
	.p2align 4
	.globl	evalimproper_
	.type	evalimproper_, @function
evalimproper_:
.LFB26:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$872, %rsp
	.cfi_def_cfa_offset 928
	movq	%rsi, 432(%rsp)
	movq	%rdi, 480(%rsp)
	movq	%rdx, 488(%rsp)
	leaq	cmp2_(%rip), %rsi
	movl	60000004(%rsi), %ecx
	movq	%fs:40, %rax
	movq	%rax, 856(%rsp)
	xorl	%eax, %eax
	testl	%ecx, %ecx
	jle	.L1429
	vmovsd	240024+for_(%rip), %xmm3
	vmovsd	240016+for_(%rip), %xmm7
	vmovsd	%xmm3, 56(%rsp)
	vmovsd	240000+for_(%rip), %xmm3
	vmovsd	240008+for_(%rip), %xmm5
	vmovsd	240040+for_(%rip), %xmm6
	vmovsd	80008+neigh_(%rip), %xmm4
	vmovsd	%xmm3, 64(%rsp)
	vmovsd	240032+for_(%rip), %xmm3
	vmovq	.LC11(%rip), %xmm10
	vmovsd	%xmm7, 96(%rsp)
	vmovsd	80+pid_(%rip), %xmm7
	movl	10004076+nmapi_(%rip), %edi
	vmovsd	%xmm3, 72(%rsp)
	vmovsd	%xmm5, 80(%rsp)
	vmovsd	7924024+sig_(%rip), %xmm3
	vmovsd	16+pid_(%rip), %xmm5
	vmovsd	%xmm6, 88(%rsp)
	vmovsd	%xmm4, 8(%rsp)
	vmovsd	40+pid_(%rip), %xmm6
	vmovsd	8+pid_(%rip), %xmm4
	vmovsd	%xmm7, 40(%rsp)
	vxorpd	%xmm10, %xmm7, %xmm7
	movl	%edi, 328(%rsp)
	movslq	540000008(%rsi), %rax
	movl	36+kier_(%rip), %r11d
	movl	40+kier_(%rip), %r8d
	movl	44+kier_(%rip), %r12d
	vmovsd	%xmm5, 288(%rsp)
	vmovsd	%xmm6, 296(%rsp)
	vmovsd	%xmm7, 216(%rsp)
	vmovsd	%xmm4, 320(%rsp)
	vmovsd	%xmm3, 16(%rsp)
	vmovsd	56+pid_(%rip), %xmm3
	movl	80024+misc_(%rip), %edi
	vmovsd	32+pid_(%rip), %xmm5
	movl	%edi, 444(%rsp)
	movl	2000020+cmapi_(%rip), %edi
	imulq	$15000000, %rax, %rax
	movl	%edi, 456(%rsp)
	movl	sdch_(%rip), %edi
	vmovsd	pid_(%rip), %xmm6
	movl	%edi, 464(%rsp)
	movl	2000012+cmapi_(%rip), %edi
	vmovsd	48+pid_(%rip), %xmm7
	movl	%edi, 448(%rsp)
	movl	12+sdch_(%rip), %edi
	vmovsd	24+pid_(%rip), %xmm4
	movl	%edi, 452(%rsp)
	movl	28+bas_(%rip), %edi
	vmovsd	%xmm3, 352(%rsp)
	movl	%edi, 512(%rsp)
	movl	88+pid_(%rip), %edi
	vmovsd	cmapi_(%rip), %xmm3
	movl	%edi, 516(%rsp)
	movl	4+sdch_(%rip), %edi
	vmovsd	%xmm5, 360(%rsp)
	movl	%edi, 468(%rsp)
	vmovsd	72+pid_(%rip), %xmm5
	movl	16+sdch_(%rip), %edi
	leaq	1(%rax), %rdx
	vmovsd	%xmm6, 304(%rsp)
	vmovsd	%xmm7, 312(%rsp)
	leaq	0(,%rdx,4), %r10
	movl	%edi, 460(%rsp)
	salq	$4, %rdx
	vmovsd	%xmm4, 472(%rsp)
	vmovsd	%xmm3, 496(%rsp)
	vmovsd	%xmm5, 504(%rsp)
	movl	32+ssb2_(%rip), %edi
	leaq	(%rdx,%rsi), %r9
	leal	-1(%rcx), %edx
	movl	%edi, 528(%rsp)
	vmovsd	.LC8(%rip), %xmm14
	vmovsd	56+hhar_(%rip), %xmm7
	movl	36+restr_(%rip), %edi
	leaq	2(%rax,%rdx), %rax
	salq	$2, %rax
	movq	%r9, %rbx
	vdivsd	48+hhar_(%rip), %xmm14, %xmm6
	movl	%edi, 532(%rsp)
	movq	%rax, 24(%rsp)
	vmovsd	%xmm6, 536(%rsp)
	vmovsd	%xmm7, 520(%rsp)
	leaq	pos_(%rip), %r13
	movl	%r11d, %r14d
	movl	%r8d, %r15d
	movl	%r12d, %ebp
	movq	%r10, %r9
	jmp	.L1489
	.p2align 4,,10
	.p2align 3
.L1437:
	addq	$4, %r9
	addq	$16, %rbx
	cmpq	%r9, 24(%rsp)
	je	.L1560
.L1489:
	movl	328(%rsp), %eax
	movl	-180000008(%rbx), %r8d
	movl	-180000004(%rbx), %edx
	vmovsd	%xmm14, %xmm14, %xmm6
	testl	%eax, %eax
	je	.L1431
	movl	-179999996(%rbx), %eax
	movl	%eax, %ecx
	sarl	$31, %ecx
	xorl	%ecx, %eax
	subl	%ecx, %eax
	decl	%eax
	cltq
	leaq	nmapi_(%rip), %rcx
	vmovsd	64(%rcx,%rax,8), %xmm6
.L1431:
	movslq	%r8d, %rax
	vmulsd	.LC83(%rip), %xmm6, %xmm5
	leaq	-1(%rax), %r11
	vmovsd	0(%r13,%r11,8), %xmm0
	movslq	%edx, %r10
	vsubsd	-8(%r13,%r10,8), %xmm0, %xmm7
	vmovsd	159992(%r13,%rax,8), %xmm9
	vmovsd	79992(%r13,%rax,8), %xmm0
	vsubsd	159992(%r13,%r10,8), %xmm9, %xmm9
	vsubsd	79992(%r13,%r10,8), %xmm0, %xmm11
	vmovsd	%xmm5, 32(%rsp)
	leaq	-1(%r10), %r12
	testl	%r14d, %r14d
	je	.L1432
	vmulsd	56(%rsp), %xmm7, %xmm2
	vmovsd	.LC60(%rip), %xmm0
	vxorpd	%xmm5, %xmm5, %xmm5
	vandpd	%xmm2, %xmm10, %xmm1
	vorpd	%xmm1, %xmm0, %xmm0
	vaddsd	%xmm2, %xmm0, %xmm0
	vcvttsd2sil	%xmm0, %eax
	vcvtsi2sdl	%eax, %xmm5, %xmm0
	vfnmadd231sd	64(%rsp), %xmm0, %xmm7
.L1432:
	testl	%r15d, %r15d
	je	.L1433
	vmulsd	72(%rsp), %xmm11, %xmm2
	vmovsd	.LC60(%rip), %xmm0
	vxorpd	%xmm4, %xmm4, %xmm4
	vandpd	%xmm2, %xmm10, %xmm1
	vorpd	%xmm1, %xmm0, %xmm0
	vaddsd	%xmm2, %xmm0, %xmm0
	vcvttsd2sil	%xmm0, %eax
	vcvtsi2sdl	%eax, %xmm4, %xmm0
	vfnmadd231sd	80(%rsp), %xmm0, %xmm11
.L1433:
	testl	%ebp, %ebp
	je	.L1434
	vmulsd	88(%rsp), %xmm9, %xmm2
	vmovsd	.LC60(%rip), %xmm0
	vxorpd	%xmm5, %xmm5, %xmm5
	vandpd	%xmm2, %xmm10, %xmm1
	vorpd	%xmm1, %xmm0, %xmm0
	vaddsd	%xmm2, %xmm0, %xmm0
	vcvttsd2sil	%xmm0, %eax
	vcvtsi2sdl	%eax, %xmm5, %xmm0
	vfnmadd231sd	96(%rsp), %xmm0, %xmm9
.L1434:
	vmulsd	%xmm11, %xmm11, %xmm0
	vmovsd	8(%rsp), %xmm3
	vfmadd231sd	%xmm7, %xmm7, %xmm0
	vfmadd231sd	%xmm9, %xmm9, %xmm0
	vcomisd	%xmm0, %xmm3
	vmovsd	%xmm0, %xmm0, %xmm13
	jbe	.L1435
	leaq	neigh_(%rip), %rax
	incl	(%rax,%r11,8)
	incl	(%rax,%r12,8)
.L1435:
	vcomisd	16(%rsp), %xmm13
	ja	.L1437
	leaq	sequence_(%rip), %rax
	leaq	10000(%r11), %rdi
	cmpl	$2, 40000(%rax,%r11,4)
	movq	%rdi, 152(%rsp)
	je	.L1437
	leaq	10000(%r12), %rdi
	cmpl	$2, 40000(%rax,%r12,4)
	movq	%rdi, 224(%rsp)
	je	.L1437
	leaq	544(%rsp), %rsi
	movq	%rsi, 104(%rsp)
	leaq	576(%rsp), %rsi
	movq	%rsi, 48(%rsp)
	subl	%r8d, %edx
	leaq	560(%rsp), %rsi
	movl	%edx, 160(%rsp)
	movq	%rsi, 232(%rsp)
	movq	%r11, 368(%rsp)
	movq	%r10, 376(%rsp)
	movl	%r14d, 332(%rsp)
	movl	%r15d, 336(%rsp)
	movq	%r9, 344(%rsp)
	movl	%r8d, 440(%rsp)
	leaq	784(%rsp), %rdi
	movl	$6, %eax
	movq	%r12, 384(%rsp)
	movl	%ebp, 340(%rsp)
	movq	%rdi, %r12
	movq	%rbx, %rbp
	vmovsd	%xmm7, 392(%rsp)
	vmovsd	%xmm11, 400(%rsp)
	vmovsd	%xmm9, 408(%rsp)
	vmovsd	%xmm6, 416(%rsp)
	vmovsd	%xmm13, 424(%rsp)
	movq	%rax, %rbx
.L1438:
	movslq	-180000032(%rbp,%rbx,4), %rsi
	movq	%rbx, %r8
	leaq	-3(%rsi,%rsi,2), %rdx
	addq	%rdx, %rdx
	negq	%r8
	movslq	-179999980(%rbp,%r8,4), %r8
	vmovsd	240000(%r13,%rdx,8), %xmm6
	vmovsd	-16(%r13,%rsi,8), %xmm0
	vmovsd	159984(%r13,%rsi,8), %xmm9
	vmovsd	%xmm6, 128(%rsp)
	vsubsd	-8(%r13,%r8,8), %xmm0, %xmm6
	vmovsd	79984(%r13,%rsi,8), %xmm0
	vmovsd	240008(%r13,%rdx,8), %xmm7
	vmovsd	240016(%r13,%rdx,8), %xmm3
	vsubsd	79992(%r13,%r8,8), %xmm0, %xmm5
	vsubsd	159992(%r13,%r8,8), %xmm9, %xmm0
	vmovsd	239992(%r13,%rdx,8), %xmm12
	vmovsd	%xmm7, 136(%rsp)
	vmovsd	%xmm3, 144(%rsp)
	vmovsd	720032(%r13,%rdx,8), %xmm7
	vmovsd	239984(%r13,%rdx,8), %xmm3
	vmulsd	%xmm5, %xmm12, %xmm4
	vmovsd	%xmm7, 112(%rsp)
	vmulsd	%xmm0, %xmm3, %xmm7
	movq	104(%rsp), %rax
	vmovsd	%xmm5, %xmm5, %xmm1
	vmovsd	%xmm5, 248(%rsp)
	vmovsd	239976(%r13,%rdx,8), %xmm11
	vsubsd	%xmm4, %xmm7, %xmm5
	movq	$0x000000000, -48(%rax,%rbx,8)
	vmovsd	720024(%r13,%rdx,8), %xmm15
	vmovsd	720040(%r13,%rdx,8), %xmm2
	movq	48(%rsp), %r14
	movq	232(%rsp), %rax
	vmovsd	%xmm6, 240(%rsp)
	vmovsd	%xmm0, 256(%rsp)
	vmovsd	%xmm2, 120(%rsp)
	movq	$0x000000000, -48(%r14,%rbx,8)
	vmovsd	%xmm6, %xmm6, %xmm2
	movq	$0x000000000, -48(%rax,%rbx,8)
	vmovsd	%xmm15, 264(%rsp)
	vmovsd	%xmm5, 272(%rsp)
	vmulsd	%xmm6, %xmm12, %xmm5
	vmulsd	%xmm0, %xmm11, %xmm6
	vmulsd	%xmm2, %xmm3, %xmm13
	vmovsd	112(%rsp), %xmm0
	vmulsd	%xmm1, %xmm11, %xmm9
	vmovsd	%xmm12, 184(%rsp)
	vsubsd	%xmm6, %xmm5, %xmm8
	vmulsd	%xmm0, %xmm0, %xmm1
	vsubsd	%xmm4, %xmm7, %xmm12
	vmulsd	%xmm8, %xmm8, %xmm2
	vmovsd	%xmm3, 168(%rsp)
	vmovsd	%xmm11, 176(%rsp)
	vfmadd231sd	%xmm15, %xmm15, %xmm1
	vsubsd	%xmm13, %xmm9, %xmm11
	vfmadd231sd	%xmm12, %xmm12, %xmm2
	vmovsd	%xmm11, 280(%rsp)
	vmovsd	%xmm2, %xmm2, %xmm3
	vmovsd	120(%rsp), %xmm2
	vfmadd231sd	%xmm11, %xmm11, %xmm3
	vfmadd231sd	%xmm2, %xmm2, %xmm1
	vmovq	%xmm3, %r15
	vcomisd	.LC104(%rip), %xmm1
	jb	.L1553
	vcomisd	.LC104(%rip), %xmm3
	jb	.L1553
	vmulsd	%xmm0, %xmm8, %xmm0
	vsubsd	%xmm7, %xmm4, %xmm4
	vsubsd	%xmm9, %xmm13, %xmm9
	vmovsd	%xmm8, 208(%rsp)
	vmovsd	%xmm1, 200(%rsp)
	vfmadd231sd	%xmm12, %xmm15, %xmm0
	vmulsd	%xmm3, %xmm1, %xmm15
	vfmadd231sd	%xmm11, %xmm2, %xmm0
	vsqrtsd	%xmm15, %xmm15, %xmm15
	vsubsd	%xmm5, %xmm6, %xmm2
	vdivsd	%xmm15, %xmm0, %xmm0
	vmulsd	136(%rsp), %xmm2, %xmm2
	vfmadd132sd	128(%rsp), %xmm2, %xmm4
	vfmadd231sd	144(%rsp), %xmm9, %xmm4
	vmovsd	%xmm4, 192(%rsp)
	vminsd	%xmm14, %xmm0, %xmm0
	vmaxsd	.LC9(%rip), %xmm0, %xmm0
	call	acos@PLT
	vmovsd	192(%rsp), %xmm4
	vxorpd	%xmm6, %xmm6, %xmm6
	vcmpltsd	%xmm6, %xmm4, %xmm4
	vmovq	.LC11(%rip), %xmm10
	vmovsd	%xmm0, %xmm0, %xmm15
	vxorpd	%xmm10, %xmm15, %xmm0
	vblendvpd	%xmm4, %xmm0, %xmm15, %xmm15
	vsubsd	296(%rsp), %xmm15, %xmm0
	vmovsd	288(%rsp), %xmm6
	movq	.LC8(%rip), %rax
	vmulsd	%xmm6, %xmm0, %xmm0
	vmovsd	%xmm6, 32(%r12)
	vmovsd	40(%rsp), %xmm6
	vmovsd	200(%rsp), %xmm1
	vmovsd	208(%rsp), %xmm8
	vcomisd	%xmm0, %xmm6
	vmovsd	168(%rsp), %xmm3
	vmovsd	176(%rsp), %xmm11
	vmovsd	184(%rsp), %xmm12
	vmovsd	%xmm0, (%r12)
	vmovq	%rax, %xmm14
	jbe	.L1442
	vcomisd	216(%rsp), %xmm0
	ja	.L1561
.L1442:
	cmpl	$3, 160(%rsp)
	leal	-5(%rbx), %esi
	jne	.L1504
	cmpl	$2, %esi
	je	.L1446
.L1504:
	vsubsd	312(%rsp), %xmm15, %xmm0
	vmovsd	304(%rsp), %xmm7
	vmulsd	%xmm7, %xmm0, %xmm0
	vmovsd	%xmm7, 48(%r12)
	vcomisd	40(%rsp), %xmm0
	vmovsd	%xmm0, 16(%r12)
	ja	.L1448
	vmovsd	216(%rsp), %xmm4
	vcomisd	%xmm0, %xmm4
	jbe	.L1547
.L1448:
	cmpl	$3, 160(%rsp)
	je	.L1548
.L1556:
	vsubsd	352(%rsp), %xmm15, %xmm0
.L1452:
	vmovsd	320(%rsp), %xmm7
	vmovsd	360(%rsp), %xmm4
	vmulsd	%xmm7, %xmm0, %xmm0
	vmovsd	%xmm4, 168(%rsp)
	vmovsd	%xmm0, 16(%r12)
	vmovsd	%xmm7, 784(%rsp,%rbx,8)
.L1453:
	vmovsd	16(%r12), %xmm0
	vmovsd	40(%rsp), %xmm4
	vcomisd	%xmm0, %xmm4
	jbe	.L1455
	vcomisd	216(%rsp), %xmm0
	ja	.L1562
.L1455:
	movq	48(%rsp), %rax
	vmovsd	.LC105(%rip), %xmm7
	vcomisd	-48(%rax,%rbx,8), %xmm7
	jb	.L1459
	movq	104(%rsp), %rax
	vcomisd	-48(%rax,%rbx,8), %xmm7
	jb	.L1459
	addq	$8, %r12
	cmpq	$7, %rbx
	jne	.L1563
.L1439:
	vmovsd	544(%rsp), %xmm8
	vmovsd	552(%rsp), %xmm12
	movq	576(%rsp), %rdi
	vmulsd	%xmm12, %xmm8, %xmm0
	vmovsd	584(%rsp), %xmm5
	vmovq	%rdi, %xmm3
	movq	%rbp, %rbx
	vmulsd	%xmm5, %xmm3, %xmm3
	vcomisd	.LC105(%rip), %xmm0
	movq	368(%rsp), %r11
	movq	376(%rsp), %r10
	movq	384(%rsp), %r12
	movl	332(%rsp), %r14d
	movl	336(%rsp), %r15d
	vmovsd	392(%rsp), %xmm7
	vmovsd	400(%rsp), %xmm11
	vmovsd	408(%rsp), %xmm9
	vmovsd	416(%rsp), %xmm6
	vmovsd	424(%rsp), %xmm13
	movl	340(%rsp), %ebp
	movq	344(%rsp), %r9
	movl	440(%rsp), %r8d
	jnb	.L1508
	vcomisd	.LC105(%rip), %xmm3
	jb	.L1437
.L1508:
	vsqrtsd	%xmm13, %xmm13, %xmm2
	vcomisd	.LC105(%rip), %xmm0
	vmovsd	568(%rsp), %xmm1
	vmovsd	%xmm2, 48(%rsp)
	vmovsd	560(%rsp), %xmm2
	ja	.L1564
	movq	$0x000000000, 104(%rsp)
.L1463:
	vcomisd	.LC105(%rip), %xmm6
	jbe	.L1475
	vcomisd	.LC105(%rip), %xmm3
	ja	.L1565
.L1475:
	vmovsd	104(%rsp), %xmm4
	leaq	for_(%rip), %rax
	vdivsd	48(%rsp), %xmm4, %xmm13
	vmovsd	%xmm13, %xmm13, %xmm0
	vfnmadd213sd	(%rax,%r11,8), %xmm7, %xmm0
	movq	152(%rsp), %rsi
	movq	224(%rsp), %rdx
	addq	$4, %r9
	addq	$16, %rbx
	vmovsd	%xmm0, (%rax,%r11,8)
	vmovsd	%xmm13, %xmm13, %xmm0
	vfnmadd213sd	(%rax,%rsi,8), %xmm11, %xmm0
	vfmadd213sd	(%rax,%r12,8), %xmm13, %xmm7
	vmovsd	%xmm0, (%rax,%rsi,8)
	vmovsd	%xmm13, %xmm13, %xmm0
	vfnmadd213sd	160000(%rax,%r11,8), %xmm9, %xmm0
	vfmadd213sd	(%rax,%rdx,8), %xmm13, %xmm11
	vmovsd	%xmm7, (%rax,%r12,8)
	leaq	20000(%r12), %rsi
	vmovsd	%xmm0, 160000(%rax,%r11,8)
	vmovsd	592(%rsp), %xmm0
	vmovsd	%xmm11, (%rax,%rdx,8)
	movslq	%r8d, %rdx
	vfnmadd213sd	-8(%rax,%rdx,8), %xmm2, %xmm0
	leaq	-1(%rdx), %r8
	vfmadd213sd	160000(%rax,%r12,8), %xmm9, %xmm13
	leaq	9999(%rdx), %rdi
	leaq	19999(%rdx), %rcx
	vmovsd	%xmm0, (%rax,%r8,8)
	vmovsd	608(%rsp), %xmm0
	vmovsd	%xmm13, (%rax,%rsi,8)
	vfnmadd213sd	79992(%rax,%rdx,8), %xmm2, %xmm0
	vmovsd	%xmm0, (%rax,%rdi,8)
	vmovsd	624(%rsp), %xmm0
	vfnmadd213sd	159992(%rax,%rdx,8), %xmm2, %xmm0
	vmovsd	%xmm0, (%rax,%rcx,8)
	vmovsd	640(%rsp), %xmm0
	vfnmadd213sd	(%rax,%rdx,8), %xmm2, %xmm0
	vmovsd	%xmm0, (%rax,%rdx,8)
	vmovsd	656(%rsp), %xmm0
	vfnmadd213sd	80000(%rax,%rdx,8), %xmm2, %xmm0
	vmovsd	%xmm0, 80000(%rax,%rdx,8)
	vmovsd	672(%rsp), %xmm0
	vfnmadd213sd	160000(%rax,%rdx,8), %xmm2, %xmm0
	vmulsd	600(%rsp), %xmm1, %xmm5
	vmovsd	%xmm0, 160000(%rax,%rdx,8)
	vmovsd	688(%rsp), %xmm0
	vfmadd231sd	736(%rsp), %xmm2, %xmm5
	vfnmadd213sd	-16(%rax,%rdx,8), %xmm2, %xmm0
	vmovsd	%xmm0, -16(%rax,%rdx,8)
	vmovsd	704(%rsp), %xmm0
	vmovsd	(%rax,%r12,8), %xmm4
	vfnmadd213sd	79984(%rax,%rdx,8), %xmm2, %xmm0
	vsubsd	%xmm5, %xmm4, %xmm4
	vmovsd	%xmm4, (%rax,%r12,8)
	vmovsd	%xmm0, 79984(%rax,%rdx,8)
	vmovsd	720(%rsp), %xmm0
	vmulsd	616(%rsp), %xmm1, %xmm4
	vfnmadd213sd	159984(%rax,%rdx,8), %xmm2, %xmm0
	vfmadd231sd	752(%rsp), %xmm2, %xmm4
	vmovsd	%xmm0, 159984(%rax,%rdx,8)
	movq	224(%rsp), %rdx
	vmovsd	(%rax,%rsi,8), %xmm0
	vmovsd	(%rax,%rdx,8), %xmm3
	vsubsd	%xmm4, %xmm3, %xmm3
	vmovsd	%xmm3, (%rax,%rdx,8)
	vmulsd	632(%rsp), %xmm1, %xmm3
	vfmadd132sd	768(%rsp), %xmm3, %xmm2
	vsubsd	%xmm2, %xmm0, %xmm0
	vmovsd	%xmm0, (%rax,%rsi,8)
	vmovsd	648(%rsp), %xmm0
	vfnmadd213sd	(%rax,%r10,8), %xmm1, %xmm0
	vmovsd	%xmm0, (%rax,%r10,8)
	vmovsd	664(%rsp), %xmm0
	vfnmadd213sd	80000(%rax,%r10,8), %xmm1, %xmm0
	vmovsd	%xmm0, 80000(%rax,%r10,8)
	vmovsd	680(%rsp), %xmm0
	vfnmadd213sd	160000(%rax,%r10,8), %xmm1, %xmm0
	vmovsd	%xmm0, 160000(%rax,%r10,8)
	vmovsd	696(%rsp), %xmm0
	vfnmadd213sd	-16(%rax,%r10,8), %xmm1, %xmm0
	vmovsd	%xmm0, -16(%rax,%r10,8)
	vmovsd	712(%rsp), %xmm0
	vfnmadd213sd	79984(%rax,%r10,8), %xmm1, %xmm0
	vmovsd	%xmm0, 79984(%rax,%r10,8)
	vmovsd	728(%rsp), %xmm0
	vfnmadd213sd	159984(%rax,%r10,8), %xmm1, %xmm0
	vmovsd	%xmm0, 159984(%rax,%r10,8)
	vmovsd	744(%rsp), %xmm0
	vmovsd	(%rax,%rcx,8), %xmm3
	vfnmadd213sd	(%rax,%r8,8), %xmm1, %xmm0
	vmovsd	%xmm0, (%rax,%r8,8)
	vmovsd	760(%rsp), %xmm0
	vfnmadd213sd	(%rax,%rdi,8), %xmm1, %xmm0
	vfnmadd132sd	776(%rsp), %xmm3, %xmm1
	vmovsd	%xmm0, (%rax,%rdi,8)
	vmovsd	%xmm1, (%rax,%rcx,8)
	cmpq	%r9, 24(%rsp)
	jne	.L1489
	.p2align 4,,10
	.p2align 3
.L1560:
	movl	444(%rsp), %eax
	vmovd	452(%rsp), %xmm4
	movl	%eax, 80024+misc_(%rip)
	movl	448(%rsp), %eax
	vpinsrd	$1, 460(%rsp), %xmm4, %xmm0
	movl	%eax, 2000012+cmapi_(%rip)
	vmovd	464(%rsp), %xmm3
	movl	456(%rsp), %eax
	vmovq	%xmm0, 12+sdch_(%rip)
	movl	%eax, 2000020+cmapi_(%rip)
	vpinsrd	$1, 468(%rsp), %xmm3, %xmm0
	vmovq	%xmm0, sdch_(%rip)
.L1429:
	movq	856(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L1566
	addq	$872, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L1459:
	.cfi_restore_state
	vmovq	%r15, %xmm6
	vdivsd	%xmm6, %xmm14, %xmm2
	vmulsd	%xmm3, %xmm3, %xmm4
	vmulsd	136(%rsp), %xmm3, %xmm13
	vmulsd	248(%rsp), %xmm3, %xmm3
	vmovsd	256(%rsp), %xmm9
	addq	$8, %r12
	vfmadd231sd	%xmm12, %xmm12, %xmm4
	vfnmsub231sd	128(%rsp), %xmm11, %xmm13
	vfmadd231sd	240(%rsp), %xmm11, %xmm3
	vfmadd231sd	%xmm11, %xmm11, %xmm4
	vfnmadd231sd	144(%rsp), %xmm12, %xmm13
	vfmadd132sd	%xmm12, %xmm3, %xmm9
	vsqrtsd	%xmm4, %xmm4, %xmm0
	vdivsd	%xmm1, %xmm14, %xmm1
	vmulsd	272(%rsp), %xmm2, %xmm7
	vmulsd	%xmm2, %xmm8, %xmm8
	vmulsd	280(%rsp), %xmm2, %xmm2
	vmulsd	%xmm0, %xmm7, %xmm6
	vmulsd	%xmm0, %xmm8, %xmm8
	vmovq	%xmm6, %rdx
	vmovsd	%xmm6, %xmm6, %xmm7
	vdivsd	%xmm4, %xmm14, %xmm4
	vxorpd	%xmm10, %xmm7, %xmm7
	vmovsd	%xmm7, 688(%rsp,%rbx,8)
	vmulsd	%xmm7, %xmm9, %xmm7
	vmovq	%rdx, %xmm3
	vmulsd	112(%rsp), %xmm1, %xmm6
	vmulsd	264(%rsp), %xmm1, %xmm5
	vmulsd	120(%rsp), %xmm1, %xmm1
	vmulsd	%xmm0, %xmm6, %xmm15
	vmulsd	%xmm0, %xmm5, %xmm5
	vmulsd	%xmm0, %xmm1, %xmm1
	vmulsd	%xmm0, %xmm2, %xmm0
	vxorpd	%xmm10, %xmm8, %xmm6
	vmovsd	%xmm6, 704(%rsp,%rbx,8)
	vfmsub231sd	%xmm5, %xmm13, %xmm7
	vmulsd	%xmm6, %xmm9, %xmm6
	vxorpd	%xmm10, %xmm0, %xmm2
	vmulsd	%xmm2, %xmm9, %xmm9
	vmovsd	%xmm5, 544(%rsp,%rbx,8)
	vmovsd	%xmm1, 576(%rsp,%rbx,8)
	vmovsd	%xmm15, 560(%rsp,%rbx,8)
	vmovsd	%xmm2, 720(%rsp,%rbx,8)
	vfmsub231sd	%xmm7, %xmm4, %xmm5
	vfnmadd132sd	%xmm4, %xmm3, %xmm7
	vmovsd	%xmm6, %xmm6, %xmm3
	vfmsub231sd	%xmm15, %xmm13, %xmm3
	vfmsub132sd	%xmm1, %xmm9, %xmm13
	vmovsd	%xmm15, %xmm15, %xmm6
	vmovsd	%xmm5, 592(%rsp,%rbx,8)
	vmovsd	%xmm7, 640(%rsp,%rbx,8)
	vfmsub231sd	%xmm3, %xmm4, %xmm6
	vfnmadd231sd	%xmm3, %xmm4, %xmm8
	vfmsub231sd	%xmm13, %xmm4, %xmm1
	vfnmadd231sd	%xmm13, %xmm4, %xmm0
	vmovsd	%xmm6, 608(%rsp,%rbx,8)
	vmovsd	%xmm8, 656(%rsp,%rbx,8)
	vmovsd	%xmm1, 624(%rsp,%rbx,8)
	vmovsd	%xmm0, 672(%rsp,%rbx,8)
	cmpq	$7, %rbx
	je	.L1439
.L1563:
	movl	$7, %ebx
	jmp	.L1438
	.p2align 4,,10
	.p2align 3
.L1562:
	movq	432(%rsp), %rax
	movl	(%rax), %eax
	testl	%eax, %eax
	je	.L1458
	vmovsd	%xmm1, 208(%rsp)
	vmovsd	%xmm8, 200(%rsp)
	vmovsd	%xmm12, 192(%rsp)
	vmovsd	%xmm3, 184(%rsp)
	vmovsd	%xmm11, 176(%rsp)
	call	cos@PLT
	movq	.LC8(%rip), %rax
	vmovsd	176(%rsp), %xmm11
	vmovq	%rax, %xmm14
	vaddsd	%xmm14, %xmm0, %xmm0
	movq	104(%rsp), %rax
	vmovsd	184(%rsp), %xmm3
	vmulsd	.LC72(%rip), %xmm0, %xmm0
	vmovsd	192(%rsp), %xmm12
	vmovsd	200(%rsp), %xmm8
	vmovsd	208(%rsp), %xmm1
	vmovq	.LC11(%rip), %xmm10
	vmovsd	%xmm0, -48(%rax,%rbx,8)
	jmp	.L1455
	.p2align 4,,10
	.p2align 3
.L1561:
	movq	432(%rsp), %rax
	movl	(%rax), %eax
	testl	%eax, %eax
	je	.L1445
	vmovsd	%xmm1, 208(%rsp)
	vmovsd	%xmm15, 200(%rsp)
	vmovsd	%xmm8, 192(%rsp)
	vmovsd	%xmm3, 176(%rsp)
	vmovsd	%xmm11, 168(%rsp)
	call	cos@PLT
	movq	.LC8(%rip), %rax
	vmovsd	168(%rsp), %xmm11
	vmovq	%rax, %xmm14
	vaddsd	%xmm14, %xmm0, %xmm0
	vmovsd	176(%rsp), %xmm3
	vmovsd	184(%rsp), %xmm12
	vmulsd	.LC72(%rip), %xmm0, %xmm0
	vmovsd	192(%rsp), %xmm8
	vmovsd	200(%rsp), %xmm15
	vmovsd	208(%rsp), %xmm1
	vmovq	.LC11(%rip), %xmm10
	vmovsd	%xmm0, -48(%r14,%rbx,8)
	jmp	.L1442
	.p2align 4,,10
	.p2align 3
.L1547:
	vmovsd	472(%rsp), %xmm5
	vmovsd	%xmm5, 168(%rsp)
	jmp	.L1453
	.p2align 4,,10
	.p2align 3
.L1548:
	vmovsd	472(%rsp), %xmm5
	vmovsd	%xmm5, 168(%rsp)
	cmpl	$1, %esi
	jne	.L1556
	jmp	.L1453
	.p2align 4,,10
	.p2align 3
.L1445:
	vmulsd	%xmm0, %xmm0, %xmm4
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vmovsd	.LC9(%rip), %xmm5
	vsubsd	%xmm4, %xmm0, %xmm0
	vfmadd132sd	.LC74(%rip), %xmm5, %xmm0
	vdivsd	%xmm0, %xmm4, %xmm0
	vaddsd	%xmm14, %xmm0, %xmm0
	vmovsd	%xmm0, -48(%r14,%rbx,8)
	jmp	.L1442
	.p2align 4,,10
	.p2align 3
.L1458:
	vmulsd	%xmm0, %xmm0, %xmm4
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vmovsd	.LC9(%rip), %xmm5
	movq	104(%rsp), %rax
	vsubsd	%xmm4, %xmm0, %xmm0
	vfmadd132sd	.LC74(%rip), %xmm5, %xmm0
	vdivsd	%xmm0, %xmm4, %xmm0
	vaddsd	%xmm14, %xmm0, %xmm0
	vmovsd	%xmm0, -48(%rax,%rbx,8)
	jmp	.L1455
.L1564:
	vmovsd	496(%rsp), %xmm15
	vmulsd	168(%rsp), %xmm15, %xmm15
	vcomisd	48(%rsp), %xmm15
	jbe	.L1465
	movl	-179999996(%rbx), %eax
	addl	$2, 444(%rsp)
	testl	%eax, %eax
	jle	.L1467
	incl	448(%rsp)
	incl	452(%rsp)
.L1465:
	movq	488(%rsp), %rax
	movq	(%rax), %rsi
	movl	512(%rsp), %eax
	vmovq	%rsi, %xmm15
	vmulsd	.LC83(%rip), %xmm15, %xmm15
	vmovq	%xmm15, %rdx
	testl	%eax, %eax
	je	.L1468
	vmovsd	504(%rsp), %xmm15
	vmulsd	168(%rsp), %xmm15, %xmm15
	vcomisd	48(%rsp), %xmm15
	jbe	.L1468
	vmovq	%rsi, %xmm4
	movq	$0x000000000, 104(%rsp)
	vxorpd	%xmm10, %xmm4, %xmm4
	vmovsd	%xmm4, 112(%rsp)
.L1470:
	movq	480(%rsp), %rax
	vmovsd	112(%rsp), %xmm15
	vmulsd	832(%rsp), %xmm12, %xmm12
	vfmadd213sd	(%rax), %xmm15, %xmm0
	vmovsd	808(%rsp), %xmm15
	vmulsd	840(%rsp), %xmm8, %xmm8
	vmovsd	%xmm15, 120(%rsp)
	movq	432(%rsp), %rsi
	vmovsd	%xmm0, (%rax)
	vmovq	%xmm12, %rax
	vmovsd	.LC72(%rip), %xmm12
	vmovq	%rax, %xmm15
	vmulsd	%xmm12, %xmm15, %xmm15
	movl	(%rsi), %edx
	vmulsd	%xmm12, %xmm8, %xmm12
	vmovsd	800(%rsp), %xmm0
	vmovsd	%xmm15, 128(%rsp)
	testl	%edx, %edx
	jne	.L1472
	vxorpd	%xmm4, %xmm4, %xmm4
	vcomisd	%xmm4, %xmm0
	vaddsd	%xmm0, %xmm0, %xmm12
	jbe	.L1567
	vsubsd	%xmm14, %xmm0, %xmm0
	vmulsd	%xmm12, %xmm0, %xmm0
	vaddsd	%xmm14, %xmm0, %xmm12
.L1559:
	vmulsd	%xmm12, %xmm12, %xmm12
	vmovq	%rax, %xmm4
	vdivsd	%xmm12, %xmm0, %xmm0
	vmovsd	120(%rsp), %xmm12
	vmulsd	%xmm4, %xmm0, %xmm0
	vxorpd	%xmm4, %xmm4, %xmm4
	vcomisd	%xmm4, %xmm12
	vfmadd231sd	112(%rsp), %xmm0, %xmm2
	vaddsd	%xmm12, %xmm12, %xmm0
	vmovsd	%xmm2, 560(%rsp)
	jbe	.L1568
	vsubsd	%xmm14, %xmm12, %xmm12
	vmulsd	%xmm0, %xmm12, %xmm12
	vaddsd	%xmm14, %xmm12, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm0
	vdivsd	%xmm0, %xmm12, %xmm0
	vmulsd	%xmm8, %xmm0, %xmm0
	vfmadd231sd	112(%rsp), %xmm0, %xmm1
	vmovsd	%xmm1, 568(%rsp)
	jmp	.L1463
.L1468:
	vmovq	%rsi, %xmm15
	vmulsd	%xmm15, %xmm0, %xmm15
	movl	516(%rsp), %ecx
	vmovq	%xmm15, %rax
	testl	%ecx, %ecx
	je	.L1471
	vmovsd	504(%rsp), %xmm4
	vmulsd	168(%rsp), %xmm4, %xmm4
	vdivsd	48(%rsp), %xmm4, %xmm15
	vmulsd	%xmm15, %xmm15, %xmm4
	vmovsd	%xmm15, 104(%rsp)
	vmulsd	%xmm15, %xmm4, %xmm4
	vmulsd	%xmm4, %xmm4, %xmm4
	vmovq	%xmm4, %rcx
	vmovsd	.LC106(%rip), %xmm4
	vfnmadd213sd	.LC107(%rip), %xmm15, %xmm4
	vmovq	%rcx, %xmm15
	vfmadd231sd	.LC83(%rip), %xmm15, %xmm4
	vmovq	%rsi, %xmm15
	vmovq	%xmm4, %rdx
	vmovq	%rcx, %xmm4
	vmulsd	%xmm15, %xmm4, %xmm4
	vmovq	%rdx, %xmm15
	vmulsd	%xmm15, %xmm4, %xmm4
	vmovsd	104(%rsp), %xmm15
	vmovsd	%xmm4, 112(%rsp)
	vmovsd	.LC109(%rip), %xmm4
	vfmadd132sd	.LC108(%rip), %xmm4, %xmm15
	vmovsd	%xmm15, %xmm15, %xmm4
	vmovq	%rcx, %xmm15
	vfnmadd231sd	.LC110(%rip), %xmm15, %xmm4
	vmovq	%xmm4, %rdx
	vmulsd	.LC85(%rip), %xmm15, %xmm4
.L1557:
	vmovq	%rdx, %xmm15
	vmulsd	%xmm15, %xmm4, %xmm4
	vmovq	%rax, %xmm15
	vdivsd	48(%rsp), %xmm4, %xmm4
	vmulsd	%xmm15, %xmm4, %xmm4
	vmovsd	%xmm4, 104(%rsp)
	jmp	.L1470
	.p2align 4,,10
	.p2align 3
.L1553:
	movq	%rbp, %rbx
	movl	332(%rsp), %r14d
	movl	336(%rsp), %r15d
	movl	340(%rsp), %ebp
	movq	344(%rsp), %r9
	jmp	.L1437
	.p2align 4,,10
	.p2align 3
.L1446:
	vsubsd	352(%rsp), %xmm15, %xmm0
	vmovsd	320(%rsp), %xmm7
	vmulsd	%xmm7, %xmm0, %xmm4
	vcomisd	40(%rsp), %xmm4
	vmovsd	%xmm4, 16(%r12)
	vmovsd	%xmm7, 840(%rsp)
	ja	.L1452
	vmovsd	216(%rsp), %xmm5
	vcomisd	%xmm4, %xmm5
	ja	.L1452
	vmovsd	360(%rsp), %xmm4
	vmovsd	%xmm4, 168(%rsp)
	jmp	.L1453
.L1565:
	movl	-179999996(%rbx), %ecx
	movl	%ecx, %edx
	sarl	$31, %edx
	movl	%edx, %eax
	xorl	%ecx, %eax
	subl	%edx, %eax
	decl	%eax
	cltq
	leaq	sig_(%rip), %rdx
	vmovsd	(%rdx,%rax,8), %xmm0
	vmulsd	496(%rsp), %xmm0, %xmm8
	vcomisd	48(%rsp), %xmm8
	jbe	.L1476
	addl	$2, 444(%rsp)
	testl	%ecx, %ecx
	jle	.L1478
	incl	448(%rsp)
	incl	460(%rsp)
.L1476:
	movl	528(%rsp), %eax
	vmovsd	%xmm13, 112(%rsp)
	testl	%eax, %eax
	je	.L1479
	leaq	sdch_(%rip), %rax
	movl	360(%rax,%r11,4), %edx
	cmpl	$2, %edx
	movl	%edx, 120(%rsp)
	jle	.L1479
	movl	360(%rax,%r12,4), %eax
	cmpl	$2, %eax
	movl	%eax, 128(%rsp)
	jle	.L1479
	vmovsd	%xmm3, 200(%rsp)
	vmovsd	48(%rsp), %xmm3
	movq	%r9, 248(%rsp)
	vmulsd	536(%rsp), %xmm3, %xmm6
	movl	%r8d, 240(%rsp)
	movq	%rdi, 160(%rsp)
	movq	%r10, 144(%rsp)
	movq	%r11, 136(%rsp)
	vxorpd	%xmm10, %xmm6, %xmm0
	vmovsd	%xmm1, 232(%rsp)
	vmovsd	%xmm2, 208(%rsp)
	vmovsd	%xmm9, 192(%rsp)
	vmovsd	%xmm11, 184(%rsp)
	vmovsd	%xmm7, 176(%rsp)
	vmovsd	%xmm5, 168(%rsp)
	vmovsd	%xmm6, 32(%rsp)
	call	exp@PLT
	movl	128(%rsp), %eax
	movl	120(%rsp), %edx
	vmulsd	520(%rsp), %xmm0, %xmm8
	cmpl	%eax, %edx
	movq	.LC8(%rip), %rax
	vmovsd	32(%rsp), %xmm6
	vmovq	.LC11(%rip), %xmm10
	movq	136(%rsp), %r11
	movq	144(%rsp), %r10
	movq	160(%rsp), %rdi
	vmovsd	168(%rsp), %xmm5
	vmovsd	176(%rsp), %xmm7
	vmovsd	184(%rsp), %xmm11
	vmovsd	192(%rsp), %xmm9
	vmovsd	200(%rsp), %xmm3
	vmovsd	208(%rsp), %xmm2
	vmovsd	232(%rsp), %xmm1
	movl	240(%rsp), %r8d
	movq	248(%rsp), %r9
	vmovsd	112(%rsp), %xmm13
	vmovq	%rax, %xmm14
	je	.L1480
	vxorpd	%xmm10, %xmm8, %xmm8
.L1480:
	movl	532(%rsp), %esi
	testl	%esi, %esi
	je	.L1481
	vmovsd	48(%rsp), %xmm12
	vmovsd	.LC9(%rip), %xmm4
	vdivsd	%xmm12, %xmm8, %xmm8
	vsubsd	%xmm6, %xmm4, %xmm0
	vmulsd	%xmm8, %xmm0, %xmm0
	vdivsd	%xmm12, %xmm0, %xmm0
	vaddsd	104(%rsp), %xmm0, %xmm4
	vmovsd	%xmm4, 104(%rsp)
.L1482:
	movq	480(%rsp), %rax
	vmovq	%rdi, %xmm4
	vfmadd213sd	(%rax), %xmm8, %xmm3
	vmulsd	816(%rsp), %xmm5, %xmm5
	vmulsd	824(%rsp), %xmm4, %xmm4
	vmovsd	.LC72(%rip), %xmm6
	vmovsd	784(%rsp), %xmm0
	vmovsd	%xmm3, (%rax)
	movq	432(%rsp), %rax
	vmulsd	%xmm6, %xmm5, %xmm12
	movl	(%rax), %eax
	vmulsd	%xmm6, %xmm4, %xmm6
	vmovsd	792(%rsp), %xmm3
	testl	%eax, %eax
	jne	.L1486
	vxorpd	%xmm12, %xmm12, %xmm12
	vcomisd	%xmm12, %xmm0
	vaddsd	%xmm0, %xmm0, %xmm6
	jbe	.L1569
	vsubsd	%xmm14, %xmm0, %xmm0
	vmulsd	%xmm6, %xmm0, %xmm0
	vaddsd	%xmm14, %xmm0, %xmm6
.L1558:
	vmulsd	%xmm6, %xmm6, %xmm6
	vcomisd	%xmm12, %xmm3
	vdivsd	%xmm6, %xmm0, %xmm6
	vaddsd	%xmm3, %xmm3, %xmm0
	vmulsd	%xmm5, %xmm6, %xmm5
	vfmadd231sd	%xmm5, %xmm8, %xmm2
	vmovsd	%xmm2, 560(%rsp)
	jbe	.L1570
	vsubsd	%xmm14, %xmm3, %xmm3
	vmulsd	%xmm0, %xmm3, %xmm3
	vaddsd	%xmm14, %xmm3, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm0
	vdivsd	%xmm0, %xmm3, %xmm3
	vmulsd	%xmm4, %xmm3, %xmm4
	vfmadd231sd	%xmm4, %xmm8, %xmm1
	vmovsd	%xmm1, 568(%rsp)
	jmp	.L1475
.L1479:
	movl	512(%rsp), %ecx
	testl	%ecx, %ecx
	jne	.L1571
.L1483:
	movl	516(%rsp), %edx
	vmulsd	%xmm3, %xmm6, %xmm12
	testl	%edx, %edx
	je	.L1485
	vmulsd	504(%rsp), %xmm0, %xmm0
	vmovsd	48(%rsp), %xmm4
	vmovsd	.LC106(%rip), %xmm8
	vdivsd	%xmm4, %xmm0, %xmm13
	vmulsd	%xmm13, %xmm13, %xmm0
	vfnmadd213sd	.LC107(%rip), %xmm13, %xmm8
	vmulsd	%xmm13, %xmm0, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm0
	vmulsd	%xmm0, %xmm6, %xmm6
	vfmadd231sd	.LC83(%rip), %xmm0, %xmm8
	vmulsd	%xmm8, %xmm6, %xmm8
	vmovsd	.LC108(%rip), %xmm6
	vfmadd213sd	.LC109(%rip), %xmm13, %xmm6
	vfnmadd231sd	.LC110(%rip), %xmm0, %xmm6
	vmulsd	.LC85(%rip), %xmm0, %xmm0
	vmulsd	%xmm6, %xmm0, %xmm0
	vdivsd	%xmm4, %xmm0, %xmm0
	vfmadd213sd	104(%rsp), %xmm12, %xmm0
	vmovsd	%xmm0, 104(%rsp)
	jmp	.L1482
.L1571:
	vmulsd	504(%rsp), %xmm0, %xmm12
	vxorpd	%xmm10, %xmm6, %xmm8
	vcomisd	48(%rsp), %xmm12
	ja	.L1482
	jmp	.L1483
.L1471:
	vmovsd	168(%rsp), %xmm4
	vdivsd	48(%rsp), %xmm4, %xmm4
	vmulsd	%xmm4, %xmm4, %xmm15
	vmulsd	%xmm4, %xmm15, %xmm4
	vmulsd	%xmm4, %xmm4, %xmm4
	vmovq	%xmm4, %rcx
	vsubsd	%xmm14, %xmm4, %xmm4
	vmovq	%rcx, %xmm15
	vmulsd	%xmm15, %xmm4, %xmm4
	vmovq	%rdx, %xmm15
	vmulsd	%xmm15, %xmm4, %xmm4
	vmovsd	%xmm4, 112(%rsp)
	vmovq	%rcx, %xmm4
	vfnmadd132sd	.LC74(%rip), %xmm14, %xmm4
	vmovq	%xmm4, %rdx
	vmovq	%rcx, %xmm4
	vmulsd	.LC88(%rip), %xmm4, %xmm4
	jmp	.L1557
.L1486:
	movq	%r9, 232(%rsp)
	movl	%r8d, 208(%rsp)
	movq	%r10, 128(%rsp)
	movq	%r11, 120(%rsp)
	vmovsd	%xmm6, 200(%rsp)
	vmovsd	%xmm1, 176(%rsp)
	vmovsd	%xmm9, 160(%rsp)
	vmovsd	%xmm11, 144(%rsp)
	vmovsd	%xmm7, 136(%rsp)
	vmovsd	%xmm12, 192(%rsp)
	vmovsd	%xmm3, 184(%rsp)
	vmovsd	%xmm2, 168(%rsp)
	vmovsd	%xmm8, 32(%rsp)
	call	sin@PLT
	vmovsd	32(%rsp), %xmm8
	vmovsd	192(%rsp), %xmm12
	vmulsd	%xmm0, %xmm8, %xmm0
	vmovsd	168(%rsp), %xmm2
	vmovsd	184(%rsp), %xmm3
	vmovsd	%xmm8, 112(%rsp)
	vfnmadd231sd	%xmm12, %xmm0, %xmm2
	vmovsd	%xmm3, %xmm3, %xmm0
	vmovsd	%xmm2, 560(%rsp)
	vmovsd	%xmm2, 32(%rsp)
	call	sin@PLT
	vmovsd	112(%rsp), %xmm8
	vmovsd	176(%rsp), %xmm1
	vmulsd	%xmm0, %xmm8, %xmm8
	vmovsd	200(%rsp), %xmm6
	movq	.LC8(%rip), %rax
	vmovsd	32(%rsp), %xmm2
	movq	120(%rsp), %r11
	vfnmadd231sd	%xmm6, %xmm8, %xmm1
	movq	128(%rsp), %r10
	vmovsd	136(%rsp), %xmm7
	vmovsd	144(%rsp), %xmm11
	vmovsd	160(%rsp), %xmm9
	movl	208(%rsp), %r8d
	vmovq	.LC11(%rip), %xmm10
	movq	232(%rsp), %r9
	vmovsd	%xmm1, 568(%rsp)
	vmovq	%rax, %xmm14
	jmp	.L1475
.L1472:
	movq	%r9, 272(%rsp)
	movl	%r8d, 264(%rsp)
	movq	%rdi, 160(%rsp)
	movq	%r10, 144(%rsp)
	movq	%r11, 136(%rsp)
	vmovsd	%xmm12, 256(%rsp)
	vmovsd	%xmm1, 248(%rsp)
	vmovsd	%xmm3, 232(%rsp)
	vmovsd	%xmm13, 208(%rsp)
	vmovsd	%xmm6, 200(%rsp)
	vmovsd	%xmm9, 192(%rsp)
	vmovsd	%xmm11, 184(%rsp)
	vmovsd	%xmm7, 176(%rsp)
	vmovsd	%xmm5, 168(%rsp)
	vmovsd	%xmm2, 240(%rsp)
	call	sin@PLT
	vmulsd	112(%rsp), %xmm0, %xmm0
	vmovsd	240(%rsp), %xmm2
	vfnmadd231sd	128(%rsp), %xmm0, %xmm2
	vmovsd	120(%rsp), %xmm0
	vmovsd	%xmm2, 560(%rsp)
	vmovsd	%xmm2, 128(%rsp)
	call	sin@PLT
	vmulsd	112(%rsp), %xmm0, %xmm0
	vmovsd	248(%rsp), %xmm1
	vmovsd	256(%rsp), %xmm12
	movq	.LC8(%rip), %rax
	vmovsd	128(%rsp), %xmm2
	vfnmadd231sd	%xmm12, %xmm0, %xmm1
	movq	136(%rsp), %r11
	movq	144(%rsp), %r10
	movq	160(%rsp), %rdi
	vmovsd	168(%rsp), %xmm5
	vmovsd	176(%rsp), %xmm7
	vmovsd	184(%rsp), %xmm11
	vmovsd	192(%rsp), %xmm9
	vmovsd	200(%rsp), %xmm6
	vmovsd	208(%rsp), %xmm13
	vmovsd	232(%rsp), %xmm3
	movl	264(%rsp), %r8d
	vmovq	.LC11(%rip), %xmm10
	movq	272(%rsp), %r9
	vmovsd	%xmm1, 568(%rsp)
	vmovq	%rax, %xmm14
	jmp	.L1463
.L1485:
	vmovsd	48(%rsp), %xmm4
	vdivsd	%xmm4, %xmm0, %xmm6
	vmulsd	%xmm6, %xmm6, %xmm0
	vmulsd	%xmm6, %xmm0, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm0
	vsubsd	%xmm14, %xmm0, %xmm8
	vmovsd	%xmm0, %xmm0, %xmm6
	vfnmadd132sd	.LC74(%rip), %xmm14, %xmm6
	vmulsd	%xmm0, %xmm8, %xmm8
	vmulsd	.LC88(%rip), %xmm0, %xmm0
	vmulsd	32(%rsp), %xmm8, %xmm8
	vmulsd	%xmm6, %xmm0, %xmm0
	vdivsd	%xmm4, %xmm0, %xmm0
	vfmadd213sd	104(%rsp), %xmm12, %xmm0
	vmovsd	%xmm0, 104(%rsp)
	jmp	.L1482
.L1567:
	vaddsd	%xmm14, %xmm0, %xmm0
	vmulsd	%xmm12, %xmm0, %xmm0
	vxorpd	%xmm10, %xmm0, %xmm0
	vsubsd	%xmm14, %xmm0, %xmm12
	jmp	.L1559
.L1478:
	incl	456(%rsp)
	incl	468(%rsp)
	jmp	.L1476
.L1568:
	vaddsd	120(%rsp), %xmm14, %xmm12
	vmulsd	%xmm0, %xmm12, %xmm0
	vxorpd	%xmm10, %xmm0, %xmm0
	vsubsd	%xmm14, %xmm0, %xmm12
	vmulsd	%xmm12, %xmm12, %xmm12
	vdivsd	%xmm12, %xmm0, %xmm0
	vmulsd	%xmm8, %xmm0, %xmm0
	vfmadd231sd	112(%rsp), %xmm0, %xmm1
	vmovsd	%xmm1, 568(%rsp)
	jmp	.L1463
.L1467:
	incl	456(%rsp)
	incl	464(%rsp)
	jmp	.L1465
.L1570:
	vaddsd	%xmm14, %xmm3, %xmm3
	vmulsd	%xmm0, %xmm3, %xmm0
	vxorpd	%xmm10, %xmm0, %xmm0
	vsubsd	%xmm14, %xmm0, %xmm3
	vmulsd	%xmm3, %xmm3, %xmm3
	vdivsd	%xmm3, %xmm0, %xmm0
	vmulsd	%xmm4, %xmm0, %xmm4
	vfmadd231sd	%xmm4, %xmm8, %xmm1
	vmovsd	%xmm1, 568(%rsp)
	jmp	.L1475
.L1569:
	vaddsd	%xmm14, %xmm0, %xmm0
	vmulsd	%xmm6, %xmm0, %xmm0
	vxorpd	%xmm10, %xmm0, %xmm0
	vsubsd	%xmm14, %xmm0, %xmm6
	jmp	.L1558
.L1481:
	vdivsd	%xmm13, %xmm8, %xmm8
	vmovsd	.LC103(%rip), %xmm0
	vsubsd	%xmm6, %xmm0, %xmm0
	vmulsd	%xmm8, %xmm0, %xmm0
	vdivsd	48(%rsp), %xmm0, %xmm0
	vaddsd	104(%rsp), %xmm0, %xmm4
	vmovsd	%xmm4, 104(%rsp)
	jmp	.L1482
.L1566:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE26:
	.size	evalimproper_, .-evalimproper_
	.p2align 4
	.globl	evalwall_
	.type	evalwall_, @function
evalwall_:
.LFB27:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	.cfi_offset 15, -24
	leaq	wal_(%rip), %r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	movl	56+wal_(%rip), %esi
	movl	8+bas_(%rip), %eax
	testl	%esi, %esi
	je	.L1573
	testl	%eax, %eax
	jle	.L1643
	movslq	16+equil_(%rip), %rdx
	movl	36+bas_(%rip), %r14d
	leaq	-1(%rdx), %rbx
	movq	%rbx, -24(%rsp)
	movl	120000+respul_(%rip), %ebx
	movl	48+wal_(%rip), %r12d
	movl	%ebx, -8(%rsp)
	movl	120004+respul_(%rip), %ebx
	vmovsd	32+plates_(%rip), %xmm9
	movl	%ebx, -16(%rsp)
	movl	%eax, %ebx
	sarl	%ebx
	movl	%ebx, -28(%rsp)
	leal	1(%rax), %r9d
	movl	%r14d, %r13d
	vmulsd	.LC88(%rip), %xmm9, %xmm13
	vmovsd	plates_(%rip), %xmm7
	vmovsd	8+plates_(%rip), %xmm6
	vmovsd	wal_(%rip), %xmm1
	vmovsd	64+sig_(%rip), %xmm14
	movl	44+wal_(%rip), %esi
	vmovsd	24+plates_(%rip), %xmm10
	vmovsd	16+plates_(%rip), %xmm8
	vmovsd	.LC8(%rip), %xmm5
	leaq	pos_(%rip), %rdx
	movl	$1, %eax
	leaq	-8+respul_(%rip), %rbx
	leaq	159992+for_(%rip), %r8
	movl	%r12d, %r14d
	jmp	.L1603
	.p2align 4,,10
	.p2align 3
.L1575:
	incq	%rax
	addq	$8, %rdx
	cmpq	%rax, %r9
	je	.L1646
.L1603:
	vmovsd	160000(%rdx), %xmm0
	movl	%eax, %r10d
	vsubsd	%xmm0, %xmm6, %xmm3
	vsubsd	%xmm7, %xmm0, %xmm11
	vcomisd	%xmm3, %xmm1
	jnb	.L1621
	vcomisd	%xmm11, %xmm1
	jb	.L1575
.L1621:
	vcmpnlesd	%xmm1, %xmm11, %xmm2
	vcomisd	%xmm3, %xmm1
	vblendvpd	%xmm2, %xmm4, %xmm11, %xmm4
	jb	.L1579
	vsubsd	%xmm6, %xmm0, %xmm4
.L1579:
	vdivsd	%xmm4, %xmm14, %xmm15
	vcomisd	(%rbx,%rax,8), %xmm5
	vmulsd	%xmm15, %xmm15, %xmm0
	vmulsd	%xmm15, %xmm0, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm0
	ja	.L1647
.L1581:
	vcomisd	%xmm11, %xmm1
	sbbl	$-1, %esi
	vcomisd	%xmm3, %xmm1
	jb	.L1645
	incl	%r14d
.L1645:
	movq	.LC74(%rip), %rcx
	vmovq	%rcx, %xmm2
.L1583:
	vfnmadd132sd	%xmm0, %xmm5, %xmm2
	vmulsd	.LC83(%rip), %xmm0, %xmm15
	vsubsd	%xmm5, %xmm0, %xmm12
	vcomisd	%xmm11, %xmm1
	vmulsd	%xmm0, %xmm2, %xmm0
	vfmadd132sd	%xmm15, %xmm5, %xmm12
	vmovsd	(%r8,%rax,8), %xmm15
	vmulsd	%xmm13, %xmm0, %xmm0
	vfmadd213sd	(%rdi), %xmm9, %xmm12
	vdivsd	%xmm4, %xmm0, %xmm0
	vmovsd	%xmm12, (%rdi)
	vsubsd	%xmm0, %xmm15, %xmm15
	vmovsd	%xmm15, (%r8,%rax,8)
	jb	.L1599
	vsubsd	%xmm0, %xmm10, %xmm10
.L1599:
	vcomisd	%xmm3, %xmm1
	jb	.L1575
	incq	%rax
	vaddsd	%xmm0, %xmm8, %xmm8
	addq	$8, %rdx
	cmpq	%rax, %r9
	jne	.L1603
.L1646:
	vmovd	-8(%rsp), %xmm7
	vmovd	%esi, %xmm6
	vpinsrd	$1, -16(%rsp), %xmm7, %xmm0
	vunpcklpd	%xmm10, %xmm8, %xmm8
	vmovq	%xmm0, 120000+respul_(%rip)
	vpinsrd	$1, %r14d, %xmm6, %xmm0
	vmovq	%xmm0, 44+wal_(%rip)
	vmovapd	%xmm8, 16+plates_(%rip)
.L1643:
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L1573:
	.cfi_restore_state
	movslq	16+equil_(%rip), %rdx
	movl	$1, %ecx
	movl	4(%r15,%rdx,4), %edx
	testl	%edx, %edx
	jne	.L1648
	cmpl	%eax, %ecx
	jg	.L1643
.L1649:
	vmovsd	plates_(%rip), %xmm7
	vmovsd	64+plates_(%rip), %xmm5
	movslq	%ecx, %rsi
	subl	%ecx, %eax
	vmovsd	%xmm7, -16(%rsp)
	leaq	4+respul_(%rip), %rcx
	vmovsd	%xmm5, -8(%rsp)
	leaq	respul_(%rip), %rdx
	addq	%rsi, %rax
	movl	44+kier_(%rip), %r12d
	vmovsd	8+plates_(%rip), %xmm15
	vmovsd	wal_(%rip), %xmm10
	movl	44+wal_(%rip), %r9d
	movl	48+wal_(%rip), %r10d
	vmovsd	32+plates_(%rip), %xmm0
	vmovsd	24+plates_(%rip), %xmm9
	vmovsd	16+plates_(%rip), %xmm6
	movl	64+wal_(%rip), %ebx
	movl	68+wal_(%rip), %r14d
	movl	8+wal_(%rip), %r13d
	movl	12+bas_(%rip), %r15d
	vmovsd	48+plates_(%rip), %xmm14
	vmovsd	8+xyforces_(%rip), %xmm7
	vmovsd	40+plates_(%rip), %xmm13
	vmovsd	xyforces_(%rip), %xmm4
	vmovsd	24+xyforces_(%rip), %xmm8
	vmovsd	56+plates_(%rip), %xmm11
	vmovsd	16+xyforces_(%rip), %xmm5
	vmovsd	.LC8(%rip), %xmm2
	leaq	(%rcx,%rax,4), %r11
	leaq	(%rdx,%rsi,4), %rdx
	leaq	pos_(%rip), %rdi
	leaq	for_(%rip), %rcx
	.p2align 4,,10
	.p2align 3
.L1612:
	testl	%r12d, %r12d
	jne	.L1605
	movslq	79996(%rdx), %rax
	movq	%rax, %r8
	addq	$19999, %rax
	vmovsd	(%rdi,%rax,8), %xmm1
	vsubsd	-16(%rsp), %xmm1, %xmm3
	vsubsd	%xmm1, %xmm15, %xmm1
	vmulsd	%xmm3, %xmm3, %xmm12
	vcomisd	%xmm3, %xmm10
	sbbl	$-1, %r9d
	vmulsd	%xmm12, %xmm12, %xmm12
	vcomisd	%xmm1, %xmm10
	sbbl	$-1, %r10d
	vmulsd	%xmm3, %xmm12, %xmm3
	vmulsd	%xmm1, %xmm1, %xmm12
	vmulsd	%xmm3, %xmm3, %xmm3
	vmulsd	%xmm12, %xmm12, %xmm12
	vdivsd	%xmm3, %xmm2, %xmm3
	vmulsd	%xmm1, %xmm12, %xmm1
	vmulsd	%xmm1, %xmm1, %xmm1
	vdivsd	%xmm1, %xmm2, %xmm1
	vfmadd231sd	%xmm3, %xmm0, %xmm9
	vfmadd213sd	(%rcx,%rax,8), %xmm0, %xmm3
	vfmadd231sd	%xmm1, %xmm0, %xmm6
	vfnmadd132sd	%xmm0, %xmm3, %xmm1
	vmovsd	%xmm1, (%rcx,%rax,8)
.L1605:
	testl	%ebx, %ebx
	jne	.L1610
	testl	%r14d, %r14d
	je	.L1611
	testl	%r13d, %r13d
	jne	.L1611
	testl	%r15d, %r15d
	jne	.L1611
	.p2align 4,,10
	.p2align 3
.L1610:
	movslq	%r8d, %rax
	leaq	-1(%rax), %rsi
	vmovsd	(%rdi,%rsi,8), %xmm1
	addq	$9999, %rax
	vsubsd	%xmm14, %xmm1, %xmm3
	vsubsd	%xmm1, %xmm13, %xmm1
	vmulsd	%xmm3, %xmm3, %xmm12
	vmulsd	%xmm12, %xmm12, %xmm12
	vmulsd	%xmm3, %xmm12, %xmm3
	vmulsd	%xmm1, %xmm1, %xmm12
	vmulsd	%xmm3, %xmm3, %xmm3
	vmulsd	%xmm12, %xmm12, %xmm12
	vdivsd	%xmm3, %xmm2, %xmm3
	vmulsd	%xmm1, %xmm12, %xmm1
	vmulsd	%xmm1, %xmm1, %xmm1
	vdivsd	%xmm1, %xmm2, %xmm1
	vfmadd231sd	%xmm3, %xmm0, %xmm7
	vfmadd213sd	(%rcx,%rsi,8), %xmm0, %xmm3
	vfmadd231sd	%xmm1, %xmm0, %xmm4
	vfnmadd132sd	%xmm0, %xmm3, %xmm1
	vmovsd	%xmm1, (%rcx,%rsi,8)
	vmovsd	(%rdi,%rax,8), %xmm1
	vsubsd	-8(%rsp), %xmm1, %xmm3
	vsubsd	%xmm1, %xmm11, %xmm1
	vmulsd	%xmm3, %xmm3, %xmm12
	vmulsd	%xmm12, %xmm12, %xmm12
	vmulsd	%xmm3, %xmm12, %xmm3
	vmulsd	%xmm1, %xmm1, %xmm12
	vmulsd	%xmm3, %xmm3, %xmm3
	vmulsd	%xmm12, %xmm12, %xmm12
	vdivsd	%xmm3, %xmm2, %xmm3
	vmulsd	%xmm1, %xmm12, %xmm1
	vmulsd	%xmm1, %xmm1, %xmm1
	vdivsd	%xmm1, %xmm2, %xmm1
	vfmadd231sd	%xmm3, %xmm0, %xmm8
	vfmadd213sd	(%rcx,%rax,8), %xmm0, %xmm3
	vfmadd231sd	%xmm1, %xmm0, %xmm5
	vfnmadd132sd	%xmm0, %xmm3, %xmm1
	vmovsd	%xmm1, (%rcx,%rax,8)
.L1611:
	addq	$4, %rdx
	cmpq	%rdx, %r11
	jne	.L1612
	vmovd	%r9d, %xmm2
	vunpcklpd	%xmm8, %xmm5, %xmm5
	vunpcklpd	%xmm7, %xmm4, %xmm4
	vpinsrd	$1, %r10d, %xmm2, %xmm0
	vunpcklpd	%xmm9, %xmm6, %xmm6
	vinsertf128	$0x1, %xmm5, %ymm4, %ymm4
	vmovq	%xmm0, 44+wal_(%rip)
	vmovapd	%xmm6, 16+plates_(%rip)
	vmovapd	%ymm4, xyforces_(%rip)
	vzeroupper
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L1648:
	.cfi_restore_state
	movl	120000+respul_(%rip), %ebx
	subl	120004+respul_(%rip), %eax
	leal	1(%rbx), %ecx
	cmpl	%eax, %ecx
	jle	.L1649
	jmp	.L1643
	.p2align 4,,10
	.p2align 3
.L1647:
	testl	%r13d, %r13d
	jne	.L1581
	movq	.LC74(%rip), %rcx
	vmovq	%rcx, %xmm2
	movq	-24(%rsp), %rcx
	movl	8(%r15,%rcx,4), %ecx
	testl	%ecx, %ecx
	je	.L1583
	movl	-8(%rsp), %r11d
	addl	-16(%rsp), %r11d
	testl	%r11d, %r11d
	jle	.L1618
	movq	%rax, -48(%rsp)
	movq	%rdx, -40(%rsp)
	xorl	%ecx, %ecx
	movl	$1, %r12d
	movl	%r11d, %eax
	jmp	.L1586
	.p2align 4,,10
	.p2align 3
.L1651:
	leal	1(%r12), %r11d
	incq	%rcx
	cmpl	%eax, %r11d
	jg	.L1650
	movslq	%r11d, %r12
.L1586:
	leaq	120012+respul_(%rip), %rdx
	movl	(%rdx,%rcx,8), %edx
	leaq	(%rcx,%rcx), %r11
	testl	%edx, %edx
	jne	.L1651
	vcomisd	%xmm11, %xmm1
	movq	-40(%rsp), %rdx
	movq	%rcx, -40(%rsp)
	leaq	respul_(%rip), %rcx
	movl	%r10d, 120008(%rcx,%r12,8)
	movq	-48(%rsp), %rax
	jnb	.L1613
.L1591:
	vcomisd	%xmm3, %xmm1
	jnb	.L1614
.L1593:
	movq	.LC74(%rip), %r10
	movq	-40(%rsp), %rcx
	vmovsd	(%rdx), %xmm15
	movq	%r10, (%rbx,%rax,8)
	vmovq	%r10, %xmm2
	leaq	pull_(%rip), %r10
	vmovsd	%xmm15, (%r10,%rcx,8)
	vmovsd	80000(%rdx), %xmm15
	movq	$0x000000000, 160000(%r10,%rcx,8)
	vmovsd	%xmm15, 80000(%r10,%rcx,8)
	jmp	.L1583
.L1615:
	movl	-16(%rsp), %ecx
	cmpl	%ecx, -28(%rsp)
	setg	%r12b
	movzbl	%r12b, %r12d
	addl	%r12d, %ecx
	movl	%ecx, -16(%rsp)
	vcomisd	%xmm11, %xmm1
	leaq	respul_(%rip), %rcx
	movl	%r10d, 120012(%rcx,%r11,4)
	movq	-40(%rsp), %rcx
	leaq	(%rcx,%rcx), %r11
	jnb	.L1613
.L1614:
	leaq	respul_(%rip), %rcx
	movl	$1, 120012(%rcx,%r11,4)
	jmp	.L1593
	.p2align 4,,10
	.p2align 3
.L1650:
	movslq	%r12d, %rcx
	movq	-40(%rsp), %rdx
	movq	%rcx, -40(%rsp)
	movslq	%r11d, %r11
	movq	-48(%rsp), %rax
	leaq	-1(%r11,%r11), %r11
.L1584:
	vcomisd	%xmm11, %xmm1
	jb	.L1640
	movl	-8(%rsp), %ecx
	cmpl	%ecx, -28(%rsp)
	setg	%r12b
	movzbl	%r12b, %r12d
	addl	%r12d, %ecx
	vcomisd	%xmm3, %xmm1
	movl	%ecx, -8(%rsp)
	jnb	.L1615
	leaq	respul_(%rip), %rcx
	movl	%r10d, 120012(%rcx,%r11,4)
	movq	-40(%rsp), %rcx
	leaq	(%rcx,%rcx), %r11
.L1613:
	leaq	respul_(%rip), %rcx
	movl	$-1, 120012(%rcx,%r11,4)
	jmp	.L1591
.L1640:
	vcomisd	%xmm3, %xmm1
	jnb	.L1615
	leaq	respul_(%rip), %rcx
	movl	%r10d, 120012(%rcx,%r11,4)
	jmp	.L1593
.L1618:
	movq	$0, -40(%rsp)
	movl	$1, %r11d
	jmp	.L1584
	.cfi_endproc
.LFE27:
	.size	evalwall_, .-evalwall_
	.p2align 4
	.globl	evalgo_
	.type	evalgo_, @function
evalgo_:
.LFB28:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	movq	%rdi, %r8
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$408, %rsp
	.cfi_def_cfa_offset 464
	movl	8+bas_(%rip), %edi
	cmpl	$1, %edi
	jle	.L1653
	vmovsd	24+hhar_(%rip), %xmm7
	vmovsd	16+hhar_(%rip), %xmm5
	leaq	80000+bon_(%rip), %rcx
	leal	-2(%rdi), %r9d
	vmovsd	%xmm7, (%rsp)
	leaq	4(%rcx), %rdi
	vaddsd	%xmm5, %xmm5, %xmm7
	leaq	(%rdi,%r9,4), %r15
	leaq	-80000(%rcx), %rdi
	negq	%rdi
	movq	80008+neigh_(%rip), %rbp
	movq	7924032+sig_(%rip), %rbx
	movq	4000+sig_(%rip), %r10
	vmovq	.LC11(%rip), %xmm6
	vmovsd	%xmm7, 8(%rsp)
	leaq	pos_(%rip), %rdx
	leaq	neigh_(%rip), %rsi
	leaq	for_(%rip), %rax
	movq	%rdi, %r14
	vmovsd	%xmm5, 16(%rsp)
	.p2align 4,,10
	.p2align 3
.L1658:
	movl	(%rcx), %r11d
	testl	%r11d, %r11d
	je	.L1654
	vmovsd	80000(%rdx), %xmm4
	vmovsd	80008(%rdx), %xmm8
	vmovsd	(%rdx), %xmm7
	vsubsd	%xmm8, %xmm4, %xmm3
	vmovsd	8(%rdx), %xmm9
	vmovsd	160000(%rdx), %xmm2
	vmulsd	%xmm3, %xmm3, %xmm3
	vsubsd	%xmm9, %xmm7, %xmm13
	vmovsd	160008(%rdx), %xmm1
	vsubsd	%xmm7, %xmm9, %xmm9
	vsubsd	%xmm1, %xmm2, %xmm0
	vfmadd132sd	%xmm13, %xmm3, %xmm13
	vsubsd	%xmm4, %xmm8, %xmm8
	vsubsd	%xmm2, %xmm1, %xmm1
	movl	(%rsi), %edi
	incl	8(%rsi)
	vfmadd132sd	%xmm0, %xmm13, %xmm0
	leal	1(%rdi), %r9d
	movl	%r9d, (%rsi)
	movl	4(%rcx), %r9d
	vsqrtsd	%xmm0, %xmm0, %xmm13
	vsubsd	-159992(%r14,%rcx,2), %xmm13, %xmm11
	vmulsd	%xmm11, %xmm11, %xmm0
	vmulsd	(%rsp), %xmm0, %xmm10
	vaddsd	16(%rsp), %xmm10, %xmm3
	vmulsd	%xmm0, %xmm3, %xmm3
	vmovsd	.LC83(%rip), %xmm0
	vfmadd213sd	8(%rsp), %xmm10, %xmm0
	vmovsd	%xmm8, %xmm8, %xmm10
	vmulsd	%xmm11, %xmm0, %xmm0
	vmovsd	%xmm9, %xmm9, %xmm11
	vminsd	.LC82(%rip), %xmm0, %xmm0
	vmaxsd	.LC86(%rip), %xmm0, %xmm0
	vdivsd	%xmm13, %xmm0, %xmm0
	vfnmadd213sd	8(%rax), %xmm0, %xmm9
	vfnmadd213sd	80008(%rax), %xmm0, %xmm8
	vfmadd213sd	(%rax), %xmm0, %xmm11
	vfmadd213sd	80000(%rax), %xmm0, %xmm10
	vxorpd	%xmm6, %xmm0, %xmm13
	vmovsd	%xmm9, 8(%rax)
	vmovsd	%xmm1, %xmm1, %xmm9
	vfmadd213sd	160000(%rax), %xmm0, %xmm9
	vfnmadd213sd	160008(%rax), %xmm0, %xmm1
	vmovsd	%xmm8, 80008(%rax)
	vaddsd	(%r8), %xmm3, %xmm8
	vmovsd	%xmm11, (%rax)
	vmovsd	%xmm10, 80000(%rax)
	vmovsd	%xmm9, 160000(%rax)
	vmovsd	%xmm1, 160008(%rax)
	vmovsd	%xmm8, (%r8)
	testl	%r9d, %r9d
	je	.L1654
	vmovsd	80016(%rdx), %xmm12
	vmovsd	16(%rdx), %xmm14
	vsubsd	%xmm12, %xmm4, %xmm5
	vsubsd	%xmm14, %xmm7, %xmm1
	vmovsd	160016(%rdx), %xmm15
	vmulsd	%xmm5, %xmm5, %xmm5
	vsubsd	%xmm15, %xmm2, %xmm0
	vfmadd132sd	%xmm1, %xmm5, %xmm1
	vmovq	%rbp, %xmm5
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vcomisd	%xmm0, %xmm5
	jbe	.L1655
	addl	$2, %edi
	incl	16(%rsi)
	movl	%edi, (%rsi)
.L1655:
	vmovq	%rbx, %xmm5
	vcomisd	%xmm0, %xmm5
	jbe	.L1654
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmovsd	.LC8(%rip), %xmm3
	vmovsd	.LC74(%rip), %xmm5
	vdivsd	%xmm0, %xmm3, %xmm0
	vmovq	%r10, %xmm3
	vsubsd	%xmm7, %xmm14, %xmm7
	vsubsd	%xmm4, %xmm12, %xmm4
	vsubsd	%xmm2, %xmm15, %xmm15
	vmulsd	%xmm0, %xmm3, %xmm1
	vmulsd	%xmm1, %xmm1, %xmm13
	vmulsd	%xmm1, %xmm13, %xmm13
	vmulsd	%xmm13, %xmm13, %xmm13
	vmulsd	.LC83(%rip), %xmm13, %xmm3
	vfnmadd213sd	.LC8(%rip), %xmm13, %xmm5
	vsubsd	.LC8(%rip), %xmm13, %xmm1
	vfmadd213sd	.LC8(%rip), %xmm1, %xmm3
	vmulsd	%xmm13, %xmm5, %xmm13
	vmulsd	.LC88(%rip), %xmm0, %xmm1
	vaddsd	%xmm8, %xmm3, %xmm8
	vmulsd	%xmm13, %xmm1, %xmm1
	vmovsd	%xmm8, (%r8)
	vminsd	.LC82(%rip), %xmm1, %xmm1
	vmaxsd	.LC86(%rip), %xmm1, %xmm1
	vmulsd	%xmm0, %xmm1, %xmm1
	vfmadd231sd	%xmm1, %xmm7, %xmm11
	vfmadd231sd	%xmm1, %xmm4, %xmm10
	vfmadd231sd	%xmm1, %xmm15, %xmm9
	vfnmadd213sd	16(%rax), %xmm1, %xmm7
	vfnmadd213sd	80016(%rax), %xmm1, %xmm4
	vfnmadd213sd	160016(%rax), %xmm1, %xmm15
	vxorpd	%xmm6, %xmm1, %xmm13
	vmovsd	%xmm11, (%rax)
	vmovsd	%xmm7, 16(%rax)
	vmovsd	%xmm10, 80000(%rax)
	vmovsd	%xmm4, 80016(%rax)
	vmovsd	%xmm9, 160000(%rax)
	vmovsd	%xmm15, 160016(%rax)
	.p2align 4,,10
	.p2align 3
.L1654:
	addq	$4, %rcx
	addq	$8, %rdx
	addq	$8, %rsi
	addq	$8, %rax
	cmpq	%rcx, %r15
	jne	.L1658
.L1653:
	movl	cmap_(%rip), %eax
	vxorps	%xmm12, %xmm12, %xmm12
	testl	%eax, %eax
	jle	.L1659
	vmovsd	240000+for_(%rip), %xmm7
	decl	%eax
	vmovsd	%xmm7, (%rsp)
	vmovsd	240032+for_(%rip), %xmm7
	leaq	4+cmap_(%rip), %rcx
	vmovsd	%xmm7, 8(%rsp)
	vmovsd	240040+for_(%rip), %xmm7
	leaq	(%rax,%rax,2), %rdx
	vmovsd	%xmm7, 16(%rsp)
	vmovsd	240016+for_(%rip), %xmm7
	movl	36+kier_(%rip), %r11d
	vmovq	.LC11(%rip), %xmm6
	vmovsd	%xmm7, 24(%rsp)
	leaq	12(%rcx), %rax
	vmovsd	4000+sig_(%rip), %xmm7
	leaq	(%rax,%rdx,4), %r13
	vmovsd	240024+for_(%rip), %xmm14
	movl	40+kier_(%rip), %r10d
	vmovsd	240008+for_(%rip), %xmm11
	movl	44+kier_(%rip), %r9d
	vmovsd	80008+neigh_(%rip), %xmm8
	vmovsd	7924032+sig_(%rip), %xmm5
	vmovsd	.LC8(%rip), %xmm4
	vmovsd	%xmm7, 32(%rsp)
	movq	%r13, %r14
	leaq	pos_(%rip), %rbx
	vmovsd	%xmm6, %xmm6, %xmm7
	leaq	neigh_(%rip), %rdi
	movl	%r11d, %r13d
	vmovsd	%xmm13, %xmm13, %xmm9
	.p2align 4,,10
	.p2align 3
.L1666:
	movslq	(%rcx), %r12
	movslq	4(%rcx), %rax
	leaq	-1(%r12), %rdx
	vmovsd	(%rbx,%rdx,8), %xmm0
	vmovsd	79992(%rbx,%r12,8), %xmm2
	vmovsd	159992(%rbx,%r12,8), %xmm1
	vsubsd	-8(%rbx,%rax,8), %xmm0, %xmm0
	vsubsd	79992(%rbx,%rax,8), %xmm2, %xmm2
	vsubsd	159992(%rbx,%rax,8), %xmm1, %xmm1
	leaq	-1(%rax), %rsi
	testl	%r13d, %r13d
	je	.L1660
	vmulsd	%xmm0, %xmm14, %xmm10
	vmovsd	.LC60(%rip), %xmm13
	vandpd	%xmm10, %xmm7, %xmm15
	vorpd	%xmm15, %xmm13, %xmm13
	vaddsd	%xmm10, %xmm13, %xmm13
	vcvttsd2sil	%xmm13, %eax
	vcvtsi2sdl	%eax, %xmm12, %xmm13
	vfnmadd231sd	(%rsp), %xmm13, %xmm0
.L1660:
	testl	%r10d, %r10d
	je	.L1661
	vmulsd	8(%rsp), %xmm2, %xmm10
	vmovsd	.LC60(%rip), %xmm13
	vandpd	%xmm10, %xmm7, %xmm15
	vorpd	%xmm15, %xmm13, %xmm13
	vaddsd	%xmm10, %xmm13, %xmm13
	vcvttsd2sil	%xmm13, %eax
	vcvtsi2sdl	%eax, %xmm12, %xmm13
	vfnmadd231sd	%xmm13, %xmm11, %xmm2
.L1661:
	testl	%r9d, %r9d
	je	.L1662
	vmulsd	16(%rsp), %xmm1, %xmm10
	vmovsd	.LC60(%rip), %xmm13
	vandpd	%xmm10, %xmm7, %xmm15
	vorpd	%xmm15, %xmm13, %xmm13
	vaddsd	%xmm10, %xmm13, %xmm13
	vcvttsd2sil	%xmm13, %eax
	vcvtsi2sdl	%eax, %xmm12, %xmm13
	vfnmadd231sd	24(%rsp), %xmm13, %xmm1
.L1662:
	vmulsd	%xmm2, %xmm2, %xmm13
	vfmadd231sd	%xmm0, %xmm0, %xmm13
	vfmadd231sd	%xmm1, %xmm1, %xmm13
	vcomisd	%xmm13, %xmm8
	jbe	.L1663
	incl	(%rdi,%rdx,8)
	incl	(%rdi,%rsi,8)
.L1663:
	vcomisd	%xmm5, %xmm13
	ja	.L1665
	vsqrtsd	%xmm13, %xmm13, %xmm13
	leaq	for_(%rip), %rax
	vdivsd	%xmm13, %xmm4, %xmm13
	vmulsd	32(%rsp), %xmm13, %xmm3
	vmulsd	%xmm3, %xmm3, %xmm9
	vmulsd	%xmm3, %xmm9, %xmm9
	vmulsd	%xmm9, %xmm9, %xmm9
	vmovsd	%xmm9, %xmm9, %xmm15
	vmulsd	.LC83(%rip), %xmm9, %xmm10
	vfnmadd132sd	.LC74(%rip), %xmm4, %xmm15
	vsubsd	%xmm4, %xmm9, %xmm3
	vfmadd132sd	%xmm10, %xmm4, %xmm3
	vmulsd	%xmm9, %xmm15, %xmm9
	vmulsd	.LC88(%rip), %xmm13, %xmm10
	vmulsd	%xmm9, %xmm10, %xmm9
	vaddsd	(%r8), %xmm3, %xmm10
	vmovsd	%xmm10, (%r8)
	vminsd	.LC82(%rip), %xmm9, %xmm9
	vmaxsd	.LC86(%rip), %xmm9, %xmm9
	vmulsd	%xmm13, %xmm9, %xmm13
	vmovsd	%xmm13, %xmm13, %xmm10
	vfnmadd213sd	(%rax,%rdx,8), %xmm0, %xmm10
	vxorpd	%xmm6, %xmm13, %xmm9
	vmovsd	%xmm10, (%rax,%rdx,8)
	vfmadd213sd	(%rax,%rsi,8), %xmm13, %xmm0
	vmovsd	%xmm0, (%rax,%rsi,8)
	vmovsd	%xmm13, %xmm13, %xmm0
	vfnmadd213sd	80000(%rax,%rdx,8), %xmm2, %xmm0
	vmovsd	%xmm0, 80000(%rax,%rdx,8)
	vmovsd	%xmm13, %xmm13, %xmm0
	vfnmadd213sd	160000(%rax,%rdx,8), %xmm1, %xmm0
	vfmadd213sd	80000(%rax,%rsi,8), %xmm13, %xmm2
	vmovsd	%xmm0, 160000(%rax,%rdx,8)
	vfmadd213sd	160000(%rax,%rsi,8), %xmm1, %xmm13
	vmovsd	%xmm2, 80000(%rax,%rsi,8)
	vmovsd	%xmm13, 160000(%rax,%rsi,8)
.L1665:
	addq	$12, %rcx
	cmpq	%rcx, %r14
	jne	.L1666
	vmovsd	%xmm9, %xmm9, %xmm13
.L1659:
	movl	cmp2_(%rip), %eax
	testl	%eax, %eax
	jle	.L1798
	vmovsd	240024+for_(%rip), %xmm7
	vmovsd	.LC8(%rip), %xmm6
	vmovsd	%xmm7, 8(%rsp)
	vmovsd	240000+for_(%rip), %xmm7
	vdivsd	48+hhar_(%rip), %xmm6, %xmm6
	vmovsd	%xmm7, 16(%rsp)
	vmovsd	240008+for_(%rip), %xmm7
	vmovsd	%xmm6, 208(%rsp)
	vmovsd	%xmm7, 24(%rsp)
	vmovsd	7924016+sig_(%rip), %xmm7
	vmovsd	.LC8(%rip), %xmm6
	vmovsd	%xmm7, 56(%rsp)
	vmovsd	80000+misc_(%rip), %xmm7
	movl	80032+misc_(%rip), %edi
	vdivsd	%xmm7, %xmm6, %xmm11
	vmovsd	%xmm7, 120(%rsp)
	movl	%edi, 52(%rsp)
	movl	28+ssb2_(%rip), %edi
	vmovsd	240040+for_(%rip), %xmm2
	movl	%edi, 184(%rsp)
	movl	36+restr_(%rip), %edi
	movl	36+kier_(%rip), %r9d
	movl	%edi, 188(%rsp)
	movl	40+kier_(%rip), %r10d
	vmovsd	240032+for_(%rip), %xmm14
	movl	44+kier_(%rip), %r14d
	vmovsd	240016+for_(%rip), %xmm15
	vmovsd	80008+neigh_(%rip), %xmm9
	vmovsd	7924024+sig_(%rip), %xmm8
	decl	%eax
	leaq	4+cmp2_(%rip), %rbp
	leaq	(%rax,%rax,2), %rdx
	leaq	12(%rbp), %rax
	leaq	(%rax,%rdx,4), %rax
	leaq	pos_(%rip), %rbx
	vmulsd	.LC88(%rip), %xmm11, %xmm7
	vmovsd	%xmm7, 224(%rsp)
	vmulsd	56+hhar_(%rip), %xmm11, %xmm7
	vmovsd	%xmm7, 256(%rsp)
	vmovsd	7924008+sig_(%rip), %xmm7
	vmovsd	cmapi_(%rip), %xmm6
	vmovsd	%xmm7, 112(%rsp)
	vmovsd	4000+sig_(%rip), %xmm7
	vmovsd	80008+ssb_(%rip), %xmm0
	vmovsd	%xmm7, 136(%rsp)
	vmovsd	16+ssb2_(%rip), %xmm7
	vmulsd	%xmm11, %xmm0, %xmm5
	vmovsd	%xmm7, 144(%rsp)
	vmulsd	%xmm7, %xmm6, %xmm7
	movl	2000016+cmapi_(%rip), %esi
	movl	80036+ssb_(%rip), %edi
	movl	%esi, 72(%rsp)
	movl	2000024+cmapi_(%rip), %esi
	vmovsd	%xmm7, 248(%rsp)
	vmovsd	80024+ssb_(%rip), %xmm7
	movl	%esi, 68(%rsp)
	vmovsd	%xmm7, 128(%rsp)
	vmovsd	80016+ssb_(%rip), %xmm7
	movl	8+ssb2_(%rip), %esi
	vmulsd	%xmm7, %xmm0, %xmm0
	vmovsd	%xmm7, 168(%rsp)
	movl	%esi, 64(%rsp)
	movl	12+ssb2_(%rip), %esi
	movl	%edi, 156(%rsp)
	vaddsd	%xmm0, %xmm0, %xmm0
	movl	248008+nat_(%rip), %edi
	movl	%esi, 76(%rsp)
	vmulsd	%xmm11, %xmm0, %xmm7
	movl	24+ssb2_(%rip), %esi
	vmovsd	%xmm5, 176(%rsp)
	vmovsd	ssb2_(%rip), %xmm5
	movl	%esi, 152(%rsp)
	vmovsd	%xmm6, 40(%rsp)
	movl	%edi, 328(%rsp)
	vmovsd	%xmm7, 160(%rsp)
	vmovsd	%xmm5, 200(%rsp)
	vmovsd	.LC88(%rip), %xmm7
	vmovsd	.LC85(%rip), %xmm0
	vmulsd	%xmm5, %xmm7, %xmm7
	vmulsd	%xmm5, %xmm11, %xmm6
	movq	%rax, (%rsp)
	movl	2000008+cmapi_(%rip), %ecx
	movl	80024+misc_(%rip), %esi
	vmovsd	%xmm7, 216(%rsp)
	vdivsd	bas_(%rip), %xmm0, %xmm7
	vmovsd	%xmm7, 80(%rsp)
	vmovsd	24+hhar_(%rip), %xmm7
	leal	-1(%rdi), %edx
	vmovsd	%xmm7, 88(%rsp)
	vmovsd	16+hhar_(%rip), %xmm7
	leaq	240016+nat_(%rip), %rax
	vmovsd	%xmm7, 96(%rsp)
	vaddsd	%xmm7, %xmm7, %xmm7
	leaq	(%rax,%rdx,8), %rax
	movl	%ecx, 32(%rsp)
	movl	%esi, 48(%rsp)
	movq	%rax, 192(%rsp)
	vmovsd	%xmm7, 104(%rsp)
	vmovsd	.LC11(%rip), %xmm7
	vmovsd	%xmm11, 240(%rsp)
	vmovsd	%xmm6, 232(%rsp)
	vmovsd	%xmm2, %xmm2, %xmm11
	.p2align 4,,10
	.p2align 3
.L1718:
	movslq	0(%rbp), %r11
	movslq	4(%rbp), %rdi
	leaq	-1(%r11), %r12
	vmovsd	(%rbx,%r12,8), %xmm2
	vmovsd	79992(%rbx,%r11,8), %xmm1
	vmovsd	159992(%rbx,%r11,8), %xmm5
	vsubsd	-8(%rbx,%rdi,8), %xmm2, %xmm2
	vsubsd	79992(%rbx,%rdi,8), %xmm1, %xmm1
	vsubsd	159992(%rbx,%rdi,8), %xmm5, %xmm5
	movq	%r11, %rdx
	movq	%rdi, %rcx
	leaq	-1(%rdi), %r13
	testl	%r9d, %r9d
	je	.L1668
	vmulsd	8(%rsp), %xmm2, %xmm4
	vmovsd	.LC60(%rip), %xmm0
	vandpd	%xmm4, %xmm7, %xmm6
	vorpd	%xmm6, %xmm0, %xmm0
	vaddsd	%xmm4, %xmm0, %xmm0
	vcvttsd2sil	%xmm0, %eax
	vcvtsi2sdl	%eax, %xmm12, %xmm0
	vfnmadd231sd	16(%rsp), %xmm0, %xmm2
.L1668:
	testl	%r10d, %r10d
	je	.L1669
	vmulsd	%xmm1, %xmm14, %xmm4
	vmovsd	.LC60(%rip), %xmm0
	vandpd	%xmm4, %xmm7, %xmm6
	vorpd	%xmm6, %xmm0, %xmm0
	vaddsd	%xmm4, %xmm0, %xmm0
	vcvttsd2sil	%xmm0, %eax
	vcvtsi2sdl	%eax, %xmm12, %xmm0
	vfnmadd231sd	24(%rsp), %xmm0, %xmm1
.L1669:
	testl	%r14d, %r14d
	je	.L1670
	vmulsd	%xmm5, %xmm11, %xmm4
	vmovsd	.LC60(%rip), %xmm0
	vandpd	%xmm4, %xmm7, %xmm6
	vorpd	%xmm6, %xmm0, %xmm0
	vaddsd	%xmm4, %xmm0, %xmm0
	vcvttsd2sil	%xmm0, %eax
	vcvtsi2sdl	%eax, %xmm12, %xmm0
	vfnmadd231sd	%xmm15, %xmm0, %xmm5
.L1670:
	vmulsd	%xmm1, %xmm1, %xmm4
	vfmadd231sd	%xmm2, %xmm2, %xmm4
	vfmadd231sd	%xmm5, %xmm5, %xmm4
	vcomisd	%xmm4, %xmm9
	jbe	.L1671
	leaq	neigh_(%rip), %rax
	incl	(%rax,%r12,8)
	incl	(%rax,%r13,8)
.L1671:
	vcomisd	%xmm8, %xmm4
	ja	.L1673
	movslq	8(%rbp), %rax
	vsqrtsd	%xmm4, %xmm4, %xmm6
	testl	%eax, %eax
	jle	.L1674
	leaq	15000001(%rax,%rax,2), %rcx
	leaq	cmap_(%rip), %rdx
	movl	(%rdx,%rcx,4), %edx
	leal	630(%rdx), %ecx
	cmpl	$1260, %ecx
	ja	.L1675
	leaq	sig_(%rip), %rdx
	vmovsd	4000(%rdx,%rax,8), %xmm0
	incq	%rax
	vmulsd	40(%rsp), %xmm0, %xmm3
	leaq	cmapi_(%rip), %rdx
	movl	(%rdx,%rax,4), %ecx
	vcomisd	%xmm6, %xmm3
	jb	.L1787
	incl	32(%rsp)
	addl	$2, 48(%rsp)
	testl	%ecx, %ecx
	je	.L1788
.L1800:
	leaq	10000(%r12), %rsi
	leaq	10000(%r13), %r15
.L1678:
	vdivsd	%xmm6, %xmm0, %xmm3
	vmovq	.LC11(%rip), %xmm10
	vmulsd	%xmm3, %xmm3, %xmm0
	vmulsd	%xmm3, %xmm0, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm0
	vmulsd	.LC83(%rip), %xmm0, %xmm3
	vsubsd	.LC8(%rip), %xmm0, %xmm4
	vmulsd	.LC88(%rip), %xmm0, %xmm13
	vmulsd	%xmm3, %xmm4, %xmm3
	vmovsd	.LC8(%rip), %xmm4
	vfnmadd231sd	.LC74(%rip), %xmm0, %xmm4
	vmulsd	%xmm4, %xmm13, %xmm13
	vdivsd	%xmm6, %xmm13, %xmm13
.L1681:
	vminsd	.LC82(%rip), %xmm13, %xmm13
	vaddsd	(%r8), %xmm3, %xmm0
	leaq	for_(%rip), %rax
	vmaxsd	.LC86(%rip), %xmm13, %xmm13
	vmovsd	%xmm0, (%r8)
	vdivsd	%xmm6, %xmm13, %xmm6
	vmovsd	%xmm6, %xmm6, %xmm0
	vfnmadd213sd	(%rax,%r12,8), %xmm2, %xmm0
	vxorpd	%xmm10, %xmm6, %xmm13
	vmovsd	%xmm0, (%rax,%r12,8)
	vmovsd	%xmm6, %xmm6, %xmm0
	vfnmadd213sd	(%rax,%rsi,8), %xmm1, %xmm0
	vfmadd213sd	(%rax,%r13,8), %xmm6, %xmm2
	vmovsd	%xmm0, (%rax,%rsi,8)
	vmovsd	%xmm6, %xmm6, %xmm0
	vfnmadd213sd	160000(%rax,%r12,8), %xmm5, %xmm0
	vfmadd213sd	(%rax,%r15,8), %xmm6, %xmm1
	vmovsd	%xmm2, (%rax,%r13,8)
	vmovsd	%xmm0, 160000(%rax,%r12,8)
	vfmadd213sd	160000(%rax,%r13,8), %xmm5, %xmm6
	vmovsd	%xmm1, (%rax,%r15,8)
	vmovsd	%xmm6, 160000(%rax,%r13,8)
.L1673:
	addq	$12, %rbp
	cmpq	(%rsp), %rbp
	jne	.L1718
	movl	32(%rsp), %eax
	vmovd	64(%rsp), %xmm3
	movl	%eax, 2000008+cmapi_(%rip)
	movl	48(%rsp), %eax
	vpinsrd	$1, 76(%rsp), %xmm3, %xmm0
	movl	%eax, 80024+misc_(%rip)
	movl	68(%rsp), %eax
	vmovq	%xmm0, 8+ssb2_(%rip)
	movl	%eax, 2000024+cmapi_(%rip)
	movl	72(%rsp), %eax
	movl	%eax, 2000016+cmapi_(%rip)
.L1798:
	addq	$408, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L1674:
	.cfi_restore_state
	movl	%eax, %esi
	shrl	$31, %esi
	addl	%eax, %esi
	sarl	%esi
	cmpl	$-1, %esi
	je	.L1804
	cmpl	$-2, %esi
	je	.L1796
.L1801:
	vmovq	.LC11(%rip), %xmm10
	leaq	10000(%r12), %rsi
	leaq	10000(%r13), %r15
	jmp	.L1681
	.p2align 4,,10
	.p2align 3
.L1675:
	movl	%edx, %eax
	sarl	$31, %eax
	xorl	%eax, %edx
	subl	%eax, %edx
	cmpl	$631, %edx
	jne	.L1801
	vsubsd	80(%rsp), %xmm6, %xmm0
	incl	32(%rsp)
	vmovq	.LC11(%rip), %xmm10
	vmulsd	%xmm0, %xmm0, %xmm3
	leaq	10000(%r12), %rsi
	leaq	10000(%r13), %r15
	vmulsd	88(%rsp), %xmm3, %xmm13
	vaddsd	96(%rsp), %xmm13, %xmm4
	vmulsd	%xmm3, %xmm4, %xmm3
	vmovsd	104(%rsp), %xmm4
	vfmadd132sd	.LC83(%rip), %xmm4, %xmm13
	vmulsd	%xmm0, %xmm13, %xmm13
	jmp	.L1681
	.p2align 4,,10
	.p2align 3
.L1787:
	leaq	10000(%r12), %rsi
	leaq	10000(%r13), %r15
	cmpl	$1, %ecx
	jne	.L1678
	movl	$0, (%rdx,%rax,4)
	movl	52(%rsp), %eax
	testl	%eax, %eax
	je	.L1678
	leaq	sdch_(%rip), %rax
	leaq	10087(,%r11,4), %rcx
	movl	(%rax,%rcx,4), %edx
	testl	%edx, %edx
	jle	.L1680
	decl	%edx
	movl	%edx, (%rax,%rcx,4)
.L1680:
	leaq	10087(,%rdi,4), %rcx
	movl	(%rax,%rcx,4), %edx
	testl	%edx, %edx
	jle	.L1800
	decl	%edx
	movl	%edx, (%rax,%rcx,4)
	jmp	.L1800
	.p2align 4,,10
	.p2align 3
.L1804:
	vcomisd	56(%rsp), %xmm6
	ja	.L1673
	movl	52(%rsp), %edi
	testl	%edi, %edi
	jne	.L1683
	movl	156(%rsp), %esi
	testl	%esi, %esi
	jne	.L1683
	vcomisd	112(%rsp), %xmm6
	ja	.L1673
	vmovsd	136(%rsp), %xmm3
	vdivsd	%xmm6, %xmm3, %xmm3
	vmulsd	%xmm3, %xmm3, %xmm0
	vmulsd	%xmm3, %xmm0, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm0
	vmulsd	.LC83(%rip), %xmm0, %xmm3
	vsubsd	.LC8(%rip), %xmm0, %xmm4
	vmulsd	.LC88(%rip), %xmm0, %xmm13
	vfmadd213sd	.LC8(%rip), %xmm4, %xmm3
	vmovsd	.LC8(%rip), %xmm4
	vfnmadd231sd	.LC74(%rip), %xmm0, %xmm4
	vmulsd	%xmm4, %xmm13, %xmm13
	vdivsd	%xmm6, %xmm13, %xmm13
	jmp	.L1801
	.p2align 4,,10
	.p2align 3
.L1788:
	movl	$1, (%rdx,%rax,4)
	movl	52(%rsp), %eax
	testl	%eax, %eax
	je	.L1800
	leaq	sdch_(%rip), %rax
	leaq	10087(,%r11,4), %r11
	leaq	sequence_(%rip), %rcx
	movl	(%rax,%r11,4), %edx
	movslq	40000(%rcx,%r12,4), %r15
	leaq	10000(%r12), %rsi
	cmpl	104(%rax,%r15,4), %edx
	jge	.L1679
	incl	%edx
	movl	%edx, (%rax,%r11,4)
.L1679:
	leaq	10087(,%rdi,4), %rdi
	movl	(%rax,%rdi,4), %edx
	movslq	40000(%rcx,%r13,4), %rcx
	leaq	10000(%r13), %r15
	cmpl	104(%rax,%rcx,4), %edx
	jge	.L1678
	incl	%edx
	movl	%edx, (%rax,%rdi,4)
	jmp	.L1678
	.p2align 4,,10
	.p2align 3
.L1683:
	leaq	ssb_(%rip), %rdi
	leaq	10000(%r13), %r15
	movl	(%rdi,%r15,4), %r11d
	cmpl	$0, 40000(%rdi,%r12,4)
	movl	%r11d, 264(%rsp)
	leaq	10000(%r12), %rsi
	jne	.L1685
	testl	%r11d, %r11d
	jne	.L1686
	vmovsd	144(%rsp), %xmm3
	vcomisd	%xmm6, %xmm3
	jnb	.L1805
.L1794:
	vmovsd	120(%rsp), %xmm4
	jmp	.L1692
	.p2align 4,,10
	.p2align 3
.L1796:
	vcomisd	56(%rsp), %xmm6
	ja	.L1673
	movl	52(%rsp), %esi
	vmovq	.LC11(%rip), %xmm10
	testl	%esi, %esi
	je	.L1711
	movl	184(%rsp), %ecx
	leaq	misc_(%rip), %rax
	vmovsd	(%rax,%r12,8), %xmm3
	vmovsd	(%rax,%r13,8), %xmm0
	vxorpd	%xmm13, %xmm13, %xmm13
	testl	%ecx, %ecx
	je	.L1806
.L1712:
	vmovsd	120(%rsp), %xmm3
	vmovsd	%xmm13, 264(%rsp)
	vcomisd	%xmm13, %xmm3
	jbe	.L1797
	vmulsd	208(%rsp), %xmm6, %xmm0
	vmovq	.LC11(%rip), %xmm10
	movq	%r8, 392(%rsp)
	movl	%r10d, 336(%rsp)
	movl	%r9d, 332(%rsp)
	vxorpd	%xmm10, %xmm0, %xmm3
	vmovsd	%xmm3, %xmm3, %xmm0
	vmovsd	%xmm8, 376(%rsp)
	vmovsd	%xmm9, 368(%rsp)
	vmovsd	%xmm15, 360(%rsp)
	vmovsd	%xmm11, 352(%rsp)
	vmovsd	%xmm14, 344(%rsp)
	vmovsd	%xmm4, 320(%rsp)
	vmovsd	%xmm5, 312(%rsp)
	vmovsd	%xmm1, 304(%rsp)
	vmovsd	%xmm2, 296(%rsp)
	vmovsd	%xmm6, 288(%rsp)
	vmovapd	%xmm10, 272(%rsp)
	vmovsd	%xmm3, 384(%rsp)
	call	exp@PLT
	leaq	sdch_(%rip), %rax
	movl	360(%rax,%r13,4), %edi
	vmovapd	272(%rsp), %xmm10
	cmpl	%edi, 360(%rax,%r12,4)
	movq	.LC90(%rip), %rax
	vmovsd	288(%rsp), %xmm6
	vmovsd	296(%rsp), %xmm2
	vmovsd	304(%rsp), %xmm1
	vmovsd	312(%rsp), %xmm5
	vmovsd	320(%rsp), %xmm4
	movl	332(%rsp), %r9d
	movl	336(%rsp), %r10d
	vmovsd	344(%rsp), %xmm14
	vmovsd	352(%rsp), %xmm11
	vmovsd	360(%rsp), %xmm15
	vmovsd	368(%rsp), %xmm9
	vmovsd	376(%rsp), %xmm8
	movq	392(%rsp), %r8
	vmovsd	264(%rsp), %xmm13
	vmovq	%rax, %xmm7
	vxorps	%xmm12, %xmm12, %xmm12
	je	.L1807
	movl	184(%rsp), %edx
	vxorpd	%xmm3, %xmm3, %xmm3
	testl	%edx, %edx
	jne	.L1713
	vsubsd	120(%rsp), %xmm13, %xmm13
	vmulsd	%xmm0, %xmm13, %xmm13
	vmulsd	256(%rsp), %xmm13, %xmm3
	jmp	.L1713
	.p2align 4,,10
	.p2align 3
.L1685:
	leaq	misc_(%rip), %r11
	cmpl	$0, 264(%rsp)
	vmovsd	(%r11,%r12,8), %xmm4
	jne	.L1808
.L1688:
	cmpl	%ecx, (%rdi,%r12,4)
	je	.L1809
.L1689:
	vmaxsd	.LC10(%rip), %xmm4, %xmm4
.L1692:
	movl	152(%rsp), %edi
	testl	%edi, %edi
	je	.L1707
	vmovsd	144(%rsp), %xmm3
	vmovsd	128(%rsp), %xmm13
	vdivsd	%xmm6, %xmm3, %xmm0
	vcomisd	%xmm6, %xmm13
	vmulsd	%xmm0, %xmm0, %xmm3
	vmulsd	%xmm0, %xmm3, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm0
	vmulsd	.LC88(%rip), %xmm0, %xmm3
	vsubsd	.LC8(%rip), %xmm0, %xmm10
	vmovq	%xmm3, %rax
	vmulsd	.LC83(%rip), %xmm0, %xmm3
	vfmadd213sd	.LC8(%rip), %xmm10, %xmm3
	vmovsd	.LC8(%rip), %xmm10
	vfnmadd231sd	.LC74(%rip), %xmm0, %xmm10
	jbe	.L1795
	vmulsd	216(%rsp), %xmm0, %xmm13
	vmulsd	200(%rsp), %xmm3, %xmm3
	vmulsd	%xmm10, %xmm13, %xmm13
	vmovq	.LC11(%rip), %xmm10
	vdivsd	%xmm6, %xmm13, %xmm13
	jmp	.L1681
.L1797:
	vmovq	.LC11(%rip), %xmm10
	vxorpd	%xmm3, %xmm3, %xmm3
.L1713:
	movl	188(%rsp), %eax
	testl	%eax, %eax
	je	.L1716
	vdivsd	%xmm6, %xmm3, %xmm3
	vmovsd	384(%rsp), %xmm4
	vsubsd	.LC8(%rip), %xmm4, %xmm13
	vmulsd	%xmm3, %xmm13, %xmm13
	vdivsd	%xmm6, %xmm13, %xmm13
.L1711:
	vmovsd	112(%rsp), %xmm4
	vcomisd	%xmm6, %xmm4
	jbe	.L1802
	vmovsd	136(%rsp), %xmm4
	vdivsd	%xmm6, %xmm4, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm4
	vmulsd	%xmm0, %xmm4, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm4
	vmovq	%xmm4, %rcx
	vsubsd	.LC8(%rip), %xmm4, %xmm4
	vmovq	%xmm4, %rdi
	vmovq	%rcx, %xmm4
	vmulsd	.LC83(%rip), %xmm4, %xmm4
	vmovq	%rdi, %xmm0
	vfmadd213sd	.LC8(%rip), %xmm4, %xmm0
	vmovsd	.LC8(%rip), %xmm4
	vaddsd	%xmm0, %xmm3, %xmm3
	vmovq	%rcx, %xmm0
	vfnmadd231sd	.LC74(%rip), %xmm0, %xmm4
	vmulsd	.LC88(%rip), %xmm0, %xmm0
	vmulsd	%xmm4, %xmm0, %xmm0
	vdivsd	%xmm6, %xmm0, %xmm0
	vaddsd	%xmm0, %xmm13, %xmm13
.L1802:
	leaq	10000(%r12), %rsi
	leaq	10000(%r13), %r15
	jmp	.L1681
	.p2align 4,,10
	.p2align 3
.L1707:
	vmovsd	128(%rsp), %xmm3
	movq	%r8, 376(%rsp)
	vsubsd	%xmm6, %xmm3, %xmm0
	movl	%r10d, 332(%rsp)
	movl	%r9d, 320(%rsp)
	vmulsd	168(%rsp), %xmm0, %xmm0
	movq	%rsi, 312(%rsp)
	vmovsd	%xmm8, 368(%rsp)
	vmovsd	%xmm9, 360(%rsp)
	vmovsd	%xmm15, 352(%rsp)
	vmovsd	%xmm11, 344(%rsp)
	vmovsd	%xmm14, 336(%rsp)
	vmovsd	%xmm5, 304(%rsp)
	vmovsd	%xmm1, 296(%rsp)
	vmovsd	%xmm2, 288(%rsp)
	vmovsd	%xmm4, 272(%rsp)
	vmovsd	%xmm6, 264(%rsp)
	call	exp@PLT
	vmovsd	.LC8(%rip), %xmm3
	vmovsd	272(%rsp), %xmm4
	vsubsd	%xmm0, %xmm3, %xmm10
	vmulsd	%xmm0, %xmm4, %xmm13
	vmovsd	112(%rsp), %xmm7
	vmulsd	%xmm10, %xmm10, %xmm3
	vmovsd	264(%rsp), %xmm6
	movq	.LC90(%rip), %rax
	vmulsd	160(%rsp), %xmm13, %xmm13
	vcomisd	%xmm6, %xmm7
	vmulsd	176(%rsp), %xmm3, %xmm3
	vmovsd	288(%rsp), %xmm2
	vmovsd	296(%rsp), %xmm1
	vmulsd	%xmm10, %xmm13, %xmm13
	vmovsd	304(%rsp), %xmm5
	vmulsd	%xmm4, %xmm3, %xmm3
	movq	312(%rsp), %rsi
	movl	320(%rsp), %r9d
	movl	332(%rsp), %r10d
	vmovsd	336(%rsp), %xmm14
	vmovsd	344(%rsp), %xmm11
	vmovsd	352(%rsp), %xmm15
	vmovsd	360(%rsp), %xmm9
	vmovsd	368(%rsp), %xmm8
	movq	376(%rsp), %r8
	vmovq	%rax, %xmm7
	vxorps	%xmm12, %xmm12, %xmm12
	jbe	.L1803
	vmovsd	136(%rsp), %xmm0
	vdivsd	%xmm6, %xmm0, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm10
	vmulsd	%xmm0, %xmm10, %xmm0
	vmovsd	120(%rsp), %xmm10
	vsubsd	%xmm4, %xmm10, %xmm4
	vmulsd	%xmm0, %xmm0, %xmm0
	vmovq	%xmm4, %rdi
	vmulsd	.LC83(%rip), %xmm0, %xmm4
	vsubsd	.LC8(%rip), %xmm0, %xmm10
	vfmadd213sd	.LC8(%rip), %xmm4, %xmm10
	vmovq	%rdi, %xmm4
	vmulsd	240(%rsp), %xmm10, %xmm10
	vfmadd231sd	%xmm4, %xmm10, %xmm3
	vmovsd	.LC8(%rip), %xmm10
	vfnmadd231sd	.LC74(%rip), %xmm0, %xmm10
	vmulsd	%xmm0, %xmm10, %xmm0
	vmulsd	224(%rsp), %xmm0, %xmm0
	vmulsd	%xmm4, %xmm0, %xmm4
	vdivsd	%xmm6, %xmm4, %xmm4
	vaddsd	%xmm4, %xmm13, %xmm13
.L1803:
	vmovq	.LC11(%rip), %xmm10
	jmp	.L1681
.L1686:
	leaq	misc_(%rip), %r11
	vmovsd	(%r11,%r13,8), %xmm4
	jmp	.L1688
.L1809:
	cmpl	%edx, (%rdi,%r13,4)
	jne	.L1689
	vcomisd	.LC10(%rip), %xmm4
	jbe	.L1690
	vmovsd	(%r11,%r12,8), %xmm0
	vsubsd	.LC8(%rip), %xmm0, %xmm0
	vmovsd	%xmm0, (%r11,%r12,8)
	vmovsd	(%r11,%r13,8), %xmm0
	vsubsd	.LC8(%rip), %xmm0, %xmm0
	vmovsd	%xmm0, (%r11,%r13,8)
.L1690:
	vcomisd	248(%rsp), %xmm6
	jbe	.L1794
	movl	$0, (%rdi,%rsi,4)
	movq	$0x000000000, (%r11,%r12,8)
	movl	$0, (%rdi,%r15,4)
	movq	$0x000000000, (%r11,%r13,8)
	testb	$1, %al
	jne	.L1694
	decl	68(%rsp)
.L1695:
	movl	328(%rsp), %eax
	testl	%eax, %eax
	jle	.L1696
	movl	$0, 264(%rsp)
	leaq	240008+nat_(%rip), %r11
	jmp	.L1699
.L1697:
	cmpl	%edi, %edx
	jne	.L1698
	cmpl	%eax, %ecx
	je	.L1810
.L1698:
	addq	$8, %r11
	cmpq	%r11, 192(%rsp)
	je	.L1811
.L1699:
	movl	(%r11), %eax
	movl	4(%r11), %edi
	cmpl	%eax, %edx
	jne	.L1697
	cmpl	%edi, %ecx
	jne	.L1697
	decl	64(%rsp)
	movl	$1, 264(%rsp)
	jmp	.L1697
	.p2align 4,,10
	.p2align 3
.L1795:
	vmulsd	232(%rsp), %xmm4, %xmm4
	vmovq	%rax, %xmm0
	vmulsd	%xmm3, %xmm4, %xmm3
	vmulsd	%xmm10, %xmm4, %xmm4
	vmovq	.LC11(%rip), %xmm10
	vmulsd	%xmm0, %xmm4, %xmm13
	vdivsd	%xmm6, %xmm13, %xmm13
	jmp	.L1681
.L1806:
	vmaxsd	%xmm0, %xmm3, %xmm13
	jmp	.L1712
.L1808:
	vminsd	(%r11,%r13,8), %xmm4, %xmm4
	jmp	.L1688
.L1805:
	vmovsd	120(%rsp), %xmm3
	movl	$1, (%rdi,%rsi,4)
	movl	%ecx, (%rdi,%r12,4)
	movl	$1, (%rdi,%r15,4)
	movl	%edx, (%rdi,%r13,4)
	leaq	misc_(%rip), %rdi
	vmovsd	%xmm3, (%rdi,%r12,8)
	vmovsd	%xmm3, (%rdi,%r13,8)
	testb	$1, %al
	jne	.L1701
	incl	68(%rsp)
.L1702:
	movl	328(%rsp), %eax
	testl	%eax, %eax
	jle	.L1703
	movq	%rsi, 272(%rsp)
	movl	$0, 264(%rsp)
	movq	192(%rsp), %rsi
	leaq	240008+nat_(%rip), %rax
	jmp	.L1706
	.p2align 4,,10
	.p2align 3
.L1704:
	cmpl	%r11d, %edx
	jne	.L1705
	cmpl	%edi, %ecx
	je	.L1812
.L1705:
	addq	$8, %rax
	cmpq	%rax, %rsi
	je	.L1813
.L1706:
	movl	(%rax), %edi
	movl	4(%rax), %r11d
	cmpl	%edi, %edx
	jne	.L1704
	cmpl	%r11d, %ecx
	jne	.L1704
	incl	64(%rsp)
	movl	$1, 264(%rsp)
	jmp	.L1704
.L1716:
	vdivsd	%xmm4, %xmm3, %xmm3
	vmovsd	384(%rsp), %xmm4
	vsubsd	.LC74(%rip), %xmm4, %xmm13
	vmulsd	%xmm3, %xmm13, %xmm13
	vdivsd	%xmm6, %xmm13, %xmm13
	jmp	.L1711
.L1807:
	vmovsd	120(%rsp), %xmm3
	vsubsd	%xmm13, %xmm3, %xmm13
	vmulsd	%xmm0, %xmm13, %xmm13
	vmulsd	256(%rsp), %xmm13, %xmm3
	jmp	.L1713
.L1812:
	incl	64(%rsp)
	movl	$1, 264(%rsp)
	jmp	.L1705
.L1813:
	movl	264(%rsp), %r11d
	movq	272(%rsp), %rsi
	vmovsd	120(%rsp), %xmm4
	testl	%r11d, %r11d
	jne	.L1692
.L1703:
	incl	76(%rsp)
	vmovsd	120(%rsp), %xmm4
	jmp	.L1692
.L1701:
	incl	72(%rsp)
	jmp	.L1702
.L1811:
	movl	264(%rsp), %eax
	vmovsd	120(%rsp), %xmm4
	testl	%eax, %eax
	jne	.L1692
.L1696:
	decl	76(%rsp)
	vmovsd	120(%rsp), %xmm4
	jmp	.L1692
.L1810:
	decl	64(%rsp)
	movl	$1, 264(%rsp)
	jmp	.L1698
.L1694:
	decl	72(%rsp)
	jmp	.L1695
	.cfi_endproc
.LFE28:
	.size	evalgo_, .-evalgo_
	.p2align 4
	.globl	prepare_
	.type	prepare_, @function
prepare_:
.LFB29:
	.cfi_startproc
	vpxor	%xmm0, %xmm0, %xmm0
	vmovdqa	%xmm0, sdch_(%rip)
	movl	8+bas_(%rip), %r8d
	vxorpd	%xmm0, %xmm0, %xmm0
	vmovapd	%xmm0, 16+plates_(%rip)
	vxorpd	%xmm0, %xmm0, %xmm0
	movq	$0x000000000, (%rdi)
	movl	$0, 80024+misc_(%rip)
	movq	$0, 2000008+cmapi_(%rip)
	movl	$0, 2000020+cmapi_(%rip)
	movq	$0, 44+wal_(%rip)
	movq	$0, 16+sdch_(%rip)
	vmovapd	%ymm0, xyforces_(%rip)
	testl	%r8d, %r8d
	jle	.L1830
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	.cfi_offset 14, -24
	.cfi_offset 13, -32
	.cfi_offset 12, -40
	.cfi_offset 3, -48
	cmpl	$2, %r8d
	jle	.L1823
	leal	-3(%r8), %edi
	leaq	neigh_(%rip), %rcx
	leaq	16+pos_(%rip), %rax
	leaq	for_(%rip), %rdx
	andl	$-2, %edi
	vmovsd	160000+pos_(%rip), %xmm6
	vmovsd	160008+pos_(%rip), %xmm5
	vmovsd	80000+pos_(%rip), %xmm4
	vmovsd	80008+pos_(%rip), %xmm3
	vmovsd	pos_(%rip), %xmm2
	vmovsd	8+pos_(%rip), %xmm1
	movq	%rcx, %rsi
	movq	%rdx, %r10
	leaq	239984(%rax), %r9
	addl	$3, %edi
	movl	$1, %r11d
	vxorpd	%xmm9, %xmm9, %xmm9
.L1819:
	vsubsd	%xmm2, %xmm1, %xmm7
	vmovsd	%xmm2, %xmm2, %xmm15
	vmovsd	(%rax), %xmm2
	vmovq	%xmm7, %r12
	vsubsd	%xmm6, %xmm5, %xmm7
	movl	(%rsi), %ebx
	vsubsd	%xmm2, %xmm15, %xmm15
	vsubsd	%xmm4, %xmm3, %xmm13
	vmovq	%xmm7, %r13
	movl	%ebx, 4(%rsi)
	vsubsd	%xmm1, %xmm2, %xmm7
	movl	8(%rsi), %ebx
	vmovq	%r13, %xmm0
	vmovq	%xmm4, %r14
	vmovsd	%xmm6, %xmm6, %xmm14
	vmovsd	80000(%rax), %xmm4
	vmovsd	160000(%rax), %xmm6
	vunpcklpd	%xmm15, %xmm0, %xmm15
	vmovq	%r12, %xmm0
	movl	%ebx, 12(%rsi)
	movl	$0, (%rsi)
	movl	$0, 8(%rsi)
	vunpcklpd	%xmm13, %xmm0, %xmm13
	vmovupd	%xmm9, (%r10)
	vmovupd	%xmm9, 80000(%r10)
	vmovupd	%xmm9, 160000(%r10)
	vmovq	%r14, %xmm0
	vsubsd	%xmm3, %xmm4, %xmm11
	vmovq	%xmm7, %rbx
	vmovsd	%xmm1, %xmm1, %xmm10
	vsubsd	%xmm5, %xmm6, %xmm7
	vmovsd	8(%rax), %xmm1
	vmovsd	%xmm3, %xmm3, %xmm8
	vmovsd	%xmm5, %xmm5, %xmm12
	vmovsd	80008(%rax), %xmm3
	vmovsd	160008(%rax), %xmm5
	vsubsd	%xmm4, %xmm0, %xmm0
	vsubsd	%xmm6, %xmm14, %xmm14
	vinsertf128	$0x1, %xmm15, %ymm13, %ymm13
	vmovupd	%ymm13, (%r9)
	vsubsd	%xmm1, %xmm10, %xmm10
	vsubsd	%xmm3, %xmm8, %xmm8
	vsubsd	%xmm5, %xmm12, %xmm12
	vmovq	%rbx, %xmm13
	vunpcklpd	%xmm11, %xmm13, %xmm11
	vunpcklpd	%xmm14, %xmm0, %xmm0
	vinsertf128	$0x1, %xmm11, %ymm0, %ymm0
	vmovupd	%ymm0, 32(%r9)
	vunpcklpd	%xmm12, %xmm8, %xmm8
	vunpcklpd	%xmm10, %xmm7, %xmm0
	vinsertf128	$0x1, %xmm8, %ymm0, %ymm0
	addl	$2, %r11d
	vmovupd	%ymm0, 64(%r9)
	addq	$16, %rsi
	addq	$16, %rax
	addq	$16, %r10
	addq	$96, %r9
	cmpl	%edi, %r11d
	jne	.L1819
.L1818:
	leal	-1(%rdi), %esi
	movslq	%esi, %rsi
	movslq	%edi, %rax
	leaq	(%rsi,%rsi,2), %rsi
	salq	$3, %rax
	leaq	pos_(%rip), %r9
	leaq	30000(%rsi,%rsi), %rsi
	addq	%rax, %rcx
	addq	%rax, %rdx
	leaq	(%r9,%rsi,8), %rsi
	addq	%r9, %rax
	.p2align 4,,10
	.p2align 3
.L1821:
	vmovsd	159992(%rax), %xmm1
	vmovsd	79992(%rax), %xmm4
	vsubsd	160008(%rax), %xmm1, %xmm0
	vsubsd	80008(%rax), %xmm4, %xmm2
	vmovsd	-8(%rax), %xmm3
	movl	-8(%rcx), %r9d
	vunpcklpd	%xmm0, %xmm2, %xmm2
	vmovsd	160000(%rax), %xmm0
	incl	%edi
	vsubsd	%xmm1, %xmm0, %xmm0
	vsubsd	8(%rax), %xmm3, %xmm1
	movl	%r9d, -4(%rcx)
	movl	$0, -8(%rcx)
	vunpcklpd	%xmm1, %xmm0, %xmm0
	vmovsd	(%rax), %xmm1
	movq	$0x000000000, -8(%rdx)
	vsubsd	%xmm3, %xmm1, %xmm1
	vmovsd	80000(%rax), %xmm3
	movq	$0x000000000, 79992(%rdx)
	vsubsd	%xmm4, %xmm3, %xmm3
	movq	$0x000000000, 159992(%rdx)
	addq	$8, %rcx
	vunpcklpd	%xmm3, %xmm1, %xmm1
	vmovapd	%xmm1, (%rsi)
	vmovapd	%xmm0, 16(%rsi)
	vmovapd	%xmm2, 32(%rsi)
	addq	$8, %rdx
	addq	$8, %rax
	addq	$48, %rsi
	cmpl	%edi, %r8d
	jge	.L1821
	cmpl	$1, %r8d
	jle	.L1826
	leaq	240024+pos_(%rip), %rax
	leal	-2(%r8), %esi
	leaq	959992(%rax), %rcx
	vmovsd	240000+pos_(%rip), %xmm6
	vmovsd	240008+pos_(%rip), %xmm5
	vmovsd	240016+pos_(%rip), %xmm4
	vmovsd	.LC8(%rip), %xmm7
	leaq	959984(%rax), %rdx
	leaq	(%rcx,%rsi,8), %rcx
	.p2align 4,,10
	.p2align 3
.L1822:
	vmovsd	16(%rax), %xmm9
	vmovsd	%xmm5, %xmm5, %xmm1
	vmovsd	32(%rax), %xmm5
	vmovsd	8(%rax), %xmm8
	vmulsd	%xmm9, %xmm5, %xmm2
	vmovsd	%xmm4, %xmm4, %xmm0
	vmovsd	40(%rax), %xmm4
	vmovsd	(%rax), %xmm3
	addq	$8, %rdx
	vfmsub231sd	%xmm8, %xmm4, %xmm2
	vmulsd	%xmm3, %xmm4, %xmm10
	addq	$48, %rax
	vmovsd	%xmm2, 480000(%rax)
	vmovsd	%xmm6, %xmm6, %xmm2
	vmovsd	-24(%rax), %xmm6
	vmulsd	%xmm6, %xmm8, %xmm8
	vfmsub132sd	%xmm6, %xmm10, %xmm9
	vfmsub132sd	%xmm5, %xmm8, %xmm3
	vmovsd	%xmm9, 480008(%rax)
	vmovsd	%xmm3, 480016(%rax)
	vmulsd	%xmm1, %xmm4, %xmm3
	vfmsub231sd	%xmm0, %xmm5, %xmm3
	vmulsd	%xmm0, %xmm6, %xmm0
	vfmsub231sd	%xmm2, %xmm4, %xmm0
	vmulsd	%xmm2, %xmm5, %xmm2
	vfmsub231sd	%xmm1, %xmm6, %xmm2
	vmulsd	%xmm0, %xmm0, %xmm1
	vfmadd231sd	%xmm3, %xmm3, %xmm1
	vfmadd231sd	%xmm2, %xmm2, %xmm1
	vsqrtsd	%xmm1, %xmm1, %xmm1
	vdivsd	%xmm1, %xmm7, %xmm8
	vmulsd	%xmm8, %xmm3, %xmm3
	vmulsd	%xmm8, %xmm0, %xmm0
	vmulsd	%xmm8, %xmm2, %xmm2
	vmovsd	%xmm3, 479976(%rax)
	vmovsd	%xmm0, 479984(%rax)
	vmovsd	%xmm2, 479992(%rax)
	vmovsd	%xmm1, -8(%rdx)
	cmpq	%rdx, %rcx
	jne	.L1822
.L1826:
	vzeroupper
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%rbp
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L1830:
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
	vzeroupper
	ret
.L1823:
	.cfi_def_cfa 6, 16
	.cfi_offset 3, -48
	.cfi_offset 6, -16
	.cfi_offset 12, -40
	.cfi_offset 13, -32
	.cfi_offset 14, -24
	movl	$1, %edi
	leaq	neigh_(%rip), %rcx
	leaq	for_(%rip), %rdx
	jmp	.L1818
	.cfi_endproc
.LFE29:
	.size	prepare_, .-prepare_
	.p2align 4
	.globl	predct_
	.type	predct_, @function
predct_:
.LFB30:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$104, %rsp
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	movl	(%rdi), %ebx
	movl	8+bas_(%rip), %eax
	movl	%ebx, -88(%rsp)
	cmpl	%eax, %ebx
	jg	.L1841
	leal	1(%rax), %edx
	subl	%ebx, %edx
	subl	%ebx, %eax
	movl	%edx, -64(%rsp)
	movl	%eax, -116(%rsp)
	cmpl	$2, %eax
	jbe	.L1838
	movslq	%ebx, %rdx
	salq	$3, %rdx
	leaq	-8(%rdx), %rdi
	leaq	pos_(%rip), %r9
	leaq	(%r9,%rdi), %rax
	leaq	239992(%rdx), %rsi
	movq	%rax, -8(%rsp)
	leaq	der_(%rip), %rax
	leaq	der2_(%rip), %rcx
	leaq	(%rax,%rsi), %rbx
	movq	%rbx, 96(%rsp)
	leaq	(%rcx,%rsi), %rbx
	leaq	79992(%rdx), %rsi
	leaq	vel_(%rip), %r13
	movq	%rbx, -24(%rsp)
	leaq	(%r9,%rsi), %rbx
	movq	%rbx, 72(%rsp)
	leaq	0(%r13,%rsi), %rbx
	movq	%rbx, -40(%rsp)
	leaq	(%rax,%rsi), %rbx
	addq	%rcx, %rsi
	leaq	319992(%rdx), %r8
	movq	%rsi, 80(%rsp)
	leaq	159992(%rdx), %rsi
	addq	$399992, %rdx
	leaq	(%rcx,%r8), %r11
	leaq	(%rax,%r8), %r12
	leaq	(%rax,%rdx), %r8
	addq	%rcx, %rdx
	movq	%r11, 40(%rsp)
	movq	%rdx, 8(%rsp)
	movl	-64(%rsp), %edx
	movq	%rcx, -72(%rsp)
	shrl	$2, %edx
	movq	%rax, -104(%rsp)
	leaq	0(%r13,%rdi), %r15
	leaq	0(%r13,%rsi), %r11
	salq	$5, %rdx
	movq	%rbx, 88(%rsp)
	movq	%r9, -96(%rsp)
	leaq	(%r9,%rsi), %rbx
	movq	%r13, -112(%rsp)
	vmovapd	.LC114(%rip), %ymm15
	movq	40(%rsp), %r9
	movq	8(%rsp), %r13
	movq	%rdx, -56(%rsp)
	leaq	(%rax,%rdi), %r14
	leaq	(%rax,%rsi), %r10
	addq	%rcx, %rdi
	addq	%rcx, %rsi
	xorl	%edx, %edx
	.p2align 4,,10
	.p2align 3
.L1834:
	movq	96(%rsp), %rax
	vmovupd	(%r15,%rdx), %ymm10
	vmovupd	(%rax,%rdx), %ymm5
	movq	-8(%rsp), %rax
	movq	-24(%rsp), %rcx
	vaddpd	(%rax,%rdx), %ymm10, %ymm0
	vaddpd	(%r14,%rdx), %ymm5, %ymm1
	vmovupd	(%rcx,%rdx), %ymm11
	movq	88(%rsp), %rcx
	vaddpd	%ymm1, %ymm0, %ymm0
	vaddpd	(%rdi,%rdx), %ymm11, %ymm1
	vmulpd	.LC111(%rip), %ymm5, %ymm9
	vmovapd	%ymm11, 8(%rsp)
	vaddpd	%ymm1, %ymm0, %ymm0
	vmovupd	%ymm0, (%rax,%rdx)
	vmovupd	(%rcx,%rdx), %ymm3
	movq	-40(%rsp), %rax
	movq	80(%rsp), %rcx
	vmovupd	(%rax,%rdx), %ymm7
	vmovupd	(%rcx,%rdx), %ymm1
	vmovupd	(%r12,%rdx), %ymm14
	movq	72(%rsp), %rcx
	vaddpd	%ymm14, %ymm3, %ymm2
	vaddpd	(%rcx,%rdx), %ymm7, %ymm0
	vaddpd	%ymm2, %ymm0, %ymm0
	vaddpd	(%r9,%rdx), %ymm1, %ymm2
	vaddpd	%ymm2, %ymm0, %ymm0
	vmovupd	%ymm0, (%rcx,%rdx)
	vmovupd	(%r11,%rdx), %ymm13
	vmovupd	(%r10,%rdx), %ymm2
	vmovupd	(%r8,%rdx), %ymm4
	vaddpd	(%rbx,%rdx), %ymm13, %ymm8
	vaddpd	%ymm4, %ymm2, %ymm6
	vmovupd	(%rsi,%rdx), %ymm0
	vaddpd	%ymm6, %ymm8, %ymm6
	vaddpd	0(%r13,%rdx), %ymm0, %ymm8
	vaddpd	%ymm8, %ymm6, %ymm6
	vmovupd	%ymm6, (%rbx,%rdx)
	vmovupd	(%r14,%rdx), %ymm8
	vmovapd	%ymm15, %ymm6
	vfmadd132pd	.LC112(%rip), %ymm9, %ymm8
	vmulpd	.LC113(%rip), %ymm11, %ymm12
	vfmadd132pd	(%rdi,%rdx), %ymm12, %ymm6
	vaddpd	%ymm8, %ymm6, %ymm6
	vmulpd	.LC111(%rip), %ymm14, %ymm8
	vaddpd	%ymm10, %ymm6, %ymm6
	vmovapd	%ymm3, %ymm10
	vmovupd	%ymm6, (%r15,%rdx)
	vmovupd	(%r9,%rdx), %ymm6
	vfmadd132pd	.LC112(%rip), %ymm8, %ymm10
	vmulpd	.LC113(%rip), %ymm6, %ymm11
	vmovapd	%ymm1, %ymm6
	vfmadd231pd	.LC115(%rip), %ymm1, %ymm8
	vfmadd132pd	%ymm15, %ymm11, %ymm6
	vaddpd	%ymm10, %ymm6, %ymm6
	vmovapd	%ymm2, %ymm10
	vaddpd	%ymm7, %ymm6, %ymm6
	vmulpd	.LC111(%rip), %ymm4, %ymm7
	vmovupd	%ymm6, (%rax,%rdx)
	vmovupd	0(%r13,%rdx), %ymm6
	movq	88(%rsp), %rax
	vfmadd132pd	.LC112(%rip), %ymm7, %ymm10
	vfmadd231pd	.LC115(%rip), %ymm0, %ymm7
	vmovapd	%ymm10, 40(%rsp)
	vmulpd	.LC113(%rip), %ymm6, %ymm10
	vmovapd	%ymm0, %ymm6
	vfmadd132pd	%ymm15, %ymm10, %ymm6
	vaddpd	40(%rsp), %ymm6, %ymm6
	vaddpd	%ymm13, %ymm6, %ymm6
	vmovupd	%ymm6, (%r11,%rdx)
	vmovapd	8(%rsp), %ymm6
	vmovupd	(%rdi,%rdx), %ymm13
	vmulpd	.LC116(%rip), %ymm6, %ymm6
	vfmadd231pd	.LC115(%rip), %ymm13, %ymm9
	vaddpd	(%r14,%rdx), %ymm6, %ymm13
	vaddpd	%ymm9, %ymm13, %ymm9
	vmovupd	%ymm9, (%r14,%rdx)
	vmovupd	(%r9,%rdx), %ymm13
	vmulpd	.LC116(%rip), %ymm13, %ymm9
	vaddpd	%ymm9, %ymm3, %ymm3
	vfmadd231pd	%ymm15, %ymm1, %ymm9
	vaddpd	%ymm11, %ymm1, %ymm1
	vaddpd	%ymm8, %ymm3, %ymm8
	vmovupd	%ymm8, (%rax,%rdx)
	vmovupd	0(%r13,%rdx), %ymm3
	vaddpd	%ymm9, %ymm14, %ymm9
	vmulpd	.LC116(%rip), %ymm3, %ymm3
	movq	96(%rsp), %rax
	vaddpd	%ymm3, %ymm2, %ymm2
	vfmadd231pd	%ymm15, %ymm0, %ymm3
	vaddpd	%ymm10, %ymm0, %ymm0
	vaddpd	%ymm7, %ymm2, %ymm2
	vmovupd	%ymm2, (%r10,%rdx)
	vfmadd231pd	(%rdi,%rdx), %ymm15, %ymm6
	vaddpd	%ymm3, %ymm4, %ymm4
	vaddpd	%ymm6, %ymm5, %ymm5
	vmovupd	%ymm5, (%rax,%rdx)
	vmovupd	%ymm9, (%r12,%rdx)
	vmovupd	%ymm4, (%r8,%rdx)
	vaddpd	(%rdi,%rdx), %ymm12, %ymm12
	movq	80(%rsp), %rax
	vmovupd	%ymm12, (%rdi,%rdx)
	vmovupd	%ymm1, (%rax,%rdx)
	vmovupd	%ymm0, (%rsi,%rdx)
	addq	$32, %rdx
	cmpq	-56(%rsp), %rdx
	jne	.L1834
	movl	-64(%rsp), %ebx
	movl	-88(%rsp), %esi
	movl	%ebx, %edi
	andl	$-4, %edi
	addl	%edi, %esi
	movl	%esi, 96(%rsp)
	movq	-72(%rsp), %rcx
	movq	-96(%rsp), %r9
	movq	-104(%rsp), %rax
	movq	-112(%rsp), %r13
	cmpl	%ebx, %edi
	je	.L1843
	vzeroupper
.L1833:
	subl	%edi, %ebx
	movl	%ebx, -72(%rsp)
	cmpl	-116(%rsp), %edi
	je	.L1836
	movslq	-88(%rsp), %rsi
	leaq	29999(%rsi,%rdi), %r15
	leaq	(%rsi,%rdi), %r8
	leaq	-8(,%r8,8), %r8
	leaq	(%rax,%r15,8), %r11
	leaq	(%rax,%r8), %rbx
	leaq	(%r9,%r8), %r14
	leaq	0(%r13,%r8), %r10
	movq	%r11, 8(%rsp)
	leaq	(%rcx,%r8), %r11
	leaq	9999(%rsi,%rdi), %r8
	salq	$3, %r8
	leaq	(%r9,%r8), %r12
	movq	%r12, 40(%rsp)
	leaq	0(%r13,%r8), %r12
	movq	%r12, -8(%rsp)
	leaq	(%rax,%r8), %r12
	addq	%rcx, %r8
	movq	%r8, 88(%rsp)
	leaq	19999(%rsi,%rdi), %r8
	salq	$3, %r8
	movq	%r12, -24(%rsp)
	leaq	39999(%rsi,%rdi), %r12
	leaq	49999(%rsi,%rdi), %rsi
	leaq	(%r8,%rcx), %rdi
	movq	%rdi, 80(%rsp)
	leaq	(%rax,%r15,8), %rdi
	vmovupd	(%rdi), %xmm12
	vmovupd	(%r14), %xmm5
	vaddpd	(%rbx), %xmm12, %xmm1
	vaddpd	(%r10), %xmm5, %xmm0
	vmovupd	(%rcx,%r15,8), %xmm3
	leaq	(%rax,%r12,8), %rdx
	vaddpd	%xmm1, %xmm0, %xmm0
	vaddpd	(%r11), %xmm3, %xmm1
	movq	%rdx, 72(%rsp)
	leaq	(%r9,%r8), %rdx
	vaddpd	%xmm1, %xmm0, %xmm0
	movq	%rdx, -40(%rsp)
	leaq	0(%r13,%r8), %rdx
	vmovupd	%xmm0, (%r14)
	movq	-24(%rsp), %rdi
	movq	%rdx, -56(%rsp)
	movq	-8(%rsp), %r14
	movq	88(%rsp), %r15
	leaq	(%rax,%r8), %rdx
	movq	%rdx, -64(%rsp)
	leaq	(%rax,%r12,8), %rdx
	vmovupd	(%r15), %xmm5
	vmovupd	(%rdi), %xmm6
	vmovupd	(%rdx), %xmm14
	vmovupd	(%r14), %xmm4
	movq	40(%rsp), %r15
	vaddpd	%xmm14, %xmm6, %xmm1
	vaddpd	(%r15), %xmm4, %xmm0
	vmovupd	(%rcx,%r12,8), %xmm2
	movq	-56(%rsp), %r12
	vaddpd	%xmm1, %xmm0, %xmm0
	vaddpd	%xmm2, %xmm5, %xmm1
	vmovapd	%xmm4, -88(%rsp)
	leaq	(%rax,%rsi,8), %r8
	vaddpd	%xmm1, %xmm0, %xmm0
	vmovupd	%xmm0, (%r15)
	vmovupd	(%r12), %xmm13
	movq	-64(%rsp), %r15
	vmovupd	(%rcx,%rsi,8), %xmm11
	vmovupd	(%r15), %xmm7
	vmovupd	(%r8), %xmm15
	movq	-40(%rsp), %rsi
	movq	80(%rsp), %rdx
	vaddpd	(%rsi), %xmm13, %xmm1
	vaddpd	%xmm7, %xmm15, %xmm0
	vmovupd	(%rdx), %xmm4
	vmovapd	.LC117(%rip), %xmm8
	vaddpd	%xmm0, %xmm1, %xmm0
	vaddpd	%xmm11, %xmm4, %xmm1
	vmovapd	%xmm11, -56(%rsp)
	vmulpd	%xmm12, %xmm8, %xmm11
	vaddpd	%xmm1, %xmm0, %xmm0
	vmovapd	%xmm7, 40(%rsp)
	vmovapd	.LC119(%rip), %xmm7
	vmovupd	%xmm0, (%rsi)
	vmovapd	.LC118(%rip), %xmm0
	vmovapd	%xmm12, -40(%rsp)
	vmovapd	%xmm0, %xmm1
	vfmadd132pd	(%rbx), %xmm11, %xmm1
	vmulpd	%xmm7, %xmm2, %xmm12
	vmovapd	%xmm1, %xmm9
	vmulpd	%xmm7, %xmm3, %xmm1
	vmovapd	%xmm12, -24(%rsp)
	vmovapd	%xmm1, %xmm10
	vmovapd	.LC120(%rip), %xmm1
	vmovapd	%xmm10, -8(%rsp)
	vfmadd231pd	(%r11), %xmm1, %xmm10
	vfmadd231pd	%xmm1, %xmm5, %xmm12
	vaddpd	%xmm10, %xmm9, %xmm9
	vmulpd	%xmm8, %xmm14, %xmm10
	vmulpd	%xmm8, %xmm15, %xmm8
	vaddpd	(%r10), %xmm9, %xmm9
	vmovupd	%xmm9, (%r10)
	vmovapd	%xmm6, %xmm9
	vfmadd132pd	%xmm0, %xmm10, %xmm9
	vfmadd132pd	40(%rsp), %xmm8, %xmm0
	vaddpd	%xmm12, %xmm9, %xmm9
	vmovapd	-56(%rsp), %xmm12
	vmulpd	%xmm12, %xmm7, %xmm7
	vaddpd	-88(%rsp), %xmm9, %xmm9
	vmovupd	%xmm9, (%r14)
	vmovapd	%xmm4, %xmm9
	vfmadd132pd	%xmm1, %xmm7, %xmm9
	vaddpd	%xmm7, %xmm4, %xmm7
	vaddpd	%xmm9, %xmm0, %xmm0
	vmovapd	.LC121(%rip), %xmm9
	vaddpd	%xmm13, %xmm0, %xmm0
	vfmadd231pd	%xmm9, %xmm5, %xmm10
	vfmadd231pd	%xmm9, %xmm4, %xmm8
	vmovupd	%xmm0, (%r12)
	vmovapd	.LC122(%rip), %xmm0
	vfmadd231pd	(%r11), %xmm9, %xmm11
	vmulpd	%xmm0, %xmm3, %xmm3
	vmulpd	%xmm0, %xmm2, %xmm2
	vmulpd	%xmm12, %xmm0, %xmm0
	vaddpd	(%rbx), %xmm3, %xmm13
	vaddpd	%xmm2, %xmm6, %xmm6
	vfmadd231pd	%xmm1, %xmm5, %xmm2
	vaddpd	%xmm11, %xmm13, %xmm11
	vaddpd	%xmm10, %xmm6, %xmm10
	vmovupd	%xmm11, (%rbx)
	vmovupd	%xmm10, (%rdi)
	vaddpd	40(%rsp), %xmm0, %xmm9
	vaddpd	%xmm2, %xmm14, %xmm2
	movq	8(%rsp), %rdi
	vaddpd	%xmm8, %xmm9, %xmm8
	movq	72(%rsp), %rdx
	vmovapd	-8(%rsp), %xmm10
	vmovupd	%xmm8, (%r15)
	vfmadd231pd	(%r11), %xmm1, %xmm3
	vfmadd132pd	%xmm4, %xmm0, %xmm1
	vaddpd	-24(%rsp), %xmm5, %xmm5
	movq	80(%rsp), %rbx
	movq	88(%rsp), %r15
	vaddpd	-40(%rsp), %xmm3, %xmm3
	vaddpd	%xmm1, %xmm15, %xmm1
	vmovupd	%xmm3, (%rdi)
	vmovupd	%xmm2, (%rdx)
	vmovupd	%xmm1, (%r8)
	vaddpd	(%r11), %xmm10, %xmm0
	vmovupd	%xmm0, (%r11)
	vmovupd	%xmm5, (%r15)
	vmovupd	%xmm7, (%rbx)
	movl	-72(%rsp), %ebx
	movl	%ebx, %esi
	andl	$-2, %esi
	addl	%esi, 96(%rsp)
	cmpl	%esi, %ebx
	je	.L1841
.L1836:
	movslq	96(%rsp), %rdx
	vmovsd	.LC100(%rip), %xmm12
	leaq	-1(%rdx), %r8
	leaq	29999(%rdx), %r11
	vmovsd	0(%r13,%r8,8), %xmm15
	vmovsd	(%rax,%r8,8), %xmm9
	vmovsd	(%rax,%r11,8), %xmm14
	vaddsd	(%r9,%r8,8), %xmm15, %xmm0
	vaddsd	%xmm14, %xmm9, %xmm1
	vmovsd	(%rcx,%r8,8), %xmm6
	vmovsd	(%rcx,%r11,8), %xmm3
	vaddsd	%xmm1, %xmm0, %xmm0
	vaddsd	%xmm3, %xmm6, %xmm1
	leaq	9999(%rdx), %rdi
	leaq	39999(%rdx), %r10
	vaddsd	%xmm1, %xmm0, %xmm0
	vmovsd	(%rax,%rdi,8), %xmm8
	vmovsd	(%rax,%r10,8), %xmm13
	vmovsd	0(%r13,%rdi,8), %xmm4
	vaddsd	%xmm13, %xmm8, %xmm1
	vmovsd	%xmm0, (%r9,%r8,8)
	vaddsd	(%r9,%rdi,8), %xmm4, %xmm0
	vmovsd	(%rcx,%rdi,8), %xmm5
	leaq	19999(%rdx), %rsi
	vaddsd	%xmm1, %xmm0, %xmm0
	vaddsd	(%rcx,%r10,8), %xmm5, %xmm1
	vmovsd	0(%r13,%rsi,8), %xmm2
	addq	$49999, %rdx
	vaddsd	%xmm1, %xmm0, %xmm0
	vmovsd	(%rcx,%rsi,8), %xmm4
	vmulsd	.LC123(%rip), %xmm3, %xmm7
	vmovsd	%xmm0, (%r9,%rdi,8)
	vaddsd	(%r9,%rsi,8), %xmm2, %xmm0
	vmovsd	(%rax,%rsi,8), %xmm2
	vmovsd	%xmm9, %xmm9, %xmm10
	vaddsd	(%rax,%rdx,8), %xmm2, %xmm1
	vmulsd	%xmm12, %xmm14, %xmm2
	vmovq	%xmm7, %rbx
	vaddsd	%xmm1, %xmm0, %xmm0
	vaddsd	(%rcx,%rdx,8), %xmm4, %xmm1
	vmovsd	.LC123(%rip), %xmm11
	vaddsd	%xmm1, %xmm0, %xmm0
	vmovsd	.LC83(%rip), %xmm1
	vmulsd	(%rcx,%r10,8), %xmm11, %xmm11
	vmovsd	%xmm0, (%r9,%rsi,8)
	vmovsd	.LC74(%rip), %xmm0
	vfmadd231sd	%xmm1, %xmm6, %xmm7
	vfmadd132sd	%xmm0, %xmm2, %xmm10
	vaddsd	%xmm7, %xmm10, %xmm7
	vmovsd	%xmm8, %xmm8, %xmm10
	vaddsd	%xmm15, %xmm7, %xmm15
	vmovsd	%xmm5, %xmm5, %xmm7
	vfmadd132sd	%xmm1, %xmm11, %xmm7
	vmovsd	%xmm15, 0(%r13,%r8,8)
	vmulsd	%xmm12, %xmm13, %xmm15
	vfmadd132sd	%xmm0, %xmm15, %xmm10
	vaddsd	%xmm7, %xmm10, %xmm7
	vmovsd	%xmm4, %xmm4, %xmm10
	vaddsd	0(%r13,%rdi,8), %xmm7, %xmm7
	vmovsd	%xmm7, 0(%r13,%rdi,8)
	vmulsd	(%rax,%rdx,8), %xmm12, %xmm7
	vfmadd132sd	(%rax,%rsi,8), %xmm7, %xmm0
	vmovsd	.LC123(%rip), %xmm12
	vfmadd231sd	.LC85(%rip), %xmm5, %xmm15
	vmulsd	(%rcx,%rdx,8), %xmm12, %xmm12
	vfmadd132sd	%xmm1, %xmm12, %xmm10
	vaddsd	%xmm10, %xmm0, %xmm0
	vmovsd	.LC124(%rip), %xmm10
	vaddsd	0(%r13,%rsi,8), %xmm0, %xmm0
	vmulsd	%xmm10, %xmm3, %xmm3
	vmovsd	%xmm0, 0(%r13,%rsi,8)
	vmovsd	.LC85(%rip), %xmm0
	vfmadd132sd	%xmm6, %xmm2, %xmm0
	vaddsd	%xmm3, %xmm9, %xmm9
	vmulsd	(%rcx,%r10,8), %xmm10, %xmm2
	vmulsd	(%rcx,%rdx,8), %xmm10, %xmm10
	vfmadd231sd	%xmm1, %xmm6, %xmm3
	vaddsd	%xmm0, %xmm9, %xmm9
	vmovsd	.LC85(%rip), %xmm0
	vaddsd	%xmm2, %xmm8, %xmm8
	vfmadd132sd	%xmm4, %xmm7, %xmm0
	vfmadd231sd	%xmm1, %xmm5, %xmm2
	vfmadd132sd	%xmm4, %xmm10, %xmm1
	vaddsd	(%rax,%rsi,8), %xmm10, %xmm7
	vaddsd	%xmm3, %xmm14, %xmm14
	vmovq	%rbx, %xmm3
	vaddsd	%xmm15, %xmm8, %xmm8
	vaddsd	%xmm0, %xmm7, %xmm0
	vaddsd	%xmm2, %xmm13, %xmm13
	vaddsd	(%rax,%rdx,8), %xmm1, %xmm1
	vaddsd	%xmm3, %xmm6, %xmm6
	vaddsd	%xmm11, %xmm5, %xmm5
	vaddsd	%xmm12, %xmm4, %xmm4
	vmovsd	%xmm9, (%rax,%r8,8)
	vmovsd	%xmm8, (%rax,%rdi,8)
	vmovsd	%xmm0, (%rax,%rsi,8)
	vmovsd	%xmm14, (%rax,%r11,8)
	vmovsd	%xmm13, (%rax,%r10,8)
	vmovsd	%xmm1, (%rax,%rdx,8)
	vmovsd	%xmm6, (%rcx,%r8,8)
	vmovsd	%xmm5, (%rcx,%rdi,8)
	vmovsd	%xmm4, (%rcx,%rsi,8)
.L1841:
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L1843:
	.cfi_restore_state
	vzeroupper
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
.L1838:
	.cfi_restore_state
	movl	%ebx, 96(%rsp)
	xorl	%edi, %edi
	leaq	pos_(%rip), %r9
	leaq	vel_(%rip), %r13
	leaq	der_(%rip), %rax
	leaq	der2_(%rip), %rcx
	movl	%edx, %ebx
	jmp	.L1833
	.cfi_endproc
.LFE30:
	.size	predct_, .-predct_
	.p2align 4
	.globl	corr_
	.type	corr_, @function
corr_:
.LFB31:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$72, %rsp
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	movl	(%rsi), %ebx
	movl	8+bas_(%rip), %eax
	movl	%ebx, -56(%rsp)
	cmpl	%eax, %ebx
	jg	.L1854
	leal	1(%rax), %edx
	vmovsd	16+parm_(%rip), %xmm6
	vmovsd	24+parm_(%rip), %xmm7
	vmovsd	32+parm_(%rip), %xmm0
	subl	%ebx, %edx
	subl	%ebx, %eax
	movl	%edx, -48(%rsp)
	movl	%eax, -108(%rsp)
	vmovsd	(%rdi), %xmm3
	vmovsd	parm_(%rip), %xmm5
	vmovsd	8+parm_(%rip), %xmm4
	vmovsd	%xmm6, 64(%rsp)
	vmovsd	%xmm7, 56(%rsp)
	vmovsd	%xmm0, 48(%rsp)
	cmpl	$2, %eax
	jbe	.L1851
	movslq	%ebx, %rsi
	salq	$3, %rsi
	leaq	-8(%rsi), %r9
	leaq	for_(%rip), %r12
	leaq	79992(%rsi), %r8
	leaq	(%r12,%r9), %rbx
	leaq	159992(%rsi), %rdi
	movq	%rbx, 40(%rsp)
	leaq	(%r12,%r8), %rbx
	movq	%rbx, 32(%rsp)
	leaq	(%r12,%rdi), %rbx
	movq	%rbx, 8(%rsp)
	leaq	pos_(%rip), %rbx
	leaq	(%rbx,%r9), %r11
	movq	%r11, 24(%rsp)
	leaq	vel_(%rip), %r11
	leaq	der_(%rip), %rcx
	leaq	(%r11,%r9), %r10
	leaq	239992(%rsi), %rax
	leaq	der2_(%rip), %rdx
	movq	%r10, (%rsp)
	leaq	(%rcx,%rax), %r10
	movq	%r10, -8(%rsp)
	leaq	(%rdx,%r9), %r10
	leaq	(%rcx,%r9), %r15
	movq	%r10, -16(%rsp)
	leaq	(%r11,%r8), %r9
	leaq	(%rdx,%rax), %r10
	movq	%r9, -64(%rsp)
	movq	%r10, -24(%rsp)
	leaq	319992(%rsi), %r9
	leaq	(%rbx,%r8), %r10
	movq	%r10, -32(%rsp)
	leaq	(%rdx,%r9), %r10
	leaq	(%rcx,%r9), %rax
	movq	%r10, -88(%rsp)
	leaq	(%rcx,%r8), %r14
	addq	%rdx, %r8
	movq	%rax, -72(%rsp)
	movq	%r8, -80(%rsp)
	movl	-48(%rsp), %eax
	addq	$399992, %rsi
	movq	%r12, -96(%rsp)
	shrl	$2, %eax
	movq	-88(%rsp), %r12
	movq	%rdx, -88(%rsp)
	leaq	(%rcx,%rdi), %r13
	leaq	(%rbx,%rdi), %r9
	leaq	(%r11,%rdi), %r8
	leaq	(%rcx,%rsi), %r10
	salq	$5, %rax
	movq	%r11, -104(%rsp)
	movq	-72(%rsp), %r11
	movq	%rbx, -72(%rsp)
	movq	-80(%rsp), %rbx
	movq	%rcx, -80(%rsp)
	movq	-64(%rsp), %rcx
	movq	%rax, -40(%rsp)
	vbroadcastsd	%xmm6, %ymm8
	vbroadcastsd	%xmm3, %ymm11
	vbroadcastsd	%xmm5, %ymm10
	vbroadcastsd	%xmm4, %ymm9
	vbroadcastsd	%xmm7, %ymm7
	vbroadcastsd	%xmm0, %ymm6
	addq	%rdx, %rdi
	addq	%rdx, %rsi
	xorl	%eax, %eax
	.p2align 4,,10
	.p2align 3
.L1847:
	movq	40(%rsp), %rdx
	vmovupd	(%r15,%rax), %ymm0
	vmulpd	(%rdx,%rax), %ymm11, %ymm14
	movq	32(%rsp), %rdx
	vmulpd	(%rdx,%rax), %ymm11, %ymm13
	movq	8(%rsp), %rdx
	vsubpd	%ymm14, %ymm0, %ymm2
	vmulpd	(%rdx,%rax), %ymm11, %ymm12
	movq	24(%rsp), %rdx
	vmovapd	%ymm2, %ymm15
	vfnmadd213pd	(%rdx,%rax), %ymm10, %ymm15
	vmovupd	(%r14,%rax), %ymm0
	vsubpd	%ymm13, %ymm0, %ymm1
	vmovupd	0(%r13,%rax), %ymm0
	vmovupd	%ymm15, (%rdx,%rax)
	movq	(%rsp), %rdx
	vmovapd	%ymm2, %ymm15
	vfnmadd213pd	(%rdx,%rax), %ymm9, %ymm15
	vsubpd	%ymm12, %ymm0, %ymm0
	vmovupd	%ymm15, (%rdx,%rax)
	movq	-8(%rsp), %rdx
	vmovupd	%ymm14, (%r15,%rax)
	vmovapd	%ymm2, %ymm14
	vfnmadd213pd	(%rdx,%rax), %ymm8, %ymm14
	vmovupd	%ymm14, (%rdx,%rax)
	movq	-16(%rsp), %rdx
	vmovapd	%ymm2, %ymm14
	vfnmadd213pd	(%rdx,%rax), %ymm7, %ymm14
	vmovupd	%ymm14, (%rdx,%rax)
	movq	-24(%rsp), %rdx
	vfnmadd213pd	(%rdx,%rax), %ymm6, %ymm2
	vmovupd	%ymm2, (%rdx,%rax)
	movq	-32(%rsp), %rdx
	vmovapd	%ymm1, %ymm2
	vfnmadd213pd	(%rdx,%rax), %ymm10, %ymm2
	vmovupd	%ymm2, (%rdx,%rax)
	vmovapd	%ymm1, %ymm2
	vfnmadd213pd	(%rcx,%rax), %ymm9, %ymm2
	vmovupd	%ymm2, (%rcx,%rax)
	vmovupd	%ymm13, (%r14,%rax)
	vmovapd	%ymm1, %ymm2
	vfnmadd213pd	(%r11,%rax), %ymm8, %ymm2
	vmovupd	%ymm2, (%r11,%rax)
	vmovapd	%ymm1, %ymm2
	vfnmadd213pd	(%rbx,%rax), %ymm7, %ymm2
	vmovupd	%ymm2, (%rbx,%rax)
	vfnmadd213pd	(%r12,%rax), %ymm6, %ymm1
	vmovupd	%ymm1, (%r12,%rax)
	vmovapd	%ymm0, %ymm1
	vfnmadd213pd	(%r9,%rax), %ymm10, %ymm1
	vmovupd	%ymm1, (%r9,%rax)
	vmovapd	%ymm0, %ymm1
	vfnmadd213pd	(%r8,%rax), %ymm9, %ymm1
	vmovupd	%ymm1, (%r8,%rax)
	vmovupd	%ymm12, 0(%r13,%rax)
	vmovapd	%ymm0, %ymm1
	vfnmadd213pd	(%r10,%rax), %ymm8, %ymm1
	vmovupd	%ymm1, (%r10,%rax)
	vmovapd	%ymm0, %ymm1
	vfnmadd213pd	(%rdi,%rax), %ymm7, %ymm1
	vmovupd	%ymm1, (%rdi,%rax)
	vfnmadd213pd	(%rsi,%rax), %ymm6, %ymm0
	vmovupd	%ymm0, (%rsi,%rax)
	addq	$32, %rax
	cmpq	-40(%rsp), %rax
	jne	.L1847
	movl	-48(%rsp), %esi
	movl	-56(%rsp), %edi
	movl	%esi, %eax
	andl	$-4, %eax
	movq	-96(%rsp), %r12
	movq	-88(%rsp), %rdx
	movq	-104(%rsp), %r11
	movq	-72(%rsp), %rbx
	movq	-80(%rsp), %rcx
	leal	(%rax,%rdi), %r13d
	cmpl	%eax, %esi
	je	.L1856
	vzeroupper
.L1846:
	subl	%eax, %esi
	movl	%esi, -88(%rsp)
	cmpl	%eax, -108(%rsp)
	je	.L1849
	movslq	-56(%rsp), %rsi
	vmovddup	%xmm3, %xmm6
	leaq	(%rsi,%rax), %rdi
	salq	$3, %rdi
	leaq	-8(%rdi), %r10
	leaq	9999(%rsi,%rax), %r9
	leaq	0(,%r9,8), %r8
	movq	%r9, -72(%rsp)
	leaq	(%r11,%r10), %r9
	leaq	(%rcx,%r8), %r14
	movq	%r9, (%rsp)
	leaq	29999(%rsi,%rax), %r9
	movq	%r14, 40(%rsp)
	leaq	(%rcx,%r10), %r15
	leaq	(%rbx,%r10), %r14
	salq	$3, %r9
	addq	%rdx, %r10
	movq	%r14, 24(%rsp)
	movq	%r10, -16(%rsp)
	leaq	(%rcx,%r9), %r14
	leaq	(%rdx,%r9), %r10
	leaq	(%r11,%r8), %r9
	movq	%rdi, -64(%rsp)
	movq	%r9, -32(%rsp)
	leaq	39999(%rsi,%rax), %r9
	salq	$3, %r9
	movq	%r14, -8(%rsp)
	leaq	(%rcx,%r9), %r14
	movq	%r15, 8(%rsp)
	movq	%r14, -40(%rsp)
	leaq	19999(%rsi,%rax), %r15
	movq	-64(%rsp), %r14
	leaq	0(,%r15,8), %rdi
	vmulpd	-8(%r12,%r14), %xmm6, %xmm13
	movq	%r15, -80(%rsp)
	leaq	(%rcx,%rdi), %r15
	movq	8(%rsp), %r14
	movq	%r15, 32(%rsp)
	movq	-72(%rsp), %r15
	vmovupd	(%r14), %xmm0
	vmulpd	(%r12,%r15,8), %xmm6, %xmm12
	movq	40(%rsp), %r15
	vsubpd	%xmm13, %xmm0, %xmm2
	vmovapd	%xmm0, 8(%rsp)
	vmovupd	(%r15), %xmm0
	movq	-80(%rsp), %r15
	movq	%r10, -24(%rsp)
	vmulpd	(%r12,%r15,8), %xmm6, %xmm6
	leaq	(%rbx,%r8), %r10
	movq	32(%rsp), %r15
	addq	%rdx, %r8
	movq	%r8, -48(%rsp)
	leaq	(%rdx,%r9), %r8
	vsubpd	%xmm12, %xmm0, %xmm1
	vmovddup	64(%rsp), %xmm8
	vmovddup	56(%rsp), %xmm7
	vmovddup	48(%rsp), %xmm11
	movq	%r8, -56(%rsp)
	vmovupd	(%r15), %xmm0
	movq	24(%rsp), %r15
	vmovddup	%xmm5, %xmm10
	vmovapd	%xmm2, %xmm14
	vfnmadd213pd	(%r15), %xmm10, %xmm14
	vmovddup	%xmm4, %xmm9
	vsubpd	%xmm6, %xmm0, %xmm0
	leaq	(%rbx,%rdi), %r8
	leaq	(%r11,%rdi), %r9
	vmovupd	%xmm14, (%r15)
	movq	(%rsp), %r15
	vmovapd	%xmm2, %xmm14
	vfnmadd213pd	(%r15), %xmm9, %xmm14
	leaq	49999(%rsi,%rax), %rax
	salq	$3, %rax
	leaq	(%rcx,%rax), %rsi
	addq	%rdx, %rdi
	vmovupd	%xmm14, (%r15)
	vmovupd	%xmm13, (%r14)
	movq	-8(%rsp), %r14
	vmovapd	%xmm2, %xmm13
	vfnmadd213pd	(%r14), %xmm8, %xmm13
	movq	-24(%rsp), %r15
	addq	%rdx, %rax
	vmovupd	%xmm13, (%r14)
	movq	-16(%rsp), %r14
	vmovapd	%xmm2, %xmm13
	vfnmadd213pd	(%r14), %xmm7, %xmm13
	vmovupd	%xmm13, (%r14)
	vfnmadd213pd	(%r15), %xmm11, %xmm2
	movq	40(%rsp), %r14
	vmovupd	%xmm2, (%r15)
	vmovapd	%xmm1, %xmm2
	vfnmadd213pd	(%r10), %xmm10, %xmm2
	vmovupd	%xmm2, (%r10)
	movq	-32(%rsp), %r10
	vmovapd	%xmm1, %xmm2
	vfnmadd213pd	(%r10), %xmm9, %xmm2
	vmovupd	%xmm2, (%r10)
	movq	-40(%rsp), %r10
	vmovupd	%xmm12, (%r14)
	vmovapd	%xmm1, %xmm2
	vfnmadd213pd	(%r10), %xmm8, %xmm2
	movq	-56(%rsp), %r14
	vmovupd	%xmm2, (%r10)
	movq	-48(%rsp), %r10
	vmovapd	%xmm1, %xmm2
	vfnmadd213pd	(%r10), %xmm7, %xmm2
	vmovupd	%xmm2, (%r10)
	vfnmadd213pd	(%r14), %xmm11, %xmm1
	vmovupd	%xmm1, (%r14)
	vfnmadd213pd	(%r8), %xmm0, %xmm10
	movq	32(%rsp), %r15
	vmovupd	%xmm10, (%r8)
	vfnmadd213pd	(%r9), %xmm0, %xmm9
	vmovupd	%xmm9, (%r9)
	vmovupd	%xmm6, (%r15)
	vfnmadd213pd	(%rsi), %xmm0, %xmm8
	vmovupd	%xmm8, (%rsi)
	vfnmadd213pd	(%rdi), %xmm0, %xmm7
	movl	-88(%rsp), %esi
	vmovupd	%xmm7, (%rdi)
	vfnmadd213pd	(%rax), %xmm11, %xmm0
	vmovupd	%xmm0, (%rax)
	movl	%esi, %eax
	andl	$-2, %eax
	addl	%eax, %r13d
	cmpl	%eax, %esi
	je	.L1854
.L1849:
	movslq	%r13d, %rax
	vmulsd	-8(%r12,%rax,8), %xmm3, %xmm7
	leaq	-1(%rax), %r8
	vmovsd	(%rcx,%r8,8), %xmm1
	vmovsd	64(%rsp), %xmm12
	vmovsd	56(%rsp), %xmm15
	vsubsd	%xmm7, %xmm1, %xmm1
	vmovsd	%xmm7, (%rcx,%r8,8)
	vmovsd	%xmm12, %xmm12, %xmm7
	vfnmadd213sd	239992(%rcx,%rax,8), %xmm1, %xmm7
	leaq	29999(%rax), %r9
	vmovsd	%xmm5, %xmm5, %xmm8
	vfnmadd213sd	(%rbx,%r8,8), %xmm1, %xmm8
	vmulsd	79992(%r12,%rax,8), %xmm3, %xmm6
	vmovsd	%xmm7, (%rcx,%r9,8)
	vmovsd	%xmm15, %xmm15, %xmm7
	vfnmadd213sd	(%rdx,%r8,8), %xmm1, %xmm7
	vmovsd	%xmm8, (%rbx,%r8,8)
	vmovsd	%xmm4, %xmm4, %xmm8
	leaq	9999(%rax), %rdi
	vfnmadd213sd	(%r11,%r8,8), %xmm1, %xmm8
	vmovsd	%xmm7, (%rdx,%r8,8)
	vmovsd	48(%rsp), %xmm7
	vmovsd	(%rcx,%rdi,8), %xmm0
	vfnmadd213sd	(%rdx,%r9,8), %xmm7, %xmm1
	vsubsd	%xmm6, %xmm0, %xmm0
	vmulsd	159992(%r12,%rax,8), %xmm3, %xmm3
	leaq	19999(%rax), %rsi
	vmovsd	(%rcx,%rsi,8), %xmm2
	vmovsd	%xmm1, (%rdx,%r9,8)
	vmovsd	%xmm5, %xmm5, %xmm1
	vfnmadd213sd	(%rbx,%rdi,8), %xmm0, %xmm1
	vsubsd	%xmm3, %xmm2, %xmm2
	vmovsd	%xmm8, (%r11,%r8,8)
	leaq	39999(%rax), %r8
	vfnmadd213sd	(%rbx,%rsi,8), %xmm2, %xmm5
	vmovsd	%xmm1, (%rbx,%rdi,8)
	vmovsd	%xmm4, %xmm4, %xmm1
	vfnmadd213sd	(%r11,%rdi,8), %xmm0, %xmm1
	vmovsd	%xmm6, (%rcx,%rdi,8)
	vmovsd	%xmm1, (%r11,%rdi,8)
	vmovsd	%xmm12, %xmm12, %xmm1
	vfnmadd213sd	319992(%rcx,%rax,8), %xmm0, %xmm1
	vmovsd	%xmm1, (%rcx,%r8,8)
	vmovsd	%xmm15, %xmm15, %xmm1
	vfnmadd213sd	(%rdx,%rdi,8), %xmm0, %xmm1
	vfnmadd213sd	(%rdx,%r8,8), %xmm7, %xmm0
	vmovsd	%xmm1, (%rdx,%rdi,8)
	leaq	49999(%rax), %rdi
	vmovsd	%xmm0, (%rdx,%r8,8)
	vmovsd	%xmm5, (%rbx,%rsi,8)
	vfnmadd213sd	(%r11,%rsi,8), %xmm2, %xmm4
	vfnmadd213sd	399992(%rcx,%rax,8), %xmm2, %xmm12
	vfnmadd213sd	(%rdx,%rsi,8), %xmm2, %xmm15
	vfnmadd213sd	(%rdx,%rdi,8), %xmm7, %xmm2
	vmovsd	%xmm3, (%rcx,%rsi,8)
	vmovsd	%xmm4, (%r11,%rsi,8)
	vmovsd	%xmm12, (%rcx,%rdi,8)
	vmovsd	%xmm15, (%rdx,%rsi,8)
	vmovsd	%xmm2, (%rdx,%rdi,8)
.L1854:
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L1856:
	.cfi_restore_state
	vzeroupper
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
.L1851:
	.cfi_restore_state
	movl	%ebx, %r13d
	movl	-48(%rsp), %esi
	xorl	%eax, %eax
	leaq	der_(%rip), %rcx
	leaq	for_(%rip), %r12
	leaq	pos_(%rip), %rbx
	leaq	vel_(%rip), %r11
	leaq	der2_(%rip), %rdx
	jmp	.L1846
	.cfi_endproc
.LFE31:
	.size	corr_, .-corr_
	.section	.rodata
	.align 4
.LC125:
	.long	0
	.text
	.p2align 4
	.globl	lang_
	.type	lang_, @function
lang_:
.LFB32:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	movq	%rdx, %r12
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$40, %rsp
	.cfi_def_cfa_offset 96
	movl	8+bas_(%rip), %edx
	movl	(%rcx), %eax
	movq	%rcx, 24(%rsp)
	movl	%edx, 20(%rsp)
	cmpl	%edx, %eax
	jg	.L1865
	movq	%rdi, %rbx
	movq	%rsi, %rbp
	movslq	%eax, %r14
	leaq	-8+vel_(%rip), %r15
	leaq	.LC125(%rip), %r13
	.p2align 4,,10
	.p2align 3
.L1859:
	movq	%r13, %rdi
	call	ran2_.constprop.0
	movq	%r13, %rdi
	vmovsd	%xmm0, %xmm0, %xmm1
	call	ran2_.constprop.0
	vmovsd	%xmm0, 8(%rsp)
	vmovsd	%xmm1, %xmm1, %xmm0
	call	log@PLT
	vaddsd	%xmm0, %xmm0, %xmm0
	vmovsd	8(%rsp), %xmm3
	vxorpd	.LC11(%rip), %xmm0, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm2
	vmulsd	(%rbx), %xmm3, %xmm0
	vmovsd	%xmm2, (%rsp)
	call	cos@PLT
	vmulsd	(%rsp), %xmm0, %xmm0
	vmovsd	(%r15,%r14,8), %xmm4
	leaq	-8+for_(%rip), %rax
	vmovsd	(%rax,%r14,8), %xmm5
	vfmadd132sd	(%r12), %xmm4, %xmm0
	vmovsd	%xmm0, (%r15,%r14,8)
	vfnmadd132sd	0(%rbp), %xmm5, %xmm0
	vmovsd	%xmm0, (%rax,%r14,8)
	incq	%r14
	cmpl	%r14d, 20(%rsp)
	jge	.L1859
	movq	24(%rsp), %rax
	movl	8+bas_(%rip), %ecx
	movl	(%rax), %eax
	movl	%ecx, 20(%rsp)
	cmpl	%ecx, %eax
	jg	.L1865
	movslq	%eax, %r14
	leaq	79992+vel_(%rip), %r15
	leaq	.LC125(%rip), %r13
	.p2align 4,,10
	.p2align 3
.L1860:
	movq	%r13, %rdi
	call	ran2_.constprop.0
	movq	%r13, %rdi
	vmovsd	%xmm0, %xmm0, %xmm1
	call	ran2_.constprop.0
	vmovsd	%xmm0, 8(%rsp)
	vmovsd	%xmm1, %xmm1, %xmm0
	call	log@PLT
	vaddsd	%xmm0, %xmm0, %xmm0
	vmovsd	8(%rsp), %xmm7
	vxorpd	.LC11(%rip), %xmm0, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm6
	vmulsd	(%rbx), %xmm7, %xmm0
	vmovsd	%xmm6, (%rsp)
	call	cos@PLT
	vmulsd	(%rsp), %xmm0, %xmm0
	vmovsd	(%r15,%r14,8), %xmm3
	leaq	79992+for_(%rip), %rax
	vmovsd	(%rax,%r14,8), %xmm4
	vfmadd132sd	(%r12), %xmm3, %xmm0
	vmovsd	%xmm0, (%r15,%r14,8)
	vfnmadd132sd	0(%rbp), %xmm4, %xmm0
	vmovsd	%xmm0, (%rax,%r14,8)
	incq	%r14
	cmpl	%r14d, 20(%rsp)
	jge	.L1860
	movq	24(%rsp), %rax
	movl	8+bas_(%rip), %esi
	movl	(%rax), %eax
	movl	%esi, 20(%rsp)
	cmpl	%esi, %eax
	jg	.L1865
	movslq	%eax, %r14
	leaq	159992+vel_(%rip), %r15
	leaq	.LC125(%rip), %r13
	.p2align 4,,10
	.p2align 3
.L1862:
	movq	%r13, %rdi
	call	ran2_.constprop.0
	movq	%r13, %rdi
	vmovsd	%xmm0, %xmm0, %xmm1
	call	ran2_.constprop.0
	vmovsd	%xmm0, 8(%rsp)
	vmovsd	%xmm1, %xmm1, %xmm0
	call	log@PLT
	vaddsd	%xmm0, %xmm0, %xmm0
	vmovsd	8(%rsp), %xmm7
	vxorpd	.LC11(%rip), %xmm0, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm5
	vmulsd	(%rbx), %xmm7, %xmm0
	vmovsd	%xmm5, (%rsp)
	call	cos@PLT
	vmulsd	(%rsp), %xmm0, %xmm0
	vmovsd	(%r15,%r14,8), %xmm2
	leaq	159992+for_(%rip), %rax
	vmovsd	(%rax,%r14,8), %xmm3
	vfmadd132sd	(%r12), %xmm2, %xmm0
	vmovsd	%xmm0, (%r15,%r14,8)
	vfnmadd132sd	0(%rbp), %xmm3, %xmm0
	vmovsd	%xmm0, (%rax,%r14,8)
	incq	%r14
	cmpl	%r14d, 20(%rsp)
	jge	.L1862
.L1865:
	addq	$40, %rsp
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.cfi_endproc
.LFE32:
	.size	lang_, .-lang_
	.p2align 4
	.globl	lang_mass_
	.type	lang_mass_, @function
lang_mass_:
.LFB33:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$56, %rsp
	.cfi_def_cfa_offset 112
	movl	8+bas_(%rip), %eax
	movl	(%rcx), %ecx
	movq	%rsi, 40(%rsp)
	movl	%eax, 36(%rsp)
	cmpl	%eax, %ecx
	jg	.L1871
	movslq	%ecx, %r12
	leaq	0(,%r12,8), %rax
	movq	%rdx, %r13
	leaq	for_(%rip), %rsi
	leaq	vel_(%rip), %rdx
	movq	%rdi, %rbp
	leaq	(%rax,%rdx), %r15
	leaq	(%rax,%rsi), %r14
	leaq	.LC125(%rip), %rbx
	.p2align 4,,10
	.p2align 3
.L1869:
	vmovsd	0(%r13), %xmm0
	leaq	79992+mass_(%rip), %rax
	vdivsd	(%rax,%r12,8), %xmm0, %xmm2
	movq	40(%rsp), %rax
	movq	%rbx, %rdi
	vmovsd	(%rax), %xmm0
	leaq	-8+mass_(%rip), %rax
	vdivsd	(%rax,%r12,8), %xmm0, %xmm3
	vmovsd	%xmm2, (%rsp)
	vmovsd	%xmm3, 8(%rsp)
	call	ran2_.constprop.0
	movq	%rbx, %rdi
	vmovsd	%xmm0, %xmm0, %xmm1
	call	ran2_.constprop.0
	vmovsd	%xmm0, 24(%rsp)
	vmovsd	%xmm1, %xmm1, %xmm0
	call	log@PLT
	vaddsd	%xmm0, %xmm0, %xmm0
	vmovsd	24(%rsp), %xmm5
	incq	%r12
	vxorpd	.LC11(%rip), %xmm0, %xmm0
	addq	$8, %r15
	vsqrtsd	%xmm0, %xmm0, %xmm4
	vmulsd	0(%rbp), %xmm5, %xmm0
	addq	$8, %r14
	vmovsd	%xmm4, 16(%rsp)
	call	cos@PLT
	vmulsd	16(%rsp), %xmm0, %xmm0
	vmovsd	(%rsp), %xmm2
	vmovsd	8(%rsp), %xmm3
	movq	%rbx, %rdi
	vfmadd213sd	-16(%r15), %xmm2, %xmm0
	vmovsd	%xmm0, -16(%r15)
	vfnmadd213sd	-16(%r14), %xmm3, %xmm0
	vmovsd	%xmm0, -16(%r14)
	call	ran2_.constprop.0
	movq	%rbx, %rdi
	vmovsd	%xmm0, %xmm0, %xmm1
	call	ran2_.constprop.0
	vmovsd	%xmm0, 24(%rsp)
	vmovsd	%xmm1, %xmm1, %xmm0
	call	log@PLT
	vaddsd	%xmm0, %xmm0, %xmm0
	vmovsd	24(%rsp), %xmm7
	vxorpd	.LC11(%rip), %xmm0, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm6
	vmulsd	0(%rbp), %xmm7, %xmm0
	vmovsd	%xmm6, 16(%rsp)
	call	cos@PLT
	vmulsd	16(%rsp), %xmm0, %xmm0
	vmovsd	(%rsp), %xmm2
	vmovsd	8(%rsp), %xmm3
	movq	%rbx, %rdi
	vfmadd213sd	79984(%r15), %xmm2, %xmm0
	vmovsd	%xmm0, 79984(%r15)
	vfnmadd213sd	79984(%r14), %xmm3, %xmm0
	vmovsd	%xmm0, 79984(%r14)
	call	ran2_.constprop.0
	movq	%rbx, %rdi
	vmovsd	%xmm0, %xmm0, %xmm1
	call	ran2_.constprop.0
	vmovsd	%xmm0, 24(%rsp)
	vmovsd	%xmm1, %xmm1, %xmm0
	call	log@PLT
	vaddsd	%xmm0, %xmm0, %xmm0
	vmovsd	24(%rsp), %xmm7
	vxorpd	.LC11(%rip), %xmm0, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm5
	vmulsd	0(%rbp), %xmm7, %xmm0
	vmovsd	%xmm5, 16(%rsp)
	call	cos@PLT
	vmulsd	16(%rsp), %xmm0, %xmm0
	vmovsd	(%rsp), %xmm2
	vmovsd	8(%rsp), %xmm3
	vfmadd213sd	159984(%r15), %xmm2, %xmm0
	vmovsd	%xmm0, 159984(%r15)
	vfnmadd213sd	159984(%r14), %xmm3, %xmm0
	vmovsd	%xmm0, 159984(%r14)
	cmpl	%r12d, 36(%rsp)
	jge	.L1869
.L1871:
	addq	$56, %rsp
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.cfi_endproc
.LFE33:
	.size	lang_mass_, .-lang_mass_
	.p2align 4
	.globl	ran2_
	.type	ran2_, @function
ran2_:
.LFB34:
	.cfi_startproc
	movl	(%rdi), %ecx
	movl	%ecx, %eax
	negl	%eax
	testl	%ecx, %ecx
	cmove	rans_(%rip), %eax
	movl	%eax, %edx
	testl	%eax, %eax
	jle	.L1876
	movl	idum2.27(%rip), %r8d
	movl	iy.25(%rip), %esi
.L1877:
	movslq	%edx, %rcx
	imulq	$327796565, %rcx, %rcx
	movl	%edx, %eax
	sarl	$31, %eax
	sarq	$44, %rcx
	subl	%eax, %ecx
	imull	$-53668, %ecx, %eax
	imull	$-12211, %ecx, %ecx
	addl	%edx, %eax
	imull	$40014, %eax, %eax
	addl	%eax, %ecx
	jns	.L1887
	addl	$2147483563, %ecx
.L1887:
	movslq	%r8d, %rax
	imulq	$1333397965, %rax, %rax
	movl	%r8d, %edx
	sarl	$31, %edx
	sarq	$46, %rax
	subl	%edx, %eax
	imull	$-52774, %eax, %edx
	imull	$-3791, %eax, %eax
	movl	%ecx, rans_(%rip)
	addl	%r8d, %edx
	imull	$40692, %edx, %edx
	addl	%eax, %edx
	jns	.L1888
	addl	$2147483399, %edx
.L1888:
	movslq	%esi, %rax
	imulq	$-2147483583, %rax, %rax
	leaq	iv.26(%rip), %rdi
	movl	%edx, idum2.27(%rip)
	shrq	$32, %rax
	addl	%esi, %eax
	sarl	$25, %eax
	sarl	$31, %esi
	subl	%esi, %eax
	cltq
	movl	(%rdi,%rax,4), %esi
	movl	%ecx, (%rdi,%rax,4)
	subl	%edx, %esi
	movl	%esi, iy.25(%rip)
	testl	%esi, %esi
	jg	.L1885
	addl	$2147483562, %esi
	movl	%esi, iy.25(%rip)
.L1885:
	vxorps	%xmm0, %xmm0, %xmm0
	vcvtsi2sdl	%esi, %xmm0, %xmm0
	vmulsd	.LC0(%rip), %xmm0, %xmm0
	vminsd	.LC1(%rip), %xmm0, %xmm0
	ret
	.p2align 4,,10
	.p2align 3
.L1876:
	negl	%edx
	movl	$1, %eax
	movl	%edx, %r8d
	cmpl	%eax, %edx
	cmovl	%eax, %r8d
	movl	$40, %esi
	movl	%r8d, %edx
	leaq	-4+iv.26(%rip), %rdi
	.p2align 4,,10
	.p2align 3
.L1880:
	movslq	%edx, %rax
	imulq	$327796565, %rax, %rax
	movl	%edx, %ecx
	sarl	$31, %ecx
	sarq	$44, %rax
	subl	%ecx, %eax
	imull	$-53668, %eax, %ecx
	imull	$-12211, %eax, %eax
	addl	%ecx, %edx
	imull	$40014, %edx, %edx
	addl	%eax, %edx
	leal	2147483563(%rdx), %eax
	cmovs	%eax, %edx
	cmpq	$32, %rsi
	ja	.L1879
	movl	%edx, (%rdi,%rsi,4)
.L1879:
	decq	%rsi
	jne	.L1880
	movl	iv.26(%rip), %esi
	jmp	.L1877
	.cfi_endproc
.LFE34:
	.size	ran2_, .-ran2_
	.p2align 4
	.globl	intvel3d_
	.type	intvel3d_, @function
intvel3d_:
.LFB35:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$32, %rsp
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	movl	(%rdx), %r12d
	movl	8+bas_(%rip), %r10d
	movq	%rdi, 24(%rsp)
	movq	%rsi, 16(%rsp)
	cmpl	%r10d, %r12d
	jg	.L1910
	movslq	%r12d, %r13
	salq	$3, %r13
	vxorpd	%xmm8, %xmm8, %xmm8
	leaq	vel_(%rip), %r15
	leaq	der_(%rip), %r14
	leaq	der2_(%rip), %rcx
	vmovsd	.LC72(%rip), %xmm6
	vmovsd	.LC8(%rip), %xmm7
	leaq	(%r15,%r13), %rbx
	addq	%r13, %r14
	movq	%rdx, %r11
	addq	%rcx, %r13
	vmovsd	%xmm8, %xmm8, %xmm4
	vmovsd	%xmm8, %xmm8, %xmm9
	leaq	.LC125(%rip), %r9
	.p2align 4,,10
	.p2align 3
.L1891:
	movq	%r9, %rdi
	call	ran2_.constprop.0
	movq	%r9, %rdi
	vsubsd	%xmm6, %xmm0, %xmm2
	call	ran2_.constprop.0
	vsubsd	%xmm6, %xmm0, %xmm1
	vaddsd	%xmm2, %xmm2, %xmm2
	movq	%r9, %rdi
	vaddsd	%xmm1, %xmm1, %xmm1
	call	ran2_.constprop.0
	vsubsd	%xmm6, %xmm0, %xmm0
	vmulsd	%xmm1, %xmm1, %xmm3
	incl	%r12d
	vaddsd	%xmm0, %xmm0, %xmm0
	movq	$0x000000000, -8(%r14)
	movq	$0x000000000, 79992(%r14)
	vfmadd231sd	%xmm2, %xmm2, %xmm3
	movq	$0x000000000, 159992(%r14)
	movq	$0x000000000, 239992(%r14)
	movq	$0x000000000, 319992(%r14)
	movq	$0x000000000, 399992(%r14)
	vfmadd231sd	%xmm0, %xmm0, %xmm3
	movq	$0x000000000, -8(%r13)
	movq	$0x000000000, 79992(%r13)
	movq	$0x000000000, 159992(%r13)
	movq	$0x000000000, 239992(%r13)
	vsqrtsd	%xmm3, %xmm3, %xmm3
	movq	$0x000000000, 319992(%r13)
	movq	$0x000000000, 399992(%r13)
	vdivsd	%xmm3, %xmm7, %xmm3
	addq	$8, %rbx
	addq	$8, %r14
	addq	$8, %r13
	vmulsd	%xmm3, %xmm2, %xmm2
	vmulsd	%xmm3, %xmm1, %xmm1
	vmulsd	%xmm3, %xmm0, %xmm0
	vmovsd	%xmm2, -16(%rbx)
	vmovsd	%xmm1, 79984(%rbx)
	vmovsd	%xmm0, 159984(%rbx)
	vaddsd	%xmm2, %xmm9, %xmm9
	vaddsd	%xmm1, %xmm4, %xmm4
	vaddsd	%xmm0, %xmm8, %xmm8
	cmpl	%r12d, %r10d
	jge	.L1891
	movslq	(%r11), %rdx
	movl	8+bas_(%rip), %esi
	cmpl	%esi, %edx
	jg	.L1910
	movq	16(%rsp), %rax
	leal	1(%rsi), %ecx
	subl	%edx, %esi
	vdivsd	(%rax), %xmm7, %xmm7
	subl	%edx, %ecx
	vmulsd	%xmm9, %xmm7, %xmm9
	vmulsd	%xmm4, %xmm7, %xmm6
	vmulsd	%xmm8, %xmm7, %xmm7
	cmpl	$2, %esi
	jbe	.L1905
	movslq	%edx, %rdi
	movl	%ecx, %r11d
	leaq	0(,%rdi,8), %rax
	shrl	$2, %r11d
	leaq	-8(%r15,%rax), %r10
	leaq	79992(%r15,%rax), %r9
	leaq	159992(%r15,%rax), %r8
	vbroadcastsd	%xmm9, %ymm8
	vbroadcastsd	%xmm6, %ymm5
	vbroadcastsd	%xmm7, %ymm4
	salq	$5, %r11
	xorl	%eax, %eax
	vxorpd	%xmm1, %xmm1, %xmm1
	.p2align 4,,10
	.p2align 3
.L1893:
	vmovupd	(%r10,%rax), %ymm2
	vsubpd	%ymm8, %ymm2, %ymm2
	vmovupd	%ymm2, (%r10,%rax)
	vmovupd	(%r9,%rax), %ymm3
	vsubpd	%ymm5, %ymm3, %ymm3
	vmovupd	%ymm3, (%r9,%rax)
	vmovupd	(%r8,%rax), %ymm0
	vmulpd	%ymm3, %ymm3, %ymm3
	vsubpd	%ymm4, %ymm0, %ymm0
	vmovupd	%ymm0, (%r8,%rax)
	vfmadd132pd	%ymm2, %ymm3, %ymm2
	vfmadd132pd	%ymm0, %ymm1, %ymm0
	addq	$32, %rax
	vaddpd	%ymm0, %ymm2, %ymm1
	cmpq	%rax, %r11
	jne	.L1893
	vextractf128	$0x1, %ymm1, %xmm8
	vaddpd	%xmm1, %xmm8, %xmm1
	movl	%ecx, %r8d
	andl	$-4, %r8d
	vunpckhpd	%xmm1, %xmm1, %xmm8
	vaddpd	%xmm1, %xmm8, %xmm8
	leal	(%r8,%rdx), %eax
	vmovsd	%xmm8, %xmm8, %xmm1
	cmpl	%r8d, %ecx
	je	.L1912
.L1892:
	movl	%ecx, %r9d
	subl	%r8d, %r9d
	cmpl	%r8d, %esi
	je	.L1895
	movslq	%edx, %rdi
	leaq	(%rdi,%r8), %r10
	leaq	-8(%r15,%r10,8), %r11
	vmovupd	(%r11), %xmm5
	vmovddup	%xmm9, %xmm2
	vsubpd	%xmm2, %xmm5, %xmm2
	leaq	9999(%r8,%rdi), %r10
	leaq	(%r15,%r10,8), %r10
	vmovupd	%xmm2, (%r11)
	vmovupd	(%r10), %xmm5
	vmovddup	%xmm6, %xmm3
	vsubpd	%xmm3, %xmm5, %xmm3
	leaq	19999(%r8,%rdi), %rdi
	leaq	(%r15,%rdi,8), %rdi
	vmovupd	%xmm3, (%r10)
	vmulpd	%xmm3, %xmm3, %xmm3
	vmovupd	(%rdi), %xmm5
	vmovddup	%xmm7, %xmm0
	vsubpd	%xmm0, %xmm5, %xmm0
	vfmadd132pd	%xmm2, %xmm3, %xmm2
	vmovupd	%xmm0, (%rdi)
	movl	%r9d, %edi
	andl	$-2, %edi
	addl	%edi, %eax
	vfmadd132pd	%xmm0, %xmm2, %xmm0
	vunpckhpd	%xmm0, %xmm0, %xmm2
	vaddpd	%xmm0, %xmm2, %xmm0
	vaddsd	%xmm0, %xmm1, %xmm1
	cmpl	%edi, %r9d
	je	.L1896
.L1895:
	cltq
	leaq	-1(%rax), %rdi
	vmovsd	(%r15,%rdi,8), %xmm5
	vsubsd	%xmm9, %xmm5, %xmm5
	vmovsd	%xmm5, (%r15,%rdi,8)
	leaq	9999(%rax), %rdi
	vmovsd	(%r15,%rdi,8), %xmm4
	addq	$19999, %rax
	vsubsd	%xmm6, %xmm4, %xmm4
	vmovsd	(%r15,%rax,8), %xmm8
	vmovsd	%xmm4, (%r15,%rdi,8)
	vmulsd	%xmm4, %xmm4, %xmm4
	vsubsd	%xmm7, %xmm8, %xmm8
	vmovsd	%xmm8, (%r15,%rax,8)
	vfmadd132sd	%xmm5, %xmm4, %xmm5
	vfmadd132sd	%xmm8, %xmm1, %xmm8
	vaddsd	%xmm8, %xmm5, %xmm1
.L1896:
	movq	24(%rsp), %rax
	vmovsd	(%rax), %xmm8
	vdivsd	%xmm1, %xmm8, %xmm8
	vsqrtsd	%xmm8, %xmm8, %xmm8
	cmpl	$2, %esi
	jbe	.L1906
	movslq	%edx, %rdi
.L1904:
	movl	%ecx, %r10d
	salq	$3, %rdi
	shrl	$2, %r10d
	leaq	-8(%r15,%rdi), %r9
	leaq	79992(%r15,%rdi), %r8
	vbroadcastsd	%xmm8, %ymm0
	leaq	159992(%r15,%rdi), %rdi
	salq	$5, %r10
	xorl	%eax, %eax
	.p2align 4,,10
	.p2align 3
.L1901:
	vmulpd	(%r9,%rax), %ymm0, %ymm1
	vmovupd	%ymm1, (%r9,%rax)
	vmulpd	(%r8,%rax), %ymm0, %ymm1
	vmovupd	%ymm1, (%r8,%rax)
	vmulpd	(%rdi,%rax), %ymm0, %ymm1
	vmovupd	%ymm1, (%rdi,%rax)
	addq	$32, %rax
	cmpq	%rax, %r10
	jne	.L1901
	movl	%ecx, %edi
	andl	$-4, %edi
	leal	(%rdi,%rdx), %eax
	cmpl	%ecx, %edi
	je	.L1909
.L1903:
	subl	%edi, %ecx
	cmpl	%esi, %edi
	je	.L1898
	leaq	(%rdx,%rdi), %rsi
	leaq	-8(%r15,%rsi,8), %r8
	vmovddup	%xmm8, %xmm0
	vmulpd	(%r8), %xmm0, %xmm1
	leaq	9999(%rdx,%rdi), %rsi
	leaq	(%r15,%rsi,8), %rsi
	leaq	19999(%rdx,%rdi), %rdx
	leaq	(%r15,%rdx,8), %rdx
	vmovupd	%xmm1, (%r8)
	vmulpd	(%rsi), %xmm0, %xmm1
	vmovupd	%xmm1, (%rsi)
	vmulpd	(%rdx), %xmm0, %xmm0
	vmovupd	%xmm0, (%rdx)
	movl	%ecx, %edx
	andl	$-2, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L1909
.L1898:
	cltq
	vmulsd	-8(%r15,%rax,8), %xmm8, %xmm0
	vmovsd	%xmm0, -8(%r15,%rax,8)
	vmulsd	79992(%r15,%rax,8), %xmm8, %xmm0
	vmulsd	159992(%r15,%rax,8), %xmm8, %xmm8
	vmovsd	%xmm0, 79992(%r15,%rax,8)
	vmovsd	%xmm8, 159992(%r15,%rax,8)
	vzeroupper
.L1910:
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L1909:
	.cfi_restore_state
	vzeroupper
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L1912:
	.cfi_restore_state
	movq	24(%rsp), %rax
	vmovsd	(%rax), %xmm8
	vdivsd	%xmm1, %xmm8, %xmm8
	vsqrtsd	%xmm8, %xmm8, %xmm8
	jmp	.L1904
.L1905:
	movl	%edx, %eax
	xorl	%r8d, %r8d
	vxorpd	%xmm1, %xmm1, %xmm1
	jmp	.L1892
.L1906:
	movl	%edx, %eax
	xorl	%edi, %edi
	jmp	.L1903
	.cfi_endproc
.LFE35:
	.size	intvel3d_, .-intvel3d_
	.section	.rodata.str1.8
	.align 8
.LC126:
	.string	"INCORRECT NUMBERS OF CHAINS TO DISPLACE"
	.align 8
.LC127:
	.string	"#initial centers of mass and gyrations"
	.align 8
.LC128:
	.string	"#A      xcen    ycen    zcen         xg    yg    zg"
	.section	.rodata.str1.1
.LC129:
	.string	"(a,6x,3(f6.2,2x),4x,3(f6.2))"
.LC130:
	.string	"#"
	.section	.rodata.str1.8
	.align 8
.LC131:
	.string	"#B      xcen    ycen    zcen         xg    yg    zg"
	.section	.rodata.str1.1
.LC132:
	.string	"CM separation between A and B "
.LC133:
	.string	"shifted CM of B "
	.text
	.p2align 4
	.globl	displace_
	.type	displace_, @function
displace_:
.LFB36:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	vxorpd	%xmm0, %xmm0, %xmm0
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$800, %rsp
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	movq	%rdx, 16(%rsp)
	movq	%rsi, 40(%rsp)
	movslq	(%rdi), %rdx
	movl	160000+bon_(%rip), %ecx
	movq	%fs:40, %rax
	movq	%rax, 792(%rsp)
	xorl	%eax, %eax
	movq	$0x000000000, 208(%rsp)
	movq	$0x000000000, 240(%rsp)
	movq	$0x000000000, 144(%rsp)
	movq	$0x000000000, 176(%rsp)
	vmovapd	%xmm0, 192(%rsp)
	vmovapd	%xmm0, 224(%rsp)
	vmovapd	%xmm0, 128(%rsp)
	vmovapd	%xmm0, 160(%rsp)
	cmpl	%ecx, %edx
	jg	.L1914
	movslq	(%rsi), %rax
	cmpl	%eax, %ecx
	jl	.L1914
	leal	1(%rdx), %ecx
	leaq	bon_(%rip), %rsi
	movslq	%ecx, %rcx
	movl	119996(%rsi,%rcx,4), %r12d
	movslq	119996(%rsi,%rdx,4), %rdx
	movl	%r12d, %r11d
	vxorps	%xmm9, %xmm9, %xmm9
	leal	1(%rax), %ecx
	subl	%edx, %r11d
	movslq	%ecx, %rcx
	vcvtsi2sdl	%r11d, %xmm9, %xmm0
	movl	119996(%rsi,%rcx,4), %ebx
	vmovsd	.LC8(%rip), %xmm6
	movslq	119996(%rsi,%rax,4), %rcx
	movl	%ebx, %r13d
	leal	1(%rdx), %edi
	vdivsd	%xmm0, %xmm6, %xmm4
	subl	%ecx, %r13d
	cmpl	%edi, %r12d
	jl	.L1941
	leal	-1(%r11), %eax
	cmpl	$2, %eax
	jbe	.L1942
	movl	%r11d, %esi
	vxorpd	%xmm3, %xmm3, %xmm3
	salq	$3, %rdx
	leaq	pos_(%rip), %rax
	shrl	$2, %esi
	leaq	(%rax,%rdx), %r10
	leaq	80000(%rax,%rdx), %r9
	leaq	160000(%rax,%rdx), %r8
	salq	$5, %rsi
	xorl	%edx, %edx
	vmovapd	%ymm3, %ymm10
	vmovapd	%ymm3, %ymm8
	vmovapd	%ymm3, %ymm7
	vmovapd	%ymm3, %ymm6
	vmovapd	%ymm3, %ymm5
	.p2align 4,,10
	.p2align 3
.L1918:
	vmovupd	(%r10,%rdx), %ymm2
	vmovupd	(%r9,%rdx), %ymm1
	vmovupd	(%r8,%rdx), %ymm0
	addq	$32, %rdx
	vfmadd231pd	%ymm2, %ymm2, %ymm8
	vfmadd231pd	%ymm1, %ymm1, %ymm10
	vfmadd231pd	%ymm0, %ymm0, %ymm3
	vaddpd	%ymm2, %ymm5, %ymm5
	vaddpd	%ymm1, %ymm6, %ymm6
	vaddpd	%ymm0, %ymm7, %ymm7
	cmpq	%rsi, %rdx
	jne	.L1918
	vextractf128	$0x1, %ymm3, %xmm2
	vaddpd	%xmm3, %xmm2, %xmm3
	vextractf128	$0x1, %ymm6, %xmm2
	vaddpd	%xmm6, %xmm2, %xmm6
	vunpckhpd	%xmm3, %xmm3, %xmm0
	vaddpd	%xmm3, %xmm0, %xmm3
	vextractf128	$0x1, %ymm10, %xmm0
	vaddpd	%xmm10, %xmm0, %xmm0
	vunpckhpd	%xmm6, %xmm6, %xmm2
	vaddpd	%xmm6, %xmm2, %xmm6
	vunpckhpd	%xmm0, %xmm0, %xmm1
	vaddpd	%xmm0, %xmm1, %xmm1
	vextractf128	$0x1, %ymm8, %xmm0
	vaddpd	%xmm8, %xmm0, %xmm8
	movl	%r11d, %edx
	andl	$-4, %edx
	vunpckhpd	%xmm8, %xmm8, %xmm0
	vaddpd	%xmm8, %xmm0, %xmm8
	vextractf128	$0x1, %ymm7, %xmm0
	vaddpd	%xmm7, %xmm0, %xmm7
	vmovsd	%xmm6, %xmm6, %xmm2
	addl	%edx, %edi
	vunpckhpd	%xmm7, %xmm7, %xmm0
	vaddpd	%xmm7, %xmm0, %xmm7
	vextractf128	$0x1, %ymm5, %xmm0
	vaddpd	%xmm5, %xmm0, %xmm5
	vunpckhpd	%xmm5, %xmm5, %xmm0
	vaddpd	%xmm5, %xmm0, %xmm5
	vmovsd	%xmm5, %xmm5, %xmm0
	cmpl	%edx, %r11d
	je	.L1919
.L1917:
	movslq	%edi, %rdx
	vmovsd	-8(%rax,%rdx,8), %xmm10
	vmovsd	79992(%rax,%rdx,8), %xmm6
	vmovsd	159992(%rax,%rdx,8), %xmm5
	leal	1(%rdi), %esi
	vfmadd231sd	%xmm10, %xmm10, %xmm8
	vfmadd231sd	%xmm6, %xmm6, %xmm1
	vfmadd231sd	%xmm5, %xmm5, %xmm3
	vaddsd	%xmm10, %xmm0, %xmm0
	vaddsd	%xmm6, %xmm2, %xmm2
	vaddsd	%xmm5, %xmm7, %xmm7
	cmpl	%esi, %r12d
	jl	.L1919
	vmovsd	(%rax,%rdx,8), %xmm10
	vmovsd	80000(%rax,%rdx,8), %xmm6
	vmovsd	160000(%rax,%rdx,8), %xmm5
	addl	$2, %edi
	vfmadd231sd	%xmm10, %xmm10, %xmm8
	vfmadd231sd	%xmm6, %xmm6, %xmm1
	vfmadd231sd	%xmm5, %xmm5, %xmm3
	vaddsd	%xmm10, %xmm0, %xmm0
	vaddsd	%xmm6, %xmm2, %xmm2
	vaddsd	%xmm5, %xmm7, %xmm7
	movslq	%esi, %rsi
	cmpl	%edi, %r12d
	jl	.L1919
	vmovsd	(%rax,%rsi,8), %xmm10
	vmovsd	80000(%rax,%rsi,8), %xmm6
	vmovsd	160000(%rax,%rsi,8), %xmm5
	vfmadd231sd	%xmm10, %xmm10, %xmm8
	vfmadd231sd	%xmm6, %xmm6, %xmm1
	vfmadd231sd	%xmm5, %xmm5, %xmm3
	vaddsd	%xmm10, %xmm0, %xmm0
	vaddsd	%xmm6, %xmm2, %xmm2
	vaddsd	%xmm5, %xmm7, %xmm7
.L1919:
	vunpcklpd	%xmm2, %xmm0, %xmm2
	vmulsd	%xmm0, %xmm4, %xmm0
	vunpcklpd	%xmm1, %xmm8, %xmm1
	vmovapd	%xmm2, 192(%rsp)
	vmovsd	%xmm7, 208(%rsp)
	vmovapd	%xmm1, 128(%rsp)
	vmulsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm3, 144(%rsp)
	vfmsub132sd	%xmm4, %xmm0, %xmm8
	vsqrtsd	%xmm8, %xmm8, %xmm8
.L1916:
	vcvtsi2sdl	%r13d, %xmm9, %xmm9
	vmovsd	.LC8(%rip), %xmm3
	leal	1(%rcx), %esi
	vdivsd	%xmm9, %xmm3, %xmm6
	vmovsd	%xmm6, 96(%rsp)
	cmpl	%esi, %ebx
	jl	.L1943
	movl	%ebx, %edi
	subl	%ecx, %edi
	leal	-1(%rdi), %eax
	cmpl	$2, %eax
	jbe	.L1944
	salq	$3, %rcx
	leaq	pos_(%rip), %rax
	leaq	(%rax,%rcx), %r9
	leaq	80000(%rax,%rcx), %r8
	leaq	160000(%rax,%rcx), %r10
	movl	%edi, %ecx
	vxorpd	%xmm3, %xmm3, %xmm3
	shrl	$2, %ecx
	salq	$5, %rcx
	xorl	%edx, %edx
	vmovapd	%ymm3, %ymm11
	vmovapd	%ymm3, %ymm10
	vmovapd	%ymm3, %ymm9
	vmovapd	%ymm3, %ymm6
	vmovapd	%ymm3, %ymm5
	.p2align 4,,10
	.p2align 3
.L1922:
	vmovupd	(%r9,%rdx), %ymm2
	vmovupd	(%r8,%rdx), %ymm1
	vmovupd	(%r10,%rdx), %ymm0
	addq	$32, %rdx
	vfmadd231pd	%ymm2, %ymm2, %ymm10
	vfmadd231pd	%ymm1, %ymm1, %ymm11
	vfmadd231pd	%ymm0, %ymm0, %ymm3
	vaddpd	%ymm2, %ymm5, %ymm5
	vaddpd	%ymm1, %ymm6, %ymm6
	vaddpd	%ymm0, %ymm9, %ymm9
	cmpq	%rcx, %rdx
	jne	.L1922
	vextractf128	$0x1, %ymm3, %xmm7
	vaddpd	%xmm3, %xmm7, %xmm3
	vextractf128	$0x1, %ymm11, %xmm1
	vaddpd	%xmm11, %xmm1, %xmm1
	vunpckhpd	%xmm3, %xmm3, %xmm0
	vaddpd	%xmm3, %xmm0, %xmm3
	vunpckhpd	%xmm1, %xmm1, %xmm0
	vaddpd	%xmm1, %xmm0, %xmm1
	vextractf128	$0x1, %ymm10, %xmm0
	vaddpd	%xmm10, %xmm0, %xmm0
	movl	%edi, %edx
	andl	$-4, %edx
	vunpckhpd	%xmm0, %xmm0, %xmm2
	vaddpd	%xmm0, %xmm2, %xmm0
	vextractf128	$0x1, %ymm9, %xmm2
	vaddpd	%xmm9, %xmm2, %xmm2
	vmovsd	%xmm0, %xmm0, %xmm10
	addl	%edx, %esi
	vunpckhpd	%xmm2, %xmm2, %xmm7
	vaddpd	%xmm2, %xmm7, %xmm2
	vmovsd	%xmm2, %xmm2, %xmm9
	vextractf128	$0x1, %ymm6, %xmm2
	vaddpd	%xmm6, %xmm2, %xmm6
	vunpckhpd	%xmm6, %xmm6, %xmm7
	vaddpd	%xmm6, %xmm7, %xmm6
	vextractf128	$0x1, %ymm5, %xmm7
	vaddpd	%xmm5, %xmm7, %xmm5
	vunpckhpd	%xmm5, %xmm5, %xmm7
	vaddpd	%xmm5, %xmm7, %xmm5
	vmovsd	%xmm5, %xmm5, %xmm0
	cmpl	%edx, %edi
	je	.L1923
.L1921:
	movslq	%esi, %rcx
	vmovsd	-8(%rax,%rcx,8), %xmm7
	vmovsd	79992(%rax,%rcx,8), %xmm5
	vmovsd	159992(%rax,%rcx,8), %xmm2
	leal	1(%rsi), %edx
	vfmadd231sd	%xmm7, %xmm7, %xmm10
	vfmadd231sd	%xmm5, %xmm5, %xmm1
	vfmadd231sd	%xmm2, %xmm2, %xmm3
	vaddsd	%xmm7, %xmm0, %xmm0
	vaddsd	%xmm5, %xmm6, %xmm6
	vaddsd	%xmm2, %xmm9, %xmm9
	cmpl	%edx, %ebx
	jl	.L1923
	vmovsd	(%rax,%rcx,8), %xmm7
	vmovsd	80000(%rax,%rcx,8), %xmm5
	vmovsd	160000(%rax,%rcx,8), %xmm2
	addl	$2, %esi
	vfmadd231sd	%xmm7, %xmm7, %xmm10
	vfmadd231sd	%xmm5, %xmm5, %xmm1
	vfmadd231sd	%xmm2, %xmm2, %xmm3
	vaddsd	%xmm7, %xmm0, %xmm0
	vaddsd	%xmm5, %xmm6, %xmm6
	vaddsd	%xmm2, %xmm9, %xmm9
	movslq	%edx, %rdx
	cmpl	%esi, %ebx
	jl	.L1923
	vmovsd	(%rax,%rdx,8), %xmm7
	vmovsd	80000(%rax,%rdx,8), %xmm5
	vmovsd	160000(%rax,%rdx,8), %xmm2
	vfmadd231sd	%xmm7, %xmm7, %xmm10
	vfmadd231sd	%xmm5, %xmm5, %xmm1
	vfmadd231sd	%xmm2, %xmm2, %xmm3
	vaddsd	%xmm7, %xmm0, %xmm0
	vaddsd	%xmm5, %xmm6, %xmm6
	vaddsd	%xmm2, %xmm9, %xmm9
.L1923:
	vmovsd	96(%rsp), %xmm7
	vunpcklpd	%xmm6, %xmm0, %xmm2
	vmulsd	%xmm7, %xmm0, %xmm0
	vunpcklpd	%xmm1, %xmm10, %xmm1
	vmovapd	%xmm2, 224(%rsp)
	vmovsd	%xmm9, 240(%rsp)
	vmovapd	%xmm1, 160(%rsp)
	vmulsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm3, 176(%rsp)
	vmovsd	%xmm7, %xmm7, %xmm5
	vfmsub231sd	%xmm7, %xmm10, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
.L1920:
	vmovsd	%xmm0, 160(%rsp)
	vmovddup	%xmm4, %xmm0
	vmulpd	200(%rsp), %xmm0, %xmm6
	vmovddup	%xmm5, %xmm1
	vmulsd	192(%rsp), %xmm4, %xmm7
	vmulpd	232(%rsp), %xmm1, %xmm4
	vmulsd	224(%rsp), %xmm5, %xmm3
	vmulpd	%xmm6, %xmm6, %xmm2
	leaq	256(%rsp), %r12
	leaq	.LC2(%rip), %r14
	movabsq	$4294967424, %rbx
	movq	%r12, %rdi
	vfmsub132pd	136(%rsp), %xmm2, %xmm0
	vmulpd	%xmm4, %xmm4, %xmm2
	movq	%r14, 264(%rsp)
	movl	$4102, 272(%rsp)
	movq	%rbx, 256(%rsp)
	vsqrtpd	%xmm0, %xmm0
	vfmsub132pd	168(%rsp), %xmm2, %xmm1
	vmovsd	%xmm7, 24(%rsp)
	vmovsd	%xmm7, 192(%rsp)
	vmovsd	%xmm8, 128(%rsp)
	vmovsd	%xmm3, 32(%rsp)
	vsqrtpd	%xmm1, %xmm1
	vmovsd	%xmm3, 224(%rsp)
	vmovapd	%xmm6, 64(%rsp)
	vmovapd	%xmm4, 48(%rsp)
	vmovupd	%xmm6, 200(%rsp)
	vmovupd	%xmm0, 136(%rsp)
	vmovupd	%xmm4, 232(%rsp)
	vmovupd	%xmm1, 168(%rsp)
	vzeroupper
	call	_gfortran_st_write@PLT
	movl	$38, %edx
	leaq	.LC127(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movq	%r12, %rdi
	movq	%r14, 264(%rsp)
	movl	$4103, 272(%rsp)
	movq	%rbx, 256(%rsp)
	call	_gfortran_st_write@PLT
	movl	$51, %edx
	leaq	.LC128(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC129(%rip), %rax
	movq	%rax, 336(%rsp)
	movq	%r12, %rdi
	movabsq	$4294971392, %rax
	movq	%r14, 264(%rsp)
	movl	$4104, 272(%rsp)
	movq	$28, 344(%rsp)
	movq	%rax, 256(%rsp)
	call	_gfortran_st_write@PLT
	movl	$1, %edx
	leaq	.LC130(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	testb	$1, 256(%rsp)
	jne	.L1954
	movl	$2, %r15d
	leaq	192(%rsp), %r14
	leaq	bas_(%rip), %rbx
	leaq	120(%rsp), %r13
.L1924:
	vmovsd	-16(%r14,%r15,8), %xmm0
	movl	$8, %edx
	vmulsd	(%rbx), %xmm0, %xmm0
	movq	%r13, %rsi
	movq	%r12, %rdi
	vmovsd	%xmm0, 120(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movl	256(%rsp), %eax
	andl	$1, %eax
	cmpl	$4, %r15d
	sete	%dl
	incq	%r15
	orb	%al, %dl
	je	.L1924
	testb	%al, %al
	jne	.L1927
	movl	$2, %r15d
	leaq	128(%rsp), %r14
.L1928:
	vmovsd	-16(%r14,%r15,8), %xmm0
	movl	$8, %edx
	vmulsd	(%rbx), %xmm0, %xmm0
	movq	%r13, %rsi
	movq	%r12, %rdi
	vmovsd	%xmm0, 120(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movl	256(%rsp), %eax
	andl	$1, %eax
	cmpl	$4, %r15d
	sete	%dl
	incq	%r15
	orb	%dl, %al
	je	.L1928
.L1927:
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC2(%rip), %rbx
	movabsq	$4294967424, %rax
	movq	%r12, %rdi
	movq	%rax, 256(%rsp)
	movq	%rbx, 264(%rsp)
	movl	$4105, 272(%rsp)
	call	_gfortran_st_write@PLT
	movl	$51, %edx
	leaq	.LC131(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC129(%rip), %rax
	movq	%rax, 336(%rsp)
	movq	%r12, %rdi
	movabsq	$4294971392, %rax
	movq	%rbx, 264(%rsp)
	movl	$4106, 272(%rsp)
	movq	$28, 344(%rsp)
	movq	%rax, 256(%rsp)
	call	_gfortran_st_write@PLT
	movl	$1, %edx
	leaq	.LC130(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	testb	$1, 256(%rsp)
	jne	.L1925
	movl	$2, %r15d
	leaq	bas_(%rip), %rbx
	leaq	224(%rsp), %r14
.L1926:
	vmovsd	-16(%r14,%r15,8), %xmm0
	movl	$8, %edx
	vmulsd	(%rbx), %xmm0, %xmm0
	movq	%r13, %rsi
	movq	%r12, %rdi
	vmovsd	%xmm0, 120(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movl	256(%rsp), %eax
	andl	$1, %eax
	cmpl	$4, %r15d
	sete	%dl
	incq	%r15
	orb	%al, %dl
	je	.L1926
	testb	%al, %al
	jne	.L1925
	movl	$2, %r15d
	leaq	160(%rsp), %r14
.L1932:
	vmovsd	-16(%r14,%r15,8), %xmm0
	movl	$8, %edx
	vmulsd	(%rbx), %xmm0, %xmm0
	movq	%r13, %rsi
	movq	%r12, %rdi
	vmovsd	%xmm0, 120(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movl	256(%rsp), %eax
	andl	$1, %eax
	cmpl	$4, %r15d
	sete	%dl
	incq	%r15
	orb	%dl, %al
	je	.L1932
.L1925:
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	vmovapd	224(%rsp), %xmm4
	movq	56(%rsp), %r14
	vsubpd	192(%rsp), %xmm4, %xmm0
	movq	72(%rsp), %r15
	vmovq	%r14, %xmm4
	vmulpd	%xmm0, %xmm0, %xmm2
	vmovq	%r15, %xmm5
	leaq	.LC2(%rip), %rax
	movq	%rax, 264(%rsp)
	movq	%r12, %rdi
	vunpckhpd	%xmm2, %xmm2, %xmm1
	vaddpd	%xmm2, %xmm1, %xmm1
	vsubsd	%xmm5, %xmm4, %xmm2
	movabsq	$4294967424, %rax
	movq	%rax, 256(%rsp)
	vfmadd231sd	%xmm2, %xmm2, %xmm1
	vmovapd	%xmm0, 80(%rsp)
	vmovsd	%xmm2, 104(%rsp)
	movl	$4115, 272(%rsp)
	vsqrtsd	%xmm1, %xmm1, %xmm4
	vmovq	%xmm4, %rbx
	call	_gfortran_st_write@PLT
	movl	$30, %edx
	leaq	.LC132(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	vmovq	%rbx, %xmm4
	vmulsd	bas_(%rip), %xmm4, %xmm1
	movq	%r13, %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	vcvtsd2ss	%xmm1, %xmm1, %xmm1
	vmovss	%xmm1, 120(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movq	40(%rsp), %rax
	vmovq	%rbx, %xmm7
	movslq	(%rax), %rax
	leaq	bon_(%rip), %rbx
	movslq	119996(%rbx,%rax,4), %rcx
	movl	120000(%rbx,%rax,4), %r10d
	vmovapd	80(%rsp), %xmm0
	vmovsd	.LC8(%rip), %xmm5
	leal	1(%rcx), %esi
	cmpl	%r10d, %esi
	vmovsd	%xmm0, %xmm0, %xmm8
	vdivsd	%xmm7, %xmm5, %xmm1
	vmovsd	104(%rsp), %xmm2
	vunpckhpd	%xmm0, %xmm0, %xmm0
	jg	.L1955
	vmovsd	48(%rsp), %xmm4
	vmovsd	64(%rsp), %xmm3
	movq	16(%rsp), %rax
	vsubsd	%xmm4, %xmm3, %xmm3
	vmovq	%r14, %xmm5
	vmovq	%r15, %xmm4
	vsubsd	%xmm5, %xmm4, %xmm5
	vmovsd	(%rax), %xmm4
	vmovsd	24(%rsp), %xmm7
	vmulsd	%xmm0, %xmm4, %xmm0
	vmulsd	%xmm2, %xmm4, %xmm2
	vmulsd	%xmm8, %xmm4, %xmm4
	vsubsd	32(%rsp), %xmm7, %xmm8
	leal	-1(%r10), %r14d
	movl	%r10d, %r15d
	subl	%ecx, %r14d
	vfmadd231sd	%xmm4, %xmm1, %xmm8
	vfmadd132sd	%xmm1, %xmm3, %xmm0
	vfmadd231sd	%xmm2, %xmm1, %xmm5
	subl	%ecx, %r15d
	cmpl	$2, %r14d
	jbe	.L1947
	movslq	%ecx, %rdx
	movl	%r15d, %r11d
	salq	$3, %rdx
	leaq	pos_(%rip), %rax
	vxorpd	%xmm4, %xmm4, %xmm4
	shrl	$2, %r11d
	leaq	(%rax,%rdx), %r9
	leaq	80000(%rax,%rdx), %r8
	leaq	160000(%rax,%rdx), %rdi
	vbroadcastsd	%xmm8, %ymm11
	vbroadcastsd	%xmm0, %ymm10
	vbroadcastsd	%xmm5, %ymm9
	salq	$5, %r11
	xorl	%edx, %edx
	vmovapd	%ymm4, %ymm7
	vmovapd	%ymm4, %ymm6
	.p2align 4,,10
	.p2align 3
.L1936:
	vmovupd	(%r8,%rdx), %ymm2
	vmovupd	(%rdi,%rdx), %ymm1
	vaddpd	(%r9,%rdx), %ymm11, %ymm3
	vaddpd	%ymm2, %ymm10, %ymm2
	vaddpd	%ymm1, %ymm9, %ymm1
	vmovupd	%ymm3, (%r9,%rdx)
	vmovupd	%ymm2, (%r8,%rdx)
	vmovupd	%ymm1, (%rdi,%rdx)
	addq	$32, %rdx
	vaddpd	%ymm3, %ymm6, %ymm6
	vaddpd	%ymm2, %ymm7, %ymm7
	vaddpd	%ymm1, %ymm4, %ymm4
	cmpq	%r11, %rdx
	jne	.L1936
	vextractf128	$0x1, %ymm4, %xmm1
	vaddpd	%xmm4, %xmm1, %xmm4
	movl	%r15d, %edx
	andl	$-4, %edx
	vunpckhpd	%xmm4, %xmm4, %xmm1
	vaddpd	%xmm4, %xmm1, %xmm4
	vextractf128	$0x1, %ymm7, %xmm1
	vaddpd	%xmm7, %xmm1, %xmm7
	addl	%edx, %esi
	vunpckhpd	%xmm7, %xmm7, %xmm1
	vaddpd	%xmm7, %xmm1, %xmm7
	vextractf128	$0x1, %ymm6, %xmm1
	vaddpd	%xmm6, %xmm1, %xmm6
	vunpckhpd	%xmm6, %xmm6, %xmm1
	vaddpd	%xmm6, %xmm1, %xmm6
	cmpl	%r15d, %edx
	je	.L1956
	vzeroupper
.L1934:
	subl	%edx, %r14d
	subl	%edx, %r15d
	cmpl	$1, %r14d
	jbe	.L1938
	leaq	(%rdx,%rcx), %rdi
	leaq	(%rax,%rdi,8), %r8
	leaq	10000(%rdx,%rcx), %rdi
	leaq	(%rax,%rdi,8), %rdi
	leaq	20000(%rdx,%rcx), %rdx
	vmovupd	(%rdi), %xmm2
	leaq	(%rax,%rdx,8), %rdx
	vmovupd	(%rdx), %xmm9
	vmovddup	%xmm0, %xmm1
	vaddpd	%xmm2, %xmm1, %xmm1
	vmovddup	%xmm5, %xmm2
	vaddpd	%xmm9, %xmm2, %xmm2
	vmovddup	%xmm8, %xmm3
	vaddpd	(%r8), %xmm3, %xmm3
	vunpckhpd	%xmm2, %xmm2, %xmm9
	vmovupd	%xmm3, (%r8)
	vmovupd	%xmm1, (%rdi)
	vmovupd	%xmm2, (%rdx)
	vaddpd	%xmm2, %xmm9, %xmm2
	movl	%r15d, %edx
	andl	$-2, %edx
	vaddsd	%xmm2, %xmm4, %xmm4
	vunpckhpd	%xmm1, %xmm1, %xmm2
	vaddpd	%xmm1, %xmm2, %xmm1
	addl	%edx, %esi
	vaddsd	%xmm1, %xmm7, %xmm7
	vunpckhpd	%xmm3, %xmm3, %xmm1
	vaddpd	%xmm3, %xmm1, %xmm3
	vaddsd	%xmm3, %xmm6, %xmm6
	cmpl	%r15d, %edx
	je	.L1930
.L1938:
	movslq	%esi, %rdx
	vaddsd	-8(%rax,%rdx,8), %xmm8, %xmm3
	vaddsd	79992(%rax,%rdx,8), %xmm0, %xmm2
	vaddsd	159992(%rax,%rdx,8), %xmm5, %xmm1
	vaddsd	%xmm3, %xmm6, %xmm6
	vaddsd	%xmm2, %xmm7, %xmm7
	vaddsd	%xmm1, %xmm4, %xmm4
	vmovsd	%xmm3, -8(%rax,%rdx,8)
	vmovsd	%xmm2, 79992(%rax,%rdx,8)
	vmovsd	%xmm1, 159992(%rax,%rdx,8)
	cmpl	%r10d, %esi
	jge	.L1930
	vaddsd	(%rax,%rdx,8), %xmm8, %xmm8
	vaddsd	80000(%rax,%rdx,8), %xmm0, %xmm0
	vaddsd	160000(%rax,%rdx,8), %xmm5, %xmm5
	vaddsd	%xmm8, %xmm6, %xmm6
	vaddsd	%xmm0, %xmm7, %xmm7
	vaddsd	%xmm5, %xmm4, %xmm4
	vmovsd	%xmm8, (%rax,%rdx,8)
	vmovsd	%xmm0, 80000(%rax,%rdx,8)
	vmovsd	%xmm5, 160000(%rax,%rdx,8)
.L1930:
	leaq	.LC2(%rip), %rax
	movq	%rax, 264(%rsp)
	movq	%r12, %rdi
	movabsq	$4294967424, %rax
	movq	%rax, 256(%rsp)
	vmovsd	%xmm4, 80(%rsp)
	vmovsd	%xmm7, 104(%rsp)
	vmovsd	%xmm6, 64(%rsp)
	movl	$4141, 272(%rsp)
	call	_gfortran_st_write@PLT
	movl	$16, %edx
	leaq	.LC133(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	vmovsd	96(%rsp), %xmm5
	vmovsd	64(%rsp), %xmm6
	vmulsd	bas_(%rip), %xmm5, %xmm0
	movl	$4, %edx
	movq	%r13, %rsi
	movq	%r12, %rdi
	vmulsd	%xmm6, %xmm0, %xmm6
	vcvtsd2ss	%xmm6, %xmm6, %xmm6
	vmovss	%xmm6, 120(%rsp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	96(%rsp), %xmm5
	vmovsd	104(%rsp), %xmm7
	vmulsd	bas_(%rip), %xmm5, %xmm0
	movl	$4, %edx
	movq	%r13, %rsi
	movq	%r12, %rdi
	vmulsd	%xmm7, %xmm0, %xmm7
	vcvtsd2ss	%xmm7, %xmm7, %xmm7
	vmovss	%xmm7, 120(%rsp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	96(%rsp), %xmm5
	vmovsd	80(%rsp), %xmm4
	vmulsd	bas_(%rip), %xmm5, %xmm0
	movq	%r12, %rdi
	movl	$4, %edx
	movq	%r13, %rsi
	vmulsd	%xmm4, %xmm0, %xmm0
	vcvtsd2ss	%xmm0, %xmm0, %xmm0
	vmovss	%xmm0, 120(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movq	792(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L1957
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L1955:
	.cfi_restore_state
	vxorpd	%xmm4, %xmm4, %xmm4
	vmovsd	%xmm4, %xmm4, %xmm7
	vmovsd	%xmm4, %xmm4, %xmm6
	jmp	.L1930
	.p2align 4,,10
	.p2align 3
.L1954:
	leaq	120(%rsp), %r13
	jmp	.L1927
	.p2align 4,,10
	.p2align 3
.L1956:
	vzeroupper
	jmp	.L1930
	.p2align 4,,10
	.p2align 3
.L1943:
	vxorpd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm6, %xmm6, %xmm5
	jmp	.L1920
	.p2align 4,,10
	.p2align 3
.L1941:
	vxorpd	%xmm8, %xmm8, %xmm8
	jmp	.L1916
.L1947:
	vxorpd	%xmm4, %xmm4, %xmm4
	xorl	%edx, %edx
	vmovsd	%xmm4, %xmm4, %xmm7
	vmovsd	%xmm4, %xmm4, %xmm6
	leaq	pos_(%rip), %rax
	jmp	.L1934
.L1942:
	vxorpd	%xmm3, %xmm3, %xmm3
	vmovsd	%xmm3, %xmm3, %xmm1
	vmovsd	%xmm3, %xmm3, %xmm8
	vmovsd	%xmm3, %xmm3, %xmm7
	vmovsd	%xmm3, %xmm3, %xmm2
	vmovsd	%xmm3, %xmm3, %xmm0
	leaq	pos_(%rip), %rax
	jmp	.L1917
.L1944:
	vxorpd	%xmm3, %xmm3, %xmm3
	vmovsd	%xmm3, %xmm3, %xmm1
	vmovsd	%xmm3, %xmm3, %xmm10
	vmovsd	%xmm3, %xmm3, %xmm9
	vmovsd	%xmm3, %xmm3, %xmm6
	vmovsd	%xmm3, %xmm3, %xmm0
	leaq	pos_(%rip), %rax
	jmp	.L1921
.L1914:
	leaq	.LC2(%rip), %rax
	leaq	256(%rsp), %r12
	movq	%rax, 264(%rsp)
	movl	$201326593, %eax
	salq	$7, %rax
	movq	%r12, %rdi
	movq	%rax, 256(%rsp)
	movl	$4066, 272(%rsp)
	call	_gfortran_st_write@PLT
	movl	$39, %edx
	leaq	.LC126(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
.L1957:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE36:
	.size	displace_, .-displace_
	.section	.rodata.str1.8
	.align 8
.LC135:
	.string	"lcpb must be used together with ldens"
	.section	.rodata.str1.1
.LC137:
	.string	"Confstart: FAILURE"
	.text
	.p2align 4
	.globl	confstart_
	.type	confstart_, @function
confstart_:
.LFB37:
	.cfi_startproc
	leaq	8(%rsp), %r10
	.cfi_def_cfa 10, 0
	andq	$-32, %rsp
	pushq	-8(%r10)
	pushq	%rbp
	.cfi_escape 0x10,0x6,0x2,0x76,0
	movq	%rsp, %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%r10
	.cfi_escape 0xf,0x3,0x76,0x58,0x6
	.cfi_escape 0x10,0xf,0x2,0x76,0x78
	.cfi_escape 0x10,0xe,0x2,0x76,0x70
	.cfi_escape 0x10,0xd,0x2,0x76,0x68
	.cfi_escape 0x10,0xc,0x2,0x76,0x60
	pushq	%rbx
	subq	$736, %rsp
	.cfi_escape 0x10,0x3,0x2,0x76,0x50
	movq	%rsi, -736(%rbp)
	movl	68+wal_(%rip), %eax
	movl	160008+bon_(%rip), %ebx
	movq	%fs:40, %rcx
	movq	%rcx, -56(%rbp)
	xorl	%ecx, %ecx
	testl	%eax, %eax
	je	.L1959
	vxorpd	%xmm7, %xmm7, %xmm7
	vcvtsi2sdl	8+bas_(%rip), %xmm7, %xmm0
	vmovsd	.LC134(%rip), %xmm1
	vdivsd	(%rdi), %xmm0, %xmm0
	call	pow@PLT
	vmovsd	.LC72(%rip), %xmm7
	vmulsd	%xmm7, %xmm0, %xmm7
	vxorpd	.LC11(%rip), %xmm7, %xmm6
	vmovsd	%xmm7, -744(%rbp)
	vmovsd	%xmm6, -664(%rbp)
	testl	%ebx, %ebx
	jne	.L2019
.L1960:
	movl	160000+bon_(%rip), %eax
	movl	%eax, -768(%rbp)
	testl	%eax, %eax
	jle	.L1958
	vmovsd	-664(%rbp), %xmm7
	leaq	120000+bon_(%rip), %rax
	vmovsd	%xmm7, -688(%rbp)
	vmovsd	%xmm7, -680(%rbp)
	vmovsd	.LC72(%rip), %xmm7
	vmovsd	-744(%rbp), %xmm6
	vmovsd	%xmm7, -720(%rbp)
	movq	%rax, -656(%rbp)
	vmovsd	.LC8(%rip), %xmm7
	movl	$1, -764(%rbp)
	vmovsd	%xmm6, -752(%rbp)
	vmovsd	%xmm6, -760(%rbp)
	vmovsd	%xmm7, -728(%rbp)
.L1962:
	vmovsd	-744(%rbp), %xmm7
	movq	-656(%rbp), %rax
	vsubsd	-664(%rbp), %xmm7, %xmm7
	incl	-764(%rbp)
	movl	$9000, -648(%rbp)
	vmovsd	%xmm7, -696(%rbp)
	vmovsd	-760(%rbp), %xmm7
	movl	(%rax), %r15d
	vsubsd	-680(%rbp), %xmm7, %xmm7
	vmovsd	%xmm7, -704(%rbp)
	vmovsd	-752(%rbp), %xmm7
	vsubsd	-688(%rbp), %xmm7, %xmm7
	vmovsd	%xmm7, -712(%rbp)
	.p2align 4,,10
	.p2align 3
.L1987:
	vmovsd	-720(%rbp), %xmm7
	leaq	phi.24(%rip), %rcx
	vmulsd	64+pid_(%rip), %xmm7, %xmm0
	movslq	%r15d, %rax
	leaq	theta.23(%rip), %rbx
	movq	$0x000000000, (%rbx,%rax,8)
	leaq	.LC125(%rip), %rdi
	vmovsd	%xmm0, (%rcx,%rax,8)
	leal	1(%r15), %eax
	cltq
	movq	$0x000000000, (%rcx,%rax,8)
	call	ran2_.constprop.0
	vmovsd	.LC136(%rip), %xmm7
	vmovsd	%xmm0, %xmm0, %xmm1
	vmulsd	64+pid_(%rip), %xmm7, %xmm0
	movq	-656(%rbp), %rcx
	movl	(%rcx), %eax
	movl	4(%rcx), %r11d
	vmulsd	%xmm1, %xmm0, %xmm0
	leal	1(%rax), %esi
	movslq	%esi, %rdx
	addl	$3, %eax
	movl	%esi, -644(%rbp)
	movl	%r11d, -632(%rbp)
	vmovsd	%xmm0, (%rbx,%rdx,8)
	cmpl	%eax, %r11d
	jle	.L1963
	vmovsd	.LC9(%rip), %xmm2
	movslq	%eax, %r9
	leaq	-8+phi.24(%rip), %r15
	subq	$8, %rbx
	leaq	.LC125(%rip), %r10
	.p2align 4,,10
	.p2align 3
.L1964:
	movq	%r10, %rdi
	call	ran2_.constprop.0
	vfmadd132sd	.LC74(%rip), %xmm2, %xmm0
	movq	%r10, %rdi
	vmulsd	64+pid_(%rip), %xmm0, %xmm0
	vmovsd	%xmm0, (%r15,%r9,8)
	call	ran2_.constprop.0
	vmovsd	.LC136(%rip), %xmm7
	vmovsd	%xmm0, %xmm0, %xmm1
	vmulsd	64+pid_(%rip), %xmm7, %xmm0
	vmulsd	%xmm1, %xmm0, %xmm0
	vmovsd	%xmm0, (%rbx,%r9,8)
	incq	%r9
	cmpl	%r9d, %r11d
	jg	.L1964
	movq	-656(%rbp), %rax
	movl	4(%rax), %ecx
	movl	(%rax), %eax
	movl	%ecx, -632(%rbp)
	movl	%eax, -616(%rbp)
	incl	%eax
	movl	%eax, -644(%rbp)
.L1963:
	movl	-644(%rbp), %ecx
	cmpl	%ecx, -632(%rbp)
	jle	.L1969
	movslq	-644(%rbp), %r14
	leaq	t.22(%rip), %rbx
	leaq	0(,%r14,8), %rax
	movq	%rax, -672(%rbp)
	addq	%rax, %rbx
	leaq	-8+theta.23(%rip), %rax
	movq	%rax, -640(%rbp)
	leaq	-8+phi.24(%rip), %r15
	leaq	-600(%rbp), %r12
	leaq	-608(%rbp), %r13
	.p2align 4,,10
	.p2align 3
.L1968:
	movq	-640(%rbp), %rax
	movq	%r13, %rsi
	vmovsd	(%rax,%r14,8), %xmm0
	movq	%r12, %rdi
	call	sincos@PLT
	vmovsd	-608(%rbp), %xmm3
	vmovsd	-600(%rbp), %xmm2
	vmovsd	(%r15,%r14,8), %xmm0
	vmovsd	%xmm3, -8(%rbx)
	vmovsd	%xmm2, 239992(%rbx)
	movq	%r13, %rsi
	movq	%r12, %rdi
	vmovsd	%xmm3, -624(%rbp)
	vmovsd	%xmm2, -616(%rbp)
	call	sincos@PLT
	vmovsd	-608(%rbp), %xmm1
	vmovsd	-616(%rbp), %xmm2
	vmovsd	-600(%rbp), %xmm0
	vmulsd	%xmm1, %xmm2, %xmm4
	vmovsd	-624(%rbp), %xmm3
	vmulsd	%xmm2, %xmm0, %xmm2
	vmovsd	%xmm0, 559992(%rbx)
	vmulsd	%xmm3, %xmm0, %xmm0
	vmovsd	%xmm4, 79992(%rbx)
	vmulsd	%xmm3, %xmm1, %xmm4
	vxorpd	.LC11(%rip), %xmm1, %xmm1
	incq	%r14
	vxorpd	.LC11(%rip), %xmm0, %xmm0
	vmovsd	%xmm2, 159992(%rbx)
	vxorpd	.LC11(%rip), %xmm4, %xmm4
	vmovsd	%xmm0, 399992(%rbx)
	vmovsd	%xmm4, 319992(%rbx)
	vmovsd	%xmm1, 639992(%rbx)
	addq	$8, %rbx
	cmpl	%r14d, -632(%rbp)
	jg	.L1968
	movl	-632(%rbp), %ebx
	movq	-672(%rbp), %rcx
	decl	%ebx
	subl	-644(%rbp), %ebx
	leaq	t.22(%rip), %rax
	leaq	8(,%rbx,8), %rdx
	leaq	479992(%rax,%rcx), %rdi
	xorl	%esi, %esi
	call	memset@PLT
.L1969:
	leaq	.LC125(%rip), %rdi
	call	ran2_.constprop.0
	vmovsd	.LC74(%rip), %xmm7
	vfnmadd213sd	-728(%rbp), %xmm7, %xmm0
	call	acos@PLT
	leaq	.LC125(%rip), %rdi
	vmovsd	%xmm0, -616(%rbp)
	call	ran2_.constprop.0
	vmovsd	%xmm0, %xmm0, %xmm1
	movq	-656(%rbp), %rax
	vmovsd	64+pid_(%rip), %xmm0
	movl	(%rax), %r14d
	vaddsd	%xmm0, %xmm0, %xmm0
	movl	4(%rax), %r15d
	leal	1(%r14), %ebx
	vmulsd	%xmm1, %xmm0, %xmm0
	cmpl	%ebx, %r15d
	jle	.L1966
	leaq	-600(%rbp), %r12
	leaq	-608(%rbp), %r13
	movq	%r13, %rsi
	movq	%r12, %rdi
	call	sincos@PLT
	vmovsd	-608(%rbp), %xmm7
	vmovsd	-600(%rbp), %xmm6
	vmovsd	-616(%rbp), %xmm0
	movq	%r13, %rsi
	movq	%r12, %rdi
	vmovsd	%xmm7, -624(%rbp)
	vmovsd	%xmm6, -632(%rbp)
	call	sincos@PLT
	vmovsd	bon_(%rip), %xmm6
	movslq	%r14d, %rax
	vmulsd	-600(%rbp), %xmm6, %xmm7
	vmulsd	-608(%rbp), %xmm6, %xmm6
	salq	$3, %rax
	leaq	r.21(%rip), %rdi
	leaq	t.22(%rip), %rsi
	vmulsd	-624(%rbp), %xmm7, %xmm8
	vmulsd	-632(%rbp), %xmm7, %xmm7
	addq	%rax, %rdi
	leaq	8(%rsi,%rax), %r9
	.p2align 4,,10
	.p2align 3
.L1973:
	movq	%r9, %rax
	vmovsd	%xmm6, %xmm6, %xmm1
	vmovsd	%xmm7, %xmm7, %xmm2
	vmovsd	%xmm8, %xmm8, %xmm5
	movl	%ebx, %edx
	.p2align 4,,10
	.p2align 3
.L1972:
	vmulsd	239992(%rax), %xmm2, %xmm3
	vmulsd	319992(%rax), %xmm2, %xmm4
	vmovsd	%xmm5, %xmm5, %xmm0
	decl	%edx
	subq	$8, %rax
	vfmadd231sd	(%rax), %xmm5, %xmm3
	vfmadd231sd	80000(%rax), %xmm0, %xmm4
	vmovsd	%xmm3, %xmm3, %xmm5
	vmovsd	%xmm2, %xmm2, %xmm3
	vmulsd	400000(%rax), %xmm3, %xmm3
	vfmadd231sd	560000(%rax), %xmm1, %xmm4
	vfmadd231sd	480000(%rax), %xmm1, %xmm5
	vfmadd132sd	160000(%rax), %xmm3, %xmm0
	vmovsd	%xmm4, %xmm4, %xmm2
	vfmadd132sd	640000(%rax), %xmm0, %xmm1
	cmpl	%edx, %r14d
	jl	.L1972
	incl	%ebx
	vmovsd	%xmm5, (%rdi)
	vmovsd	%xmm4, 80000(%rdi)
	vmovsd	%xmm1, 160000(%rdi)
	addq	$8, %r9
	addq	$8, %rdi
	cmpl	%ebx, %r15d
	jne	.L1973
.L1966:
	leaq	.LC125(%rip), %rdi
	call	ran2_.constprop.0
	vmovsd	-696(%rbp), %xmm5
	leaq	.LC125(%rip), %rdi
	vfmadd213sd	-664(%rbp), %xmm0, %xmm5
	call	ran2_.constprop.0
	vmovsd	-704(%rbp), %xmm4
	leaq	.LC125(%rip), %rdi
	vfmadd213sd	-680(%rbp), %xmm0, %xmm4
	call	ran2_.constprop.0
	movq	-656(%rbp), %rax
	vmovsd	-712(%rbp), %xmm6
	movl	(%rax), %r15d
	movl	4(%rax), %r11d
	leal	1(%r15), %r14d
	vfmadd213sd	-688(%rbp), %xmm0, %xmm6
	cmpl	%r11d, %r14d
	jg	.L1970
	movslq	%r15d, %rdx
	leaq	pos_(%rip), %rax
	leal	2(%r15), %ecx
	vmovsd	%xmm5, (%rax,%rdx,8)
	vmovsd	%xmm4, 80000(%rax,%rdx,8)
	vmovsd	%xmm6, 160000(%rax,%rdx,8)
	cmpl	%r11d, %ecx
	jg	.L1970
	movl	%r15d, %ebx
	notl	%ebx
	movl	%ebx, -616(%rbp)
	salq	$3, %rdx
	leaq	r.21(%rip), %rcx
	addq	%rdx, %rax
	movl	%r14d, %esi
	leaq	(%rcx,%rdx), %r9
	leaq	80000(%rcx,%rdx), %r8
	leaq	160000(%rcx,%rdx), %rdi
	movl	$1, %r10d
	.p2align 4,,10
	.p2align 3
.L1980:
	vmovsd	%xmm5, 8(%rax)
	vmovsd	%xmm4, 80008(%rax)
	vmovsd	%xmm6, 160008(%rax)
	cmpl	%esi, %r15d
	jge	.L1976
	movl	-616(%rbp), %ebx
	leal	(%rbx,%rsi), %edx
	cmpl	$2, %edx
	jbe	.L1997
	movl	%r10d, %ebx
	vxorpd	%xmm2, %xmm2, %xmm2
	shrl	$2, %ebx
	salq	$5, %rbx
	xorl	%edx, %edx
	vmovapd	%ymm2, %ymm1
	vmovapd	%ymm2, %ymm0
	.p2align 4,,10
	.p2align 3
.L1978:
	vaddpd	(%r9,%rdx), %ymm0, %ymm0
	vaddpd	(%r8,%rdx), %ymm1, %ymm1
	vaddpd	(%rdi,%rdx), %ymm2, %ymm2
	addq	$32, %rdx
	cmpq	%rbx, %rdx
	jne	.L1978
	vextractf128	$0x1, %ymm2, %xmm3
	vaddpd	%xmm2, %xmm3, %xmm3
	movl	%r10d, %ebx
	andl	$-4, %ebx
	vunpckhpd	%xmm3, %xmm3, %xmm2
	vaddpd	%xmm3, %xmm2, %xmm2
	vextractf128	$0x1, %ymm1, %xmm3
	vaddpd	%xmm1, %xmm3, %xmm3
	vaddsd	%xmm2, %xmm6, %xmm2
	leal	(%rbx,%r14), %edx
	vunpckhpd	%xmm3, %xmm3, %xmm1
	vaddpd	%xmm3, %xmm1, %xmm1
	vextractf128	$0x1, %ymm0, %xmm3
	vaddpd	%xmm0, %xmm3, %xmm3
	vaddsd	%xmm1, %xmm4, %xmm1
	vunpckhpd	%xmm3, %xmm3, %xmm0
	vaddpd	%xmm3, %xmm0, %xmm0
	vaddsd	%xmm0, %xmm5, %xmm0
	cmpl	%ebx, %r10d
	je	.L1979
.L1977:
	movslq	%edx, %rbx
	vaddsd	-8(%rcx,%rbx,8), %xmm0, %xmm0
	vaddsd	79992(%rcx,%rbx,8), %xmm1, %xmm1
	vaddsd	159992(%rcx,%rbx,8), %xmm2, %xmm2
	leal	1(%rdx), %r13d
	cmpl	%edx, %esi
	jle	.L1979
	movslq	%r13d, %r12
	vaddsd	(%rcx,%rbx,8), %xmm0, %xmm0
	vaddsd	79992(%rcx,%r12,8), %xmm1, %xmm1
	vaddsd	159992(%rcx,%r12,8), %xmm2, %xmm2
	addl	$2, %edx
	cmpl	%r13d, %esi
	jle	.L1979
	movslq	%edx, %rdx
	vaddsd	(%rcx,%r12,8), %xmm0, %xmm0
	vaddsd	79992(%rcx,%rdx,8), %xmm1, %xmm1
	vaddsd	159992(%rcx,%rdx,8), %xmm2, %xmm2
.L1979:
	vmovsd	%xmm0, 8(%rax)
	vmovsd	%xmm1, 80008(%rax)
	vmovsd	%xmm2, 160008(%rax)
.L1976:
	incl	%esi
	addq	$8, %rax
	incl	%r10d
	cmpl	%r11d, %esi
	jne	.L1980
.L1970:
	movl	160008+bon_(%rip), %edi
	cmpl	$3, %r11d
	jle	.L1974
	vmovsd	240016+for_(%rip), %xmm7
	vmovsd	240024+for_(%rip), %xmm12
	vmovsd	240000+for_(%rip), %xmm11
	vmovsd	240032+for_(%rip), %xmm10
	vmovsd	240008+for_(%rip), %xmm9
	vmovsd	240040+for_(%rip), %xmm8
	vmovsd	.LC60(%rip), %xmm3
	movq	-736(%rbp), %rdx
	vmovsd	%xmm7, -616(%rbp)
	leaq	8+pos_(%rip), %rcx
	movl	$4, %esi
.L1988:
	movl	%esi, %eax
	cmpl	%esi, %r11d
	jl	.L1981
	vmovsd	(%rdx), %xmm14
	vmovsd	-8(%rcx), %xmm4
	vmulsd	%xmm14, %xmm14, %xmm14
	vmovsd	79992(%rcx), %xmm5
	vmovsd	159992(%rcx), %xmm6
	movq	%rcx, %r8
	testl	%edi, %edi
	je	.L1984
	vmovsd	%xmm3, %xmm3, %xmm13
	jmp	.L1982
	.p2align 4,,10
	.p2align 3
.L2013:
	incl	%eax
	addq	$8, %r8
	cmpl	%eax, %r11d
	jl	.L1981
.L1982:
	vmovsd	16(%r8), %xmm1
	vmovsd	.LC90(%rip), %xmm15
	vsubsd	%xmm4, %xmm1, %xmm2
	vmovsd	160016(%r8), %xmm1
	vmovsd	80016(%r8), %xmm0
	vsubsd	%xmm6, %xmm1, %xmm7
	vmulsd	%xmm2, %xmm12, %xmm1
	vsubsd	%xmm5, %xmm0, %xmm0
	vandpd	%xmm1, %xmm15, %xmm15
	vorpd	%xmm15, %xmm13, %xmm13
	vaddsd	%xmm1, %xmm13, %xmm13
	vxorpd	%xmm1, %xmm1, %xmm1
	vmovsd	.LC90(%rip), %xmm15
	vcvttsd2sil	%xmm13, %r10d
	vmovsd	.LC60(%rip), %xmm13
	vcvtsi2sdl	%r10d, %xmm1, %xmm1
	vfnmadd132sd	%xmm11, %xmm2, %xmm1
	vmulsd	%xmm0, %xmm10, %xmm2
	vandpd	%xmm2, %xmm15, %xmm15
	vorpd	%xmm15, %xmm13, %xmm13
	vaddsd	%xmm2, %xmm13, %xmm13
	vxorpd	%xmm2, %xmm2, %xmm2
	vmovsd	.LC90(%rip), %xmm15
	vcvttsd2sil	%xmm13, %r10d
	vmovsd	%xmm3, %xmm3, %xmm13
	vcvtsi2sdl	%r10d, %xmm2, %xmm2
	vfnmadd132sd	%xmm9, %xmm0, %xmm2
	vmulsd	%xmm7, %xmm8, %xmm0
	vmulsd	%xmm2, %xmm2, %xmm2
	vandpd	%xmm0, %xmm15, %xmm15
	vorpd	%xmm15, %xmm3, %xmm15
	vaddsd	%xmm0, %xmm15, %xmm15
	vxorpd	%xmm0, %xmm0, %xmm0
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vcvttsd2sil	%xmm15, %r10d
	vcvtsi2sdl	%r10d, %xmm0, %xmm0
	vfnmadd132sd	-616(%rbp), %xmm7, %xmm0
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vcomisd	%xmm0, %xmm14
	jbe	.L2013
.L1983:
	decl	-648(%rbp)
	jne	.L1987
	leaq	.LC2(%rip), %rax
	leaq	-592(%rbp), %r12
	movq	%rax, -584(%rbp)
	movq	%r12, %rdi
	movabsq	$8589934720, %rax
	movl	$4520, -576(%rbp)
	movq	%rax, -592(%rbp)
	vzeroupper
	call	_gfortran_st_write@PLT
	movl	$18, %edx
	leaq	.LC137(%rip), %rsi
.L2018:
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
	.p2align 4,,10
	.p2align 3
.L2020:
	incl	%eax
	addq	$8, %r8
	cmpl	%eax, %r11d
	jl	.L1981
.L1984:
	vmovsd	80016(%r8), %xmm2
	vmovsd	16(%r8), %xmm1
	vsubsd	%xmm5, %xmm2, %xmm2
	vsubsd	%xmm4, %xmm1, %xmm1
	vmovsd	160016(%r8), %xmm0
	vmulsd	%xmm2, %xmm2, %xmm2
	vsubsd	%xmm6, %xmm0, %xmm0
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vcomisd	%xmm0, %xmm14
	jbe	.L2020
	jmp	.L1983
	.p2align 4,,10
	.p2align 3
.L1981:
	leal	1(%rsi), %eax
	addq	$8, %rcx
	cmpl	%esi, %r11d
	je	.L1974
	movl	%eax, %esi
	jmp	.L1988
.L1997:
	vmovsd	%xmm6, %xmm6, %xmm2
	vmovsd	%xmm4, %xmm4, %xmm1
	vmovsd	%xmm5, %xmm5, %xmm0
	movl	%r14d, %edx
	jmp	.L1977
.L1974:
	testl	%edi, %edi
	je	.L2021
.L1989:
	movl	-764(%rbp), %ecx
	addq	$4, -656(%rbp)
	cmpl	%ecx, -768(%rbp)
	jge	.L1962
.L1958:
	movq	-56(%rbp), %rax
	subq	%fs:40, %rax
	jne	.L2022
	vzeroupper
	addq	$736, %rsp
	popq	%rbx
	popq	%r10
	.cfi_remember_state
	.cfi_def_cfa 10, 0
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	leaq	-8(%r10), %rsp
	.cfi_def_cfa 7, 8
	ret
.L2021:
	.cfi_restore_state
	testl	%r11d, %r11d
	jle	.L1989
	leal	-1(%r11), %eax
	cmpl	$3, %eax
	jbe	.L2000
	movl	%r11d, %eax
	shrl	$2, %eax
	leaq	160000+pos_(%rip), %rdx
	salq	$5, %rax
	vbroadcastsd	-744(%rbp), %ymm3
	vbroadcastsd	-664(%rbp), %ymm1
	vbroadcastsd	-760(%rbp), %ymm5
	vbroadcastsd	-680(%rbp), %ymm0
	vbroadcastsd	-752(%rbp), %ymm6
	vbroadcastsd	-688(%rbp), %ymm2
	addq	%rdx, %rax
.L1992:
	vmovapd	-160000(%rdx), %ymm8
	vmovapd	-80000(%rdx), %ymm7
	vmovapd	(%rdx), %ymm4
	addq	$32, %rdx
	vminpd	%ymm8, %ymm1, %ymm1
	vminpd	%ymm7, %ymm0, %ymm0
	vminpd	%ymm4, %ymm2, %ymm2
	vmaxpd	%ymm8, %ymm3, %ymm3
	vmaxpd	%ymm7, %ymm5, %ymm5
	vmaxpd	%ymm4, %ymm6, %ymm6
	cmpq	%rdx, %rax
	jne	.L1992
	vextractf128	$0x1, %ymm6, %xmm4
	vmaxpd	%xmm6, %xmm4, %xmm4
	movl	%r11d, %eax
	andl	$-4, %eax
	vunpckhpd	%xmm4, %xmm4, %xmm6
	vmaxpd	%xmm4, %xmm6, %xmm4
	leal	1(%rax), %edx
	vmovlpd	%xmm4, -752(%rbp)
	vextractf128	$0x1, %ymm5, %xmm4
	vmaxpd	%xmm5, %xmm4, %xmm4
	vunpckhpd	%xmm4, %xmm4, %xmm5
	vmaxpd	%xmm4, %xmm5, %xmm4
	vmovlpd	%xmm4, -760(%rbp)
	vextractf128	$0x1, %ymm3, %xmm4
	vmaxpd	%xmm3, %xmm4, %xmm3
	vunpckhpd	%xmm3, %xmm3, %xmm4
	vmaxpd	%xmm3, %xmm4, %xmm3
	vmovlpd	%xmm3, -744(%rbp)
	vextractf128	$0x1, %ymm2, %xmm3
	vminpd	%xmm2, %xmm3, %xmm2
	vunpckhpd	%xmm2, %xmm2, %xmm3
	vminpd	%xmm2, %xmm3, %xmm2
	vmovlpd	%xmm2, -688(%rbp)
	vextractf128	$0x1, %ymm0, %xmm2
	vminpd	%xmm0, %xmm2, %xmm0
	vunpckhpd	%xmm0, %xmm0, %xmm2
	vminpd	%xmm0, %xmm2, %xmm0
	vmovlpd	%xmm0, -680(%rbp)
	vextractf128	$0x1, %ymm1, %xmm0
	vminpd	%xmm1, %xmm0, %xmm1
	vunpckhpd	%xmm1, %xmm1, %xmm0
	vminpd	%xmm1, %xmm0, %xmm1
	vmovlpd	%xmm1, -664(%rbp)
	cmpl	%r11d, %eax
	je	.L1989
.L1990:
	leal	-1(%rdx), %ecx
	movslq	%ecx, %rcx
	leaq	pos_(%rip), %rax
	vmovsd	(%rax,%rcx,8), %xmm2
	vmovsd	80000(%rax,%rcx,8), %xmm1
	vmovsd	160000(%rax,%rcx,8), %xmm0
	vminsd	-664(%rbp), %xmm2, %xmm7
	vminsd	-680(%rbp), %xmm1, %xmm6
	vminsd	-688(%rbp), %xmm0, %xmm5
	vmaxsd	-744(%rbp), %xmm2, %xmm4
	vmaxsd	-760(%rbp), %xmm1, %xmm3
	vmaxsd	-752(%rbp), %xmm0, %xmm9
	leal	1(%rdx), %esi
	vmovsd	%xmm7, -664(%rbp)
	vmovsd	%xmm6, -680(%rbp)
	vmovsd	%xmm5, -688(%rbp)
	vmovsd	%xmm4, -744(%rbp)
	vmovsd	%xmm3, -760(%rbp)
	vmovsd	%xmm9, -752(%rbp)
	cmpl	%r11d, %esi
	jg	.L1989
	movslq	%edx, %rcx
	vmovsd	(%rax,%rcx,8), %xmm2
	vmovsd	80000(%rax,%rcx,8), %xmm1
	vmovsd	160000(%rax,%rcx,8), %xmm0
	vminsd	%xmm7, %xmm2, %xmm7
	vminsd	%xmm6, %xmm1, %xmm6
	vminsd	%xmm5, %xmm0, %xmm5
	vmaxsd	%xmm4, %xmm2, %xmm4
	vmaxsd	%xmm3, %xmm1, %xmm3
	vmaxsd	%xmm9, %xmm0, %xmm10
	leal	2(%rdx), %ecx
	vmovsd	%xmm7, -664(%rbp)
	vmovsd	%xmm6, -680(%rbp)
	vmovsd	%xmm5, -688(%rbp)
	vmovsd	%xmm4, -744(%rbp)
	vmovsd	%xmm3, -760(%rbp)
	vmovsd	%xmm10, -752(%rbp)
	cmpl	%r11d, %ecx
	jg	.L1989
	movslq	%esi, %rsi
	vmovsd	(%rax,%rsi,8), %xmm2
	vmovsd	80000(%rax,%rsi,8), %xmm1
	vmovsd	160000(%rax,%rsi,8), %xmm0
	vminsd	%xmm7, %xmm2, %xmm7
	vminsd	%xmm6, %xmm1, %xmm6
	vminsd	%xmm5, %xmm0, %xmm5
	vmaxsd	%xmm4, %xmm2, %xmm4
	vmaxsd	%xmm3, %xmm1, %xmm3
	vmaxsd	%xmm10, %xmm0, %xmm11
	addl	$3, %edx
	vmovsd	%xmm7, -664(%rbp)
	vmovsd	%xmm6, -680(%rbp)
	vmovsd	%xmm5, -688(%rbp)
	vmovsd	%xmm4, -744(%rbp)
	vmovsd	%xmm3, -760(%rbp)
	vmovsd	%xmm11, -752(%rbp)
	cmpl	%edx, %r11d
	jl	.L1989
	movslq	%ecx, %rdx
	vmovsd	(%rax,%rdx,8), %xmm2
	vmovsd	80000(%rax,%rdx,8), %xmm1
	vminsd	%xmm7, %xmm2, %xmm7
	vmovsd	160000(%rax,%rdx,8), %xmm0
	vmovsd	%xmm7, -664(%rbp)
	vminsd	%xmm6, %xmm1, %xmm7
	vmovsd	%xmm7, -680(%rbp)
	vminsd	%xmm5, %xmm0, %xmm7
	vmovsd	%xmm7, -688(%rbp)
	vmaxsd	%xmm4, %xmm2, %xmm7
	vmovsd	%xmm7, -744(%rbp)
	vmaxsd	%xmm3, %xmm1, %xmm7
	vmovsd	%xmm7, -760(%rbp)
	vmaxsd	%xmm11, %xmm0, %xmm7
	vmovsd	%xmm7, -752(%rbp)
	jmp	.L1989
.L1959:
	testl	%ebx, %ebx
	jne	.L2023
	vxorpd	%xmm7, %xmm7, %xmm7
	vmovsd	%xmm7, -664(%rbp)
	vmovsd	%xmm7, -744(%rbp)
	jmp	.L1960
.L2019:
	vunpcklpd	%xmm6, %xmm7, %xmm1
	vinsertf128	$1, %xmm1, %ymm1, %ymm1
	vmovupd	%ymm1, 40+plates_(%rip)
	vunpcklpd	%xmm7, %xmm6, %xmm1
	vmovapd	%xmm1, plates_(%rip)
	vaddsd	%xmm7, %xmm7, %xmm1
	vmovsd	.LC8(%rip), %xmm7
	vdivsd	%xmm0, %xmm7, %xmm0
	vmovsd	%xmm1, 240000+for_(%rip)
	vmovsd	%xmm1, 240008+for_(%rip)
	vmovsd	%xmm1, 240016+for_(%rip)
	vmovsd	%xmm0, 240024+for_(%rip)
	vmovsd	%xmm0, 240032+for_(%rip)
	vmovsd	%xmm0, 240040+for_(%rip)
	jmp	.L1960
.L2000:
	movl	$1, %edx
	jmp	.L1990
.L2022:
	vzeroupper
	call	__stack_chk_fail@PLT
.L2023:
	leaq	.LC2(%rip), %rax
	movq	%rax, -584(%rbp)
	leaq	-592(%rbp), %r12
	movl	$67108865, %eax
	salq	$7, %rax
	movq	%r12, %rdi
	movl	$4436, -576(%rbp)
	movq	%rax, -592(%rbp)
	call	_gfortran_st_write@PLT
	movl	$37, %edx
	leaq	.LC135(%rip), %rsi
	jmp	.L2018
	.cfi_endproc
.LFE37:
	.size	confstart_, .-confstart_
	.p2align 4
	.globl	countpid_
	.type	countpid_, @function
countpid_:
.LFB39:
	.cfi_startproc
	pushq	%rbx
	.cfi_def_cfa_offset 16
	.cfi_offset 3, -16
	movq	%rdx, %rbx
	subq	$80, %rsp
	.cfi_def_cfa_offset 96
	movq	%fs:40, %rax
	movq	%rax, 72(%rsp)
	xorl	%eax, %eax
	movq	.LC138(%rip), %rax
	movq	%rax, (%rdx)
	movslq	(%rdi), %rdx
	leaq	bon_(%rip), %rax
	leal	-1(%rdx), %ecx
	movslq	%ecx, %rcx
	movl	79996(%rax,%rcx,4), %edi
	testl	%edi, %edi
	je	.L2024
	movl	79996(%rax,%rdx,4), %eax
	leaq	-1(%rdx), %r10
	leaq	19999(%rdx), %r9
	testl	%eax, %eax
	jne	.L2034
.L2024:
	movq	72(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L2035
	addq	$80, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 16
	popq	%rbx
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L2034:
	.cfi_restore_state
	leaq	pos_(%rip), %rax
	leaq	19999(%rcx), %rdi
	vmovsd	(%rax,%rdx,8), %xmm8
	vmovsd	80000(%rax,%rdx,8), %xmm3
	vmovsd	160000(%rax,%rdx,8), %xmm2
	vmovsd	79992(%rax,%rdx,8), %xmm6
	vmovsd	79992(%rax,%rcx,8), %xmm0
	movslq	(%rsi), %rdx
	vmovsd	(%rax,%rdi,8), %xmm1
	vmovsd	(%rax,%r9,8), %xmm4
	vsubsd	%xmm3, %xmm6, %xmm6
	vsubsd	%xmm2, %xmm4, %xmm4
	vsubsd	%xmm3, %xmm0, %xmm3
	vsubsd	%xmm2, %xmm1, %xmm2
	vsubsd	79992(%rax,%rdx,8), %xmm0, %xmm0
	leaq	-1(%rcx), %r8
	vmovsd	(%rax,%r8,8), %xmm9
	vmulsd	%xmm0, %xmm2, %xmm10
	vmovsd	(%rax,%r10,8), %xmm5
	vsubsd	159992(%rax,%rdx,8), %xmm1, %xmm1
	vsubsd	%xmm8, %xmm5, %xmm5
	vsubsd	%xmm8, %xmm9, %xmm8
	vfmsub231sd	%xmm1, %xmm3, %xmm10
	vmulsd	%xmm3, %xmm4, %xmm11
	vmulsd	%xmm1, %xmm8, %xmm1
	vmulsd	%xmm2, %xmm5, %xmm12
	vmulsd	%xmm8, %xmm6, %xmm7
	vsubsd	-8(%rax,%rdx,8), %xmm9, %xmm9
	vfmsub231sd	%xmm2, %xmm6, %xmm11
	vmovsd	%xmm10, 48(%rsp)
	vfmsub132sd	%xmm9, %xmm1, %xmm2
	vfmsub231sd	%xmm8, %xmm4, %xmm12
	vfmsub231sd	%xmm3, %xmm5, %xmm7
	vmulsd	%xmm9, %xmm3, %xmm3
	vmovsd	%xmm11, 16(%rsp)
	vmovsd	%xmm2, 56(%rsp)
	vmovsd	%xmm12, 24(%rsp)
	vmovapd	48(%rsp), %xmm1
	vfmsub132sd	%xmm8, %xmm3, %xmm0
	vmovapd	16(%rsp), %xmm3
	vmulpd	%xmm1, %xmm1, %xmm8
	vmulpd	%xmm3, %xmm3, %xmm1
	vmovsd	.LC104(%rip), %xmm9
	vunpckhpd	%xmm1, %xmm1, %xmm3
	vaddpd	%xmm1, %xmm3, %xmm3
	vunpckhpd	%xmm8, %xmm8, %xmm1
	vaddpd	%xmm8, %xmm1, %xmm1
	vmovq	.LC69(%rip), %xmm8
	vfmadd231sd	%xmm7, %xmm7, %xmm3
	vfmadd231sd	%xmm0, %xmm0, %xmm1
	vandpd	%xmm8, %xmm1, %xmm13
	vcomisd	%xmm13, %xmm9
	ja	.L2024
	vandpd	%xmm8, %xmm3, %xmm8
	vcomisd	%xmm8, %xmm9
	ja	.L2024
	vmulsd	%xmm2, %xmm12, %xmm12
	vmulsd	%xmm2, %xmm6, %xmm6
	vmulsd	%xmm1, %xmm3, %xmm3
	vfmadd132sd	%xmm10, %xmm12, %xmm11
	vfmadd132sd	%xmm10, %xmm6, %xmm5
	vsqrtsd	%xmm3, %xmm3, %xmm3
	vfmadd132sd	%xmm0, %xmm11, %xmm7
	vfmadd132sd	%xmm0, %xmm5, %xmm4
	vdivsd	%xmm3, %xmm7, %xmm0
	vmovsd	%xmm4, 8(%rsp)
	vminsd	.LC8(%rip), %xmm0, %xmm0
	vmaxsd	.LC9(%rip), %xmm0, %xmm0
	call	acos@PLT
	vmovsd	8(%rsp), %xmm4
	vxorpd	%xmm1, %xmm1, %xmm1
	vcmpnltsd	%xmm1, %xmm4, %xmm4
	vxorpd	.LC11(%rip), %xmm0, %xmm5
	vblendvpd	%xmm4, %xmm0, %xmm5, %xmm0
	vmovsd	%xmm0, (%rbx)
	jmp	.L2024
.L2035:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE39:
	.size	countpid_, .-countpid_
	.p2align 4
	.globl	compute_details_
	.type	compute_details_, @function
compute_details_:
.LFB38:
	.cfi_startproc
	pushq	%r13
	.cfi_def_cfa_offset 16
	.cfi_offset 13, -16
	vxorps	%xmm0, %xmm0, %xmm0
	pushq	%r12
	.cfi_def_cfa_offset 24
	.cfi_offset 12, -24
	movq	%rdi, %r12
	pushq	%rbp
	.cfi_def_cfa_offset 32
	.cfi_offset 6, -32
	movq	%rsi, %rbp
	subq	$16, %rsp
	.cfi_def_cfa_offset 48
	movslq	(%rdi), %r10
	movq	%fs:40, %rax
	movq	%rax, 8(%rsp)
	xorl	%eax, %eax
	leaq	-1(%r10), %rdx
	leaq	pos_(%rip), %rax
	movslq	(%rsi), %rsi
	vmovsd	(%rax,%rdx,8), %xmm7
	vmovsd	79992(%rax,%r10,8), %xmm8
	vmovsd	159992(%rax,%r10,8), %xmm2
	movl	36+kier_(%rip), %r9d
	vsubsd	-8(%rax,%rsi,8), %xmm7, %xmm7
	vsubsd	79992(%rax,%rsi,8), %xmm8, %xmm8
	vsubsd	159992(%rax,%rsi,8), %xmm2, %xmm6
	leaq	-1(%rsi), %rdi
	testl	%r9d, %r9d
	je	.L2037
	vmulsd	240024+for_(%rip), %xmm7, %xmm3
	vmovsd	.LC11(%rip), %xmm2
	vmovsd	.LC60(%rip), %xmm1
	vandpd	%xmm3, %xmm2, %xmm2
	vorpd	%xmm2, %xmm1, %xmm1
	vaddsd	%xmm3, %xmm1, %xmm1
	vcvttsd2sil	%xmm1, %ecx
	vcvtsi2sdl	%ecx, %xmm0, %xmm1
	vfnmadd231sd	240000+for_(%rip), %xmm1, %xmm7
.L2037:
	movl	40+kier_(%rip), %r8d
	testl	%r8d, %r8d
	je	.L2038
	vmulsd	240032+for_(%rip), %xmm8, %xmm3
	vmovsd	.LC11(%rip), %xmm2
	vmovsd	.LC60(%rip), %xmm1
	vandpd	%xmm3, %xmm2, %xmm2
	vorpd	%xmm2, %xmm1, %xmm1
	vaddsd	%xmm3, %xmm1, %xmm1
	vcvttsd2sil	%xmm1, %ecx
	vcvtsi2sdl	%ecx, %xmm0, %xmm1
	vfnmadd231sd	240008+for_(%rip), %xmm1, %xmm8
.L2038:
	movl	44+kier_(%rip), %ecx
	testl	%ecx, %ecx
	je	.L2039
	vmulsd	240040+for_(%rip), %xmm6, %xmm3
	vmovsd	.LC11(%rip), %xmm2
	vmovsd	.LC60(%rip), %xmm1
	vandpd	%xmm3, %xmm2, %xmm2
	vorpd	%xmm2, %xmm1, %xmm1
	vaddsd	%xmm3, %xmm1, %xmm1
	vcvttsd2sil	%xmm1, %ecx
	vcvtsi2sdl	%ecx, %xmm0, %xmm0
	vfnmadd231sd	240016+for_(%rip), %xmm0, %xmm6
.L2039:
	vmulsd	%xmm8, %xmm8, %xmm3
	leaq	(%rdx,%rdx,2), %rcx
	leaq	(%rdi,%rdi,2), %rdx
	addq	%rcx, %rcx
	addq	%rdx, %rdx
	vfmadd231sd	%xmm7, %xmm7, %xmm3
	vmovsd	720008(%rax,%rcx,8), %xmm1
	vmovsd	720008(%rax,%rdx,8), %xmm10
	vmulsd	%xmm8, %xmm1, %xmm5
	vmulsd	%xmm8, %xmm10, %xmm9
	vfmadd231sd	%xmm6, %xmm6, %xmm3
	vmulsd	%xmm10, %xmm1, %xmm10
	vmovsd	720000(%rax,%rdx,8), %xmm12
	vmovsd	720016(%rax,%rdx,8), %xmm11
	vfmadd231sd	%xmm7, %xmm12, %xmm9
	vsqrtsd	%xmm3, %xmm3, %xmm4
	vmovsd	720016(%rax,%rcx,8), %xmm2
	leaq	1(%rdx), %r8
	vmulsd	bas_(%rip), %xmm4, %xmm0
	vfmadd231sd	%xmm6, %xmm11, %xmm9
	leaq	2(%rdx), %rdi
	leaq	30002(%rcx), %r9
	vmovsd	%xmm0, nmapi_(%rip)
	vmovsd	720000(%rax,%rcx,8), %xmm0
	vdivsd	%xmm4, %xmm9, %xmm9
	vfmadd231sd	%xmm12, %xmm0, %xmm10
	vfmadd231sd	%xmm7, %xmm0, %xmm5
	vmovsd	239960(%rax,%rcx,8), %xmm0
	vmovsd	239968(%rax,%rcx,8), %xmm12
	vsubsd	240008(%rax,%rcx,8), %xmm0, %xmm0
	vfmadd231sd	%xmm11, %xmm2, %xmm10
	vmovsd	239952(%rax,%rcx,8), %xmm11
	vmulsd	%xmm8, %xmm0, %xmm0
	vsubsd	240000(%rax,%rcx,8), %xmm11, %xmm11
	vfmadd231sd	%xmm6, %xmm2, %xmm5
	vfmadd132sd	%xmm7, %xmm0, %xmm11
	vsubsd	240016(%rax,%rcx,8), %xmm12, %xmm0
	vfmadd231sd	%xmm6, %xmm0, %xmm11
	vdivsd	%xmm4, %xmm5, %xmm5
	vxorpd	%xmm4, %xmm4, %xmm4
	vmovsd	%xmm4, %xmm4, %xmm1
	vcomisd	%xmm11, %xmm4
	ja	.L2040
	leaq	(%r10,%r10,2), %rcx
	salq	$4, %rcx
	leaq	239952+pos_(%rip), %r10
	vmovapd	(%r10,%rcx), %xmm2
	vmovsd	(%rax,%r9,8), %xmm0
	vsubpd	-48(%r10,%rcx), %xmm2, %xmm2
	vsubsd	%xmm12, %xmm0, %xmm0
	vmulsd	%xmm11, %xmm11, %xmm11
	vmulpd	%xmm2, %xmm2, %xmm2
	vunpckhpd	%xmm2, %xmm2, %xmm1
	vaddpd	%xmm2, %xmm1, %xmm2
	vfmadd132sd	%xmm0, %xmm2, %xmm0
	vmulsd	%xmm0, %xmm3, %xmm1
	vdivsd	%xmm1, %xmm11, %xmm1
.L2040:
	vmovsd	240000(%rax,%r8,8), %xmm0
	vmovsd	240000(%rax,%rdx,8), %xmm2
	vsubsd	239960(%rax,%rdx,8), %xmm0, %xmm0
	vsubsd	239952(%rax,%rdx,8), %xmm2, %xmm2
	vmovsd	239968(%rax,%rdx,8), %xmm11
	vmulsd	%xmm8, %xmm0, %xmm8
	vfmadd132sd	%xmm2, %xmm8, %xmm7
	vmovsd	240000(%rax,%rdi,8), %xmm2
	vsubsd	%xmm11, %xmm2, %xmm2
	vfmadd132sd	%xmm6, %xmm7, %xmm2
	vcomisd	%xmm2, %xmm4
	ja	.L2041
	leaq	(%rsi,%rsi,2), %rcx
	salq	$4, %rcx
	leaq	239952+pos_(%rip), %rsi
	vmovapd	(%rsi,%rcx), %xmm0
	vmulsd	%xmm2, %xmm2, %xmm2
	vsubpd	-48(%rsi,%rcx), %xmm0, %xmm0
	vmulpd	%xmm0, %xmm0, %xmm0
	vunpckhpd	%xmm0, %xmm0, %xmm4
	vaddpd	%xmm0, %xmm4, %xmm0
	vmovsd	240016(%rax,%rdx,8), %xmm4
	vsubsd	%xmm11, %xmm4, %xmm4
	vfmadd132sd	%xmm4, %xmm0, %xmm4
	vmulsd	%xmm4, %xmm3, %xmm4
	vdivsd	%xmm4, %xmm2, %xmm4
.L2041:
	vunpcklpd	%xmm9, %xmm5, %xmm5
	vandpd	.LC139(%rip), %xmm5, %xmm5
	vandpd	.LC69(%rip), %xmm10, %xmm10
	movq	%rsp, %r13
	movq	%r13, %rdx
	movq	%rbp, %rsi
	movq	%r12, %rdi
	vmovupd	%xmm5, 8+nmapi_(%rip)
	vmovsd	%xmm10, 24+nmapi_(%rip)
	vmovsd	%xmm1, 32+nmapi_(%rip)
	vmovsd	%xmm4, 40+nmapi_(%rip)
	movq	$0x000000000, (%rsp)
	call	countpid_
	vmovsd	(%rsp), %xmm0
	movq	%r13, %rdx
	movq	%r12, %rsi
	movq	%rbp, %rdi
	vmovsd	%xmm0, 48+nmapi_(%rip)
	movq	$0x000000000, (%rsp)
	call	countpid_
	vmovsd	(%rsp), %xmm0
	vmovsd	%xmm0, 56+nmapi_(%rip)
	movq	8(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L2047
	addq	$16, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 32
	popq	%rbp
	.cfi_def_cfa_offset 24
	popq	%r12
	.cfi_def_cfa_offset 16
	popq	%r13
	.cfi_def_cfa_offset 8
	ret
.L2047:
	.cfi_restore_state
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE38:
	.size	compute_details_, .-compute_details_
	.section	.rodata.str1.1
.LC140:
	.string	"(a,i9)"
.LC141:
	.string	"# number of contacts"
.LC142:
	.string	"(5(a,f9.4))"
.LC143:
	.string	"bbij "
.LC144:
	.string	" sdchnmax^2 "
.LC145:
	.string	" ssPID "
.LC146:
	.string	" bbPID1 "
.LC147:
	.string	" bbPID2 "
.LC148:
	.string	"(2a)"
	.section	.rodata.str1.8
	.align 8
.LC149:
	.string	"         time i j nr type Ri Rj r bbir bbjr "
	.align 8
.LC150:
	.string	"bbij sdchni^2 sdchnj^2 conttype"
	.align 8
.LC151:
	.string	"(a,i9,2i6,i9,i4,x,a,x,a,7f7.3,i4,2f7.3,2i3,i7)"
	.section	.rodata.str1.1
.LC152:
	.string	"K"
.LC153:
	.string	"(a,i9,2i5,i9,i3,x,a,x,a,f7.3)"
.LC154:
	.string	"A"
.LC155:
	.string	"(a,i9,2f8.4,x,a)"
	.text
	.p2align 4
	.globl	print_map_
	.type	print_map_, @function
print_map_:
.LFB10:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	leaq	cmp2_(%rip), %rcx
	vxorps	%xmm4, %xmm4, %xmm4
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$648, %rsp
	.cfi_def_cfa_offset 704
	movq	%rdi, 8(%rsp)
	movq	%rsi, 64(%rsp)
	movl	60000004(%rcx), %edi
	movq	%fs:40, %rax
	movq	%rax, 632(%rsp)
	xorl	%eax, %eax
	movl	$0, 4064+nmapi_(%rip)
	testl	%edi, %edi
	jle	.L2087
	movslq	540000008(%rcx), %rax
	movl	36+kier_(%rip), %r15d
	imulq	$15000000, %rax, %rsi
	vmovsd	240024+for_(%rip), %xmm12
	vmovsd	240000+for_(%rip), %xmm11
	movq	%rsi, %rax
	salq	$4, %rax
	leaq	-179999992(%rcx,%rax), %rdx
	leal	-1(%rdi), %eax
	addq	%rsi, %rax
	salq	$4, %rax
	leaq	-179999976(%rcx,%rax), %r12
	leaq	sig_(%rip), %rax
	movq	%rax, (%rsp)
	movl	40+kier_(%rip), %r14d
	vmovsd	240032+for_(%rip), %xmm10
	vmovsd	240008+for_(%rip), %xmm9
	movl	44+kier_(%rip), %r13d
	vmovsd	240040+for_(%rip), %xmm8
	vmovsd	240016+for_(%rip), %xmm7
	vmovsd	cmapi_(%rip), %xmm6
	vmovsd	.LC11(%rip), %xmm5
	xorl	%r9d, %r9d
	leaq	pos_(%rip), %rax
	leaq	nmapi_(%rip), %r11
	jmp	.L2055
	.p2align 4,,10
	.p2align 3
.L2122:
	xorl	%ebx, %ebx
	cmpl	$1, %ecx
	setg	%bl
	movl	%ecx, %ebp
.L2050:
	movq	(%rsp), %rsi
	decl	%ecx
	movslq	%ecx, %rcx
	vmovsd	(%rsi,%rcx,8), %xmm3
	movslq	(%rdx), %rsi
	movslq	4(%rdx), %rcx
	vmovsd	-8(%rax,%rsi,8), %xmm1
	vmovsd	79992(%rax,%rsi,8), %xmm2
	vmovsd	159992(%rax,%rsi,8), %xmm0
	vsubsd	-8(%rax,%rcx,8), %xmm1, %xmm1
	vsubsd	79992(%rax,%rcx,8), %xmm2, %xmm2
	vsubsd	159992(%rax,%rcx,8), %xmm0, %xmm0
	movq	%rsi, %r8
	movq	%rcx, %r10
	testl	%r15d, %r15d
	je	.L2051
	vmulsd	%xmm1, %xmm12, %xmm14
	vmovsd	.LC60(%rip), %xmm13
	vandpd	%xmm14, %xmm5, %xmm15
	vorpd	%xmm15, %xmm13, %xmm13
	vaddsd	%xmm14, %xmm13, %xmm13
	vcvttsd2sil	%xmm13, %ecx
	vcvtsi2sdl	%ecx, %xmm4, %xmm13
	vfnmadd231sd	%xmm13, %xmm11, %xmm1
.L2051:
	testl	%r14d, %r14d
	je	.L2052
	vmulsd	%xmm2, %xmm10, %xmm14
	vmovsd	.LC60(%rip), %xmm13
	vandpd	%xmm14, %xmm5, %xmm15
	vorpd	%xmm15, %xmm13, %xmm13
	vaddsd	%xmm14, %xmm13, %xmm13
	vcvttsd2sil	%xmm13, %ecx
	vcvtsi2sdl	%ecx, %xmm4, %xmm13
	vfnmadd231sd	%xmm13, %xmm9, %xmm2
.L2052:
	testl	%r13d, %r13d
	je	.L2053
	vmulsd	%xmm0, %xmm8, %xmm14
	vmovsd	.LC60(%rip), %xmm13
	vandpd	%xmm14, %xmm5, %xmm15
	vorpd	%xmm15, %xmm13, %xmm13
	vaddsd	%xmm14, %xmm13, %xmm13
	vcvttsd2sil	%xmm13, %ecx
	vcvtsi2sdl	%ecx, %xmm4, %xmm13
	vfnmadd231sd	%xmm13, %xmm7, %xmm0
.L2053:
	vmulsd	%xmm2, %xmm2, %xmm2
	vmulsd	%xmm3, %xmm6, %xmm3
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vmulsd	%xmm3, %xmm3, %xmm3
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vcomisd	%xmm0, %xmm3
	jb	.L2054
	testl	%ebx, %ebx
	je	.L2054
	movslq	%r9d, %rcx
	leaq	(%rcx,%rcx,4), %rcx
	vmovd	%r8d, %xmm3
	movl	$0, 4076(%r11,%rcx,4)
	movl	%ebp, 4080(%r11,%rcx,4)
	movl	%edi, 4084(%r11,%rcx,4)
	vpinsrd	$1, %r10d, %xmm3, %xmm0
	vmovq	%xmm0, 4068(%r11,%rcx,4)
	incl	%r9d
.L2054:
	addq	$16, %rdx
	cmpq	%r12, %rdx
	je	.L2121
.L2055:
	movl	12(%rdx), %edi
	movl	%edi, %esi
	sarl	$31, %esi
	movl	%esi, %ecx
	xorl	%edi, %ecx
	subl	%esi, %ecx
	cmpl	$8, %ecx
	jle	.L2122
	movl	$1, %ebx
	movl	$5, %ebp
	jmp	.L2050
	.p2align 4,,10
	.p2align 3
.L2121:
	movl	%r9d, 4064+nmapi_(%rip)
.L2049:
	movl	cmp2_(%rip), %eax
	testl	%eax, %eax
	jle	.L2056
	vmovsd	cmapi_(%rip), %xmm12
	decl	%eax
	vmulsd	80024+ssb_(%rip), %xmm12, %xmm11
	leaq	4+cmp2_(%rip), %rdx
	leaq	(%rax,%rax,2), %rcx
	leaq	12(%rdx), %rax
	leaq	(%rax,%rcx,4), %r15
	vmulsd	%xmm11, %xmm11, %xmm11
	movl	36+kier_(%rip), %ebp
	vmovsd	240024+for_(%rip), %xmm10
	vmovsd	240000+for_(%rip), %xmm9
	movl	40+kier_(%rip), %ebx
	vmovsd	240032+for_(%rip), %xmm8
	vmovsd	240008+for_(%rip), %xmm7
	movl	44+kier_(%rip), %r11d
	vmovsd	240040+for_(%rip), %xmm6
	vmovsd	240016+for_(%rip), %xmm5
	vmovsd	.LC11(%rip), %xmm3
	leaq	pos_(%rip), %rax
	leaq	nmapi_(%rip), %r10
	leaq	cmap_(%rip), %r14
	jmp	.L2068
	.p2align 4,,10
	.p2align 3
.L2124:
	movslq	%r12d, %r8
	leaq	15000001(%r8,%r8,2), %rdi
	movl	(%r14,%rdi,4), %edi
	leal	630(%rdi), %r13d
	cmpl	$1260, %r13d
	ja	.L2061
	leaq	sig_(%rip), %r13
	vmulsd	4000(%r13,%r8,8), %xmm12, %xmm1
	vmulsd	%xmm1, %xmm1, %xmm1
	vcomisd	%xmm2, %xmm1
	jb	.L2061
	movslq	%r9d, %r8
	leaq	(%r8,%r8,4), %r8
	movl	%esi, 4068(%r10,%r8,4)
	movl	%edi, %esi
	sarl	$31, %esi
	movl	%ecx, 4072(%r10,%r8,4)
	movl	%esi, %ecx
	xorl	%edi, %ecx
	xorl	%r12d, %edi
	sarl	$31, %edi
	addl	%edi, %r12d
	subl	%esi, %ecx
	xorl	%r12d, %edi
	movl	%ecx, 4076(%r10,%r8,4)
	movl	$0, 4080(%r10,%r8,4)
	movl	%edi, 4084(%r10,%r8,4)
	incl	%r9d
	.p2align 4,,10
	.p2align 3
.L2061:
	addq	$12, %rdx
	cmpq	%r15, %rdx
	je	.L2123
.L2068:
	movslq	(%rdx), %r13
	movslq	4(%rdx), %r12
	leaq	-1(%r13), %rdi
	vmovsd	(%rax,%rdi,8), %xmm0
	vmovsd	79992(%rax,%r13,8), %xmm1
	vmovsd	159992(%rax,%r13,8), %xmm2
	vsubsd	-8(%rax,%r12,8), %xmm0, %xmm0
	vsubsd	79992(%rax,%r12,8), %xmm1, %xmm1
	vsubsd	159992(%rax,%r12,8), %xmm2, %xmm2
	movq	%r13, %rsi
	movq	%r12, %rcx
	leaq	-1(%r12), %r8
	testl	%ebp, %ebp
	je	.L2057
	vmulsd	%xmm0, %xmm10, %xmm14
	vmovsd	.LC60(%rip), %xmm13
	vandpd	%xmm14, %xmm3, %xmm15
	vorpd	%xmm15, %xmm13, %xmm13
	vaddsd	%xmm14, %xmm13, %xmm13
	vcvttsd2sil	%xmm13, %r12d
	vcvtsi2sdl	%r12d, %xmm4, %xmm13
	vfnmadd231sd	%xmm9, %xmm13, %xmm0
.L2057:
	testl	%ebx, %ebx
	je	.L2058
	vmulsd	%xmm1, %xmm8, %xmm14
	vmovsd	.LC60(%rip), %xmm13
	vandpd	%xmm14, %xmm3, %xmm15
	vorpd	%xmm15, %xmm13, %xmm13
	vaddsd	%xmm14, %xmm13, %xmm13
	vcvttsd2sil	%xmm13, %r12d
	vcvtsi2sdl	%r12d, %xmm4, %xmm13
	vfnmadd231sd	%xmm7, %xmm13, %xmm1
.L2058:
	testl	%r11d, %r11d
	je	.L2059
	vmulsd	%xmm2, %xmm6, %xmm14
	vmovsd	.LC60(%rip), %xmm13
	vandpd	%xmm14, %xmm3, %xmm15
	vorpd	%xmm15, %xmm13, %xmm13
	vaddsd	%xmm14, %xmm13, %xmm13
	vcvttsd2sil	%xmm13, %r12d
	vcvtsi2sdl	%r12d, %xmm4, %xmm13
	vfnmadd231sd	%xmm5, %xmm13, %xmm2
.L2059:
	vmulsd	%xmm1, %xmm1, %xmm1
	movl	8(%rdx), %r12d
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vfmadd132sd	%xmm2, %xmm0, %xmm2
	testl	%r12d, %r12d
	jg	.L2124
	leal	3(%r12), %r13d
	cmpl	$1, %r13d
	ja	.L2061
	vcomisd	%xmm2, %xmm11
	jb	.L2061
	leal	1(%r9), %r13d
	movslq	%r9d, %r9
	leaq	(%r9,%r9,4), %r9
	movl	%r13d, (%rsp)
	leaq	3(%r9), %r13
	cmpl	$-3, %r12d
	movq	%r13, 16(%rsp)
	movl	$-88, %r12d
	movl	$88, %r13d
	cmovne	%r13d, %r12d
	movl	%esi, 4068(%r10,%r9,4)
	movl	%r12d, 4084(%r10,%r9,4)
	leaq	ssb_(%rip), %r12
	movl	40000(%r12,%rdi,4), %r13d
	movl	%ecx, 4072(%r10,%r9,4)
	movl	$-1, 4076(%r10,%r9,4)
	movl	$-1, 4080(%r10,%r9,4)
	testl	%r13d, %r13d
	je	.L2125
	leaq	ssb_(%rip), %r9
	cmpl	%ecx, (%r9,%rdi,4)
	je	.L2126
.L2067:
	movq	16(%rsp), %rcx
	addq	$12, %rdx
	movl	$2, 4068(%r10,%rcx,4)
	movl	(%rsp), %r9d
	cmpq	%r15, %rdx
	jne	.L2068
	.p2align 4,,10
	.p2align 3
.L2123:
	movl	%r9d, 4064+nmapi_(%rip)
.L2056:
	movq	8(%rsp), %r15
	leaq	.LC140(%rip), %rax
	leaq	96(%rsp), %rbp
	movq	%rax, 176(%rsp)
	movl	(%r15), %eax
	leaq	.LC2(%rip), %rbx
	movq	%rbp, %rdi
	movl	%eax, 100(%rsp)
	movq	%rbx, 104(%rsp)
	movl	$6414, 112(%rsp)
	movq	$6, 184(%rsp)
	movl	$4096, 96(%rsp)
	call	_gfortran_st_write@PLT
	movl	$20, %edx
	leaq	.LC141(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	leaq	4064+nmapi_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC142(%rip), %rax
	movq	%rax, 176(%rsp)
	movl	(%r15), %eax
	movq	%rbp, %rdi
	movl	%eax, 100(%rsp)
	movq	%rbx, 104(%rsp)
	movl	$6416, 112(%rsp)
	movq	$11, 184(%rsp)
	movl	$4096, 96(%rsp)
	call	_gfortran_st_write@PLT
	movl	$5, %edx
	leaq	.LC143(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	leaq	restr_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$12, %edx
	leaq	.LC144(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	leaq	16+restr_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$7, %edx
	leaq	.LC145(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	leaq	40+pid_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	.LC146(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	leaq	48+pid_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	.LC147(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	leaq	56+pid_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC148(%rip), %rax
	movq	%rax, 176(%rsp)
	movl	(%r15), %eax
	movq	%rbp, %rdi
	movl	%eax, 100(%rsp)
	movq	%rbx, 104(%rsp)
	movl	$6418, 112(%rsp)
	movq	$4, 184(%rsp)
	movl	$4096, 96(%rsp)
	call	_gfortran_st_write@PLT
	movl	$44, %edx
	leaq	.LC149(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$31, %edx
	leaq	.LC150(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	movl	4064+nmapi_(%rip), %eax
	vxorps	%xmm4, %xmm4, %xmm4
	testl	%eax, %eax
	movl	%eax, 76(%rsp)
	jle	.L2079
	leaq	sig_(%rip), %rax
	movq	%rax, (%rsp)
	leaq	80(%rsp), %rax
	movq	%rax, 16(%rsp)
	leaq	4080+nmapi_(%rip), %r14
	movl	$1, %r13d
	leaq	84(%rsp), %r15
	leaq	88(%rsp), %r12
	leaq	sequence_(%rip), %rbx
	jmp	.L2080
	.p2align 4,,10
	.p2align 3
.L2128:
	vmulsd	4008(%rcx,%rax,8), %xmm0, %xmm0
.L2073:
	movl	-12(%r14), %eax
	movl	-8(%r14), %r9d
	movl	10004068+nmapi_(%rip), %edi
	movl	%eax, 80(%rsp)
	movl	%r9d, 84(%rsp)
	testl	%edi, %edi
	jne	.L2127
	movslq	%eax, %rdi
	leaq	pos_(%rip), %rdx
	leaq	-1(%rdi), %r10
	vmovsd	(%rdx,%r10,8), %xmm1
	vmovsd	79992(%rdx,%rdi,8), %xmm2
	vmovsd	159992(%rdx,%rdi,8), %xmm0
	movslq	%r9d, %rsi
	vsubsd	-8(%rdx,%rsi,8), %xmm1, %xmm1
	vsubsd	79992(%rdx,%rsi,8), %xmm2, %xmm2
	vsubsd	159992(%rdx,%rsi,8), %xmm0, %xmm0
	leaq	-1(%rsi), %r11
	movl	36+kier_(%rip), %esi
	testl	%esi, %esi
	je	.L2076
	vmulsd	240024+for_(%rip), %xmm1, %xmm6
	vmovsd	.LC11(%rip), %xmm5
	vmovsd	.LC60(%rip), %xmm3
	vandpd	%xmm6, %xmm5, %xmm5
	vorpd	%xmm5, %xmm3, %xmm3
	vaddsd	%xmm6, %xmm3, %xmm3
	vcvttsd2sil	%xmm3, %edx
	vcvtsi2sdl	%edx, %xmm4, %xmm3
	vfnmadd231sd	240000+for_(%rip), %xmm3, %xmm1
.L2076:
	movl	40+kier_(%rip), %ecx
	testl	%ecx, %ecx
	je	.L2077
	vmulsd	240032+for_(%rip), %xmm2, %xmm5
	vmovsd	.LC90(%rip), %xmm7
	vmovsd	.LC60(%rip), %xmm3
	vandpd	%xmm5, %xmm7, %xmm6
	vorpd	%xmm6, %xmm3, %xmm3
	vaddsd	%xmm5, %xmm3, %xmm3
	vcvttsd2sil	%xmm3, %edx
	vcvtsi2sdl	%edx, %xmm4, %xmm3
	vfnmadd231sd	240008+for_(%rip), %xmm3, %xmm2
.L2077:
	movl	44+kier_(%rip), %edx
	testl	%edx, %edx
	je	.L2078
	vmulsd	240040+for_(%rip), %xmm0, %xmm6
	vmovsd	.LC11(%rip), %xmm5
	vmovsd	.LC60(%rip), %xmm3
	vandpd	%xmm6, %xmm5, %xmm5
	vorpd	%xmm5, %xmm3, %xmm3
	vaddsd	%xmm6, %xmm3, %xmm3
	vcvttsd2sil	%xmm3, %edx
	vcvtsi2sdl	%edx, %xmm4, %xmm3
	vfnmadd231sd	240016+for_(%rip), %xmm3, %xmm0
.L2078:
	vmulsd	%xmm2, %xmm2, %xmm2
	movl	%eax, 32(%rsp)
	leaq	.LC2(%rip), %rax
	movq	%rax, 104(%rsp)
	leaq	.LC153(%rip), %rax
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	movq	%rax, 176(%rsp)
	movq	8(%rsp), %rax
	movq	%rbp, %rdi
	movl	(%rax), %edx
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	movq	%r11, 56(%rsp)
	movq	%r10, 48(%rsp)
	movl	%r9d, 40(%rsp)
	movl	%edx, 100(%rsp)
	vsqrtsd	%xmm0, %xmm0, %xmm0
	movl	$6443, 112(%rsp)
	movq	$29, 184(%rsp)
	vmovsd	%xmm0, 24(%rsp)
	movl	$4096, 96(%rsp)
	call	_gfortran_st_write@PLT
	movl	$1, %edx
	leaq	.LC152(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	64(%rsp), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	16(%rsp), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	movq	%r15, %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	32(%rsp), %eax
	movl	40(%rsp), %r9d
	imull	8+bas_(%rip), %eax
	movl	$4, %edx
	movq	%r12, %rsi
	addl	%eax, %r9d
	movq	%rbp, %rdi
	movl	%r9d, 88(%rsp)
	call	_gfortran_transfer_integer_write@PLT
	movq	%r14, %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	48(%rsp), %r10
	movl	$3, %edx
	leaq	80000(%r10,%r10,2), %rsi
	addq	%rbx, %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	56(%rsp), %r11
	movl	$3, %edx
	leaq	80000(%r11,%r11,2), %rsi
	addq	%rbx, %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	vmovsd	24(%rsp), %xmm0
	leaq	bas_(%rip), %rax
	vmulsd	(%rax), %xmm0, %xmm0
	movl	$8, %edx
	movq	%r12, %rsi
	movq	%rbp, %rdi
	incl	%r13d
	vmovsd	%xmm0, 88(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	addq	$20, %r14
	vxorps	%xmm4, %xmm4, %xmm4
	cmpl	%r13d, 76(%rsp)
	jl	.L2079
.L2080:
	movl	4(%r14), %eax
	movl	(%r14), %r8d
	cltd
	xorl	%edx, %eax
	subl	%edx, %eax
	decl	%eax
	vmovsd	72+pid_(%rip), %xmm0
	movq	(%rsp), %rcx
	cltq
	testl	%r8d, %r8d
	je	.L2128
	vmulsd	(%rcx,%rax,8), %xmm0, %xmm0
	jmp	.L2073
	.p2align 4,,10
	.p2align 3
.L2127:
	movq	16(%rsp), %rdi
	movq	%r15, %rsi
	vmovsd	%xmm0, 40(%rsp)
	call	compute_details_
	leaq	.LC2(%rip), %rax
	movq	%rax, 104(%rsp)
	leaq	.LC151(%rip), %rax
	movq	%rax, 176(%rsp)
	movq	8(%rsp), %rax
	movq	%rbp, %rdi
	movl	(%rax), %eax
	movl	$6433, 112(%rsp)
	movl	%eax, 100(%rsp)
	movq	$46, 184(%rsp)
	movl	$4096, 96(%rsp)
	call	_gfortran_st_write@PLT
	movl	$1, %edx
	leaq	.LC152(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	64(%rsp), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	16(%rsp), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	movq	%r15, %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	80(%rsp), %r9d
	movl	84(%rsp), %eax
	movl	%r9d, %edx
	imull	8+bas_(%rip), %edx
	movq	%r12, %rsi
	movq	%rbp, %rdi
	addl	%eax, %edx
	movl	%edx, 88(%rsp)
	movl	$4, %edx
	movl	%eax, 24(%rsp)
	movl	%r9d, 32(%rsp)
	call	_gfortran_transfer_integer_write@PLT
	movq	%r14, %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movslq	32(%rsp), %rdx
	movq	%rbp, %rdi
	leaq	79997(%rdx,%rdx,2), %rsi
	leaq	-1(%rdx), %r9
	addq	%rbx, %rsi
	movl	$3, %edx
	movq	%r9, 32(%rsp)
	call	_gfortran_transfer_character_write@PLT
	movslq	24(%rsp), %rdx
	movq	%rbp, %rdi
	leaq	79997(%rdx,%rdx,2), %rsi
	leaq	-1(%rdx), %rax
	addq	%rbx, %rsi
	movl	$3, %edx
	movq	%rax, 24(%rsp)
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	leaq	nmapi_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	8+nmapi_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	16+nmapi_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	24+nmapi_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	32+nmapi_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	40+nmapi_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	vmovsd	40(%rsp), %xmm0
	leaq	bas_(%rip), %rax
	vmulsd	(%rax), %xmm0, %xmm0
	movl	$8, %edx
	movq	%r12, %rsi
	movq	%rbp, %rdi
	incl	%r13d
	vmovsd	%xmm0, 88(%rsp)
	call	_gfortran_transfer_real_write@PLT
	leaq	-4(%r14), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$8, %edx
	leaq	48+nmapi_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$8, %edx
	leaq	56+nmapi_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	32(%rsp), %r9
	leaq	neigh_(%rip), %r10
	leaq	(%r10,%r9,8), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	24(%rsp), %rax
	leaq	neigh_(%rip), %r10
	leaq	(%r10,%rax,8), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	leaq	4(%r14), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	addq	$20, %r14
	vxorps	%xmm4, %xmm4, %xmm4
	cmpl	%r13d, 76(%rsp)
	jge	.L2080
.L2079:
	movq	8(%rsp), %rax
	movl	80028+chiral_(%rip), %r9d
	movl	(%rax), %eax
	testl	%r9d, %r9d
	je	.L2071
	movl	80016+chiral_(%rip), %r11d
	movl	8+bas_(%rip), %edx
	testl	%r11d, %r11d
	je	.L2081
	cmpl	$4, %edx
	jle	.L2071
	leaq	16+angtemp_(%rip), %r14
	leal	-5(%rdx), %ecx
	movq	64(%rsp), %r13
	leaq	8(%r14), %rdx
	leaq	80000+bon_(%rip), %rbx
	leaq	(%rdx,%rcx,8), %r15
	leaq	.LC154(%rip), %r12
	.p2align 4,,10
	.p2align 3
.L2083:
	movl	(%rbx), %r10d
	testl	%r10d, %r10d
	je	.L2082
	movl	4(%rbx), %r9d
	testl	%r9d, %r9d
	je	.L2082
	movl	8(%rbx), %r8d
	testl	%r8d, %r8d
	jne	.L2129
	.p2align 4,,10
	.p2align 3
.L2082:
	addq	$8, %r14
	addq	$4, %rbx
	cmpq	%r15, %r14
	jne	.L2083
.L2071:
	leaq	.LC2(%rip), %rbx
	movq	%rbp, %rdi
	movl	%eax, 100(%rsp)
	movq	%rbx, 104(%rsp)
	movl	$6468, 112(%rsp)
	movl	$128, 96(%rsp)
	call	_gfortran_st_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	movq	8(%rsp), %rax
	movq	%rbp, %rdi
	movl	(%rax), %eax
	movq	%rbx, 104(%rsp)
	movl	%eax, 100(%rsp)
	movl	$6469, 112(%rsp)
	movl	$128, 96(%rsp)
	call	_gfortran_st_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	movq	632(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L2130
	addq	$648, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L2125:
	.cfi_restore_state
	movl	40000(%r12,%r8,4), %r12d
	movl	(%rsp), %r9d
	testl	%r12d, %r12d
	je	.L2061
	leaq	ssb_(%rip), %r9
	cmpl	%ecx, (%r9,%rdi,4)
	jne	.L2067
	jmp	.L2126
	.p2align 4,,10
	.p2align 3
.L2081:
	cmpl	$4, %edx
	jle	.L2071
	leaq	16+angtemp_(%rip), %r12
	leal	-5(%rdx), %ecx
	movq	64(%rsp), %r13
	leaq	8(%r12), %rdx
	leaq	(%rdx,%rcx,8), %r15
	leaq	80000+bon_(%rip), %rbx
	leaq	80006+sequence_(%rip), %r14
	leaq	.LC155(%rip), %rcx
	.p2align 4,,10
	.p2align 3
.L2085:
	movl	(%rbx), %edi
	testl	%edi, %edi
	je	.L2084
	movl	4(%rbx), %esi
	testl	%esi, %esi
	je	.L2084
	movl	8(%rbx), %edx
	testl	%edx, %edx
	jne	.L2131
	.p2align 4,,10
	.p2align 3
.L2084:
	addq	$8, %r12
	addq	$4, %rbx
	addq	$3, %r14
	cmpq	%r15, %r12
	jne	.L2085
	jmp	.L2071
	.p2align 4,,10
	.p2align 3
.L2126:
	cmpl	%esi, (%r9,%r8,4)
	jne	.L2067
	movq	16(%rsp), %rcx
	movl	(%rsp), %r9d
	movl	$3, 4068(%r10,%rcx,4)
	jmp	.L2061
	.p2align 4,,10
	.p2align 3
.L2129:
	leaq	.LC2(%rip), %rcx
	movq	%rbp, %rdi
	movl	%eax, 100(%rsp)
	movq	%rcx, 104(%rsp)
	movl	$6451, 112(%rsp)
	movl	$128, 96(%rsp)
	call	_gfortran_st_write@PLT
	movl	$1, %edx
	movq	%r12, %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	movq	%r13, %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$8, %edx
	movq	%r14, %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	80000(%r14), %rsi
	movl	$8, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	159992(%r14), %rsi
	movl	$8, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	movq	8(%rsp), %rax
	movl	(%rax), %eax
	jmp	.L2082
	.p2align 4,,10
	.p2align 3
.L2131:
	leaq	.LC2(%rip), %rdi
	movq	%rdi, 104(%rsp)
	movq	%rbp, %rdi
	movq	%rcx, 176(%rsp)
	movl	%eax, 100(%rsp)
	movl	$6461, 112(%rsp)
	movq	$16, 184(%rsp)
	movl	$4096, 96(%rsp)
	call	_gfortran_st_write@PLT
	movl	$1, %edx
	leaq	.LC154(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	movq	%r13, %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$8, %edx
	movq	%r12, %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	80000(%r12), %rsi
	movl	$8, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$3, %edx
	movq	%r14, %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	movq	8(%rsp), %rax
	leaq	.LC155(%rip), %rcx
	movl	(%rax), %eax
	jmp	.L2084
	.p2align 4,,10
	.p2align 3
.L2087:
	xorl	%r9d, %r9d
	jmp	.L2049
.L2130:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE10:
	.size	print_map_, .-print_map_
	.section	.rodata.str1.1
.LC156:
	.string	"(a,i7)"
	.section	.rodata.str1.8
	.align 8
.LC157:
	.string	" time i j nr type Ri Rj r, length = "
	.text
	.p2align 4
	.globl	print_cmap_
	.type	print_cmap_, @function
print_cmap_:
.LFB40:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	leaq	.LC2(%rip), %r15
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movq	%rdi, %r14
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	leaq	cmap_(%rip), %rbx
	subq	$632, %rsp
	.cfi_def_cfa_offset 688
	movq	%rsi, 8(%rsp)
	leaq	80(%rsp), %rbp
	movq	%fs:40, %rax
	movq	%rax, 616(%rsp)
	xorl	%eax, %eax
	leaq	.LC140(%rip), %rax
	movq	%rax, 160(%rsp)
	movl	(%rdi), %eax
	movq	%rbp, %rdi
	movl	%eax, 84(%rsp)
	movq	%r15, 88(%rsp)
	movl	$6284, 96(%rsp)
	movq	$6, 168(%rsp)
	movl	$4096, 80(%rsp)
	call	_gfortran_st_write@PLT
	movl	$20, %edx
	leaq	.LC141(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	leaq	60000004(%rbx), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC156(%rip), %rax
	movq	%rax, 160(%rsp)
	movl	(%r14), %eax
	movq	%rbp, %rdi
	movl	%eax, 84(%rsp)
	movq	%r15, 88(%rsp)
	movl	$6285, 96(%rsp)
	movq	$6, 168(%rsp)
	movl	$4096, 80(%rsp)
	call	_gfortran_st_write@PLT
	movl	$36, %edx
	leaq	.LC157(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	leaq	8+bas_(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	movl	60000004(%rbx), %eax
	movl	%eax, 44(%rsp)
	testl	%eax, %eax
	jle	.L2136
	leaq	64(%rsp), %rax
	movq	%rax, 48(%rsp)
	leaq	68(%rsp), %rax
	leaq	60000016(%rbx), %r13
	movl	$1, %r15d
	movq	%rax, 56(%rsp)
	leaq	72(%rsp), %rax
	movq	%r14, 32(%rsp)
	movq	%r15, %r14
	movq	%r13, %r15
	movq	%rax, %r13
	.p2align 4,,10
	.p2align 3
.L2137:
	leaq	4000+sig_(%rip), %rax
	vmovsd	(%rax,%r14,8), %xmm1
	leaq	.LC2(%rip), %rax
	movq	%rax, 88(%rsp)
	leaq	.LC153(%rip), %rax
	movq	%rax, 160(%rsp)
	movq	32(%rsp), %rax
	vmovsd	72+pid_(%rip), %xmm0
	movl	(%rax), %edx
	movslq	-8(%r15), %r12
	movslq	-4(%r15), %rbx
	movq	%rbp, %rdi
	vmovsd	%xmm1, 16(%rsp)
	vmovsd	%xmm0, 24(%rsp)
	movl	%r12d, 64(%rsp)
	movl	%edx, 84(%rsp)
	movl	%ebx, 68(%rsp)
	movl	$6291, 96(%rsp)
	movq	$29, 168(%rsp)
	movl	$4096, 80(%rsp)
	call	_gfortran_st_write@PLT
	movl	$1, %edx
	leaq	.LC152(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	8(%rsp), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	48(%rsp), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	56(%rsp), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	8+bas_(%rip), %edx
	movq	%r13, %rsi
	imull	%r12d, %edx
	movq	%rbp, %rdi
	incq	%r14
	addl	%ebx, %edx
	movl	%edx, 72(%rsp)
	movl	$4, %edx
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	leaq	79997(%r12,%r12,2), %rsi
	leaq	sequence_(%rip), %r12
	addq	%r12, %rsi
	movl	$3, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	79997(%rbx,%rbx,2), %rsi
	addq	%r12, %rsi
	movl	$3, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	vmovsd	24(%rsp), %xmm0
	leaq	bas_(%rip), %rax
	vmulsd	(%rax), %xmm0, %xmm0
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%rbp, %rdi
	addq	$12, %r15
	vmulsd	16(%rsp), %xmm0, %xmm0
	vmovsd	%xmm0, 72(%rsp)
	call	_gfortran_transfer_real_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	cmpl	%r14d, 44(%rsp)
	jge	.L2137
	movq	32(%rsp), %r14
.L2136:
	movl	8+bas_(%rip), %eax
	leaq	angnat_(%rip), %rbx
	movl	%eax, 16(%rsp)
	leaq	80000+sequence_(%rip), %r12
	movl	$1, %r15d
	leaq	.LC154(%rip), %r13
	testl	%eax, %eax
	jle	.L2134
	.p2align 4,,10
	.p2align 3
.L2138:
	movl	(%r14), %edx
	leaq	.LC2(%rip), %rax
	movq	%rax, 88(%rsp)
	movq	%rbp, %rdi
	leaq	.LC155(%rip), %rax
	movq	%rax, 160(%rsp)
	movl	%edx, 84(%rsp)
	movl	$6296, 96(%rsp)
	movq	$16, 168(%rsp)
	movl	$4096, 80(%rsp)
	call	_gfortran_st_write@PLT
	movl	$1, %edx
	movq	%r13, %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	8(%rsp), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%rbx, %rsi
	movl	$8, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	80000(%rbx), %rsi
	movl	$8, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rsi
	movl	$3, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	incl	%r15d
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	addq	$8, %rbx
	addq	$3, %r12
	cmpl	%r15d, 16(%rsp)
	jge	.L2138
.L2134:
	movl	(%r14), %eax
	leaq	.LC2(%rip), %rbx
	movq	%rbp, %rdi
	movl	%eax, 84(%rsp)
	movq	%rbx, 88(%rsp)
	movl	$6299, 96(%rsp)
	movl	$128, 80(%rsp)
	call	_gfortran_st_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	movl	(%r14), %eax
	movq	%rbp, %rdi
	movl	%eax, 84(%rsp)
	movq	%rbx, 88(%rsp)
	movl	$6300, 96(%rsp)
	movl	$128, 80(%rsp)
	call	_gfortran_st_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	movq	616(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L2144
	addq	$632, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
.L2144:
	.cfi_restore_state
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE40:
	.size	print_cmap_, .-print_cmap_
	.p2align 4
	.globl	gopotential_
	.type	gopotential_, @function
gopotential_:
.LFB41:
	.cfi_startproc
	pushq	%r13
	.cfi_def_cfa_offset 16
	.cfi_offset 13, -16
	movl	$1600, %edx
	movq	%rdi, %r13
	pushq	%rbp
	.cfi_def_cfa_offset 24
	.cfi_offset 6, -24
	xorl	%esi, %esi
	leaq	histo.20(%rip), %rdi
	pushq	%rbx
	.cfi_def_cfa_offset 32
	.cfi_offset 3, -32
	subq	$16, %rsp
	.cfi_def_cfa_offset 48
	call	memset@PLT
	leaq	cmap_(%rip), %rax
	movl	60000004(%rax), %ebp
	testl	%ebp, %ebp
	jle	.L2154
	vmovsd	240040+for_(%rip), %xmm7
	leaq	4008+sig_(%rip), %rcx
	vmovsd	%xmm7, (%rsp)
	vmovsd	240016+for_(%rip), %xmm7
	leaq	60000012(%rax), %rdx
	vmovsd	%xmm7, 8(%rsp)
	vmovsd	bas_(%rip), %xmm7
	leal	-1(%rbp), %eax
	vaddsd	%xmm7, %xmm7, %xmm7
	leaq	8(%rcx), %rsi
	movl	36+kier_(%rip), %ebx
	vmovsd	240024+for_(%rip), %xmm15
	vmovsd	240000+for_(%rip), %xmm14
	movl	40+kier_(%rip), %r11d
	vmovsd	240032+for_(%rip), %xmm13
	vmovsd	240008+for_(%rip), %xmm12
	movl	44+kier_(%rip), %r10d
	vmovsd	.LC60(%rip), %xmm4
	vmovsd	.LC158(%rip), %xmm9
	vmovsd	.LC8(%rip), %xmm8
	vmovsd	.LC11(%rip), %xmm3
	leaq	(%rsi,%rax,8), %r9
	vxorps	%xmm6, %xmm6, %xmm6
	vxorpd	%xmm10, %xmm10, %xmm10
	leaq	nat_(%rip), %rax
	leaq	histo.20(%rip), %r8
	.p2align 4,,10
	.p2align 3
.L2153:
	movslq	-4(%rdx), %rdi
	movslq	(%rdx), %rsi
	vmovsd	-8(%rax,%rdi,8), %xmm1
	vmovsd	79992(%rax,%rdi,8), %xmm2
	vmovsd	159992(%rax,%rdi,8), %xmm0
	vsubsd	-8(%rax,%rsi,8), %xmm1, %xmm1
	vsubsd	79992(%rax,%rsi,8), %xmm2, %xmm2
	vsubsd	159992(%rax,%rsi,8), %xmm0, %xmm0
	testl	%ebx, %ebx
	je	.L2147
	vmulsd	%xmm1, %xmm15, %xmm11
	vandpd	%xmm11, %xmm3, %xmm5
	vorpd	%xmm5, %xmm4, %xmm5
	vaddsd	%xmm11, %xmm5, %xmm5
	vcvttsd2sil	%xmm5, %esi
	vcvtsi2sdl	%esi, %xmm6, %xmm5
	vfnmadd231sd	%xmm5, %xmm14, %xmm1
.L2147:
	testl	%r11d, %r11d
	je	.L2148
	vmulsd	%xmm2, %xmm13, %xmm11
	vandpd	%xmm11, %xmm3, %xmm5
	vorpd	%xmm5, %xmm4, %xmm5
	vaddsd	%xmm11, %xmm5, %xmm5
	vcvttsd2sil	%xmm5, %esi
	vcvtsi2sdl	%esi, %xmm6, %xmm5
	vfnmadd231sd	%xmm5, %xmm12, %xmm2
.L2148:
	testl	%r10d, %r10d
	je	.L2149
	vmulsd	(%rsp), %xmm0, %xmm11
	vandpd	%xmm11, %xmm3, %xmm5
	vorpd	%xmm5, %xmm4, %xmm5
	vaddsd	%xmm11, %xmm5, %xmm5
	vcvttsd2sil	%xmm5, %esi
	vcvtsi2sdl	%esi, %xmm6, %xmm5
	vfnmadd231sd	8(%rsp), %xmm5, %xmm0
.L2149:
	vmulsd	%xmm2, %xmm2, %xmm2
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmulsd	%xmm9, %xmm0, %xmm1
	vaddsd	%xmm0, %xmm10, %xmm10
	vmulsd	%xmm0, %xmm7, %xmm0
	vmovsd	%xmm1, (%rcx)
	vandpd	%xmm0, %xmm3, %xmm1
	vorpd	%xmm1, %xmm4, %xmm1
	vaddsd	%xmm0, %xmm1, %xmm0
	vcvttsd2sil	%xmm0, %esi
	testl	%esi, %esi
	je	.L2150
	movslq	%esi, %rsi
	vaddsd	-8(%r8,%rsi,8), %xmm8, %xmm0
	addq	$8, %rcx
	addq	$12, %rdx
	vmovsd	%xmm0, -8(%r8,%rsi,8)
	cmpq	%rcx, %r9
	jne	.L2153
.L2151:
	vcvtsi2sdl	%ebp, %xmm6, %xmm6
	vdivsd	%xmm6, %xmm10, %xmm6
	vmovsd	%xmm6, 0(%r13)
	addq	$16, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 32
	popq	%rbx
	.cfi_def_cfa_offset 24
	popq	%rbp
	.cfi_def_cfa_offset 16
	popq	%r13
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L2150:
	.cfi_restore_state
	vaddsd	(%r8), %xmm8, %xmm0
	addq	$8, %rcx
	addq	$12, %rdx
	vmovsd	%xmm0, (%r8)
	cmpq	%rcx, %r9
	jne	.L2153
	jmp	.L2151
.L2154:
	vxorpd	%xmm6, %xmm6, %xmm6
	vmovsd	%xmm6, 0(%r13)
	addq	$16, %rsp
	.cfi_def_cfa_offset 32
	popq	%rbx
	.cfi_def_cfa_offset 24
	popq	%rbp
	.cfi_def_cfa_offset 16
	popq	%r13
	.cfi_def_cfa_offset 8
	ret
	.cfi_endproc
.LFE41:
	.size	gopotential_, .-gopotential_
	.p2align 4
	.globl	compute_native_angles_
	.type	compute_native_angles_, @function
compute_native_angles_:
.LFB42:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$32, %rsp
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	movl	8+bas_(%rip), %edx
	movq	%fs:40, %rax
	movq	%rax, 24(%rsp)
	xorl	%eax, %eax
	cmpl	$2, %edx
	jle	.L2167
	leaq	nat_(%rip), %rbx
	subl	$3, %edx
	leaq	8(%rbx), %rax
	leaq	8+angnat_(%rip), %r14
	leaq	(%rax,%rdx,8), %r15
	leaq	four_(%rip), %r13
	leaq	16(%rsp), %r12
	.p2align 4,,10
	.p2align 3
.L2169:
	vmovsd	(%rbx), %xmm0
	movq	%r12, %rdi
	vmovsd	%xmm0, 0(%r13)
	vmovsd	80000(%rbx), %xmm0
	addq	$8, %rbx
	vmovsd	%xmm0, 32+four_(%rip)
	vmovsd	159992(%rbx), %xmm0
	addq	$8, %r14
	vmovsd	%xmm0, 64+four_(%rip)
	vmovsd	(%rbx), %xmm0
	vmovsd	%xmm0, 8+four_(%rip)
	vmovsd	80000(%rbx), %xmm0
	vmovsd	%xmm0, 40+four_(%rip)
	vmovsd	160000(%rbx), %xmm0
	vmovsd	%xmm0, 72+four_(%rip)
	vmovsd	8(%rbx), %xmm0
	vmovsd	%xmm0, 16+four_(%rip)
	vmovsd	80008(%rbx), %xmm0
	vmovsd	%xmm0, 48+four_(%rip)
	vmovsd	160008(%rbx), %xmm0
	vmovsd	%xmm0, 80+four_(%rip)
	call	bondangle_
	vmovsd	16(%rsp), %xmm0
	vmovsd	%xmm0, -8(%r14)
	cmpq	%r15, %rbx
	jne	.L2169
	movl	8+bas_(%rip), %eax
	cmpl	$3, %eax
	jle	.L2167
	leaq	nat_(%rip), %rbx
	subl	$4, %eax
	leaq	8(%rbx), %rcx
	leaq	80016+angnat_(%rip), %r12
	leaq	(%rcx,%rax,8), %r15
	leaq	8(%rsp), %r14
	.p2align 4,,10
	.p2align 3
.L2171:
	vmovsd	160016(%rbx), %xmm0
	movq	%r14, %rdi
	vmovhpd	160024(%rbx), %xmm0, %xmm1
	vmovupd	160000(%rbx), %xmm0
	vinsertf128	$0x1, %xmm1, %ymm0, %ymm0
	vmovsd	80016(%rbx), %xmm1
	vmovapd	%ymm0, 64+four_(%rip)
	vmovhpd	80024(%rbx), %xmm1, %xmm2
	vmovupd	80000(%rbx), %xmm1
	vinsertf128	$0x1, %xmm2, %ymm1, %ymm1
	vmovsd	16(%rbx), %xmm2
	vmovapd	%ymm1, 32+four_(%rip)
	vmovhpd	24(%rbx), %xmm2, %xmm3
	vmovupd	(%rbx), %xmm2
	vinsertf128	$0x1, %xmm3, %ymm2, %ymm2
	vmovapd	%ymm2, 0(%r13)
	vzeroupper
	call	dihedral_
	vmovsd	8(%rsp), %xmm0
	addq	$8, %rbx
	vmovsd	%xmm0, (%r12)
	addq	$8, %r12
	cmpq	%rbx, %r15
	jne	.L2171
.L2167:
	movq	24(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L2176
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
.L2176:
	.cfi_restore_state
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE42:
	.size	compute_native_angles_, .-compute_native_angles_
	.p2align 4
	.globl	model_chirality_
	.type	model_chirality_, @function
model_chirality_:
.LFB43:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	movl	8+bas_(%rip), %r8d
	cmpl	$1, %r8d
	jle	.L2184
	leal	-2(%r8), %eax
	cmpl	$5, %eax
	jbe	.L2248
	vmovsd	8+nat_(%rip), %xmm2
	vmovsd	80008+nat_(%rip), %xmm1
	vsubsd	nat_(%rip), %xmm2, %xmm0
	vmovsd	16+nat_(%rip), %xmm5
	vmovsd	80016+nat_(%rip), %xmm4
	vmovsd	%xmm0, xs.19(%rip)
	vsubsd	80000+nat_(%rip), %xmm1, %xmm0
	vsubsd	%xmm2, %xmm5, %xmm2
	vsubsd	%xmm1, %xmm4, %xmm1
	vmovsd	%xmm0, ys.18(%rip)
	vmovsd	160008+nat_(%rip), %xmm0
	vmovsd	%xmm2, 8+xs.19(%rip)
	vsubsd	160000+nat_(%rip), %xmm0, %xmm3
	vmovsd	24+nat_(%rip), %xmm2
	vmovsd	%xmm1, 8+ys.18(%rip)
	vmovsd	%xmm3, zs.17(%rip)
	vmovsd	160016+nat_(%rip), %xmm3
	vmovsd	80024+nat_(%rip), %xmm1
	vsubsd	%xmm0, %xmm3, %xmm0
	leal	-4(%r8), %edx
	vsubsd	%xmm5, %xmm2, %xmm2
	vmovsd	%xmm0, 8+zs.17(%rip)
	vmovsd	160024+nat_(%rip), %xmm0
	vsubsd	%xmm4, %xmm1, %xmm1
	vsubsd	%xmm3, %xmm0, %xmm0
	movl	%edx, %r10d
	shrl	$2, %r10d
	salq	$5, %r10
	vmovsd	%xmm2, 16+xs.19(%rip)
	vmovsd	%xmm1, 16+ys.18(%rip)
	vmovsd	%xmm0, 16+zs.17(%rip)
	leaq	32+nat_(%rip), %rax
	addq	$24, %r10
	movl	$24, %r9d
	leaq	xs.19(%rip), %rdi
	leaq	ys.18(%rip), %rsi
	leaq	zs.17(%rip), %rcx
	.p2align 4,,10
	.p2align 3
.L2183:
	vmovapd	(%rax), %ymm7
	addq	$32, %rax
	vsubpd	-40(%rax), %ymm7, %ymm0
	vmovupd	%ymm0, (%rdi,%r9)
	vmovapd	79968(%rax), %ymm7
	vsubpd	79960(%rax), %ymm7, %ymm0
	vmovupd	%ymm0, (%rsi,%r9)
	vmovapd	159968(%rax), %ymm6
	vsubpd	159960(%rax), %ymm6, %ymm0
	vmovupd	%ymm0, (%rcx,%r9)
	addq	$32, %r9
	cmpq	%r10, %r9
	jne	.L2183
	movl	%edx, %r9d
	andl	$-4, %r9d
	movl	%edx, %r10d
	orl	$3, %r10d
	leal	4(%r9), %eax
	cmpl	%r9d, %edx
	je	.L2279
.L2181:
	movl	%r8d, %edx
	leal	-1(%r8), %r11d
	subl	%r10d, %edx
	subl	%r10d, %r11d
	cmpl	$2, %edx
	je	.L2280
	leaq	nat_(%rip), %rdx
	leal	1(%r10), %r9d
	leaq	(%rdx,%r9,8), %r15
	movl	%r11d, %ebx
	movl	%r10d, %r9d
	salq	$3, %r9
	shrl	%ebx
	movl	%ebx, -24(%rsp)
	leaq	(%rdi,%r9), %rbx
	vmovupd	(%r15), %xmm4
	movq	%rbx, -8(%rsp)
	leal	10001(%r10), %ebx
	leaq	(%rdx,%rbx,8), %r13
	leaq	(%rdx,%r9), %r14
	vsubpd	(%r14), %xmm4, %xmm0
	leaq	(%rsi,%r9), %r12
	movq	%r13, -40(%rsp)
	leal	10000(%r10), %ebx
	movq	%r12, -16(%rsp)
	leaq	(%rdx,%rbx,8), %rbx
	movq	-8(%rsp), %r12
	movq	%rbx, %r13
	vmovupd	%xmm0, (%r12)
	movq	%r13, -32(%rsp)
	movq	%r13, %r12
	movq	-40(%rsp), %r13
	leal	20001(%r10), %ebx
	vmovupd	0(%r13), %xmm4
	leaq	(%rdx,%rbx,8), %rbx
	vsubpd	(%r12), %xmm4, %xmm0
	movq	-16(%rsp), %r12
	addl	$20000, %r10d
	vmovupd	%xmm0, (%r12)
	vmovupd	(%rbx), %xmm4
	leaq	(%rdx,%r10,8), %r10
	vsubpd	(%r10), %xmm4, %xmm0
	addq	%rcx, %r9
	cmpl	$1, -24(%rsp)
	vmovupd	%xmm0, (%r9)
	je	.L2187
	vmovupd	16(%r15), %xmm5
	movq	-8(%rsp), %r12
	vsubpd	16(%r14), %xmm5, %xmm0
	cmpl	$2, -24(%rsp)
	vmovupd	%xmm0, 16(%r12)
	vmovupd	16(%r13), %xmm6
	movq	-32(%rsp), %r12
	vsubpd	16(%r12), %xmm6, %xmm0
	movq	-16(%rsp), %r12
	vmovupd	%xmm0, 16(%r12)
	vmovupd	16(%rbx), %xmm4
	vsubpd	16(%r10), %xmm4, %xmm0
	vmovupd	%xmm0, 16(%r9)
	je	.L2187
	vmovupd	32(%r15), %xmm0
	movq	-8(%rsp), %r15
	vsubpd	32(%r14), %xmm0, %xmm0
	movq	-32(%rsp), %r12
	vmovupd	%xmm0, 32(%r15)
	vmovupd	32(%r13), %xmm0
	vsubpd	32(%r12), %xmm0, %xmm0
	movq	-16(%rsp), %r12
	vmovupd	%xmm0, 32(%r12)
	vmovupd	32(%rbx), %xmm0
	vsubpd	32(%r10), %xmm0, %xmm0
	vmovupd	%xmm0, 32(%r9)
.L2187:
	movl	%r11d, %r9d
	andl	$-2, %r9d
	addl	%r9d, %eax
	cmpl	%r9d, %r11d
	je	.L2184
.L2186:
	movslq	%eax, %r9
	vmovsd	(%rdx,%r9,8), %xmm0
	decl	%eax
	cltq
	vsubsd	(%rdx,%rax,8), %xmm0, %xmm0
	vmovsd	%xmm0, (%rdi,%rax,8)
	vmovsd	80000(%rdx,%r9,8), %xmm0
	vsubsd	80000(%rdx,%rax,8), %xmm0, %xmm0
	vmovsd	%xmm0, (%rsi,%rax,8)
	vmovsd	160000(%rdx,%r9,8), %xmm0
	vsubsd	160000(%rdx,%rax,8), %xmm0, %xmm0
	vmovsd	%xmm0, (%rcx,%rax,8)
.L2184:
	leal	-3(%r8), %eax
	movl	%eax, -8(%rsp)
	testl	%eax, %eax
	jle	.L2277
	leal	-4(%r8), %edx
.L2180:
	movl	200000+angnat_(%rip), %ebx
	testl	%ebx, %ebx
	jne	.L2189
	cmpl	$7, %edx
	jbe	.L2249
	movl	80000+bon_(%rip), %r11d
	testl	%r11d, %r11d
	jne	.L2191
.L2193:
	movl	%edx, %r10d
	shrl	$3, %r10d
	leaq	80004+bon_(%rip), %r8
	salq	$5, %r10
	leaq	8+ys.18(%rip), %rdi
	leaq	16+zs.17(%rip), %rsi
	leaq	16+xs.19(%rip), %rcx
	leaq	8+chiral_(%rip), %r9
	addq	%r8, %r10
	leaq	-79988(%r8), %rax
	vpxor	%xmm4, %xmm4, %xmm4
	jmp	.L2192
	.p2align 4,,10
	.p2align 3
.L2194:
	vptest	%ymm0, %ymm0
	jne	.L2281
.L2195:
	addq	$32, %r8
	addq	$64, %rax
	addq	$64, %rdi
	addq	$64, %rsi
	addq	$64, %rcx
	addq	$64, %r9
	cmpq	%r8, %r10
	je	.L2282
.L2192:
	vpcmpeqd	(%r8), %ymm4, %ymm0
	vmovupd	-8(%rsi), %ymm5
	vmovupd	8(%rdi), %ymm2
	vpcmpeqd	%ymm4, %ymm0, %ymm1
	vpcmpeqd	4(%r8), %ymm4, %ymm0
	vmulpd	%ymm2, %ymm5, %ymm7
	vmovupd	(%rdi), %ymm9
	vpcmpeqd	%ymm4, %ymm0, %ymm0
	vmovupd	(%rsi), %ymm10
	vmovupd	-8(%rcx), %ymm12
	vfmsub231pd	%ymm10, %ymm9, %ymm7
	vpand	%ymm0, %ymm1, %ymm0
	vmovupd	24(%rsi), %ymm15
	vmovupd	40(%rdi), %ymm1
	vmulpd	%ymm12, %ymm10, %ymm10
	vmulpd	%ymm1, %ymm15, %ymm6
	vmovupd	(%rcx), %ymm13
	vmovupd	32(%rdi), %ymm8
	vmovupd	32(%rsi), %ymm3
	vmovupd	24(%rcx), %ymm11
	vfmsub132pd	%ymm13, %ymm10, %ymm5
	vfmsub231pd	%ymm3, %ymm8, %ymm6
	vmulpd	%ymm11, %ymm3, %ymm3
	vmovupd	32(%rcx), %ymm14
	vmulpd	%ymm13, %ymm9, %ymm9
	vmulpd	16(%rdi), %ymm5, %ymm5
	vmulpd	%ymm14, %ymm8, %ymm8
	vfmsub231pd	%ymm14, %ymm15, %ymm3
	vfmsub132pd	%ymm12, %ymm9, %ymm2
	vfmadd132pd	8(%rcx), %ymm5, %ymm7
	vmovupd	32(%rax), %ymm5
	vmulpd	48(%rdi), %ymm3, %ymm3
	vfmsub132pd	%ymm11, %ymm8, %ymm1
	vfmadd132pd	8(%rsi), %ymm7, %ymm2
	vmovupd	(%rax), %ymm7
	vfmadd132pd	40(%rcx), %ymm3, %ymm6
	vmulpd	8(%rax), %ymm7, %ymm3
	vfmadd132pd	40(%rsi), %ymm6, %ymm1
	vmulpd	16(%rax), %ymm3, %ymm3
	vdivpd	%ymm3, %ymm2, %ymm2
	vmulpd	40(%rax), %ymm5, %ymm3
	vmulpd	48(%rax), %ymm3, %ymm3
	vdivpd	%ymm3, %ymm1, %ymm1
	vpmovsxdq	%xmm0, %ymm3
	vptest	%ymm3, %ymm3
	vextracti128	$0x1, %ymm0, %xmm0
	vpmovsxdq	%xmm0, %ymm0
	je	.L2194
	vptest	%ymm0, %ymm0
	vmaskmovpd	%ymm2, %ymm3, (%r9)
	je	.L2195
.L2281:
	vmaskmovpd	%ymm1, %ymm0, 32(%r9)
	jmp	.L2195
.L2235:
	addl	$2, %ecx
	cmpl	-8(%rsp), %edx
	jg	.L2277
.L2237:
	cmpl	%ecx, -8(%rsp)
	jl	.L2277
	movslq	%edx, %rdx
	movl	80000(%rax,%rdx,4), %esi
	testl	%esi, %esi
	jne	.L2239
.L2277:
	vzeroupper
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L2189:
	.cfi_restore_state
	cmpl	$7, %edx
	jbe	.L2250
	movl	80000+bon_(%rip), %ebx
	testl	%ebx, %ebx
	jne	.L2214
.L2216:
	movl	%edx, %ebx
	shrl	$3, %ebx
	leaq	80004+bon_(%rip), %r8
	salq	$5, %rbx
	vmovdqa	.LC159(%rip), %ymm10
	leaq	-8+sig_(%rip), %r11
	leaq	8+ys.18(%rip), %rdi
	leaq	16+zs.17(%rip), %rsi
	leaq	16+xs.19(%rip), %rcx
	leaq	8+chiral_(%rip), %r9
	leaq	40004+sequence_(%rip), %r10
	addq	%r8, %rbx
	leaq	-79988(%r8), %rax
	vpxor	%xmm9, %xmm9, %xmm9
	jmp	.L2215
	.p2align 4,,10
	.p2align 3
.L2217:
	vptest	%ymm0, %ymm0
	jne	.L2283
.L2218:
	vpminsd	(%r10), %ymm10, %ymm2
	vptest	%ymm1, %ymm1
	vmovapd	%ymm1, %ymm4
	vmovapd	%ymm1, %ymm5
	vgatherdpd	%ymm5, (%r11,%xmm2,8), %ymm4
	vmovapd	%ymm0, %ymm3
	vperm2i128	$17, %ymm2, %ymm2, %ymm2
	vmovapd	%ymm0, %ymm7
	vgatherdpd	%ymm7, (%r11,%xmm2,8), %ymm3
	jne	.L2247
.L2220:
	addq	$32, %r8
	addq	$64, %rax
	addq	$64, %rdi
	addq	$64, %rsi
	addq	$64, %rcx
	addq	$64, %r9
	addq	$32, %r10
	cmpq	%rbx, %r8
	je	.L2284
.L2215:
	vmovupd	-8(%rsi), %ymm15
	vmovupd	8(%rdi), %ymm4
	vmovupd	(%rdi), %ymm8
	vmulpd	%ymm4, %ymm15, %ymm6
	vmovupd	(%rsi), %ymm2
	vmovupd	-8(%rcx), %ymm11
	vpcmpeqd	(%r8), %ymm9, %ymm0
	vmovupd	(%rcx), %ymm12
	vfmsub231pd	%ymm2, %ymm8, %ymm6
	vmulpd	%ymm11, %ymm2, %ymm2
	vpcmpeqd	%ymm9, %ymm0, %ymm1
	vpcmpeqd	4(%r8), %ymm9, %ymm0
	vmovupd	24(%rsi), %ymm14
	vmovupd	40(%rdi), %ymm3
	vfmsub231pd	%ymm12, %ymm15, %ymm2
	vmulpd	%ymm3, %ymm14, %ymm5
	vpcmpeqd	%ymm9, %ymm0, %ymm0
	vmovupd	32(%rdi), %ymm7
	vmulpd	%ymm12, %ymm8, %ymm8
	vpand	%ymm0, %ymm1, %ymm0
	vmulpd	16(%rdi), %ymm2, %ymm2
	vmovupd	32(%rsi), %ymm1
	vmovupd	32(%rcx), %ymm13
	vfmsub231pd	%ymm1, %ymm7, %ymm5
	vmulpd	24(%rcx), %ymm1, %ymm1
	vmulpd	%ymm13, %ymm7, %ymm7
	vfmadd132pd	8(%rcx), %ymm2, %ymm6
	vfmsub132pd	%ymm11, %ymm8, %ymm4
	vfmsub231pd	%ymm13, %ymm14, %ymm1
	vfmsub132pd	24(%rcx), %ymm7, %ymm3
	vmovupd	(%rax), %ymm7
	vfmadd132pd	8(%rsi), %ymm6, %ymm4
	vmulpd	8(%rax), %ymm7, %ymm6
	vmulpd	48(%rdi), %ymm1, %ymm1
	vmulpd	16(%rax), %ymm6, %ymm6
	vfmadd132pd	40(%rcx), %ymm1, %ymm5
	vpmovsxdq	%xmm0, %ymm1
	vptest	%ymm1, %ymm1
	vextracti128	$0x1, %ymm0, %xmm0
	vdivpd	%ymm6, %ymm4, %ymm4
	vmovupd	32(%rax), %ymm6
	vfmadd132pd	40(%rsi), %ymm5, %ymm3
	vmulpd	40(%rax), %ymm6, %ymm5
	vpmovsxdq	%xmm0, %ymm0
	vmulpd	48(%rax), %ymm5, %ymm5
	vdivpd	%ymm5, %ymm3, %ymm3
	je	.L2217
	vptest	%ymm0, %ymm0
	vmaskmovpd	%ymm4, %ymm1, (%r9)
	je	.L2218
.L2283:
	vpminsd	(%r10), %ymm10, %ymm2
	vptest	%ymm1, %ymm1
	vmovapd	%ymm1, %ymm6
	vmovapd	%ymm1, %ymm4
	vmaskmovpd	%ymm3, %ymm0, 32(%r9)
	vmovapd	%ymm0, %ymm3
	vgatherdpd	%ymm6, (%r11,%xmm2,8), %ymm4
	vperm2i128	$17, %ymm2, %ymm2, %ymm2
	vmovapd	%ymm0, %ymm6
	vgatherdpd	%ymm6, (%r11,%xmm2,8), %ymm3
	jne	.L2247
.L2219:
	vmaskmovpd	%ymm3, %ymm0, 32(%r9)
	jmp	.L2220
	.p2align 4,,10
	.p2align 3
.L2247:
	vptest	%ymm0, %ymm0
	vmaskmovpd	%ymm4, %ymm1, (%r9)
	je	.L2220
	jmp	.L2219
	.p2align 4,,10
	.p2align 3
.L2282:
	movl	%edx, %eax
	andl	$-8, %eax
	leal	1(%rax), %r8d
	leal	2(%rax), %ecx
	cmpl	%eax, %edx
	je	.L2277
.L2190:
	movl	-8(%rsp), %eax
	subl	%r8d, %edx
	subl	%r8d, %eax
	movl	%eax, -16(%rsp)
	cmpl	$2, %edx
	jbe	.L2285
	shrl	$2, %eax
	movl	%r8d, %esi
	movl	%eax, -56(%rsp)
	leaq	bon_(%rip), %rax
	leaq	80000(%rax,%rsi,4), %rbx
	leaq	80004(%rax,%rsi,4), %rdi
	leal	1(%r8), %r9d
	leal	2(%r8), %edx
	salq	$3, %rsi
	salq	$3, %r9
	salq	$3, %rdx
	movq	%rbx, -24(%rsp)
	movq	%rdi, -32(%rsp)
	leaq	zs.17(%rip), %r10
	leaq	ys.18(%rip), %rdi
	leaq	xs.19(%rip), %r11
	leaq	(%r9,%r10), %r14
	leaq	(%rsi,%r10), %r13
	leaq	(%r9,%rdi), %rbx
	leaq	(%r9,%r11), %r12
	addq	%rdx, %r10
	addq	%rax, %r9
	movq	%r10, -48(%rsp)
	movq	%r9, -64(%rsp)
	movq	%r9, %r10
	leaq	chiral_(%rip), %r9
	leaq	(%rsi,%rdi), %r15
	movq	%rbx, -40(%rsp)
	addq	%rsi, %r9
	leaq	(%rsi,%r11), %rbx
	movq	-24(%rsp), %rsi
	vpxor	%xmm1, %xmm1, %xmm1
	vpcmpeqd	(%rsi), %xmm1, %xmm0
	movq	-32(%rsp), %rsi
	vmovupd	16(%r13), %xmm3
	vpcmpeqd	%xmm1, %xmm0, %xmm2
	vpcmpeqd	(%rsi), %xmm1, %xmm0
	movq	-40(%rsp), %rsi
	vmovupd	0(%r13), %xmm15
	vmovupd	16(%rsi), %xmm11
	vmovupd	(%rsi), %xmm12
	vmulpd	%xmm3, %xmm11, %xmm7
	vpcmpeqd	%xmm1, %xmm0, %xmm1
	vmulpd	%xmm15, %xmm12, %xmm4
	vmovupd	16(%r15), %xmm14
	vpand	%xmm1, %xmm2, %xmm0
	vmovupd	16(%r14), %xmm6
	vmovupd	16(%rbx), %xmm1
	vmovupd	(%r15), %xmm13
	vmovupd	(%r14), %xmm10
	vfmsub231pd	%xmm6, %xmm14, %xmm7
	vmulpd	%xmm6, %xmm1, %xmm6
	vmovupd	(%rbx), %xmm2
	vfmsub231pd	%xmm10, %xmm13, %xmm4
	vmovupd	16(%r12), %xmm9
	vmulpd	%xmm10, %xmm2, %xmm5
	vfmsub231pd	%xmm3, %xmm9, %xmm6
	vmulpd	%xmm14, %xmm9, %xmm3
	vmovapd	%xmm4, %xmm8
	vmovupd	(%r12), %xmm4
	addq	%rdx, %rdi
	vfmsub231pd	%xmm15, %xmm4, %xmm5
	vfmsub132pd	%xmm11, %xmm3, %xmm1
	vmulpd	16(%rdi), %xmm6, %xmm3
	vmulpd	%xmm13, %xmm4, %xmm4
	addq	%rdx, %r11
	vmulpd	(%rdi), %xmm5, %xmm5
	movq	-48(%rsp), %rsi
	vfmadd231pd	16(%r11), %xmm7, %xmm3
	vfmsub132pd	%xmm12, %xmm4, %xmm2
	vmovapd	%xmm8, %xmm4
	vfmadd132pd	(%r11), %xmm5, %xmm4
	vmovupd	(%r10), %xmm5
	addq	%rax, %rdx
	vfmadd132pd	16(%rsi), %xmm3, %xmm1
	vmulpd	(%rdx), %xmm5, %xmm3
	addl	$3, %r8d
	leaq	(%rax,%r8,8), %r8
	vfmadd132pd	(%rsi), %xmm4, %xmm2
	vmulpd	(%r8), %xmm3, %xmm3
	vmovupd	16(%r10), %xmm6
	vdivpd	%xmm3, %xmm2, %xmm2
	vmulpd	16(%rdx), %xmm6, %xmm3
	vmulpd	16(%r8), %xmm3, %xmm3
	vdivpd	%xmm3, %xmm1, %xmm1
	vpmovsxdq	%xmm0, %xmm3
	vptest	%xmm3, %xmm3
	vpsrldq	$8, %xmm0, %xmm0
	vpmovsxdq	%xmm0, %xmm0
	jne	.L2286
.L2200:
	vptest	%xmm0, %xmm0
	leaq	16(%r9), %rsi
	jne	.L2287
.L2201:
	cmpl	$1, -56(%rsp)
	leaq	32(%r9), %rsi
	jne	.L2288
.L2202:
	movl	-16(%rsp), %ebx
	movl	%ebx, %edx
	andl	$-4, %edx
	addl	%edx, %ecx
	cmpl	%edx, %ebx
	je	.L2277
.L2199:
	leal	-1(%rcx), %edx
	movslq	%edx, %rdx
	movl	80000(%rax,%rdx,4), %r9d
	leal	1(%rcx), %edi
	testl	%r9d, %r9d
	jne	.L2289
	cmpl	-8(%rsp), %edi
	jg	.L2277
	movslq	%ecx, %rdx
	movl	80000(%rax,%rdx,4), %r15d
	addl	$2, %ecx
	testl	%r15d, %r15d
	je	.L2209
	movslq	%edi, %r8
.L2242:
	movl	80000(%rax,%r8,4), %r14d
	testl	%r14d, %r14d
	je	.L2277
	leaq	zs.17(%rip), %rdi
	leaq	ys.18(%rip), %r10
	vmovsd	(%rdi,%rdx,8), %xmm1
	vmovsd	(%r10,%r8,8), %xmm0
	leaq	xs.19(%rip), %r9
	vmulsd	%xmm0, %xmm1, %xmm2
	vmovsd	(%r10,%rdx,8), %xmm3
	vmovsd	(%rdi,%r8,8), %xmm4
	vmovsd	(%r9,%rdx,8), %xmm5
	vmovsd	(%r9,%r8,8), %xmm6
	vfmsub231sd	%xmm4, %xmm3, %xmm2
	vmulsd	%xmm5, %xmm4, %xmm4
	movslq	%ecx, %rsi
	vmulsd	%xmm6, %xmm3, %xmm3
	vfmsub132sd	%xmm6, %xmm4, %xmm1
	vfmsub132sd	%xmm5, %xmm3, %xmm0
	vmulsd	(%r10,%rsi,8), %xmm1, %xmm1
	vfmadd231sd	(%r9,%rsi,8), %xmm2, %xmm1
	vfmadd132sd	(%rdi,%rsi,8), %xmm1, %xmm0
	vmovsd	8(%rax,%rdx,8), %xmm1
	leaq	chiral_(%rip), %rdi
	vmulsd	8(%rax,%rsi,8), %xmm1, %xmm1
	vmulsd	8(%rax,%r8,8), %xmm1, %xmm1
	vdivsd	%xmm1, %xmm0, %xmm0
	vmovsd	%xmm0, (%rdi,%rdx,8)
	leal	1(%rcx), %edx
	cmpl	%ecx, -8(%rsp)
	jl	.L2277
.L2211:
	movl	80000(%rax,%rsi,4), %r12d
	testl	%r12d, %r12d
	je	.L2277
	leaq	ys.18(%rip), %r9
	leaq	zs.17(%rip), %rcx
	vmovsd	(%rcx,%r8,8), %xmm1
	vmovsd	(%r9,%rsi,8), %xmm0
	leaq	xs.19(%rip), %rdi
	vmulsd	%xmm0, %xmm1, %xmm2
	vmovsd	(%r9,%r8,8), %xmm3
	vmovsd	(%rcx,%rsi,8), %xmm4
	vmovsd	(%rdi,%r8,8), %xmm5
	vmovsd	(%rdi,%rsi,8), %xmm6
	vfmsub231sd	%xmm4, %xmm3, %xmm2
	vmulsd	%xmm5, %xmm4, %xmm4
	movslq	%edx, %rdx
	vmulsd	%xmm6, %xmm3, %xmm3
	vfmsub132sd	%xmm6, %xmm4, %xmm1
	vfmsub132sd	%xmm5, %xmm3, %xmm0
	vmulsd	(%r9,%rdx,8), %xmm1, %xmm1
	vfmadd231sd	(%rdi,%rdx,8), %xmm2, %xmm1
	vfmadd132sd	(%rcx,%rdx,8), %xmm1, %xmm0
	vmovsd	8(%rax,%r8,8), %xmm1
	vmulsd	8(%rax,%rdx,8), %xmm1, %xmm1
	vmulsd	8(%rax,%rsi,8), %xmm1, %xmm1
	leaq	chiral_(%rip), %rax
	vdivsd	%xmm1, %xmm0, %xmm0
	vmovsd	%xmm0, (%rax,%r8,8)
	jmp	.L2277
	.p2align 4,,10
	.p2align 3
.L2284:
	movl	%edx, %eax
	andl	$-8, %eax
	leal	1(%rax), %esi
	leal	2(%rax), %ecx
	cmpl	%eax, %edx
	je	.L2277
.L2213:
	movl	-8(%rsp), %eax
	subl	%esi, %edx
	subl	%esi, %eax
	movl	%eax, -16(%rsp)
	cmpl	$2, %edx
	jbe	.L2290
	shrl	$2, %eax
	movl	%esi, %r8d
	movl	%eax, -68(%rsp)
	leaq	bon_(%rip), %rax
	leaq	80004(%rax,%r8,4), %rdi
	movq	%rdi, -40(%rsp)
	leal	1(%rsi), %edi
	salq	$3, %rdi
	leaq	zs.17(%rip), %r10
	leaq	0(,%r8,8), %r9
	leaq	(%rdi,%r10), %rdx
	leaq	80000(%rax,%r8,4), %rbx
	leaq	ys.18(%rip), %r11
	movq	%rbx, -32(%rsp)
	movq	%rdx, -56(%rsp)
	leaq	(%r9,%r11), %rbx
	leal	2(%rsi), %edx
	salq	$3, %rdx
	movq	%rbx, -48(%rsp)
	leaq	xs.19(%rip), %rbx
	leaq	(%r9,%r10), %r12
	leaq	(%rdi,%r11), %r13
	leaq	(%rdi,%rbx), %r14
	addq	%rdx, %r10
	addq	%rax, %rdi
	movq	%r10, -64(%rsp)
	movq	%rdi, -80(%rsp)
	movq	%rdi, %r10
	leaq	chiral_(%rip), %rdi
	leaq	(%r9,%rbx), %r15
	addq	%rdi, %r9
	leaq	sequence_(%rip), %rdi
	leaq	40000(%rdi,%r8,4), %rdi
	movq	-32(%rsp), %r8
	vpxor	%xmm1, %xmm1, %xmm1
	vpcmpeqd	(%r8), %xmm1, %xmm0
	movq	-40(%rsp), %r8
	vmovupd	(%r12), %xmm15
	vpcmpeqd	%xmm1, %xmm0, %xmm2
	vpcmpeqd	(%r8), %xmm1, %xmm0
	movq	-48(%rsp), %r8
	vmovupd	16(%r12), %xmm3
	vpcmpeqd	%xmm1, %xmm0, %xmm1
	vmovupd	(%r8), %xmm10
	vmovupd	16(%r8), %xmm9
	vpand	%xmm1, %xmm2, %xmm0
	vmovupd	0(%r13), %xmm2
	vmovupd	16(%r13), %xmm1
	vmulpd	%xmm2, %xmm15, %xmm4
	movq	-56(%rsp), %r8
	vmulpd	%xmm1, %xmm3, %xmm7
	vmovupd	(%r8), %xmm11
	vmovupd	16(%r8), %xmm6
	vmovupd	(%r15), %xmm13
	vmovupd	16(%r15), %xmm12
	vfmsub231pd	%xmm11, %xmm10, %xmm4
	vfmsub231pd	%xmm6, %xmm9, %xmm7
	vmulpd	%xmm13, %xmm11, %xmm5
	vmulpd	%xmm12, %xmm6, %xmm6
	vmovupd	16(%r14), %xmm14
	vmovapd	%xmm4, %xmm8
	vmovupd	(%r14), %xmm4
	addq	%rdx, %r11
	vfmsub231pd	%xmm4, %xmm15, %xmm5
	vfmsub231pd	%xmm14, %xmm3, %xmm6
	vmulpd	%xmm14, %xmm9, %xmm3
	vmulpd	%xmm4, %xmm10, %xmm4
	addq	%rdx, %rbx
	vmulpd	(%r11), %xmm5, %xmm5
	movq	-64(%rsp), %r8
	vfmsub132pd	%xmm12, %xmm3, %xmm1
	vmulpd	16(%r11), %xmm6, %xmm3
	vfmsub132pd	%xmm13, %xmm4, %xmm2
	vmovapd	%xmm8, %xmm4
	vfmadd132pd	(%rbx), %xmm5, %xmm4
	movq	%rdi, -24(%rsp)
	vfmadd231pd	16(%rbx), %xmm7, %xmm3
	addq	%rax, %rdx
	addl	$3, %esi
	vfmadd132pd	(%r8), %xmm4, %xmm2
	leaq	(%rax,%rsi,8), %rsi
	vfmadd132pd	16(%r8), %xmm3, %xmm1
	vmovupd	(%r10), %xmm7
	vmovupd	16(%r10), %xmm4
	vmulpd	(%rdx), %xmm7, %xmm3
	leaq	-8+sig_(%rip), %rdi
	vmulpd	(%rsi), %xmm3, %xmm3
	vdivpd	%xmm3, %xmm2, %xmm2
	vmulpd	16(%rdx), %xmm4, %xmm3
	vmulpd	16(%rsi), %xmm3, %xmm3
	vdivpd	%xmm3, %xmm1, %xmm1
	vpmovsxdq	%xmm0, %xmm3
	vptest	%xmm3, %xmm3
	vpsrldq	$8, %xmm0, %xmm0
	vpmovsxdq	%xmm0, %xmm0
	jne	.L2291
.L2224:
	vptest	%xmm0, %xmm0
	leaq	16(%r9), %r8
	jne	.L2292
	vmovdqa	.LC160(%rip), %xmm4
	movq	-24(%rsp), %r10
	vptest	%xmm3, %xmm3
	vpminsd	(%r10), %xmm4, %xmm1
	vmovapd	%xmm3, %xmm5
	vmovapd	%xmm3, %xmm6
	vgatherdpd	%xmm6, (%rdi,%xmm1,8), %xmm5
	vmovapd	%xmm0, %xmm2
	vpshufd	$238, %xmm1, %xmm1
	vmovapd	%xmm0, %xmm7
	vgatherdpd	%xmm7, (%rdi,%xmm1,8), %xmm2
	jne	.L2246
.L2227:
	cmpl	$1, -68(%rsp)
	leaq	32(%r9), %r8
	je	.L2228
	movq	-32(%rsp), %r10
	vpxor	%xmm1, %xmm1, %xmm1
	vpcmpeqd	16(%r10), %xmm1, %xmm0
	movq	-40(%rsp), %r10
	vmovupd	32(%r12), %xmm15
	vpcmpeqd	%xmm1, %xmm0, %xmm2
	vpcmpeqd	16(%r10), %xmm1, %xmm0
	vmovupd	32(%r13), %xmm8
	movq	-48(%rsp), %r10
	vpcmpeqd	%xmm1, %xmm0, %xmm1
	vmovupd	48(%r12), %xmm3
	vmovupd	48(%r13), %xmm7
	vmulpd	%xmm8, %xmm15, %xmm5
	vpand	%xmm1, %xmm2, %xmm0
	vmovupd	32(%r10), %xmm2
	vmovupd	48(%r10), %xmm1
	movq	-56(%rsp), %r10
	vmulpd	%xmm7, %xmm3, %xmm10
	vmovupd	32(%r10), %xmm6
	vmovupd	48(%r10), %xmm9
	vfmsub231pd	%xmm6, %xmm2, %xmm5
	vmovupd	32(%r15), %xmm13
	vmovupd	48(%r15), %xmm12
	vfmsub231pd	%xmm9, %xmm1, %xmm10
	vmulpd	%xmm13, %xmm6, %xmm6
	vmulpd	%xmm12, %xmm9, %xmm9
	vmovupd	48(%r14), %xmm14
	vmovapd	%xmm5, %xmm11
	vmovupd	32(%r14), %xmm5
	vfmsub231pd	%xmm14, %xmm3, %xmm9
	vfmsub231pd	%xmm5, %xmm15, %xmm6
	vmulpd	%xmm14, %xmm1, %xmm3
	vmulpd	%xmm5, %xmm2, %xmm5
	vmovapd	%xmm8, %xmm2
	vmulpd	32(%r11), %xmm6, %xmm6
	vfmsub132pd	%xmm12, %xmm3, %xmm7
	vmulpd	48(%r11), %xmm9, %xmm3
	vfmsub132pd	%xmm13, %xmm5, %xmm2
	vmovapd	%xmm11, %xmm5
	vfmadd132pd	32(%rbx), %xmm6, %xmm5
	vmovapd	%xmm7, %xmm1
	vfmadd231pd	48(%rbx), %xmm10, %xmm3
	movq	-64(%rsp), %rbx
	vfmadd132pd	32(%rbx), %xmm5, %xmm2
	vfmadd132pd	48(%rbx), %xmm3, %xmm1
	movq	-80(%rsp), %rbx
	vmovupd	32(%rbx), %xmm6
	vmulpd	32(%rdx), %xmm6, %xmm3
	vmulpd	32(%rsi), %xmm3, %xmm3
	vdivpd	%xmm3, %xmm2, %xmm2
	vmovupd	48(%rdx), %xmm3
	vmulpd	48(%rbx), %xmm3, %xmm3
	vmulpd	48(%rsi), %xmm3, %xmm3
	vdivpd	%xmm3, %xmm1, %xmm1
	vpmovsxdq	%xmm0, %xmm3
	vptest	%xmm3, %xmm3
	vpsrldq	$8, %xmm0, %xmm0
	vpmovsxdq	%xmm0, %xmm0
	jne	.L2293
.L2229:
	addq	$48, %r9
	vptest	%xmm0, %xmm0
	jne	.L2294
	movq	-24(%rsp), %rbx
	vptest	%xmm3, %xmm3
	vpminsd	16(%rbx), %xmm4, %xmm4
	vmovapd	%xmm3, %xmm2
	vmovapd	%xmm3, %xmm5
	vgatherdpd	%xmm5, (%rdi,%xmm4,8), %xmm2
	vmovapd	%xmm0, %xmm1
	vpshufd	$238, %xmm4, %xmm4
	vmovapd	%xmm0, %xmm6
	vgatherdpd	%xmm6, (%rdi,%xmm4,8), %xmm1
	jne	.L2245
.L2228:
	movl	-16(%rsp), %ebx
	movl	%ebx, %edx
	andl	$-4, %edx
	addl	%edx, %ecx
	cmpl	%edx, %ebx
	je	.L2277
.L2223:
	leal	-1(%rcx), %esi
	movslq	%esi, %rsi
	movl	80000(%rax,%rsi,4), %r10d
	leal	1(%rcx), %edx
	testl	%r10d, %r10d
	jne	.L2295
	cmpl	-8(%rsp), %edx
	jg	.L2277
	movslq	%ecx, %rsi
	movl	80000(%rax,%rsi,4), %r8d
	addl	$2, %ecx
	testl	%r8d, %r8d
	je	.L2237
.L2243:
	movslq	%edx, %rdx
	movl	80000(%rax,%rdx,4), %edi
	testl	%edi, %edi
	je	.L2277
	leaq	sequence_(%rip), %rdi
	vmovd	40000(%rdi,%rsi,4), %xmm0
	vmovdqa	%xmm0, %xmm1
	vmovdqa	.LC101(%rip), %xmm0
	leaq	sig_(%rip), %r8
	vpminsd	%xmm0, %xmm1, %xmm0
	vmovd	%xmm0, %edi
	movslq	%edi, %rdi
	vmovsd	-8(%r8,%rdi,8), %xmm0
	leaq	chiral_(%rip), %rdi
	vmovsd	%xmm0, (%rdi,%rsi,8)
	cmpl	%ecx, -8(%rsp)
	jl	.L2277
.L2239:
	movslq	%ecx, %rcx
	movl	80000(%rax,%rcx,4), %eax
	testl	%eax, %eax
	je	.L2277
	leaq	sequence_(%rip), %rax
	vmovd	40000(%rax,%rdx,4), %xmm0
	vmovdqa	%xmm0, %xmm1
	vmovdqa	.LC101(%rip), %xmm0
	leaq	sig_(%rip), %rcx
	vpminsd	%xmm0, %xmm1, %xmm0
	vmovd	%xmm0, %eax
	cltq
	vmovsd	-8(%rcx,%rax,8), %xmm0
	leaq	chiral_(%rip), %rax
	vmovsd	%xmm0, (%rax,%rdx,8)
	jmp	.L2277
	.p2align 4,,10
	.p2align 3
.L2279:
	leal	-3(%r8), %eax
	movl	%eax, -8(%rsp)
	jmp	.L2180
	.p2align 4,,10
	.p2align 3
.L2288:
	movq	-24(%rsp), %r10
	vpxor	%xmm1, %xmm1, %xmm1
	vpcmpeqd	16(%r10), %xmm1, %xmm0
	movq	-32(%rsp), %r10
	vmovupd	32(%r14), %xmm5
	vmovupd	48(%r14), %xmm8
	movq	-40(%rsp), %r14
	vpcmpeqd	%xmm1, %xmm0, %xmm2
	vpcmpeqd	16(%r10), %xmm1, %xmm0
	vmovupd	32(%r13), %xmm14
	vmovupd	32(%r14), %xmm7
	vmovupd	48(%r13), %xmm3
	vmulpd	%xmm7, %xmm14, %xmm4
	vpcmpeqd	%xmm1, %xmm0, %xmm1
	vmovupd	48(%r14), %xmm6
	vmovupd	32(%rbx), %xmm12
	vmulpd	%xmm6, %xmm3, %xmm9
	vpand	%xmm1, %xmm2, %xmm0
	vmovupd	32(%r15), %xmm2
	vmovupd	48(%r15), %xmm1
	vfmsub231pd	%xmm5, %xmm2, %xmm4
	vmovupd	48(%rbx), %xmm11
	vfmsub231pd	%xmm8, %xmm1, %xmm9
	vmulpd	%xmm12, %xmm5, %xmm5
	vmulpd	%xmm11, %xmm8, %xmm8
	vmovupd	48(%r12), %xmm13
	vmovapd	%xmm4, %xmm10
	vmovupd	32(%r12), %xmm4
	movq	-48(%rsp), %rbx
	vfmsub231pd	%xmm4, %xmm14, %xmm5
	vfmsub231pd	%xmm13, %xmm3, %xmm8
	vmulpd	%xmm13, %xmm1, %xmm3
	vmulpd	%xmm4, %xmm2, %xmm4
	vmulpd	32(%rdi), %xmm5, %xmm5
	vfmsub132pd	%xmm11, %xmm3, %xmm6
	vmulpd	48(%rdi), %xmm8, %xmm3
	vfmsub132pd	%xmm12, %xmm4, %xmm7
	vmovapd	%xmm10, %xmm4
	vfmadd132pd	32(%r11), %xmm5, %xmm4
	vmovapd	%xmm6, %xmm1
	vfmadd231pd	48(%r11), %xmm9, %xmm3
	vmovapd	%xmm7, %xmm2
	vfmadd132pd	32(%rbx), %xmm4, %xmm2
	vfmadd132pd	48(%rbx), %xmm3, %xmm1
	movq	-64(%rsp), %rbx
	vmovupd	32(%rbx), %xmm5
	vmulpd	32(%rdx), %xmm5, %xmm3
	vmulpd	32(%r8), %xmm3, %xmm3
	vdivpd	%xmm3, %xmm2, %xmm2
	vmovupd	48(%rdx), %xmm3
	vmulpd	48(%rbx), %xmm3, %xmm3
	vmulpd	48(%r8), %xmm3, %xmm3
	vdivpd	%xmm3, %xmm1, %xmm1
	vpmovsxdq	%xmm0, %xmm3
	vptest	%xmm3, %xmm3
	vpsrldq	$8, %xmm0, %xmm0
	vpmovsxdq	%xmm0, %xmm0
	jne	.L2296
.L2203:
	addq	$48, %r9
	vptest	%xmm0, %xmm0
	je	.L2202
	vmaskmovpd	%xmm1, %xmm0, (%r9)
	jmp	.L2202
	.p2align 4,,10
	.p2align 3
.L2191:
	movl	80004+bon_(%rip), %r10d
	testl	%r10d, %r10d
	je	.L2193
	vmovsd	zs.17(%rip), %xmm1
	vmovsd	8+ys.18(%rip), %xmm0
	vmovsd	ys.18(%rip), %xmm3
	vmulsd	%xmm0, %xmm1, %xmm2
	vmovsd	8+zs.17(%rip), %xmm4
	vmovsd	xs.19(%rip), %xmm5
	vmovsd	8+xs.19(%rip), %xmm6
	vfmsub231sd	%xmm4, %xmm3, %xmm2
	vmulsd	%xmm5, %xmm4, %xmm4
	vmulsd	%xmm6, %xmm3, %xmm3
	vfmsub132sd	%xmm6, %xmm4, %xmm1
	vfmsub132sd	%xmm5, %xmm3, %xmm0
	vmulsd	16+ys.18(%rip), %xmm1, %xmm1
	vfmadd231sd	16+xs.19(%rip), %xmm2, %xmm1
	vfmadd132sd	16+zs.17(%rip), %xmm1, %xmm0
	vmovsd	8+bon_(%rip), %xmm1
	vmulsd	24+bon_(%rip), %xmm1, %xmm1
	vmulsd	16+bon_(%rip), %xmm1, %xmm1
	vdivsd	%xmm1, %xmm0, %xmm0
	vmovsd	%xmm0, chiral_(%rip)
	jmp	.L2193
	.p2align 4,,10
	.p2align 3
.L2214:
	movl	80004+bon_(%rip), %r11d
	testl	%r11d, %r11d
	je	.L2216
	vmovd	40000+sequence_(%rip), %xmm0
	vmovdqa	%xmm0, %xmm1
	vmovdqa	.LC101(%rip), %xmm0
	leaq	sig_(%rip), %rcx
	vpminsd	%xmm0, %xmm1, %xmm0
	vmovd	%xmm0, %eax
	cltq
	vmovsd	-8(%rcx,%rax,8), %xmm0
	vmovsd	%xmm0, chiral_(%rip)
	jmp	.L2216
	.p2align 4,,10
	.p2align 3
.L2295:
	movslq	%ecx, %rdi
	movl	80000(%rax,%rdi,4), %r9d
	testl	%r9d, %r9d
	je	.L2235
	leaq	sequence_(%rip), %r8
	vmovd	40000(%r8,%rsi,4), %xmm0
	vmovdqa	%xmm0, %xmm1
	vmovdqa	.LC101(%rip), %xmm0
	leaq	sig_(%rip), %r9
	vpminsd	%xmm0, %xmm1, %xmm0
	vmovd	%xmm0, %r8d
	movslq	%r8d, %r8
	vmovsd	-8(%r9,%r8,8), %xmm0
	leaq	chiral_(%rip), %r8
	vmovsd	%xmm0, (%r8,%rsi,8)
	addl	$2, %ecx
	movq	%rdi, %rsi
	cmpl	-8(%rsp), %edx
	jle	.L2243
	jmp	.L2277
	.p2align 4,,10
	.p2align 3
.L2289:
	movslq	%ecx, %rsi
	movl	80000(%rax,%rsi,4), %r8d
	testl	%r8d, %r8d
	je	.L2207
	leaq	zs.17(%rip), %r9
	leaq	ys.18(%rip), %r11
	vmovsd	(%r9,%rdx,8), %xmm1
	vmovsd	(%r11,%rsi,8), %xmm0
	leaq	xs.19(%rip), %r10
	vmulsd	%xmm0, %xmm1, %xmm2
	vmovsd	(%r11,%rdx,8), %xmm3
	vmovsd	(%r9,%rsi,8), %xmm4
	vmovsd	(%r10,%rdx,8), %xmm5
	vmovsd	(%r10,%rsi,8), %xmm6
	vfmsub231sd	%xmm4, %xmm3, %xmm2
	vmulsd	%xmm5, %xmm4, %xmm4
	movslq	%edi, %r8
	vmulsd	%xmm6, %xmm3, %xmm3
	addl	$2, %ecx
	vfmsub132sd	%xmm6, %xmm4, %xmm1
	vfmsub132sd	%xmm5, %xmm3, %xmm0
	vmulsd	(%r11,%r8,8), %xmm1, %xmm1
	vfmadd231sd	(%r10,%r8,8), %xmm2, %xmm1
	vfmadd132sd	(%r9,%r8,8), %xmm1, %xmm0
	vmovsd	8(%rax,%rdx,8), %xmm1
	leaq	chiral_(%rip), %r9
	vmulsd	8(%rax,%r8,8), %xmm1, %xmm1
	vmulsd	8(%rax,%rsi,8), %xmm1, %xmm1
	vdivsd	%xmm1, %xmm0, %xmm0
	vmovsd	%xmm0, (%r9,%rdx,8)
	movq	%rsi, %rdx
	cmpl	-8(%rsp), %edi
	jle	.L2242
	jmp	.L2277
.L2207:
	addl	$2, %ecx
	cmpl	-8(%rsp), %edi
	jg	.L2277
.L2209:
	cmpl	%ecx, -8(%rsp)
	jl	.L2277
	movslq	%edi, %r8
	movl	80000(%rax,%r8,4), %r13d
	leal	1(%rcx), %edx
	testl	%r13d, %r13d
	je	.L2277
	movslq	%ecx, %rsi
	jmp	.L2211
.L2248:
	xorl	%r10d, %r10d
	movl	$1, %eax
	leaq	xs.19(%rip), %rdi
	leaq	ys.18(%rip), %rsi
	leaq	zs.17(%rip), %rcx
	jmp	.L2181
.L2287:
	vmaskmovpd	%xmm1, %xmm0, (%rsi)
	jmp	.L2201
.L2291:
	vmaskmovpd	%xmm2, %xmm3, (%r9)
	jmp	.L2224
.L2292:
	vmovdqa	.LC160(%rip), %xmm4
	movq	-24(%rsp), %r10
	vmaskmovpd	%xmm1, %xmm0, (%r8)
	vptest	%xmm3, %xmm3
	vpminsd	(%r10), %xmm4, %xmm1
	vmovapd	%xmm3, %xmm6
	vmovapd	%xmm3, %xmm5
	vgatherdpd	%xmm6, (%rdi,%xmm1,8), %xmm5
	vmovapd	%xmm0, %xmm2
	vpshufd	$238, %xmm1, %xmm1
	vmovapd	%xmm0, %xmm6
	vgatherdpd	%xmm6, (%rdi,%xmm1,8), %xmm2
	je	.L2226
.L2246:
	vptest	%xmm0, %xmm0
	vmaskmovpd	%xmm5, %xmm3, (%r9)
	je	.L2227
.L2226:
	vmaskmovpd	%xmm2, %xmm0, (%r8)
	jmp	.L2227
.L2286:
	vmaskmovpd	%xmm2, %xmm3, (%r9)
	jmp	.L2200
.L2280:
	leaq	nat_(%rip), %rdx
	jmp	.L2186
.L2294:
	movq	-24(%rsp), %rbx
	vptest	%xmm3, %xmm3
	vpminsd	16(%rbx), %xmm4, %xmm4
	vmovapd	%xmm3, %xmm5
	vmovapd	%xmm3, %xmm2
	vmaskmovpd	%xmm1, %xmm0, (%r9)
	vmovapd	%xmm0, %xmm1
	vgatherdpd	%xmm5, (%rdi,%xmm4,8), %xmm2
	vpshufd	$238, %xmm4, %xmm4
	vmovapd	%xmm0, %xmm5
	vgatherdpd	%xmm5, (%rdi,%xmm4,8), %xmm1
	je	.L2231
.L2245:
	vptest	%xmm0, %xmm0
	vmaskmovpd	%xmm2, %xmm3, (%r8)
	je	.L2228
.L2231:
	vmaskmovpd	%xmm1, %xmm0, (%r9)
	jmp	.L2228
.L2249:
	xorl	%r8d, %r8d
	movl	$1, %ecx
	jmp	.L2190
.L2250:
	xorl	%esi, %esi
	movl	$1, %ecx
	jmp	.L2213
.L2290:
	leaq	bon_(%rip), %rax
	jmp	.L2223
.L2285:
	leaq	bon_(%rip), %rax
	jmp	.L2199
.L2296:
	vmaskmovpd	%xmm2, %xmm3, (%rsi)
	jmp	.L2203
.L2293:
	vmaskmovpd	%xmm2, %xmm3, (%r8)
	jmp	.L2229
	.cfi_endproc
.LFE43:
	.size	model_chirality_, .-model_chirality_
	.section	.rodata.str1.1
.LC161:
	.string	"GLY"
.LC163:
	.string	"ALA"
.LC165:
	.string	"SER"
.LC167:
	.string	"PRO"
.LC169:
	.string	"VAL"
.LC171:
	.string	"THR"
.LC173:
	.string	"CYS"
.LC175:
	.string	"ILE"
.LC177:
	.string	"LEU"
.LC178:
	.string	"ASN"
.LC180:
	.string	"ASP"
.LC182:
	.string	"GLN"
.LC184:
	.string	"LYS"
.LC186:
	.string	"GLU"
.LC188:
	.string	"MET"
.LC190:
	.string	"HIS"
.LC192:
	.string	"PHE"
.LC194:
	.string	"ARG"
.LC196:
	.string	"TYR"
.LC198:
	.string	"TRP"
	.text
	.p2align 4
	.globl	amino_acid_mass_
	.type	amino_acid_mass_, @function
amino_acid_mass_:
.LFB44:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$64, %rsp
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	movl	8+bas_(%rip), %ebx
	movq	%fs:40, %rax
	movq	%rax, 56(%rsp)
	xorl	%eax, %eax
	testl	%ebx, %ebx
	jle	.L2297
	leaq	mass_(%rip), %r12
	leal	-1(%rbx), %edx
	leaq	8(%r12), %rax
	leaq	80000+sequence_(%rip), %r13
	movl	%ebx, %r9d
	movq	%rdx, %r10
	leaq	(%rax,%rdx,8), %r8
	movq	%r12, %r15
	movq	%r12, %r14
	leaq	53(%rsp), %rdi
	leaq	.LC161(%rip), %rcx
	.p2align 4,,10
	.p2align 3
.L2345:
	movzwl	0(%r13), %eax
	movzbl	2(%r13), %edx
	movw	%ax, 53(%rsp)
	movb	%dl, 55(%rsp)
	cmpw	(%rcx), %ax
	je	.L2374
.L2299:
	movzwl	.LC163(%rip), %eax
	cmpw	%ax, (%rdi)
	je	.L2375
.L2303:
	movzwl	.LC165(%rip), %eax
	cmpw	%ax, (%rdi)
	je	.L2376
.L2306:
	movzwl	.LC167(%rip), %eax
	cmpw	%ax, (%rdi)
	je	.L2377
.L2309:
	movzwl	.LC169(%rip), %eax
	cmpw	%ax, (%rdi)
	je	.L2378
.L2312:
	movzwl	.LC171(%rip), %eax
	cmpw	%ax, (%rdi)
	je	.L2379
.L2315:
	movzwl	.LC173(%rip), %eax
	cmpw	%ax, (%rdi)
	je	.L2380
.L2318:
	movzwl	.LC175(%rip), %eax
	cmpw	%ax, (%rdi)
	je	.L2381
.L2321:
	movzwl	.LC177(%rip), %eax
	cmpw	%ax, (%rdi)
	je	.L2382
.L2324:
	movzwl	.LC178(%rip), %eax
	cmpw	%ax, (%rdi)
	je	.L2383
.L2327:
	movzwl	.LC180(%rip), %eax
	cmpw	%ax, (%rdi)
	je	.L2384
.L2330:
	movzwl	.LC182(%rip), %eax
	cmpw	%ax, (%rdi)
	je	.L2385
.L2333:
	movzwl	.LC184(%rip), %eax
	cmpw	%ax, (%rdi)
	je	.L2386
.L2336:
	movl	$3, %edx
	leaq	.LC186(%rip), %rsi
	movq	%r8, 24(%rsp)
	movl	%r9d, 32(%rsp)
	movl	%r10d, 36(%rsp)
	movq	%rdi, 40(%rsp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	40(%rsp), %rdi
	movl	36(%rsp), %r10d
	movl	32(%rsp), %r9d
	movq	24(%rsp), %r8
	leaq	.LC161(%rip), %rcx
	jne	.L2339
	movq	.LC187(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
	.p2align 4,,10
	.p2align 3
.L2374:
	movzbl	2+.LC161(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2299
	movq	.LC162(%rip), %rax
	movq	%rax, (%r14)
.L2302:
	addq	$8, %r14
	addq	$3, %r13
	cmpq	%r8, %r14
	jne	.L2345
	vxorps	%xmm2, %xmm2, %xmm2
	cmpl	$2, %r10d
	jbe	.L2346
	movl	%ebx, %edx
	shrl	$2, %edx
	salq	$5, %rdx
	addq	%r12, %rdx
	leaq	mass_(%rip), %rax
	vxorpd	%xmm1, %xmm1, %xmm1
	.p2align 4,,10
	.p2align 3
.L2347:
	vaddpd	(%rax), %ymm1, %ymm1
	addq	$32, %rax
	cmpq	%rdx, %rax
	jne	.L2347
	vextractf128	$0x1, %ymm1, %xmm0
	vaddpd	%xmm1, %xmm0, %xmm1
	movl	%ebx, %eax
	andl	$-4, %eax
	vunpckhpd	%xmm1, %xmm1, %xmm0
	vaddpd	%xmm1, %xmm0, %xmm0
	leal	1(%rax), %edx
	cmpl	%eax, %ebx
	je	.L2361
	movslq	%eax, %rcx
	addl	$2, %eax
	vaddsd	(%r15,%rcx,8), %xmm0, %xmm0
	cmpl	%eax, %ebx
	jl	.L2361
.L2360:
	movslq	%edx, %rdx
	vaddsd	(%r15,%rdx,8), %xmm0, %xmm0
	cmpl	%eax, %ebx
	jle	.L2350
	cltq
	vaddsd	(%r15,%rax,8), %xmm0, %xmm0
.L2350:
	vmovsd	.LC8(%rip), %xmm1
	vcvtsi2sdl	%ebx, %xmm2, %xmm2
	vdivsd	%xmm0, %xmm1, %xmm0
	cmpl	$2, %r10d
	jbe	.L2363
.L2358:
	vbroadcastsd	%xmm0, %ymm3
	vbroadcastsd	%xmm2, %ymm1
	vmulpd	%ymm3, %ymm1, %ymm3
	movl	%ebx, %eax
	shrl	$2, %eax
	salq	$5, %rax
	addq	%r12, %rax
	.p2align 4,,10
	.p2align 3
.L2355:
	vmulpd	(%r12), %ymm3, %ymm1
	addq	$32, %r12
	vmovapd	%ymm1, -32(%r12)
	vsqrtpd	%ymm1, %ymm1
	vmovapd	%ymm1, 79968(%r12)
	cmpq	%rax, %r12
	jne	.L2355
	movl	%ebx, %eax
	andl	$-4, %eax
	leal	1(%rax), %ebx
	cmpl	%eax, %r9d
	je	.L2387
	vzeroupper
.L2357:
	subl	%eax, %r9d
	cmpl	$1, %r9d
	je	.L2352
	vmovddup	%xmm2, %xmm1
	vmovddup	%xmm0, %xmm3
	vmulpd	%xmm3, %xmm1, %xmm1
	movl	%eax, %edx
	leaq	(%r15,%rdx,8), %rdx
	addl	$10000, %eax
	vmulpd	(%rdx), %xmm1, %xmm1
	vmovapd	%xmm1, (%rdx)
	vsqrtpd	%xmm1, %xmm1
	vmovapd	%xmm1, (%r15,%rax,8)
	movl	%r9d, %eax
	andl	$-2, %eax
	addl	%eax, %ebx
	cmpl	%r9d, %eax
	je	.L2297
.L2352:
	vmulsd	%xmm2, %xmm0, %xmm0
	decl	%ebx
	movslq	%ebx, %rbx
	vmulsd	(%r15,%rbx,8), %xmm0, %xmm0
	vmovsd	%xmm0, (%r15,%rbx,8)
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm0, 80000(%r15,%rbx,8)
.L2297:
	movq	56(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L2388
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L2375:
	.cfi_restore_state
	movzbl	2+.LC163(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2303
	movq	.LC164(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
	.p2align 4,,10
	.p2align 3
.L2376:
	movzbl	2+.LC165(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2306
	movq	.LC166(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
	.p2align 4,,10
	.p2align 3
.L2377:
	movzbl	2+.LC167(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2309
	movq	.LC168(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
	.p2align 4,,10
	.p2align 3
.L2361:
	vmovsd	.LC8(%rip), %xmm1
	vcvtsi2sdl	%ebx, %xmm2, %xmm2
	vdivsd	%xmm0, %xmm1, %xmm0
	jmp	.L2358
	.p2align 4,,10
	.p2align 3
.L2387:
	vzeroupper
	jmp	.L2297
	.p2align 4,,10
	.p2align 3
.L2379:
	movzbl	2+.LC171(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2315
	movq	.LC172(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
	.p2align 4,,10
	.p2align 3
.L2378:
	movzbl	2+.LC169(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2312
	movq	.LC170(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
.L2346:
	vmovsd	mass_(%rip), %xmm0
	cmpl	$1, %ebx
	je	.L2359
	movl	$1, %edx
	movl	$2, %eax
	jmp	.L2360
.L2363:
	xorl	%eax, %eax
	movl	$1, %ebx
	vzeroupper
	jmp	.L2357
.L2380:
	movzbl	2+.LC173(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2318
	movq	.LC174(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
.L2382:
	movzbl	2+.LC177(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2324
.L2373:
	movq	.LC176(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
.L2381:
	movzbl	2+.LC175(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2321
	jmp	.L2373
.L2359:
	vmovsd	.LC8(%rip), %xmm2
	xorl	%eax, %eax
	vdivsd	%xmm0, %xmm2, %xmm0
	jmp	.L2357
.L2383:
	movzbl	2+.LC178(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2327
	movq	.LC179(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
.L2384:
	movzbl	2+.LC180(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2330
	movq	.LC181(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
.L2339:
	movl	$3, %edx
	leaq	.LC188(%rip), %rsi
	movq	%r8, 24(%rsp)
	movl	%r9d, 32(%rsp)
	movl	%r10d, 36(%rsp)
	movq	%rdi, 40(%rsp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	40(%rsp), %rdi
	movl	36(%rsp), %r10d
	movl	32(%rsp), %r9d
	movq	24(%rsp), %r8
	leaq	.LC161(%rip), %rcx
	jne	.L2340
	movq	.LC189(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
.L2386:
	movzbl	2+.LC184(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2336
	movq	.LC185(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
.L2385:
	movzbl	2+.LC182(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2333
	movq	.LC183(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
.L2388:
	call	__stack_chk_fail@PLT
.L2340:
	movl	$3, %edx
	leaq	.LC190(%rip), %rsi
	movq	%r8, 24(%rsp)
	movl	%r9d, 32(%rsp)
	movl	%r10d, 36(%rsp)
	movq	%rdi, 40(%rsp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	40(%rsp), %rdi
	movl	36(%rsp), %r10d
	movl	32(%rsp), %r9d
	movq	24(%rsp), %r8
	leaq	.LC161(%rip), %rcx
	jne	.L2341
	movq	.LC191(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
.L2341:
	movl	$3, %edx
	leaq	.LC192(%rip), %rsi
	movq	%r8, 24(%rsp)
	movl	%r9d, 32(%rsp)
	movl	%r10d, 36(%rsp)
	movq	%rdi, 40(%rsp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	40(%rsp), %rdi
	movl	36(%rsp), %r10d
	movl	32(%rsp), %r9d
	movq	24(%rsp), %r8
	leaq	.LC161(%rip), %rcx
	jne	.L2342
	movq	.LC193(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
.L2342:
	movl	$3, %edx
	leaq	.LC194(%rip), %rsi
	movq	%r8, 24(%rsp)
	movl	%r9d, 32(%rsp)
	movl	%r10d, 36(%rsp)
	movq	%rdi, 40(%rsp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	40(%rsp), %rdi
	movl	36(%rsp), %r10d
	movl	32(%rsp), %r9d
	movq	24(%rsp), %r8
	leaq	.LC161(%rip), %rcx
	jne	.L2343
	movq	.LC195(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
.L2343:
	movl	$3, %edx
	leaq	.LC196(%rip), %rsi
	movq	%r8, 24(%rsp)
	movl	%r9d, 32(%rsp)
	movl	%r10d, 36(%rsp)
	movq	%rdi, 40(%rsp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	40(%rsp), %rdi
	movl	36(%rsp), %r10d
	movl	32(%rsp), %r9d
	movq	24(%rsp), %r8
	leaq	.LC161(%rip), %rcx
	jne	.L2344
	movq	.LC197(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
.L2344:
	movl	$3, %edx
	leaq	.LC198(%rip), %rsi
	movq	%r8, 24(%rsp)
	movl	%r9d, 32(%rsp)
	movl	%r10d, 36(%rsp)
	movq	%rdi, 40(%rsp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	40(%rsp), %rdi
	movl	36(%rsp), %r10d
	movl	32(%rsp), %r9d
	movq	24(%rsp), %r8
	leaq	.LC161(%rip), %rcx
	jne	.L2302
	movq	.LC199(%rip), %rax
	movq	%rax, (%r14)
	jmp	.L2302
	.cfi_endproc
.LFE44:
	.size	amino_acid_mass_, .-amino_acid_mass_
	.p2align 4
	.globl	interdomain_
	.type	interdomain_, @function
interdomain_:
.LFB45:
	.cfi_startproc
	movl	8+bas_(%rip), %eax
	leaq	cmap_(%rip), %r11
	cltd
	idivl	(%rdi)
	movl	%eax, %esi
	movl	60000004(%r11), %eax
	testl	%eax, %eax
	jle	.L2390
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	decl	%eax
	leaq	60000008(%r11), %rdi
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r13
	leaq	(%rax,%rax,2), %rax
	movq	%rdi, %rcx
	pushq	%r12
	xorl	%r10d, %r10d
	.cfi_offset 13, -24
	.cfi_offset 12, -32
	leaq	60000020(%r11,%rax,4), %r12
	pushq	%rbx
	.cfi_offset 3, -40
	leaq	klst.16(%rip), %rbx
	jmp	.L2394
	.p2align 4,,10
	.p2align 3
.L2414:
	movl	$-1, 8(%rcx)
	addq	$12, %rcx
	cmpq	%rcx, %r12
	je	.L2413
.L2394:
	movl	4(%rcx), %r8d
	movl	(%rcx), %r9d
	leal	-1(%r8), %eax
	cltd
	idivl	%esi
	movl	%eax, %r13d
	leal	-1(%r9), %eax
	cltd
	idivl	%esi
	cmpl	%eax, %r13d
	jne	.L2414
	movl	8(%rcx), %edx
	movslq	%r10d, %rax
	leaq	(%rax,%rax,2), %rax
	addq	$12, %rcx
	movl	%r9d, (%rbx,%rax,4)
	movl	%r8d, 4(%rbx,%rax,4)
	movl	%edx, 8(%rbx,%rax,4)
	incl	%r10d
	cmpq	%rcx, %r12
	jne	.L2394
.L2413:
	movl	%r10d, 60000004(%r11)
	testl	%r10d, %r10d
	je	.L2408
	leal	-1(%r10), %esi
	cmpl	$6, %esi
	jbe	.L2402
	movl	%r10d, %edx
	shrl	$3, %edx
	leaq	(%rdx,%rdx,2), %rdx
	leaq	klst.16(%rip), %rcx
	salq	$5, %rdx
	movq	%rcx, %rax
	addq	%rcx, %rdx
	.p2align 4,,10
	.p2align 3
.L2398:
	vmovdqa	(%rax), %ymm2
	addq	$96, %rax
	vmovdqu	%ymm2, (%rdi)
	vmovdqa	-64(%rax), %ymm3
	addq	$96, %rdi
	vmovdqu	%ymm3, -64(%rdi)
	vmovdqa	-32(%rax), %ymm4
	vmovdqu	%ymm4, -32(%rdi)
	cmpq	%rax, %rdx
	jne	.L2398
	movl	%r10d, %eax
	andl	$-8, %eax
	leal	1(%rax), %edx
	cmpl	%eax, %r10d
	je	.L2415
	vzeroupper
.L2397:
	movl	%r10d, %edi
	subl	%eax, %esi
	subl	%eax, %edi
	cmpl	$2, %esi
	jbe	.L2400
	leaq	(%rax,%rax,2), %rax
	salq	$2, %rax
	leaq	(%rcx,%rax), %rsi
	vmovdqa	(%rsi), %xmm1
	vmovdqa	16(%rsi), %xmm0
	vmovdqa	32(%rsi), %xmm5
	leaq	60000008(%r11,%rax), %rax
	vmovdqu	%xmm5, 32(%rax)
	vmovdqu	%xmm1, (%rax)
	vmovdqu	%xmm0, 16(%rax)
	movl	%edi, %eax
	andl	$-4, %eax
	addl	%eax, %edx
	cmpl	%eax, %edi
	je	.L2408
.L2400:
	leal	-1(%rdx), %eax
	cltq
	leaq	(%rax,%rax,2), %rax
	movq	(%rcx,%rax,4), %rsi
	leaq	3(%rax), %rdi
	movq	%rsi, 60000008(%r11,%rax,4)
	movl	8(%rcx,%rax,4), %esi
	movl	%esi, 60000016(%r11,%rax,4)
	leal	1(%rdx), %esi
	cmpl	%esi, %r10d
	jl	.L2408
	movq	(%rcx,%rdi,4), %rsi
	addl	$2, %edx
	movq	%rsi, 60000020(%r11,%rax,4)
	leaq	6(%rax), %r8
	movl	20(%rcx,%rax,4), %esi
	movl	%esi, 60000028(%r11,%rax,4)
	cmpl	%edx, %r10d
	jl	.L2408
	movq	(%rcx,%r8,4), %rdx
	movq	%rdx, 60000032(%r11,%rax,4)
	movl	32(%rcx,%rax,4), %edx
	movl	%edx, 60000040(%r11,%rax,4)
.L2408:
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%rbp
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L2390:
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	movl	$0, 60000004(%r11)
	ret
	.p2align 4,,10
	.p2align 3
.L2415:
	.cfi_def_cfa 6, 16
	.cfi_offset 3, -40
	.cfi_offset 6, -16
	.cfi_offset 12, -32
	.cfi_offset 13, -24
	vzeroupper
	jmp	.L2408
.L2402:
	xorl	%eax, %eax
	movl	$1, %edx
	leaq	klst.16(%rip), %rcx
	jmp	.L2397
	.cfi_endproc
.LFE45:
	.size	interdomain_, .-interdomain_
	.section	.rodata.str1.8
	.align 8
.LC200:
	.string	"NUMBER OF DOMAIN EXCEEDS ALLOWED DIMENSION."
	.section	.rodata.str1.1
.LC201:
	.string	"PROGRAM STOPPED."
	.text
	.p2align 4
	.globl	build_titin_
	.type	build_titin_, @function
build_titin_:
.LFB46:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$736, %rsp
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
	movq	%fs:40, %rax
	movq	%rax, 728(%rsp)
	movl	(%rdi), %eax
	movl	8+bas_(%rip), %edi
	movl	%edi, 132(%rsp)
	movl	%eax, 92(%rsp)
	imull	%edi, %eax
	cmpl	$10000, %eax
	jg	.L2448
	movslq	%edi, %rax
	leaq	nat_(%rip), %rsi
	vmovsd	79992(%rsi,%rax,8), %xmm3
	vmovsd	-8(%rsi,%rax,8), %xmm4
	vsubsd	80000+nat_(%rip), %xmm3, %xmm3
	vsubsd	nat_(%rip), %xmm4, %xmm4
	vmovsd	159992(%rsi,%rax,8), %xmm2
	vmulsd	%xmm3, %xmm3, %xmm0
	vsubsd	160000+nat_(%rip), %xmm2, %xmm2
	cmpl	$1, 92(%rsp)
	vfmadd231sd	%xmm4, %xmm4, %xmm0
	vfmadd231sd	%xmm2, %xmm2, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vaddsd	bon_(%rip), %xmm0, %xmm1
	vdivsd	%xmm0, %xmm1, %xmm0
	vmulsd	%xmm0, %xmm4, %xmm4
	vmovsd	%xmm4, 64(%rsp)
	vmulsd	%xmm0, %xmm3, %xmm4
	vmovsd	%xmm4, 56(%rsp)
	vmulsd	%xmm0, %xmm2, %xmm4
	vmovsd	%xmm4, 48(%rsp)
	jle	.L2433
	leaq	cmap_(%rip), %rcx
	movslq	60000004(%rcx), %rbx
	leaq	8+nat_(%rip), %rdx
	leaq	(%rbx,%rbx,2), %rax
	leaq	0(,%rax,4), %r9
	leaq	60000008(%rcx,%r9), %rax
	movq	%rax, 104(%rsp)
	leal	-1(%rdi), %eax
	leaq	(%rdx,%rax,8), %rax
	movq	%rax, 144(%rsp)
	movl	%ebx, %eax
	shrl	$3, %eax
	leaq	(%rax,%rax,2), %rax
	salq	$5, %rax
	movq	%rax, 32(%rsp)
	movl	%ebx, %eax
	andl	$-8, %eax
	leal	-1(%rbx), %edx
	movl	%eax, 44(%rsp)
	incl	%eax
	movl	%eax, 40(%rsp)
	movl	%edx, %eax
	leaq	(%rax,%rax,2), %rax
	leaq	60000020(%rcx,%rax,4), %rax
	movq	%rcx, 112(%rsp)
	movl	%ebx, 136(%rsp)
	movq	%rbx, 80(%rsp)
	movq	%r9, 72(%rsp)
	movl	%edx, 88(%rsp)
	movq	%rax, 24(%rsp)
	movq	%rbx, 120(%rsp)
	movq	%r9, 96(%rsp)
	movl	%edi, 188(%rsp)
	movl	%ebx, 140(%rsp)
	movl	%edi, 128(%rsp)
	movl	$1, 184(%rsp)
	.p2align 4,,10
	.p2align 3
.L2431:
	movl	132(%rsp), %edx
	testl	%edx, %edx
	jle	.L2419
	vxorpd	%xmm4, %xmm4, %xmm4
	vcvtsi2sdl	184(%rsp), %xmm4, %xmm0
	movslq	128(%rsp), %r12
	leaq	nat_(%rip), %rax
	leaq	sequence_(%rip), %r13
	vmulsd	64(%rsp), %xmm0, %xmm4
	leaq	(%rax,%r12,8), %rbx
	leaq	80000(%r13), %r14
	leaq	(%r12,%r12,2), %rax
	leaq	nat_(%rip), %r15
	vmovsd	%xmm4, 176(%rsp)
	vmulsd	56(%rsp), %xmm0, %xmm4
	movq	%rax, 152(%rsp)
	vmovsd	%xmm4, 168(%rsp)
	vmulsd	48(%rsp), %xmm0, %xmm4
	vmovsd	%xmm4, 160(%rsp)
	vzeroupper
	.p2align 4,,10
	.p2align 3
.L2420:
	vmovsd	176(%rsp), %xmm7
	vmovsd	168(%rsp), %xmm4
	vaddsd	(%r15), %xmm7, %xmm0
	movl	188(%rsp), %eax
	vmovsd	160(%rsp), %xmm7
	vmovsd	%xmm0, (%rbx)
	vaddsd	80000(%r15), %xmm4, %xmm0
	addl	0(%r13), %eax
	movl	%eax, 0(%r13,%r12,4)
	vmovsd	%xmm0, 80000(%rbx)
	vaddsd	160000(%r15), %xmm7, %xmm0
	movq	152(%rsp), %rax
	movq	%r14, %rsi
	vmovsd	%xmm0, 160000(%rbx)
	leaq	(%r14,%rax), %rdi
	movl	$3, %edx
	addq	$8, %r15
	call	memmove@PLT
	addq	$8, %rbx
	addq	$4, %r13
	addq	$3, %r14
	cmpq	144(%rsp), %r15
	jne	.L2420
	movl	132(%rsp), %esi
	addl	%esi, 128(%rsp)
.L2419:
	movl	136(%rsp), %eax
	movl	140(%rsp), %edx
	testl	%eax, %eax
	jle	.L2449
	movq	120(%rsp), %rax
	leaq	-1(%rax,%rax,2), %rax
	cmpq	$22, %rax
	jbe	.L2422
	movl	88(%rsp), %eax
	cmpl	$2, %eax
	jbe	.L2422
	cmpl	$6, %eax
	jbe	.L2434
	movq	112(%rsp), %rax
	movq	32(%rsp), %rcx
	leaq	60000008(%rax), %rdx
	movq	104(%rsp), %rax
	vpbroadcastd	188(%rsp), %ymm4
	addq	%rax, %rcx
	.p2align 4,,10
	.p2align 3
.L2425:
	vmovdqu	(%rdx), %ymm0
	vmovdqu	32(%rdx), %ymm5
	vpshufb	.LC202(%rip), %ymm0, %ymm2
	vmovdqu	64(%rdx), %ymm3
	vpermq	$78, %ymm2, %ymm1
	vmovdqa	.LC205(%rip), %ymm7
	vpshufb	.LC203(%rip), %ymm0, %ymm2
	vpshufb	.LC204(%rip), %ymm5, %ymm6
	vpor	%ymm1, %ymm2, %ymm2
	vpor	%ymm6, %ymm2, %ymm2
	vpermd	%ymm3, %ymm7, %ymm1
	vpblendd	$224, %ymm1, %ymm2, %ymm2
	vpshufb	.LC206(%rip), %ymm0, %ymm1
	vpermq	$78, %ymm1, %ymm6
	vpshufb	.LC207(%rip), %ymm0, %ymm1
	vpor	%ymm6, %ymm1, %ymm1
	vmovdqa	.LC209(%rip), %ymm6
	vpshufb	.LC208(%rip), %ymm5, %ymm7
	vpermd	%ymm3, %ymm6, %ymm6
	vpor	%ymm7, %ymm1, %ymm1
	vpblendd	$192, %ymm6, %ymm1, %ymm1
	vpshufb	.LC210(%rip), %ymm0, %ymm6
	vmovdqa	.LC213(%rip), %ymm7
	vpermq	$78, %ymm6, %ymm6
	vpshufb	.LC211(%rip), %ymm0, %ymm0
	vpshufb	.LC212(%rip), %ymm5, %ymm5
	vpor	%ymm6, %ymm0, %ymm0
	vpermd	%ymm3, %ymm7, %ymm3
	vpor	%ymm5, %ymm0, %ymm0
	vpblendd	$224, %ymm3, %ymm0, %ymm0
	vpaddd	%ymm4, %ymm1, %ymm1
	vpaddd	%ymm4, %ymm0, %ymm0
	vmovdqa	.LC214(%rip), %ymm6
	vmovdqa	.LC215(%rip), %ymm7
	vinserti128	$1, %xmm0, %ymm1, %ymm3
	vpermd	%ymm2, %ymm7, %ymm5
	vpermd	%ymm3, %ymm6, %ymm3
	vpblendd	$36, %ymm5, %ymm3, %ymm3
	vmovdqu	%ymm3, (%rax)
	vpshufb	.LC216(%rip), %ymm1, %ymm3
	vpermq	$78, %ymm3, %ymm5
	vpshufb	.LC217(%rip), %ymm1, %ymm3
	vpshufb	.LC218(%rip), %ymm0, %ymm6
	vpor	%ymm5, %ymm3, %ymm3
	vpor	%ymm6, %ymm3, %ymm3
	vpshufb	.LC219(%rip), %ymm2, %ymm5
	vpshufb	.LC220(%rip), %ymm3, %ymm3
	vpor	%ymm3, %ymm5, %ymm3
	vmovdqu	%ymm3, 32(%rax)
	vpshufb	.LC221(%rip), %ymm0, %ymm5
	vpshufb	.LC222(%rip), %ymm1, %ymm3
	vmovdqa	.LC225(%rip), %ymm6
	vpermq	$78, %ymm5, %ymm5
	vpermq	$78, %ymm3, %ymm3
	vpshufb	.LC223(%rip), %ymm0, %ymm0
	vpshufb	.LC224(%rip), %ymm1, %ymm1
	vpor	%ymm5, %ymm0, %ymm0
	vpor	%ymm3, %ymm1, %ymm1
	vpor	%ymm1, %ymm0, %ymm0
	vpermd	%ymm2, %ymm6, %ymm2
	vpblendd	$146, %ymm2, %ymm0, %ymm0
	vmovdqu	%ymm0, 64(%rax)
	addq	$96, %rax
	addq	$96, %rdx
	cmpq	%rcx, %rax
	jne	.L2425
	movl	140(%rsp), %edx
	movl	44(%rsp), %ecx
	movl	136(%rsp), %esi
	addl	%ecx, %edx
	cmpl	%esi, %ecx
	je	.L2429
	subl	%ecx, %esi
	leal	-1(%rsi), %eax
	cmpl	$2, %eax
	jbe	.L2435
	movl	40(%rsp), %edi
	movl	%ecx, %eax
.L2423:
	movq	112(%rsp), %rbx
	leaq	(%rax,%rax,2), %rcx
	leaq	60000008(%rbx,%rcx,4), %rcx
	vmovdqu	(%rcx), %xmm3
	vmovdqu	16(%rcx), %xmm5
	vmovdqu	32(%rcx), %xmm4
	vpshufb	.LC227(%rip), %xmm5, %xmm0
	vpshufb	.LC226(%rip), %xmm3, %xmm2
	vpshufb	.LC229(%rip), %xmm5, %xmm1
	vpor	%xmm0, %xmm2, %xmm2
	vpshufb	.LC228(%rip), %xmm3, %xmm0
	vpor	%xmm1, %xmm0, %xmm0
	vpshufb	.LC230(%rip), %xmm3, %xmm3
	vpshufd	$100, %xmm4, %xmm1
	vpshufb	.LC231(%rip), %xmm5, %xmm5
	vshufps	$196, %xmm4, %xmm2, %xmm2
	vpblendw	$192, %xmm1, %xmm0, %xmm0
	vpshufd	$164, %xmm4, %xmm4
	vbroadcastss	188(%rsp), %xmm1
	vpor	%xmm5, %xmm3, %xmm3
	vpblendw	$192, %xmm4, %xmm3, %xmm3
	vpaddd	%xmm0, %xmm1, %xmm0
	vpaddd	%xmm3, %xmm1, %xmm1
	vpunpckldq	%xmm1, %xmm0, %xmm3
	addq	120(%rsp), %rax
	vpshufd	$196, %xmm2, %xmm4
	leaq	(%rax,%rax,2), %rax
	vpshufd	$132, %xmm3, %xmm3
	leaq	60000008(%rbx,%rax,4), %rax
	vpblendw	$48, %xmm4, %xmm3, %xmm3
	vmovdqu	%xmm3, (%rax)
	vpshufb	.LC233(%rip), %xmm0, %xmm4
	vpshufb	.LC232(%rip), %xmm1, %xmm3
	vpshufb	.LC228(%rip), %xmm0, %xmm0
	vpshufb	.LC234(%rip), %xmm1, %xmm1
	vpor	%xmm4, %xmm3, %xmm3
	vpor	%xmm1, %xmm0, %xmm1
	vpblendw	$12, %xmm2, %xmm3, %xmm3
	vpshufb	.LC236(%rip), %xmm1, %xmm1
	vpshufb	.LC235(%rip), %xmm2, %xmm2
	vpor	%xmm1, %xmm2, %xmm1
	vmovdqu	%xmm3, 16(%rax)
	vmovdqu	%xmm1, 32(%rax)
	movl	%esi, %eax
	andl	$-4, %eax
	leal	(%rax,%rdi), %ecx
	addl	%eax, %edx
	cmpl	%esi, %eax
	je	.L2429
.L2427:
	leal	-1(%rcx), %eax
	movq	112(%rsp), %rbx
	cltq
	leaq	(%rax,%rax,2), %rsi
	vmovd	188(%rsp), %xmm4
	vmovq	60000008(%rbx,%rsi,4), %xmm0
	vpshufd	$0, %xmm4, %xmm1
	vpaddd	%xmm1, %xmm0, %xmm0
	movl	60000016(%rbx,%rsi,4), %edi
	movslq	%edx, %rdx
	movl	136(%rsp), %r8d
	leaq	(%rdx,%rdx,2), %rax
	leal	1(%rcx), %edx
	movl	%edi, 60000016(%rbx,%rax,4)
	vmovq	%xmm0, 60000008(%rbx,%rax,4)
	cmpl	%edx, %r8d
	jl	.L2429
	vmovq	60000020(%rbx,%rsi,4), %xmm0
	movl	60000028(%rbx,%rsi,4), %edx
	vpaddd	%xmm1, %xmm0, %xmm0
	addl	$2, %ecx
	movl	%edx, 60000028(%rbx,%rax,4)
	vmovq	%xmm0, 60000020(%rbx,%rax,4)
	cmpl	%ecx, %r8d
	jl	.L2429
	vmovq	60000032(%rbx,%rsi,4), %xmm0
	movl	60000040(%rbx,%rsi,4), %edx
	vpaddd	%xmm1, %xmm0, %xmm1
	movl	%edx, 60000040(%rbx,%rax,4)
	vmovq	%xmm1, 60000032(%rbx,%rax,4)
.L2429:
	movl	140(%rsp), %eax
	addl	136(%rsp), %eax
	movl	%eax, %edx
.L2421:
	incl	184(%rsp)
	movl	132(%rsp), %esi
	movl	%eax, 140(%rsp)
	addl	%esi, 188(%rsp)
	movq	80(%rsp), %rcx
	movq	72(%rsp), %rsi
	movl	184(%rsp), %eax
	addq	%rsi, 96(%rsp)
	addq	%rcx, 120(%rsp)
	addq	%rsi, 104(%rsp)
	cmpl	92(%rsp), %eax
	jne	.L2431
	vzeroupper
.L2418:
	movl	128(%rsp), %eax
	movl	%eax, 8+bas_(%rip)
	movq	112(%rsp), %rax
	movl	%edx, 60000004(%rax)
	movq	728(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L2450
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L2422:
	.cfi_restore_state
	movq	112(%rsp), %rax
	vmovd	188(%rsp), %xmm4
	movq	24(%rsp), %rsi
	movq	96(%rsp), %rdx
	addq	$60000008, %rax
	vpshufd	$0, %xmm4, %xmm1
	.p2align 4,,10
	.p2align 3
.L2430:
	vmovq	(%rax), %xmm0
	movl	8(%rax), %ecx
	vpaddd	%xmm1, %xmm0, %xmm0
	movl	%ecx, 8(%rax,%rdx)
	addq	$12, %rax
	vmovq	%xmm0, -12(%rax,%rdx)
	cmpq	%rsi, %rax
	jne	.L2430
	jmp	.L2429
	.p2align 4,,10
	.p2align 3
.L2449:
	movl	136(%rsp), %eax
	addl	%edx, %eax
	jmp	.L2421
.L2434:
	movl	136(%rsp), %esi
	xorl	%eax, %eax
	movl	$1, %edi
	jmp	.L2423
.L2435:
	movl	40(%rsp), %ecx
	jmp	.L2427
.L2433:
	leaq	cmap_(%rip), %rax
	movl	%edi, 128(%rsp)
	movq	%rax, 112(%rsp)
	jmp	.L2418
.L2450:
	call	__stack_chk_fail@PLT
.L2448:
	leaq	192(%rsp), %r12
	movl	$6291457, %ebx
	leaq	.LC2(%rip), %r14
	leaq	.LC56(%rip), %r13
	salq	$12, %rbx
	movq	%r12, %rdi
	movq	%r14, 200(%rsp)
	movl	$6953, 208(%rsp)
	movq	%r13, 272(%rsp)
	movq	$3, 280(%rsp)
	movq	%rbx, 192(%rsp)
	call	_gfortran_st_write@PLT
	movl	$43, %edx
	leaq	.LC200(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movq	%r12, %rdi
	movq	%r14, 200(%rsp)
	movl	$6954, 208(%rsp)
	movq	%r13, 272(%rsp)
	movq	$3, 280(%rsp)
	movq	%rbx, 192(%rsp)
	call	_gfortran_st_write@PLT
	movl	$16, %edx
	leaq	.LC201(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
	.cfi_endproc
.LFE46:
	.size	build_titin_, .-build_titin_
	.section	.rodata.str1.1
.LC237:
	.string	"old"
.LC238:
	.string	"(a,2x,a)"
.LC239:
	.string	"ERROR OPENING FILENAME"
	.text
	.p2align 4
	.globl	load_cmap_
	.type	load_cmap_, @function
load_cmap_:
.LFB47:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	.cfi_offset 15, -24
	leaq	.LC2(%rip), %r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	movq	%rdi, %r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$1024, %rsp
	.cfi_offset 3, -56
	movq	%fs:40, %rax
	movq	%rax, 1016(%rsp)
	xorl	%eax, %eax
	leaq	56(%rsp), %rax
	movq	%rax, 104(%rsp)
	leaq	.LC237(%rip), %rax
	movq	%rax, 136(%rsp)
	movabsq	$420923573024, %rax
	movq	%rax, 64(%rsp)
	leaq	64(%rsp), %rax
	movq	%rdi, 128(%rsp)
	movq	%rax, %rdi
	movq	%rax, 24(%rsp)
	movq	%r15, 72(%rsp)
	movl	$4867, 80(%rsp)
	movl	$0, 56(%rsp)
	movq	$32, 120(%rsp)
	movq	$3, 144(%rsp)
	movl	$0, 368(%rsp)
	call	_gfortran_st_open@PLT
	movl	56(%rsp), %eax
	movq	%r15, 488(%rsp)
	testl	%eax, %eax
	jne	.L2464
	leaq	480(%rsp), %rbx
	movabsq	$420906795136, %r14
	movq	%rbx, %rdi
	movl	$4873, 496(%rsp)
	movq	%r14, 480(%rsp)
	call	_gfortran_st_read@PLT
	leaq	52(%rsp), %rsi
	movl	$4, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%rbx, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%rbx, %rdi
	movq	%r15, 488(%rsp)
	movl	$4874, 496(%rsp)
	movq	%r14, 480(%rsp)
	call	_gfortran_st_read@PLT
	leaq	60(%rsp), %rsi
	movl	$4, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%rbx, %rdi
	call	_gfortran_st_read_done@PLT
	movl	52(%rsp), %eax
	movl	%eax, 44(%rsp)
	testl	%eax, %eax
	leaq	cmap_(%rip), %rax
	movq	%rax, 16(%rsp)
	jle	.L2456
	leaq	60000008(%rax), %r13
	leaq	416(%rsp), %rax
	movq	%rax, 32(%rsp)
	leaq	4008+sig_(%rip), %r14
	movl	$1, %r12d
	.p2align 4,,10
	.p2align 3
.L2457:
	movabsq	$420906795136, %rax
	movq	%rbx, %rdi
	movq	%rax, 480(%rsp)
	movq	%r15, 488(%rsp)
	movl	$4876, 496(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC240(%rip), %ymm0
	movabsq	$1103806595072, %rax
	movq	32(%rsp), %rsi
	movq	%rax, 440(%rsp)
	xorl	%ecx, %ecx
	leaq	-7(%r12,%r12,2), %rax
	movl	$4, %edx
	movq	%rbx, %rdi
	movq	$4, 432(%rsp)
	movq	%r13, 416(%rsp)
	movq	%rax, 424(%rsp)
	vmovdqa	%ymm0, 448(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r14, %rsi
	movl	$8, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_real@PLT
	incq	%r12
	movq	%rbx, %rdi
	call	_gfortran_st_read_done@PLT
	addq	$12, %r13
	movl	$1, -4(%r13)
	addq	$8, %r14
	cmpl	%r12d, 44(%rsp)
	jge	.L2457
.L2456:
	movq	16(%rsp), %rax
	movl	44(%rsp), %ecx
	leaq	angnat_(%rip), %r12
	movl	%ecx, 60000004(%rax)
	movl	60(%rsp), %eax
	movl	$1, %r13d
	movl	%eax, 44(%rsp)
	leaq	159996(%r12), %r14
	testl	%eax, %eax
	jle	.L2454
	.p2align 4,,10
	.p2align 3
.L2458:
	movabsq	$420906795136, %rax
	movq	%rbx, %rdi
	movq	%rax, 480(%rsp)
	movq	%r15, 488(%rsp)
	movl	$4882, 496(%rsp)
	call	_gfortran_st_read@PLT
	movq	%r12, %rsi
	movl	$8, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_real@PLT
	leaq	80000(%r12), %rsi
	movl	$8, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%rbx, %rdi
	call	_gfortran_st_read_done@PLT
	movl	$1, (%r14,%r13,4)
	incq	%r13
	addq	$8, %r12
	cmpl	%r13d, 44(%rsp)
	jge	.L2458
.L2454:
	movq	24(%rsp), %rdi
	movabsq	$420906795008, %rax
	movq	%rax, 64(%rsp)
	movq	%r15, 72(%rsp)
	movl	$4885, 80(%rsp)
	call	_gfortran_st_close@PLT
	movq	1016(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L2465
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
.L2464:
	.cfi_restore_state
	leaq	.LC238(%rip), %rax
	leaq	480(%rsp), %r13
	movq	%rax, 560(%rsp)
	movl	$6291457, %eax
	salq	$12, %rax
	movq	%r13, %rdi
	movq	%rax, 480(%rsp)
	movl	$4869, 496(%rsp)
	movq	$8, 568(%rsp)
	call	_gfortran_st_write@PLT
	movl	$22, %edx
	leaq	.LC239(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$32, %edx
	movq	%r12, %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	movl	$201326593, %eax
	salq	$7, %rax
	movq	%r13, %rdi
	movq	%rax, 480(%rsp)
	movq	%r15, 488(%rsp)
	movl	$4870, 496(%rsp)
	call	_gfortran_st_write@PLT
	movl	$16, %edx
	leaq	.LC201(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
.L2465:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE47:
	.size	load_cmap_, .-load_cmap_
	.p2align 4
	.globl	compute_cmap_
	.type	compute_cmap_, @function
compute_cmap_:
.LFB48:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	movl	160000+bon_(%rip), %eax
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	leaq	cmap_(%rip), %r14
	movl	$0, 60000004(%r14)
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	movq	%rdi, -64(%rsp)
	movq	%rsi, -56(%rsp)
	movl	%eax, -36(%rsp)
	testl	%eax, %eax
	jle	.L2499
	incl	%eax
	movl	36+kier_(%rip), %r12d
	vmovsd	240008+for_(%rip), %xmm5
	movl	44+kier_(%rip), %r10d
	vmovsd	240040+for_(%rip), %xmm6
	vmovsd	240016+for_(%rip), %xmm7
	movq	%rax, -8(%rsp)
	movq	$1, -48(%rsp)
	vmovsd	240024+for_(%rip), %xmm15
	vmovsd	240000+for_(%rip), %xmm14
	movl	40+kier_(%rip), %r11d
	vmovsd	240032+for_(%rip), %xmm13
	vmovsd	72+pid_(%rip), %xmm10
	vmovsd	.LC11(%rip), %xmm9
	vxorps	%xmm4, %xmm4, %xmm4
	vmovsd	%xmm5, -104(%rsp)
	vmovsd	%xmm6, -96(%rsp)
	vmovsd	%xmm7, -88(%rsp)
	xorl	%r13d, %r13d
	movl	%r12d, %r15d
	movl	%r10d, %ebx
.L2482:
	movq	-48(%rsp), %rdi
	leaq	119996+bon_(%rip), %rax
	movslq	(%rax,%rdi,4), %rax
	movq	%rdi, -72(%rsp)
	leal	1(%rax), %ecx
	movl	%ecx, -32(%rsp)
	leaq	120000+bon_(%rip), %rcx
	movl	(%rcx,%rdi,4), %ecx
	movl	%ecx, -28(%rsp)
	leaq	sequence_(%rip), %rcx
	leaq	(%rcx,%rax,4), %rcx
	movq	%rcx, -24(%rsp)
	leaq	nat_(%rip), %rcx
	leaq	(%rcx,%rax,8), %rax
	movq	%rax, -16(%rsp)
	.p2align 4,,10
	.p2align 3
.L2481:
	movl	-32(%rsp), %eax
	movl	-28(%rsp), %ecx
	cmpl	%ecx, %eax
	jg	.L2468
	incl	%ecx
	movq	-72(%rsp), %rdx
	movl	%ecx, -40(%rsp)
	movl	-48(%rsp), %ecx
	leaq	120000+bon_(%rip), %rdi
	movl	%edx, -108(%rsp)
	movl	%ecx, -80(%rsp)
	movl	%eax, -112(%rsp)
	movl	(%rdi,%rdx,4), %edi
	movq	-16(%rsp), %r12
	movq	-24(%rsp), %r10
	.p2align 4,,10
	.p2align 3
.L2480:
	movl	-80(%rsp), %ecx
	cmpl	%ecx, -108(%rsp)
	je	.L2501
	movq	-72(%rsp), %rcx
	leaq	119996+bon_(%rip), %rax
	movl	(%rax,%rcx,4), %eax
	movl	%eax, -76(%rsp)
	incl	%eax
.L2470:
	cmpl	%edi, %eax
	jg	.L2471
	movq	-64(%rsp), %rcx
	cltq
	vmovsd	(%rcx), %xmm5
	movq	-56(%rsp), %rcx
	vmovsd	(%r12), %xmm8
	movl	(%rcx), %r8d
	leaq	nat_(%rip), %rcx
	vmovsd	80000(%r12), %xmm7
	vmovsd	160000(%r12), %xmm6
	leaq	(%rcx,%rax,8), %rdx
	leaq	39996+sequence_(%rip), %rbp
	jmp	.L2479
	.p2align 4,,10
	.p2align 3
.L2478:
	movl	$-1, 60000016(%r14,%r9,4)
	movslq	%esi, %r13
.L2476:
	incq	%rax
	addq	$8, %rdx
	cmpl	%eax, %edi
	jl	.L2471
.L2479:
	vsubsd	-8(%rdx), %xmm8, %xmm1
	vsubsd	79992(%rdx), %xmm7, %xmm2
	vsubsd	159992(%rdx), %xmm6, %xmm0
	movl	%eax, %ecx
	testl	%r15d, %r15d
	je	.L2472
	vmulsd	%xmm1, %xmm15, %xmm12
	vmovsd	.LC60(%rip), %xmm3
	vandpd	%xmm12, %xmm9, %xmm11
	vorpd	%xmm11, %xmm3, %xmm3
	vaddsd	%xmm12, %xmm3, %xmm3
	vcvttsd2sil	%xmm3, %esi
	vcvtsi2sdl	%esi, %xmm4, %xmm3
	vfnmadd231sd	%xmm3, %xmm14, %xmm1
.L2472:
	testl	%r11d, %r11d
	je	.L2473
	vmulsd	%xmm2, %xmm13, %xmm12
	vmovsd	.LC60(%rip), %xmm3
	vandpd	%xmm12, %xmm9, %xmm11
	vorpd	%xmm11, %xmm3, %xmm3
	vaddsd	%xmm12, %xmm3, %xmm3
	vcvttsd2sil	%xmm3, %esi
	vcvtsi2sdl	%esi, %xmm4, %xmm3
	vfnmadd231sd	-104(%rsp), %xmm3, %xmm2
.L2473:
	testl	%ebx, %ebx
	je	.L2474
	vmulsd	-96(%rsp), %xmm0, %xmm12
	vmovsd	.LC60(%rip), %xmm3
	vandpd	%xmm12, %xmm9, %xmm11
	vorpd	%xmm11, %xmm3, %xmm3
	vaddsd	%xmm12, %xmm3, %xmm3
	vcvttsd2sil	%xmm3, %esi
	vcvtsi2sdl	%esi, %xmm4, %xmm3
	vfnmadd231sd	-88(%rsp), %xmm3, %xmm0
.L2474:
	vmulsd	%xmm2, %xmm2, %xmm2
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vmovsd	%xmm5, %xmm5, %xmm1
	vsqrtsd	%xmm0, %xmm0, %xmm0
	testl	%r8d, %r8d
	je	.L2475
	movl	40000(%r10), %esi
	leal	(%rsi,%rsi,4), %r9d
	leal	(%rsi,%r9,4), %esi
	addl	0(%rbp,%rax,4), %esi
	movslq	%esi, %rsi
	leaq	sig_(%rip), %r9
	vmulsd	-8(%r9,%rsi,8), %xmm10, %xmm1
.L2475:
	vcomisd	%xmm0, %xmm1
	jb	.L2476
	vmovd	-112(%rsp), %xmm2
	leaq	0(%r13,%r13,2), %r9
	leal	1(%r13), %esi
	movl	-80(%rsp), %r13d
	vpinsrd	$1, %ecx, %xmm2, %xmm0
	vmovq	%xmm0, 60000008(%r14,%r9,4)
	cmpl	%r13d, -108(%rsp)
	jne	.L2478
	incq	%rax
	movl	$1, 60000016(%r14,%r9,4)
	movslq	%esi, %r13
	addq	$8, %rdx
	cmpl	%eax, %edi
	jge	.L2479
	.p2align 4,,10
	.p2align 3
.L2471:
	incl	-112(%rsp)
	addq	$4, %r10
	addq	$8, %r12
	movl	-112(%rsp), %eax
	cmpl	%eax, -40(%rsp)
	jne	.L2480
.L2468:
	incq	-72(%rsp)
	movq	-72(%rsp), %rax
	cmpl	%eax, -36(%rsp)
	jge	.L2481
	incq	-48(%rsp)
	movq	-48(%rsp), %rax
	cmpq	-8(%rsp), %rax
	jne	.L2482
	movl	%r13d, 60000004(%r14)
.L2499:
	popq	%rbx
	.cfi_remember_state
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L2501:
	.cfi_restore_state
	movl	-112(%rsp), %eax
	addl	$3, %eax
	jmp	.L2470
	.cfi_endproc
.LFE48:
	.size	compute_cmap_, .-compute_cmap_
	.section	.rodata.str1.8
	.align 8
.LC248:
	.string	"AMINO ACID HAS FEWER ATOMS THAN SHOULD BE"
	.section	.rodata.str1.1
.LC249:
	.string	"(i5,2x,a3,2x,2i6)"
.LC250:
	.string	"ATOM ERROR:"
.LC251:
	.string	"(a3,2x,i3,2x,a3)"
	.text
	.p2align 4
	.globl	assign_vdw_radius_
	.type	assign_vdw_radius_, @function
assign_vdw_radius_:
.LFB50:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$40600, %rsp
	.cfi_def_cfa_offset 40656
	movq	%fs:40, %rax
	movq	%rax, 40584(%rsp)
	movl	8+bas_(%rip), %eax
	movl	%eax, (%rsp)
	testl	%eax, %eax
	jle	.L2502
	leaq	radi_(%rip), %rbx
	decl	%eax
	leaq	8(%rbx), %rdx
	leaq	80000+sequence_(%rip), %r12
	leaq	576(%rsp), %r13
	leaq	(%rdx,%rax,8), %r9
	vmovsd	.LC241(%rip), %xmm2
	vmovsd	.LC242(%rip), %xmm5
	vmovsd	.LC243(%rip), %xmm0
	vmovsd	.LC244(%rip), %xmm1
	movq	%r12, 8(%rsp)
	movq	%r13, 16(%rsp)
	movq	%r12, %r14
	leaq	40581(%rsp), %r15
	movq	%r13, %r12
	leaq	.LC161(%rip), %rbp
	movq	%r9, %r13
	.p2align 4,,10
	.p2align 3
.L2550:
	movzwl	(%r14), %eax
	movzbl	2(%r14), %edx
	movw	%ax, 40581(%rsp)
	movb	%dl, 40583(%rsp)
	vmovsd	%xmm2, (%rbx)
	vmovsd	%xmm5, 80000(%rbx)
	vmovsd	%xmm0, 160000(%rbx)
	vmovsd	%xmm1, 240000(%rbx)
	cmpw	0(%rbp), %ax
	je	.L2587
.L2504:
	movzwl	.LC167(%rip), %eax
	cmpw	%ax, (%r15)
	je	.L2588
.L2508:
	movzwl	.LC182(%rip), %eax
	cmpw	%ax, (%r15)
	je	.L2589
.L2511:
	movzwl	.LC173(%rip), %eax
	cmpw	%ax, (%r15)
	je	.L2590
.L2514:
	movzwl	.LC169(%rip), %eax
	cmpw	%ax, (%r15)
	je	.L2591
.L2517:
	movzwl	.LC192(%rip), %eax
	cmpw	%ax, (%r15)
	je	.L2592
.L2520:
	movzwl	.LC188(%rip), %eax
	cmpw	%ax, (%r15)
	je	.L2593
.L2523:
	movzwl	.LC175(%rip), %eax
	cmpw	%ax, (%r15)
	je	.L2594
.L2526:
	movzwl	.LC180(%rip), %eax
	cmpw	%ax, (%r15)
	je	.L2595
.L2529:
	movzwl	.LC186(%rip), %eax
	cmpw	%ax, (%r15)
	je	.L2596
.L2532:
	movzwl	.LC184(%rip), %eax
	cmpw	%ax, (%r15)
	je	.L2597
.L2535:
	movzwl	.LC194(%rip), %eax
	cmpw	%ax, (%r15)
	je	.L2598
.L2538:
	movzwl	.LC165(%rip), %eax
	cmpw	%ax, (%r15)
	je	.L2599
.L2541:
	movl	$3, %edx
	leaq	.LC171(%rip), %rsi
	movq	%r15, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	movq	.LC241(%rip), %rax
	vmovq	%rax, %xmm2
	movq	.LC242(%rip), %rax
	vmovq	%rax, %xmm5
	movq	.LC243(%rip), %rax
	vmovq	%rax, %xmm0
	movq	.LC244(%rip), %rax
	vmovq	%rax, %xmm1
	jne	.L2544
	movq	.LC247(%rip), %rax
	movl	$7, (%r12)
	movq	%rax, 400000(%rbx)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm5, 480000(%rbx)
	jmp	.L2507
	.p2align 4,,10
	.p2align 3
.L2587:
	movzbl	2+.LC161(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2504
	movl	$4, (%r12)
.L2507:
	addq	$8, %rbx
	addq	$3, %r14
	addq	$4, %r12
	cmpq	%r13, %rbx
	jne	.L2550
	movl	(%rsp), %eax
	leaq	40000+nall_(%rip), %r8
	movq	%rax, (%rsp)
	movq	8(%rsp), %r12
	movq	16(%rsp), %r13
	leaq	8+radi_(%rip), %rcx
	xorl	%r14d, %r14d
	leaq	-40000(%r8), %r9
	vxorpd	%xmm1, %xmm1, %xmm1
	.p2align 4,,10
	.p2align 3
.L2555:
	movq	%r14, %r15
	movl	(%r9,%r15,4), %ebx
	movl	0(%r13,%r15,4), %eax
	movl	%ebx, 44(%rsp)
	incq	%r14
	cmpl	%eax, %ebx
	jl	.L2600
	jle	.L2552
	movl	%eax, 44(%rsp)
	movl	%eax, (%r9,%r15,4)
	movl	%eax, %ebx
.L2552:
	testl	%ebx, %ebx
	jle	.L2564
	movzwl	(%r12), %edi
	movzbl	2(%r12), %esi
	vmovsd	.LC247(%rip), %xmm4
	vmovsd	.LC245(%rip), %xmm3
	movq	%rcx, %rax
	movq	%r8, %rbp
	movl	$1, %edx
	jmp	.L2565
	.p2align 4,,10
	.p2align 3
.L2556:
	cmpb	$83, %r10b
	je	.L2601
	cmpb	$79, %r10b
	jne	.L2562
	vcomisd	.LC244(%rip), %xmm0
	je	.L2559
	vcomisd	.LC247(%rip), %xmm0
	je	.L2559
	vmovsd	%xmm4, -8(%rax)
.L2559:
	vcomisd	%xmm1, %xmm0
	je	.L2602
.L2557:
	incl	%edx
	addq	$30000, %rbp
	addq	$80000, %rax
	cmpl	%ebx, %edx
	jg	.L2564
.L2565:
	movzbl	0(%rbp), %r10d
	movw	%di, 40581(%rsp)
	movb	%sil, 40583(%rsp)
	vmovsd	-8(%rax), %xmm0
	cmpb	$78, %r10b
	jne	.L2556
	vcomisd	%xmm2, %xmm0
	je	.L2557
	vcomisd	%xmm1, %xmm0
	vmovsd	%xmm2, -8(%rax)
	jne	.L2557
.L2602:
	leaq	48(%rsp), %r13
	leaq	.LC56(%rip), %rax
	leaq	.LC2(%rip), %r14
	movabsq	$4294971392, %rbx
	movq	%r13, %rdi
	movq	%rax, 128(%rsp)
	movq	%r14, 56(%rsp)
	movl	$7478, 64(%rsp)
	movq	$3, 136(%rsp)
	movq	%rbx, 48(%rsp)
	call	_gfortran_st_write@PLT
	movl	$11, %edx
	leaq	.LC250(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC251(%rip), %rax
	movq	%r13, %rdi
	movq	%rax, 128(%rsp)
	movq	%r14, 56(%rsp)
	movl	$7479, 64(%rsp)
	movq	$16, 136(%rsp)
	movq	%rbx, 48(%rsp)
	call	_gfortran_st_write@PLT
	movl	$3, %edx
	movq	%r12, %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	sequence_(%rip), %rax
	leaq	(%rax,%r15,4), %rsi
	movl	$4, %edx
	movq	%r13, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$3, %edx
	movq	%rbp, %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
	.p2align 4,,10
	.p2align 3
.L2601:
	vcomisd	%xmm3, %xmm0
	je	.L2557
	vmovsd	%xmm3, -8(%rax)
	jmp	.L2559
	.p2align 4,,10
	.p2align 3
.L2562:
	cmpb	$67, %r10b
	jne	.L2559
	xorl	%r11d, %r11d
	vcomisd	.LC242(%rip), %xmm0
	setne	%r11b
	xorl	%r10d, %r10d
	vcomisd	.LC246(%rip), %xmm0
	setne	%r10b
	testb	%r10b, %r11b
	je	.L2559
	vcomisd	.LC243(%rip), %xmm0
	je	.L2559
	vmovsd	%xmm5, -8(%rax)
	jmp	.L2559
	.p2align 4,,10
	.p2align 3
.L2564:
	addq	$3, %r12
	addq	$3, %r8
	addq	$8, %rcx
	cmpq	(%rsp), %r14
	jne	.L2555
.L2502:
	movq	40584(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L2603
	addq	$40600, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L2600:
	.cfi_restore_state
	leaq	48(%rsp), %rbp
	leaq	.LC2(%rip), %rax
	movq	%rcx, 16(%rsp)
	movq	%rbp, %rdi
	movabsq	$4294967424, %rcx
	movq	%r8, 24(%rsp)
	movq	%rcx, 48(%rsp)
	movq	%rax, 56(%rsp)
	movl	$7452, 64(%rsp)
	call	_gfortran_st_write@PLT
	movl	$41, %edx
	leaq	.LC248(%rip), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC2(%rip), %rax
	movq	%rax, 56(%rsp)
	leaq	.LC249(%rip), %rax
	movq	%rax, 128(%rsp)
	movq	%rbp, %rdi
	movabsq	$4294971392, %rax
	movq	%rax, 48(%rsp)
	movl	$7453, 64(%rsp)
	movq	$17, 136(%rsp)
	call	_gfortran_st_write@PLT
	leaq	0(,%r15,4), %rax
	leaq	sequence_(%rip), %rsi
	addq	%rax, %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	movq	%rax, 8(%rsp)
	call	_gfortran_transfer_integer_write@PLT
	movl	$3, %edx
	movq	%r12, %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	44(%rsp), %rsi
	movl	$4, %edx
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	8(%rsp), %rax
	movl	$4, %edx
	leaq	0(%r13,%rax), %rsi
	movq	%rbp, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%rbp, %rdi
	call	_gfortran_st_write_done@PLT
	movq	.LC241(%rip), %rax
	movq	16(%rsp), %rcx
	vmovq	%rax, %xmm2
	movq	.LC242(%rip), %rax
	movq	24(%rsp), %r8
	vmovq	%rax, %xmm5
	leaq	nall_(%rip), %r9
	vxorpd	%xmm1, %xmm1, %xmm1
	jmp	.L2552
.L2588:
	movzbl	2+.LC167(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2508
.L2585:
	movl	$7, (%r12)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm5, 400000(%rbx)
	vmovsd	%xmm5, 480000(%rbx)
	jmp	.L2507
.L2589:
	movzbl	2+.LC182(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2511
	movl	$9, (%r12)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm5, 400000(%rbx)
	vmovsd	%xmm0, 480000(%rbx)
	vmovsd	%xmm1, 560000(%rbx)
	vmovsd	%xmm2, 640000(%rbx)
	jmp	.L2507
.L2590:
	movzbl	2+.LC173(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2514
	movq	.LC245(%rip), %rax
	movl	$6, (%r12)
	movq	%rax, 400000(%rbx)
	vmovsd	%xmm5, 320000(%rbx)
	jmp	.L2507
.L2592:
	movzbl	2+.LC192(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2520
	movq	.LC246(%rip), %rax
	movl	$11, (%r12)
	movq	%rax, 560000(%rbx)
	movq	%rax, 640000(%rbx)
	movq	%rax, 720000(%rbx)
	movq	%rax, 800000(%rbx)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm5, 400000(%rbx)
	vmovsd	%xmm0, 480000(%rbx)
	jmp	.L2507
.L2591:
	movzbl	2+.LC169(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2517
	jmp	.L2585
.L2593:
	movzbl	2+.LC188(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2523
	movq	.LC245(%rip), %rax
	movl	$8, (%r12)
	movq	%rax, 480000(%rbx)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm5, 400000(%rbx)
	vmovsd	%xmm5, 560000(%rbx)
	jmp	.L2507
.L2595:
	movzbl	2+.LC180(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2529
	movq	.LC247(%rip), %rax
	movl	$8, (%r12)
	movq	%rax, 480000(%rbx)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm0, 400000(%rbx)
	vmovsd	%xmm1, 560000(%rbx)
	jmp	.L2507
.L2594:
	movzbl	2+.LC175(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2526
.L2586:
	movl	$8, (%r12)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm5, 400000(%rbx)
	vmovsd	%xmm5, 480000(%rbx)
	vmovsd	%xmm5, 560000(%rbx)
	jmp	.L2507
.L2599:
	movzbl	2+.LC165(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2541
	movq	.LC247(%rip), %rax
	movl	$6, (%r12)
	movq	%rax, 400000(%rbx)
	vmovsd	%xmm5, 320000(%rbx)
	jmp	.L2507
.L2598:
	movzbl	2+.LC194(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2538
	movl	$11, (%r12)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm5, 400000(%rbx)
	vmovsd	%xmm5, 480000(%rbx)
	vmovsd	%xmm2, 560000(%rbx)
	vmovsd	%xmm0, 640000(%rbx)
	vmovsd	%xmm2, 720000(%rbx)
	vmovsd	%xmm2, 800000(%rbx)
	jmp	.L2507
.L2544:
	movl	$3, %edx
	leaq	.LC196(%rip), %rsi
	movq	%r15, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	movq	.LC241(%rip), %rax
	vmovq	%rax, %xmm2
	movq	.LC242(%rip), %rax
	vmovq	%rax, %xmm5
	movq	.LC243(%rip), %rax
	vmovq	%rax, %xmm0
	movq	.LC244(%rip), %rax
	vmovq	%rax, %xmm1
	jne	.L2545
	movq	.LC246(%rip), %rax
	movl	$12, (%r12)
	movq	%rax, 480000(%rbx)
	movq	%rax, 560000(%rbx)
	movq	%rax, 640000(%rbx)
	movq	%rax, 720000(%rbx)
	movq	.LC247(%rip), %rax
	vmovsd	%xmm5, 320000(%rbx)
	movq	%rax, 880000(%rbx)
	vmovsd	%xmm0, 400000(%rbx)
	vmovsd	%xmm0, 800000(%rbx)
	jmp	.L2507
.L2603:
	call	__stack_chk_fail@PLT
.L2545:
	movl	$3, %edx
	leaq	.LC190(%rip), %rsi
	movq	%r15, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	movq	.LC241(%rip), %rax
	vmovq	%rax, %xmm2
	movq	.LC242(%rip), %rax
	vmovq	%rax, %xmm5
	movq	.LC243(%rip), %rax
	vmovq	%rax, %xmm0
	movq	.LC244(%rip), %rax
	vmovq	%rax, %xmm1
	jne	.L2546
	movq	.LC246(%rip), %rax
	movl	$10, (%r12)
	movq	%rax, 560000(%rbx)
	movq	%rax, 640000(%rbx)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm0, 400000(%rbx)
	vmovsd	%xmm2, 480000(%rbx)
	vmovsd	%xmm2, 720000(%rbx)
	jmp	.L2507
	.p2align 4,,10
	.p2align 3
.L2597:
	movzbl	2+.LC184(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2535
	movl	$9, (%r12)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm5, 400000(%rbx)
	vmovsd	%xmm5, 480000(%rbx)
	vmovsd	%xmm5, 560000(%rbx)
	vmovsd	%xmm2, 640000(%rbx)
	jmp	.L2507
.L2596:
	movzbl	2+.LC186(%rip), %eax
	cmpb	%al, 2(%r15)
	jne	.L2532
	movq	.LC247(%rip), %rax
	movl	$9, (%r12)
	movq	%rax, 560000(%rbx)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm5, 400000(%rbx)
	vmovsd	%xmm0, 480000(%rbx)
	vmovsd	%xmm1, 640000(%rbx)
	jmp	.L2507
.L2546:
	movl	$3, %edx
	leaq	.LC178(%rip), %rsi
	movq	%r15, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	movq	.LC241(%rip), %rax
	vmovq	%rax, %xmm2
	movq	.LC242(%rip), %rax
	vmovq	%rax, %xmm5
	movq	.LC243(%rip), %rax
	vmovq	%rax, %xmm0
	movq	.LC244(%rip), %rax
	vmovq	%rax, %xmm1
	jne	.L2547
	movl	$8, (%r12)
	movq	%rax, 480000(%rbx)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm0, 400000(%rbx)
	vmovsd	%xmm2, 560000(%rbx)
	jmp	.L2507
.L2547:
	movl	$3, %edx
	leaq	.LC198(%rip), %rsi
	movq	%r15, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	movq	.LC241(%rip), %rax
	vmovq	%rax, %xmm2
	movq	.LC242(%rip), %rax
	vmovq	%rax, %xmm5
	movq	.LC243(%rip), %rax
	vmovq	%rax, %xmm0
	movq	.LC244(%rip), %rax
	vmovq	%rax, %xmm1
	jne	.L2548
	movq	.LC246(%rip), %rax
	movl	$14, (%r12)
	movq	%rax, 480000(%rbx)
	movq	%rax, 800000(%rbx)
	movq	%rax, 880000(%rbx)
	movq	%rax, 960000(%rbx)
	movq	%rax, 1040000(%rbx)
	vmovsd	%xmm5, 320000(%rbx)
	vmovsd	%xmm0, 400000(%rbx)
	vmovsd	%xmm0, 560000(%rbx)
	vmovsd	%xmm2, 640000(%rbx)
	vmovsd	%xmm0, 720000(%rbx)
	jmp	.L2507
.L2548:
	movl	$3, %edx
	leaq	.LC163(%rip), %rsi
	movq	%r15, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	movq	.LC241(%rip), %rax
	vmovq	%rax, %xmm2
	movq	.LC242(%rip), %rax
	vmovq	%rax, %xmm5
	movq	.LC243(%rip), %rax
	vmovq	%rax, %xmm0
	movq	.LC244(%rip), %rax
	vmovq	%rax, %xmm1
	jne	.L2549
	movl	$5, (%r12)
	vmovsd	%xmm5, 320000(%rbx)
	jmp	.L2507
.L2549:
	movl	$3, %edx
	leaq	.LC177(%rip), %rsi
	movq	%r15, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	movq	.LC241(%rip), %rax
	vmovq	%rax, %xmm2
	movq	.LC242(%rip), %rax
	vmovq	%rax, %xmm5
	movq	.LC243(%rip), %rax
	vmovq	%rax, %xmm0
	movq	.LC244(%rip), %rax
	vmovq	%rax, %xmm1
	jne	.L2507
	jmp	.L2586
	.cfi_endproc
.LFE50:
	.size	assign_vdw_radius_, .-assign_vdw_radius_
	.section	.rodata.str1.1
.LC252:
	.string	"(13x,a3,1x,a3,2x,i4,4x,3f8.3)"
	.text
	.p2align 4
	.globl	load_allatom_
	.type	load_allatom_, @function
load_allatom_:
.LFB51:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	leaq	.LC2(%rip), %r12
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	movq	%rdi, %rbp
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$1096, %rsp
	.cfi_def_cfa_offset 1152
	movq	%fs:40, %rax
	movq	%rax, 1080(%rsp)
	xorl	%eax, %eax
	leaq	16(%rsp), %rax
	movq	%rax, 88(%rsp)
	leaq	48(%rsp), %r15
	leaq	.LC237(%rip), %rax
	movq	%rdi, 112(%rsp)
	movq	%rax, 120(%rsp)
	movq	%r15, %rdi
	movabsq	$64441287456, %rax
	movq	%r12, 56(%rsp)
	movl	$7254, 64(%rsp)
	movl	$0, 16(%rsp)
	movq	$32, 104(%rsp)
	movq	$3, 128(%rsp)
	movl	$0, 352(%rsp)
	movq	%rax, 48(%rsp)
	call	_gfortran_st_open@PLT
	movl	16(%rsp), %edx
	testl	%edx, %edx
	jne	.L2632
	movl	$40000, %edx
	xorl	%esi, %esi
	leaq	nall_(%rip), %rdi
	call	memset@PLT
	movl	$8224, %eax
	movw	%ax, 941(%rsp)
	movb	$32, 943(%rsp)
	movl	$0, 4(%rsp)
	movl	$-1, 8(%rsp)
	leaq	400(%rsp), %rbx
	leaq	.LC56(%rip), %r14
	leaq	944(%rsp), %rbp
	movabsq	$64424513544, %r13
	jmp	.L2612
	.p2align 4,,10
	.p2align 3
.L2626:
	cmpl	$1297044545, 944(%rsp)
	je	.L2633
.L2612:
	movq	%rbx, %rdi
	movq	%r12, 408(%rsp)
	movl	$7266, 416(%rsp)
	movq	%r14, 480(%rsp)
	movq	$3, 488(%rsp)
	movq	%r13, 400(%rsp)
	call	_gfortran_st_read@PLT
	movl	$128, %edx
	movq	%rbp, %rsi
	movq	%rbx, %rdi
	call	_gfortran_transfer_character@PLT
	movq	%rbx, %rdi
	call	_gfortran_st_read_done@PLT
	movl	400(%rsp), %eax
	andl	$3, %eax
	cmpl	$2, %eax
	je	.L2610
	movzwl	.LC57(%rip), %eax
	cmpw	%ax, 0(%rbp)
	jne	.L2626
	movzbl	2+.LC57(%rip), %eax
	cmpb	%al, 2(%rbp)
	jne	.L2626
.L2610:
	movabsq	$64424509440, %rax
	movq	%r15, %rdi
	movq	%rax, 48(%rsp)
	movq	%r12, 56(%rsp)
	movl	$7292, 64(%rsp)
	call	_gfortran_st_close@PLT
	movl	4(%rsp), %eax
	movl	%eax, 8+bas_(%rip)
	movq	1080(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L2634
	addq	$1096, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
.L2633:
	.cfi_restore_state
	leaq	.LC252(%rip), %rax
	movq	%rax, 480(%rsp)
	movq	%rbx, %rdi
	movabsq	$-4294946816, %rax
	movq	%rax, 400(%rsp)
	movq	%r12, 408(%rsp)
	movl	$7270, 416(%rsp)
	movq	%rbp, 512(%rsp)
	movq	$128, 520(%rsp)
	movq	$0, 472(%rsp)
	movq	$29, 488(%rsp)
	call	_gfortran_st_read@PLT
	leaq	938(%rsp), %rsi
	movl	$3, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_character@PLT
	leaq	935(%rsp), %rsi
	movl	$3, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_character@PLT
	leaq	20(%rsp), %rsi
	movl	$4, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_integer@PLT
	leaq	24(%rsp), %rsi
	movl	$8, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_real@PLT
	leaq	32(%rsp), %rsi
	movl	$8, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_real@PLT
	leaq	40(%rsp), %rsi
	movl	$8, %edx
	movq	%rbx, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%rbx, %rdi
	call	_gfortran_st_read_done@PLT
	movzwl	941(%rsp), %eax
	cmpw	%ax, 938(%rsp)
	je	.L2635
.L2613:
	cmpb	$65, 960(%rsp)
	je	.L2616
	leaq	960(%rsp), %rsi
	movl	$1, %edi
	call	_gfortran_string_len_trim@PLT
	testq	%rax, %rax
	jne	.L2612
.L2616:
	movzwl	938(%rsp), %esi
	movzbl	940(%rsp), %ecx
	movl	20(%rsp), %edx
	movw	%si, 941(%rsp)
	movb	%cl, 943(%rsp)
	cmpl	8(%rsp), %edx
	je	.L2617
	movslq	4(%rsp), %rdi
	leaq	80000+sequence_(%rip), %rax
	leaq	(%rdi,%rdi,2), %r8
	addq	%r8, %rax
	movzwl	935(%rsp), %r8d
	movl	$0, 12(%rsp)
	movw	%r8w, (%rax)
	movzbl	937(%rsp), %r8d
	movb	%r8b, 2(%rax)
	leaq	sequence_(%rip), %rax
	movl	%edx, (%rax,%rdi,4)
	leal	1(%rdi), %eax
	movl	%eax, 4(%rsp)
.L2617:
	movzbl	938(%rsp), %eax
	xorl	%r8d, %r8d
	cmpb	$78, %al
	sete	%r8b
	xorl	%edi, %edi
	cmpb	$67, %al
	sete	%dil
	orb	%dil, %r8b
	jne	.L2621
	subl	$79, %eax
	movl	%edx, 8(%rsp)
	testb	$-5, %al
	jne	.L2612
.L2621:
	incl	12(%rsp)
	movslq	4(%rsp), %rdi
	vmovsd	24(%rsp), %xmm0
	leaq	rall_(%rip), %r10
	movslq	12(%rsp), %rax
	movq	%rdi, %r11
	movq	%rax, %r9
	imulq	$10000, %rax, %rax
	leaq	nall_(%rip), %r8
	movl	%edx, 8(%rsp)
	addq	%rdi, %rax
	leaq	-10001(%rax), %rdi
	vmovsd	%xmm0, (%r10,%rdi,8)
	vmovsd	32(%rsp), %xmm0
	leaq	(%rdi,%rdi,2), %rdi
	vmovsd	%xmm0, 1039992(%r10,%rax,8)
	vmovsd	40(%rsp), %xmm0
	vmovsd	%xmm0, 2159992(%r10,%rax,8)
	leal	-1(%r11), %eax
	cltq
	movl	%r9d, (%r8,%rax,4)
	leaq	40000(%r8), %rax
	addq	%rdi, %rax
	movw	%si, (%rax)
	movb	%cl, 2(%rax)
	jmp	.L2612
.L2635:
	movzbl	943(%rsp), %eax
	cmpb	%al, 940(%rsp)
	jne	.L2613
	jmp	.L2612
.L2634:
	call	__stack_chk_fail@PLT
.L2632:
	leaq	.LC238(%rip), %rax
	leaq	400(%rsp), %r13
	movq	%rax, 480(%rsp)
	movl	$6291457, %eax
	salq	$12, %rax
	movq	%r13, %rdi
	movq	%rax, 400(%rsp)
	movq	%r12, 408(%rsp)
	movl	$7256, 416(%rsp)
	movq	$8, 488(%rsp)
	call	_gfortran_st_write@PLT
	movl	$22, %edx
	leaq	.LC239(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$32, %edx
	movq	%rbp, %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	movl	$201326593, %eax
	salq	$7, %rax
	movq	%r13, %rdi
	movq	%rax, 400(%rsp)
	movq	%r12, 408(%rsp)
	movl	$7257, 416(%rsp)
	call	_gfortran_st_write@PLT
	movl	$16, %edx
	leaq	.LC201(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
	.cfi_endproc
.LFE51:
	.size	load_allatom_, .-load_allatom_
	.p2align 4
	.globl	compute_contact_map_
	.type	compute_contact_map_, @function
compute_contact_map_:
.LFB49:
	.cfi_startproc
	pushq	%r15
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	movl	$32, %esi
	pushq	%r14
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$136, %rsp
	.cfi_def_cfa_offset 192
	call	load_allatom_
	call	assign_vdw_radius_
	leaq	cmap_(%rip), %rax
	movl	$0, 60000004(%rax)
	movl	160000+bon_(%rip), %eax
	movl	%eax, 120(%rsp)
	testl	%eax, %eax
	jle	.L2709
	incl	%eax
	movq	%rax, 112(%rsp)
	movq	$1, 96(%rsp)
	movl	$0, 48(%rsp)
	vmovsd	.LC253(%rip), %xmm7
.L2661:
	movq	96(%rsp), %rax
	leaq	119996+bon_(%rip), %rdi
	movl	(%rdi,%rax,4), %edi
	movq	%rax, 88(%rsp)
	movl	%edi, 4(%rsp)
	incl	%edi
	movl	%edi, 124(%rsp)
	leaq	120000+bon_(%rip), %rdi
	movl	(%rdi,%rax,4), %edi
	movl	%eax, 104(%rsp)
	movl	%edi, 108(%rsp)
.L2660:
	movslq	124(%rsp), %rax
	movl	108(%rsp), %ebx
	cmpl	%ebx, %eax
	jg	.L2638
	movq	88(%rsp), %rdi
	leaq	120000+bon_(%rip), %rbx
	movl	(%rbx,%rdi,4), %ebx
	movq	%rax, 80(%rsp)
	movl	%ebx, 72(%rsp)
	movl	%edi, 76(%rsp)
.L2659:
	movq	80(%rsp), %rax
	leaq	-4+nall_(%rip), %rdi
	vmovd	%eax, %xmm8
	movl	(%rdi,%rax,4), %eax
	movl	76(%rsp), %edi
	movl	%eax, 52(%rsp)
	cmpl	%edi, 104(%rsp)
	je	.L2711
	movq	88(%rsp), %rdi
	leaq	119996+bon_(%rip), %rax
	movl	(%rax,%rdi,4), %eax
	movl	%eax, 4(%rsp)
	incl	%eax
.L2640:
	cmpl	72(%rsp), %eax
	jg	.L2641
	cltq
	leaq	rall_(%rip), %rdi
	movq	%rax, 32(%rsp)
	salq	$3, %rax
	leaq	(%rax,%rdi), %rbx
	movq	%rbx, 16(%rsp)
	leaq	radi_(%rip), %rbx
	addq	%rbx, %rax
	movq	%rax, 8(%rsp)
	movq	80(%rsp), %rax
	salq	$3, %rax
	addq	%rax, %rdi
	addq	%rbx, %rax
	movq	%rax, 56(%rsp)
	movl	52(%rsp), %eax
	movq	%rdi, 64(%rsp)
	incl	%eax
	movl	%eax, 24(%rsp)
	.p2align 4,,10
	.p2align 3
.L2658:
	movq	32(%rsp), %rax
	leaq	-4+nall_(%rip), %rdi
	movl	%eax, 44(%rsp)
	movl	52(%rsp), %r8d
	movl	(%rdi,%rax,4), %eax
	movl	%eax, 4(%rsp)
	testl	%r8d, %r8d
	jle	.L2642
	movl	$0, 40(%rsp)
	movl	$0, 28(%rsp)
	movq	56(%rsp), %r13
	movq	64(%rsp), %r11
	xorl	%r14d, %r14d
	xorl	%r15d, %r15d
	xorl	%r12d, %r12d
	xorl	%r8d, %r8d
	movl	$1, %esi
	leal	1(%rax), %r9d
	.p2align 4,,10
	.p2align 3
.L2651:
	movl	4(%rsp), %edi
	testl	%edi, %edi
	jle	.L2643
	vmovsd	-8(%r11), %xmm6
	vmovsd	1119992(%r11), %xmm5
	vmovsd	2239992(%r11), %xmm4
	vmovsd	-8(%r13), %xmm3
	movq	8(%rsp), %rcx
	movq	16(%rsp), %rax
	movl	$1, %edx
	jmp	.L2650
	.p2align 4,,10
	.p2align 3
.L2712:
	incl	%r12d
.L2647:
	incl	%r8d
.L2644:
	incl	%edx
	addq	$80000, %rax
	addq	$80000, %rcx
	cmpl	%r9d, %edx
	je	.L2643
.L2650:
	vsubsd	1119992(%rax), %xmm5, %xmm2
	vsubsd	-8(%rax), %xmm6, %xmm1
	vsubsd	2239992(%rax), %xmm4, %xmm0
	vmulsd	%xmm2, %xmm2, %xmm2
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vaddsd	-8(%rcx), %xmm3, %xmm1
	vmulsd	%xmm7, %xmm1, %xmm1
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vcomisd	%xmm0, %xmm1
	jb	.L2644
	xorl	%edi, %edi
	cmpl	$4, %esi
	setle	%dil
	xorl	%r10d, %r10d
	cmpl	$4, %edx
	setle	%r10b
	testl	%edi, %edi
	je	.L2646
	testl	%r10d, %r10d
	jne	.L2712
.L2646:
	xorl	%ebx, %ebx
	cmpl	$4, %esi
	setg	%bl
	xorl	%ebp, %ebp
	cmpl	$4, %edx
	setg	%bpl
	testl	%ebx, %ebx
	je	.L2648
	testl	%ebp, %ebp
	je	.L2648
	incl	%r14d
	jmp	.L2647
	.p2align 4,,10
	.p2align 3
.L2648:
	incl	%r15d
	testl	%edi, %edi
	je	.L2649
	testl	%ebp, %ebp
	je	.L2649
	incl	28(%rsp)
	jmp	.L2647
	.p2align 4,,10
	.p2align 3
.L2643:
	incl	%esi
	addq	$80000, %r11
	addq	$80000, %r13
	cmpl	24(%rsp), %esi
	jne	.L2651
	testl	%r8d, %r8d
	je	.L2642
	movl	76(%rsp), %esi
	movl	104(%rsp), %edi
	movslq	48(%rsp), %rax
	cmpl	%esi, %edi
	sete	%sil
	vpinsrd	$1, 44(%rsp), %xmm8, %xmm0
	movzbl	%sil, %esi
	leaq	(%rax,%rax,2), %rcx
	leaq	cmap_(%rip), %rbx
	leal	-1(%rsi,%rsi), %esi
	leal	1(%rax), %edx
	movl	%esi, 60000016(%rbx,%rcx,4)
	vmovq	%xmm0, 60000008(%rbx,%rcx,4)
	leaq	2(%rcx), %rax
	testl	%r12d, %r12d
	je	.L2654
	sall	60000008(%rbx,%rax,4)
.L2654:
	testl	%r15d, %r15d
	je	.L2655
	leaq	15000002(%rax), %rcx
	leaq	cmap_(%rip), %rbx
	movl	(%rbx,%rcx,4), %esi
	leal	(%rsi,%rsi,2), %esi
	movl	%esi, (%rbx,%rcx,4)
.L2655:
	testl	%r14d, %r14d
	je	.L2656
	leaq	15000002(%rax), %rcx
	leaq	cmap_(%rip), %rbx
	movl	(%rbx,%rcx,4), %esi
	leal	(%rsi,%rsi,4), %esi
	movl	%esi, (%rbx,%rcx,4)
.L2656:
	movl	28(%rsp), %ecx
	testl	%ecx, %ecx
	je	.L2657
	leaq	15000002(%rax), %rcx
	leaq	cmap_(%rip), %rdi
	movl	(%rdi,%rcx,4), %esi
	leal	(%rsi,%rsi,2), %esi
	movl	%esi, (%rdi,%rcx,4)
.L2657:
	movl	%edx, 48(%rsp)
	movl	40(%rsp), %edx
	testl	%edx, %edx
	je	.L2642
	addq	$15000002, %rax
	leaq	cmap_(%rip), %rbx
	movl	(%rbx,%rax,4), %ecx
	leal	0(,%rcx,8), %edx
	subl	%ecx, %edx
	movl	%edx, (%rbx,%rax,4)
.L2642:
	incq	32(%rsp)
	addq	$8, 16(%rsp)
	addq	$8, 8(%rsp)
	movq	32(%rsp), %rax
	cmpl	%eax, 72(%rsp)
	jge	.L2658
.L2641:
	incq	80(%rsp)
	movq	80(%rsp), %rax
	cmpl	%eax, 108(%rsp)
	jge	.L2659
.L2638:
	incq	88(%rsp)
	movq	88(%rsp), %rax
	cmpl	%eax, 120(%rsp)
	jge	.L2660
	incq	96(%rsp)
	movq	96(%rsp), %rax
	cmpq	%rax, 112(%rsp)
	jne	.L2661
	movl	48(%rsp), %ebx
	leaq	cmap_(%rip), %rax
	movl	%ebx, 60000004(%rax)
.L2709:
	addq	$136, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%rbp
	.cfi_def_cfa_offset 40
	popq	%r12
	.cfi_def_cfa_offset 32
	popq	%r13
	.cfi_def_cfa_offset 24
	popq	%r14
	.cfi_def_cfa_offset 16
	popq	%r15
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L2649:
	.cfi_restore_state
	testl	%r10d, %r10d
	je	.L2647
	cmpl	$1, %ebx
	sbbl	$-1, 40(%rsp)
	jmp	.L2647
.L2711:
	movl	80(%rsp), %eax
	addl	$3, %eax
	jmp	.L2640
	.cfi_endproc
.LFE49:
	.size	compute_contact_map_, .-compute_contact_map_
	.section	.rodata.str1.1
.LC254:
	.string	"ERROR OPENING FILENAME "
.LC255:
	.string	"screend"
	.text
	.p2align 4
	.globl	load_sequence_
	.type	load_sequence_, @function
load_sequence_:
.LFB52:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	movq	%rdi, %r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$2112, %rsp
	.cfi_offset 3, -56
	movq	%fs:40, %rax
	movq	%rax, 2104(%rsp)
	leaq	.LC2(%rip), %rax
	movq	%rdi, 224(%rsp)
	movl	$5364, 176(%rsp)
	movl	$0, 136(%rsp)
	movq	$32, 216(%rsp)
	movq	$3, 240(%rsp)
	movq	%rax, 168(%rsp)
	leaq	136(%rsp), %rax
	movq	%rax, 56(%rsp)
	movq	%rax, 200(%rsp)
	leaq	.LC237(%rip), %rax
	movq	%rax, 232(%rsp)
	movabsq	$34376516384, %rax
	movq	%rax, 160(%rsp)
	leaq	160(%rsp), %rax
	movq	%rax, %rdi
	movq	%rax, 72(%rsp)
	movl	$0, 464(%rsp)
	call	_gfortran_st_open@PLT
	movl	136(%rsp), %eax
	movl	%eax, 52(%rsp)
	testl	%eax, %eax
	jne	.L2770
	leaq	.LC2(%rip), %rax
	leaq	512(%rsp), %r12
	movq	%rax, 520(%rsp)
	leaq	.LC56(%rip), %rax
	movq	%rax, 592(%rsp)
	movq	%r12, %rdi
	movabsq	$34359742464, %rax
	movq	%rax, 512(%rsp)
	movl	$5372, 528(%rsp)
	movq	$3, 600(%rsp)
	call	_gfortran_st_read@PLT
	leaq	1072(%rsp), %rax
	movq	%rax, %rsi
	movl	$1024, %edx
	movq	%r12, %rdi
	movq	%rax, 40(%rsp)
	call	_gfortran_transfer_character@PLT
	movq	%r12, %rdi
	call	_gfortran_st_read_done@PLT
	movl	.LC255(%rip), %eax
	cmpl	%eax, 1072(%rsp)
	je	.L2771
.L2715:
	leaq	.LC2(%rip), %rax
	movq	%rax, 520(%rsp)
	movl	$5377, 528(%rsp)
	movq	40(%rsp), %rax
	movq	$1024, 632(%rsp)
	movq	$0, 584(%rsp)
	movq	%rax, 624(%rsp)
	movabsq	$-4294950784, %rax
.L2768:
	movq	%r12, %rdi
	movq	%rax, 512(%rsp)
	call	_gfortran_st_read@PLT
	movl	$4, %edx
	leaq	160000+bon_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%r12, %rdi
	call	_gfortran_st_read_done@PLT
	movl	160000+bon_(%rip), %eax
	movl	$0, 120000+bon_(%rip)
	movl	%eax, 36(%rsp)
	testl	%eax, %eax
	jle	.L2719
	leaq	120004+bon_(%rip), %r15
	leaq	152(%rsp), %rax
	movl	$2, 48(%rsp)
	movq	%rax, 24(%rsp)
	movq	%r15, 112(%rsp)
	movq	%r12, %r14
	.p2align 4,,10
	.p2align 3
.L2751:
	leaq	.LC2(%rip), %r15
	movabsq	$34359738496, %r12
	movq	%r14, %rdi
	movq	%r15, 520(%rsp)
	movl	$5382, 528(%rsp)
	movq	%r12, 512(%rsp)
	call	_gfortran_st_read@PLT
	movq	112(%rsp), %rbx
	movl	$4, %edx
	movq	%rbx, %rsi
	movq	%r14, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%r14, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r14, %rdi
	movq	%r15, 520(%rsp)
	movl	$5383, 528(%rsp)
	movq	%r12, 512(%rsp)
	call	_gfortran_st_read@PLT
	movq	40(%rsp), %r15
	movl	$1024, %edx
	movq	%r15, %rsi
	movq	%r14, %rdi
	call	_gfortran_transfer_character@PLT
	movq	%r14, %rdi
	call	_gfortran_st_read_done@PLT
	movl	(%rbx), %r11d
	testl	%r11d, %r11d
	jle	.L2720
	movl	-4(%rbx), %r13d
	movslq	52(%rsp), %rbx
	leaq	bon_(%rip), %rdx
	leaq	80000(,%rbx,4), %rax
	leaq	(%rdx,%rax), %r9
	leal	1(%rbx), %r10d
	movslq	%r13d, %rdx
	leaq	sequence_(%rip), %r12
	movq	%rbx, %r8
	subq	%rdx, %r8
	movl	%r10d, %esi
	leaq	-80000(%r12,%rax), %rdi
	leaq	80000(%rbx,%rbx,2), %rcx
	leaq	nat_(%rip), %rax
	addl	%r11d, %r10d
	addq	%r15, %r8
	subl	%r13d, %esi
	leaq	(%rax,%rbx,8), %rdx
	addq	%r12, %rcx
	subl	%r13d, %r10d
	.p2align 4,,10
	.p2align 3
.L2742:
	movzbl	(%r8), %eax
	movl	$1, (%r9)
	cmpb	$71, %al
	je	.L2772
	cmpb	$80, %al
	je	.L2773
	cmpb	$81, %al
	je	.L2774
	cmpb	$67, %al
	je	.L2775
	cmpb	$65, %al
	je	.L2776
	cmpb	$83, %al
	je	.L2777
	cmpb	$86, %al
	je	.L2778
	cmpb	$84, %al
	je	.L2779
	cmpb	$73, %al
	je	.L2780
	cmpb	$76, %al
	je	.L2781
	cmpb	$78, %al
	je	.L2782
	cmpb	$68, %al
	je	.L2783
	cmpb	$75, %al
	je	.L2784
	cmpb	$69, %al
	je	.L2785
	cmpb	$77, %al
	je	.L2786
	cmpb	$72, %al
	je	.L2787
	cmpb	$70, %al
	je	.L2788
	cmpb	$82, %al
	je	.L2789
	cmpb	$89, %al
	je	.L2790
	cmpb	$87, %al
	je	.L2791
	cmpb	$88, %al
	jne	.L2722
	movl	$0, 40000(%rdi)
	.p2align 4,,10
	.p2align 3
.L2722:
	movl	%esi, (%rdi)
	incl	%esi
	movq	$0x000000000, (%rdx)
	movq	$0x000000000, 80000(%rdx)
	movq	$0x000000000, 160000(%rdx)
	addq	$4, %r9
	incq	%r8
	addq	$4, %rdi
	addq	$8, %rdx
	addq	$3, %rcx
	cmpl	%r10d, %esi
	jne	.L2742
	leal	-1(%r11), %edx
	addl	%r11d, 52(%rsp)
	addq	%rdx, %rbx
	cmpl	$6, %edx
	jbe	.L2761
	movl	%r11d, %edi
	shrl	$3, %edi
	leaq	angnat_(%rip), %rcx
	salq	$6, %rdi
	leaq	-8+sig_(%rip), %rsi
	movq	%rcx, %rax
	leaq	40000+sequence_(%rip), %rdx
	addq	%rcx, %rdi
	.p2align 4,,10
	.p2align 3
.L2745:
	vmovdqa	.LC159(%rip), %ymm3
	vmovapd	.LC94(%rip), %ymm4
	vpminsd	(%rdx), %ymm3, %ymm0
	vmovapd	.LC94(%rip), %ymm5
	vgatherdpd	%ymm4, (%rsi,%xmm0,8), %ymm2
	vperm2i128	$17, %ymm0, %ymm0, %ymm0
	vgatherdpd	%ymm5, (%rsi,%xmm0,8), %ymm1
	vmovapd	%ymm1, 32(%rax)
	vmovapd	%ymm2, (%rax)
	addq	$64, %rax
	addq	$32, %rdx
	cmpq	%rdi, %rax
	jne	.L2745
	movl	%r11d, %eax
	andl	$-8, %eax
	leal	1(%rax), %edx
	cmpl	%eax, %r11d
	je	.L2792
	vzeroupper
.L2743:
	movl	%r11d, %esi
	subl	%eax, %esi
	leal	-1(%rsi), %edi
	cmpl	$2, %edi
	jbe	.L2748
	vmovdqa	.LC160(%rip), %xmm6
	vmovapd	.LC97(%rip), %xmm1
	movl	%eax, %edi
	addl	$10000, %eax
	vpminsd	(%r12,%rax,4), %xmm6, %xmm0
	leaq	-8+sig_(%rip), %r8
	vmovapd	%xmm1, %xmm7
	vgatherdpd	%xmm7, (%r8,%xmm0,8), %xmm2
	vmovapd	%xmm1, %xmm6
	vpshufd	$238, %xmm0, %xmm0
	movl	%esi, %eax
	leaq	(%rcx,%rdi,8), %rdi
	vgatherdpd	%xmm6, (%r8,%xmm0,8), %xmm1
	andl	$-4, %eax
	vmovapd	%xmm2, (%rdi)
	vmovapd	%xmm1, 16(%rdi)
	addl	%eax, %edx
	cmpl	%esi, %eax
	je	.L2746
.L2748:
	leal	-1(%rdx), %esi
	movslq	%esi, %rsi
	vmovdqa	.LC101(%rip), %xmm1
	vmovd	40000(%r12,%rsi,4), %xmm0
	vpminsd	%xmm1, %xmm0, %xmm0
	vmovd	%xmm0, %eax
	leaq	sig_(%rip), %rdi
	cltq
	vmovsd	-8(%rdi,%rax,8), %xmm0
	vmovsd	%xmm0, (%rcx,%rsi,8)
	leal	1(%rdx), %esi
	cmpl	%esi, %r11d
	jl	.L2746
	movslq	%edx, %r8
	vmovd	40000(%r12,%r8,4), %xmm0
	vpminsd	%xmm1, %xmm0, %xmm0
	vmovd	%xmm0, %eax
	cltq
	vmovsd	-8(%rdi,%rax,8), %xmm0
	addl	$2, %edx
	vmovsd	%xmm0, (%rcx,%r8,8)
	cmpl	%edx, %r11d
	jl	.L2746
	movslq	%esi, %rsi
	vmovd	40000(%r12,%rsi,4), %xmm0
	vpminsd	%xmm1, %xmm0, %xmm0
	vmovd	%xmm0, %eax
	cltq
	vmovsd	-8(%rdi,%rax,8), %xmm0
	vmovsd	%xmm0, (%rcx,%rsi,8)
.L2746:
	movq	112(%rsp), %rax
	addl	%r13d, %r11d
	movl	%r11d, (%rax)
	leaq	bon_(%rip), %rax
	movl	$0, 80000(%rax,%rbx,4)
	leaq	.LC2(%rip), %rax
	movq	%rax, 520(%rsp)
	movq	%r14, %rdi
	movabsq	$34359738496, %rax
	movq	%rax, 512(%rsp)
	movl	$5461, 528(%rsp)
	call	_gfortran_st_read@PLT
	movq	24(%rsp), %rsi
	movl	$4, %edx
	movq	%r14, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%r14, %rdi
	call	_gfortran_st_read_done@PLT
	movl	152(%rsp), %eax
	movl	%eax, 80(%rsp)
	testl	%eax, %eax
	jg	.L2762
.L2758:
	movl	48(%rsp), %ecx
	addq	$4, 112(%rsp)
	leal	1(%rcx), %eax
	cmpl	%ecx, 36(%rsp)
	jl	.L2719
	movl	%eax, 48(%rsp)
	jmp	.L2751
	.p2align 4,,10
	.p2align 3
.L2772:
	movzwl	.LC161(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC161(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$1, 40000(%rdi)
	jmp	.L2722
	.p2align 4,,10
	.p2align 3
.L2773:
	movzwl	.LC167(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC167(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$2, 40000(%rdi)
	jmp	.L2722
	.p2align 4,,10
	.p2align 3
.L2774:
	movzwl	.LC182(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC182(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$3, 40000(%rdi)
	jmp	.L2722
	.p2align 4,,10
	.p2align 3
.L2775:
	movzwl	.LC173(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC173(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$4, 40000(%rdi)
	jmp	.L2722
	.p2align 4,,10
	.p2align 3
.L2776:
	movzwl	.LC163(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC163(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$5, 40000(%rdi)
	jmp	.L2722
.L2777:
	movzwl	.LC165(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC165(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$6, 40000(%rdi)
	jmp	.L2722
.L2778:
	movzwl	.LC169(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC169(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$7, 40000(%rdi)
	jmp	.L2722
.L2762:
	leaq	1040(%rsp), %rax
	movl	$1, 84(%rsp)
	movq	%rax, 64(%rsp)
	leaq	cmap_(%rip), %r13
	.p2align 4,,10
	.p2align 3
.L2750:
	movabsq	$34359738496, %rax
	leaq	.LC2(%rip), %rbx
	movq	%r14, %rdi
	movq	%rax, 512(%rsp)
	movq	%rbx, 520(%rsp)
	movl	$5464, 528(%rsp)
	call	_gfortran_st_read@PLT
	movq	64(%rsp), %r15
	movl	$32, %edx
	movq	%r15, %rsi
	movq	%r14, %rdi
	call	_gfortran_transfer_character@PLT
	movq	%r14, %rdi
	call	_gfortran_st_read_done@PLT
	movq	56(%rsp), %rax
	movq	72(%rsp), %rdi
	movq	%rax, 200(%rsp)
	leaq	.LC237(%rip), %rax
	movq	%rax, 232(%rsp)
	movabsq	$120275862304, %rax
	movq	%rax, 160(%rsp)
	movq	%rbx, 168(%rsp)
	movl	$5465, 176(%rsp)
	movl	$0, 136(%rsp)
	movq	%r15, 224(%rsp)
	movq	$32, 216(%rsp)
	movq	$3, 240(%rsp)
	movl	$0, 464(%rsp)
	call	_gfortran_st_open@PLT
	movl	136(%rsp), %eax
	testl	%eax, %eax
	jne	.L2793
	leaq	.LC2(%rip), %rbx
	movabsq	$120259084416, %r15
	movq	%r14, %rdi
	movq	%rbx, 520(%rsp)
	movl	$5471, 528(%rsp)
	movq	%r15, 512(%rsp)
	call	_gfortran_st_read@PLT
	leaq	140(%rsp), %rsi
	movl	$4, %edx
	movq	%r14, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%r14, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r14, %rdi
	movq	%rbx, 520(%rsp)
	movl	$5472, 528(%rsp)
	movq	%r15, 512(%rsp)
	call	_gfortran_st_read@PLT
	leaq	156(%rsp), %rsi
	movl	$4, %edx
	movq	%r14, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%r14, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r14, %rdi
	movq	%rbx, 520(%rsp)
	movl	$5473, 528(%rsp)
	movq	%r15, 512(%rsp)
	call	_gfortran_st_read@PLT
	leaq	148(%rsp), %rsi
	movl	$4, %edx
	movq	%r14, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%r14, %rdi
	call	_gfortran_st_read_done@PLT
	movl	148(%rsp), %eax
	movl	%eax, 120(%rsp)
	testl	%eax, %eax
	jle	.L2756
	leaq	sig_(%rip), %rax
	movq	%rax, 88(%rsp)
	leaq	132(%rsp), %rax
	movq	%rax, 104(%rsp)
	leaq	144(%rsp), %rax
	movq	%rax, 96(%rsp)
	movl	60000004(%r13), %edx
	movl	140(%rsp), %ebx
	movq	112(%rsp), %r15
	movl	$1, %r12d
	.p2align 4,,10
	.p2align 3
.L2757:
	leaq	.LC2(%rip), %rax
	incl	%edx
	movq	%rax, 520(%rsp)
	movq	%r14, %rdi
	movabsq	$120259084416, %rax
	movq	%rax, 512(%rsp)
	movl	%edx, 60000004(%r13)
	movl	$5476, 528(%rsp)
	call	_gfortran_st_read@PLT
	movq	104(%rsp), %rsi
	movl	$4, %edx
	movq	%r14, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	96(%rsp), %rsi
	movl	$4, %edx
	movq	%r14, %rdi
	call	_gfortran_transfer_integer@PLT
	movslq	60000004(%r13), %rax
	movq	88(%rsp), %rcx
	movl	$8, %edx
	leaq	4000(%rcx,%rax,8), %rsi
	movq	%r14, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r14, %rdi
	call	_gfortran_st_read_done@PLT
	movl	-4(%r15), %eax
	movl	132(%rsp), %edi
	movslq	60000004(%r13), %rsi
	addl	%eax, %edi
	addl	144(%rsp), %eax
	movq	%rsi, %rdx
	addl	%ebx, %edi
	leaq	-3(%rsi,%rsi,2), %rsi
	addl	%ebx, %eax
	incl	%r12d
	movl	%edi, 60000008(%r13,%rsi,4)
	movl	%eax, 60000012(%r13,%rsi,4)
	movl	$1, 60000016(%r13,%rsi,4)
	cmpl	%r12d, 120(%rsp)
	jge	.L2757
.L2756:
	movl	156(%rsp), %eax
	movl	$1, 132(%rsp)
	movl	%eax, 104(%rsp)
	testl	%eax, %eax
	jle	.L2754
	movl	140(%rsp), %eax
	leaq	angnat_(%rip), %r12
	movl	%eax, 96(%rsp)
	movl	$1, %eax
	movl	%eax, %r15d
	.p2align 4,,10
	.p2align 3
.L2759:
	movq	112(%rsp), %rax
	movq	%r14, %rdi
	movl	-4(%rax), %ebx
	leaq	.LC2(%rip), %rax
	addl	%r15d, %ebx
	addl	96(%rsp), %ebx
	movq	%rax, 520(%rsp)
	movslq	%ebx, %rbx
	movabsq	$120259084416, %rax
	movq	%rax, 512(%rsp)
	movl	$5483, 528(%rsp)
	call	_gfortran_st_read@PLT
	leaq	-8(,%rbx,8), %rcx
	leaq	(%r12,%rcx), %rsi
	movl	$8, %edx
	movq	%r14, %rdi
	movq	%rcx, 120(%rsp)
	call	_gfortran_transfer_real@PLT
	movq	120(%rsp), %rcx
	movl	$8, %edx
	leaq	80000(%r12,%rcx), %rsi
	movq	%r14, %rdi
	call	_gfortran_transfer_real@PLT
	incl	%r15d
	movq	%r14, %rdi
	call	_gfortran_st_read_done@PLT
	movl	$1, 159996(%r12,%rbx,4)
	movl	%r15d, 132(%rsp)
	cmpl	104(%rsp), %r15d
	jle	.L2759
.L2754:
	leaq	.LC2(%rip), %rax
	movq	72(%rsp), %rdi
	movq	%rax, 168(%rsp)
	movabsq	$120259084288, %rax
	movq	%rax, 160(%rsp)
	movl	$5486, 176(%rsp)
	call	_gfortran_st_close@PLT
	incl	84(%rsp)
	movl	84(%rsp), %eax
	cmpl	%eax, 80(%rsp)
	jge	.L2750
	jmp	.L2758
.L2779:
	movzwl	.LC171(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC171(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$8, 40000(%rdi)
	jmp	.L2722
.L2780:
	movzwl	.LC175(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC175(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$9, 40000(%rdi)
	jmp	.L2722
.L2781:
	movzwl	.LC177(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC177(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$10, 40000(%rdi)
	jmp	.L2722
.L2782:
	movzwl	.LC178(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC178(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$11, 40000(%rdi)
	jmp	.L2722
.L2783:
	movzwl	.LC180(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC180(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$12, 40000(%rdi)
	jmp	.L2722
.L2784:
	movzwl	.LC184(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC184(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$13, 40000(%rdi)
	jmp	.L2722
.L2720:
	movq	112(%rsp), %rax
	movl	-4(%rax), %r13d
	movl	52(%rsp), %eax
	leal	-1(%rax), %ebx
	movslq	%ebx, %rbx
	jmp	.L2746
.L2792:
	vzeroupper
	jmp	.L2746
.L2761:
	xorl	%eax, %eax
	movl	$1, %edx
	leaq	angnat_(%rip), %rcx
	jmp	.L2743
.L2785:
	movzwl	.LC186(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC186(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$14, 40000(%rdi)
	jmp	.L2722
.L2786:
	movzwl	.LC188(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC188(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$15, 40000(%rdi)
	jmp	.L2722
.L2719:
	leaq	.LC2(%rip), %rax
	movq	72(%rsp), %rdi
	movq	%rax, 168(%rsp)
	movabsq	$34359738368, %rax
	movq	%rax, 160(%rsp)
	movl	$5490, 176(%rsp)
	call	_gfortran_st_close@PLT
	movl	52(%rsp), %eax
	movl	%eax, 8+bas_(%rip)
	movq	2104(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L2794
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
.L2787:
	.cfi_restore_state
	movzwl	.LC190(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC190(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$16, 40000(%rdi)
	jmp	.L2722
.L2788:
	movzwl	.LC192(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC192(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$17, 40000(%rdi)
	jmp	.L2722
.L2789:
	movzwl	.LC194(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC194(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$18, 40000(%rdi)
	jmp	.L2722
.L2790:
	movzwl	.LC196(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC196(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$19, 40000(%rdi)
	jmp	.L2722
.L2791:
	movzwl	.LC198(%rip), %eax
	movw	%ax, (%rcx)
	movzbl	2+.LC198(%rip), %eax
	movb	%al, 2(%rcx)
	movl	$20, 40000(%rdi)
	jmp	.L2722
.L2771:
	movzwl	4+.LC255(%rip), %eax
	cmpw	%ax, 1076(%rsp)
	jne	.L2715
	movq	40(%rsp), %rax
	movzbl	6+.LC255(%rip), %ecx
	cmpb	%cl, 6(%rax)
	jne	.L2715
	leaq	1079(%rsp), %rax
	movq	%rax, 624(%rsp)
	leaq	.LC2(%rip), %rbx
	movabsq	$-4294950784, %rax
	movq	%r12, %rdi
	movq	%rax, 512(%rsp)
	movq	%rbx, 520(%rsp)
	movl	$5374, 528(%rsp)
	movq	$1017, 632(%rsp)
	movq	$0, 584(%rsp)
	call	_gfortran_st_read@PLT
	movl	$8, %edx
	leaq	48+hhar_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r12, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%rbx, 520(%rsp)
	movl	$5375, 528(%rsp)
	movabsq	$34359738496, %rax
	jmp	.L2768
.L2770:
	leaq	.LC27(%rip), %rax
	leaq	512(%rsp), %r13
	movq	%rax, 592(%rsp)
	movl	$6291457, %eax
	salq	$12, %rax
	leaq	.LC2(%rip), %rbx
	movq	%r13, %rdi
	movq	%rax, 512(%rsp)
	movq	%rbx, 520(%rsp)
	movl	$5366, 528(%rsp)
	movq	$5, 600(%rsp)
	call	_gfortran_st_write@PLT
	movl	$23, %edx
	leaq	.LC254(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$32, %edx
	movq	%r12, %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	movl	$201326593, %eax
	salq	$7, %rax
	movq	%r13, %rdi
	movq	%rax, 512(%rsp)
	movq	%rbx, 520(%rsp)
	movl	$5367, 528(%rsp)
	call	_gfortran_st_write@PLT
	movq	%r13, %rdi
	movl	$16, %edx
	leaq	.LC201(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
.L2769:
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
.L2794:
	call	__stack_chk_fail@PLT
	.p2align 4,,10
	.p2align 3
.L2793:
	leaq	.LC27(%rip), %rax
	movq	%rax, 592(%rsp)
	movq	%r14, %rdi
	movabsq	$25769807872, %rax
	movq	%rax, 512(%rsp)
	movq	%rbx, 520(%rsp)
	movl	$5467, 528(%rsp)
	movq	$5, 600(%rsp)
	call	_gfortran_st_write@PLT
	movl	$23, %edx
	leaq	.LC254(%rip), %rsi
	movq	%r14, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	64(%rsp), %rsi
	movl	$32, %edx
	movq	%r14, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r14, %rdi
	call	_gfortran_st_write_done@PLT
	movabsq	$25769803904, %rax
	movq	%r14, %rdi
	movq	%rax, 512(%rsp)
	movq	%rbx, 520(%rsp)
	movl	$5468, 528(%rsp)
	call	_gfortran_st_write@PLT
	movq	%r14, %rdi
	movl	$16, %edx
	leaq	.LC201(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r14, %rdi
	jmp	.L2769
	.cfi_endproc
.LFE52:
	.size	load_sequence_, .-load_sequence_
	.section	.rodata.str1.1
.LC256:
	.string	"TER"
.LC257:
	.string	"(6x,3f9.3)"
.LC258:
	.string	"(13x,a4,a3,x,a1,i4,4x,3f8.3)"
.LC259:
	.string	"(a2,2x)"
.LC260:
	.string	"(x,a2,x)"
.LC261:
	.string	"(a1,i5)"
.LC262:
	.string	"NO ATOMS IN THE FILE "
	.text
	.p2align 4
	.globl	load_protein_
	.type	load_protein_, @function
load_protein_:
.LFB53:
	.cfi_startproc
	leaq	8(%rsp), %r10
	.cfi_def_cfa 10, 0
	andq	$-32, %rsp
	pushq	-8(%r10)
	pushq	%rbp
	.cfi_escape 0x10,0x6,0x2,0x76,0
	movq	%rsp, %rbp
	pushq	%r15
	.cfi_escape 0x10,0xf,0x2,0x76,0x78
	leaq	.LC2(%rip), %r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%r10
	.cfi_escape 0xf,0x3,0x76,0x58,0x6
	.cfi_escape 0x10,0xe,0x2,0x76,0x70
	.cfi_escape 0x10,0xd,0x2,0x76,0x68
	.cfi_escape 0x10,0xc,0x2,0x76,0x60
	pushq	%rbx
	subq	$11360, %rsp
	.cfi_escape 0x10,0x3,0x2,0x76,0x50
	movq	%rdi, -11184(%rbp)
	movq	%rsi, -11208(%rbp)
	movq	%fs:40, %rax
	movq	%rax, -56(%rbp)
	xorl	%eax, %eax
	leaq	-11120(%rbp), %rax
	movq	%rax, -11176(%rbp)
	movq	%rax, -11048(%rbp)
	leaq	.LC237(%rip), %rax
	movq	%rax, -11016(%rbp)
	movabsq	$34376516384, %rax
	movq	%rax, -11088(%rbp)
	leaq	-11088(%rbp), %rax
	movq	%rdi, -11024(%rbp)
	movq	%rax, %rdi
	movq	%rax, -11168(%rbp)
	movq	%r15, -11080(%rbp)
	movl	$5041, -11072(%rbp)
	movl	$0, -11120(%rbp)
	movq	$32, -11032(%rbp)
	movq	$3, -11008(%rbp)
	movl	$0, -10784(%rbp)
	call	_gfortran_st_open@PLT
	movl	-11120(%rbp), %eax
	movl	%eax, -11160(%rbp)
	testl	%eax, %eax
	jne	.L3376
	movl	$40000, %edx
	xorl	%esi, %esi
	leaq	80000+bon_(%rip), %rdi
	call	memset@PLT
	movl	$0, 160000+bon_(%rip)
	movl	$0, 120000+bon_(%rip)
	movq	$0x000000000, 48+plates_(%rip)
	movq	$0x000000000, 64+plates_(%rip)
	movq	$0x000000000, plates_(%rip)
	leaq	.LC56(%rip), %r13
	leaq	-10736(%rbp), %r12
	leaq	-192(%rbp), %r14
	.p2align 4,,10
	.p2align 3
.L2797:
	movabsq	$34359742472, %rax
	movq	%r12, %rdi
	movq	%rax, -10736(%rbp)
	movq	%r15, -10728(%rbp)
	movl	$5057, -10720(%rbp)
	movq	%r13, -10656(%rbp)
	movq	$3, -10648(%rbp)
	call	_gfortran_st_read@PLT
	movl	$128, %edx
	movq	%r14, %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character@PLT
	movq	%r12, %rdi
	call	_gfortran_st_read_done@PLT
	movl	-10736(%rbp), %eax
	andl	$3, %eax
	cmpl	$2, %eax
	je	.L2801
	cmpl	$1297044545, -192(%rbp)
	je	.L3342
	movzwl	.LC57(%rip), %eax
	cmpw	%ax, (%r14)
	je	.L3377
.L2802:
	movzwl	.LC256(%rip), %eax
	cmpw	%ax, (%r14)
	je	.L3378
.L2804:
	movl	.LC19(%rip), %eax
	cmpl	%eax, (%r14)
	jne	.L2797
	movzwl	4+.LC19(%rip), %eax
	cmpw	%ax, 4(%r14)
	jne	.L2797
	leaq	.LC257(%rip), %rax
	movq	%rax, -10656(%rbp)
	movq	%r12, %rdi
	movabsq	$-4294946816, %rax
	movq	%rax, -10736(%rbp)
	movq	%r15, -10728(%rbp)
	movl	$5067, -10720(%rbp)
	movq	%r14, -10624(%rbp)
	movq	$33, -10616(%rbp)
	movq	$0, -10664(%rbp)
	movq	$10, -10648(%rbp)
	call	_gfortran_st_read@PLT
	movl	$8, %edx
	leaq	40+plates_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_real@PLT
	movl	$8, %edx
	leaq	56+plates_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_real@PLT
	movl	$8, %edx
	leaq	8+plates_(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r12, %rdi
	call	_gfortran_st_read_done@PLT
	vmovsd	.LC8(%rip), %xmm3
	vdivsd	bas_(%rip), %xmm3, %xmm0
	vmulsd	40+plates_(%rip), %xmm0, %xmm2
	vmulsd	56+plates_(%rip), %xmm0, %xmm1
	vmulsd	8+plates_(%rip), %xmm0, %xmm0
	vmovsd	%xmm2, 40+plates_(%rip)
	vmovsd	%xmm1, 56+plates_(%rip)
	vsubsd	48+plates_(%rip), %xmm2, %xmm2
	vsubsd	64+plates_(%rip), %xmm1, %xmm1
	vmovsd	%xmm0, 8+plates_(%rip)
	vsubsd	plates_(%rip), %xmm0, %xmm0
	vmovsd	%xmm2, 240000+for_(%rip)
	vmovsd	%xmm1, 240008+for_(%rip)
	vdivsd	%xmm2, %xmm3, %xmm2
	vmovsd	%xmm0, 240016+for_(%rip)
	vdivsd	%xmm1, %xmm3, %xmm1
	vmovsd	%xmm2, 240024+for_(%rip)
	vdivsd	%xmm0, %xmm3, %xmm0
	vmovsd	%xmm1, 240032+for_(%rip)
	vmovsd	%xmm0, 240040+for_(%rip)
	jmp	.L2797
	.p2align 4,,10
	.p2align 3
.L3342:
	cmpb	$65, -176(%rbp)
	je	.L2810
	leaq	-176(%rbp), %rsi
	movl	$1, %edi
	call	_gfortran_string_len_trim@PLT
	testq	%rax, %rax
	jne	.L2797
.L2810:
	leaq	.LC258(%rip), %rax
	leaq	-196(%rbp), %rbx
	movq	%rax, -10656(%rbp)
	movq	%r12, %rdi
	movabsq	$-4294946816, %rax
	movq	%rax, -10736(%rbp)
	movq	%r15, -10728(%rbp)
	movl	$5082, -10720(%rbp)
	movq	%r14, -10624(%rbp)
	movq	$128, -10616(%rbp)
	movq	$0, -10664(%rbp)
	movq	$28, -10648(%rbp)
	call	_gfortran_st_read@PLT
	movq	%rbx, %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character@PLT
	leaq	-199(%rbp), %rsi
	movl	$3, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character@PLT
	leaq	-205(%rbp), %rsi
	movl	$1, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character@PLT
	leaq	-11116(%rbp), %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_integer@PLT
	leaq	-11112(%rbp), %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real@PLT
	leaq	-11104(%rbp), %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real@PLT
	leaq	-11096(%rbp), %rsi
	movl	$8, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r12, %rdi
	call	_gfortran_st_read_done@PLT
	movabsq	$-4294946816, %rax
	leaq	.LC259(%rip), %rdx
	movq	%r12, %rdi
	movq	%rax, -10736(%rbp)
	movq	%rbx, -10624(%rbp)
	movq	%rdx, -10656(%rbp)
	movq	%r15, -10728(%rbp)
	movl	$5083, -10720(%rbp)
	movq	$4, -10616(%rbp)
	movq	$0, -10664(%rbp)
	movq	$7, -10648(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-203(%rbp), %rsi
	movl	$2, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character@PLT
	movq	%r12, %rdi
	call	_gfortran_st_read_done@PLT
	movabsq	$-4294946816, %rax
	movq	%rbx, -10624(%rbp)
	movq	%r12, %rdi
	leaq	.LC260(%rip), %rbx
	movq	%rax, -10736(%rbp)
	movq	%r15, -10728(%rbp)
	movl	$5084, -10720(%rbp)
	movq	$4, -10616(%rbp)
	movq	$0, -10664(%rbp)
	movq	%rbx, -10656(%rbp)
	movq	$8, -10648(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-201(%rbp), %rsi
	movl	$2, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character@PLT
	movq	%r12, %rdi
	call	_gfortran_st_read_done@PLT
	cmpw	$16707, -203(%rbp)
	je	.L2811
	cmpw	$16707, -201(%rbp)
	jne	.L2797
.L2811:
	movslq	-11160(%rbp), %rax
	movl	16+bas_(%rip), %ebx
	leaq	bon_(%rip), %rdx
	leaq	20000(%rax), %rsi
	movl	$1, (%rdx,%rsi,4)
	leal	1(%rax), %r8d
	testl	%ebx, %ebx
	je	.L2812
	movl	200004+angnat_(%rip), %r11d
	testl	%r11d, %r11d
	jne	.L2812
	leaq	angnat_(%rip), %rcx
	movl	$1, 160000(%rcx,%rax,4)
.L2812:
	movzwl	-199(%rbp), %r9d
	leaq	sequence_(%rip), %rcx
	leaq	80000(%rax,%rax,2), %rdi
	addq	%rcx, %rdi
	movw	%r9w, (%rdi)
	movzbl	-197(%rbp), %r9d
	movb	%r9b, 2(%rdi)
	movl	-11116(%rbp), %r9d
	movl	%r9d, (%rcx,%rax,4)
	movzbl	-205(%rbp), %r9d
	movb	%r9b, -10208(%rbp,%rax)
	cmpl	$2, %r8d
	jle	.L2813
	movl	79996(%rdx,%rax,4), %r10d
	leaq	19999(%rax), %r11
	testl	%r10d, %r10d
	je	.L2813
	cmpb	-10209(%rbp,%rax), %r9b
	je	.L2813
	movl	160000+bon_(%rip), %ebx
	movl	$0, (%rdx,%r11,4)
	leal	1(%rbx), %r9d
	movl	-11160(%rbp), %ebx
	movl	%r9d, 160000+bon_(%rip)
	movslq	%r9d, %r9
	movl	%ebx, 120000(%rdx,%r9,4)
	.p2align 4,,10
	.p2align 3
.L2813:
	vmovsd	.LC8(%rip), %xmm0
	leaq	nat_(%rip), %rdx
	vdivsd	bas_(%rip), %xmm0, %xmm0
	vmulsd	-11112(%rbp), %xmm0, %xmm1
	leaq	10000(%rax), %rbx
	vmovsd	%xmm1, (%rdx,%rax,8)
	vmulsd	-11104(%rbp), %xmm0, %xmm1
	vmulsd	-11096(%rbp), %xmm0, %xmm0
	movzwl	(%rdi), %eax
	vmovsd	%xmm1, (%rdx,%rbx,8)
	vmovsd	%xmm0, (%rdx,%rsi,8)
	cmpw	.LC161(%rip), %ax
	je	.L3379
.L2814:
	cmpw	.LC167(%rip), %ax
	je	.L3380
.L2817:
	cmpw	.LC182(%rip), %ax
	je	.L3381
.L2820:
	cmpw	.LC173(%rip), %ax
	je	.L3382
.L2823:
	cmpw	.LC163(%rip), %ax
	je	.L3383
.L2826:
	cmpw	.LC165(%rip), %ax
	je	.L3384
.L2829:
	cmpw	.LC169(%rip), %ax
	je	.L3385
.L2832:
	cmpw	.LC171(%rip), %ax
	je	.L3386
.L2835:
	cmpw	.LC175(%rip), %ax
	je	.L3387
.L2838:
	cmpw	.LC177(%rip), %ax
	je	.L3388
.L2841:
	cmpw	.LC178(%rip), %ax
	je	.L3389
.L2844:
	cmpw	.LC180(%rip), %ax
	je	.L3390
.L2847:
	movl	$3, %edx
	leaq	.LC184(%rip), %rsi
	movl	%r8d, -11192(%rbp)
	movq	%rdi, -11160(%rbp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	-11160(%rbp), %rdi
	movl	-11192(%rbp), %r8d
	leaq	sequence_(%rip), %rcx
	jne	.L2850
	movl	$13, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
	.p2align 4,,10
	.p2align 3
.L3377:
	movzbl	2+.LC57(%rip), %eax
	cmpb	%al, 2(%r14)
	jne	.L2802
.L2801:
	movq	-11168(%rbp), %rbx
	movabsq	$34359738368, %rax
	movq	%rbx, %rdi
	movq	%rax, -11088(%rbp)
	movq	%r15, -11080(%rbp)
	movl	$5146, -11072(%rbp)
	call	_gfortran_st_close@PLT
	movl	-11160(%rbp), %eax
	movq	%rbx, %rdi
	movl	%eax, 8+bas_(%rip)
	movq	-11176(%rbp), %rax
	movq	%r15, -11080(%rbp)
	movq	%rax, -11048(%rbp)
	movq	-11184(%rbp), %rax
	movl	$5152, -11072(%rbp)
	movq	%rax, -11024(%rbp)
	leaq	.LC237(%rip), %rax
	movq	%rax, -11016(%rbp)
	movabsq	$34376516384, %rax
	movl	$0, -11120(%rbp)
	movq	$32, -11032(%rbp)
	movq	$3, -11008(%rbp)
	movl	$0, -10784(%rbp)
	movq	%rax, -11088(%rbp)
	movabsq	$34359742472, %rbx
	call	_gfortran_st_open@PLT
	.p2align 4,,10
	.p2align 3
.L2864:
	movq	%r12, %rdi
	movq	%r15, -10728(%rbp)
	movl	$5153, -10720(%rbp)
	movq	%r13, -10656(%rbp)
	movq	$3, -10648(%rbp)
	movq	%rbx, -10736(%rbp)
	call	_gfortran_st_read@PLT
	movl	$128, %edx
	movq	%r14, %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character@PLT
	movq	%r12, %rdi
	call	_gfortran_st_read_done@PLT
	movl	-10736(%rbp), %eax
	andl	$3, %eax
	cmpl	$2, %eax
	je	.L2863
	movl	.LC51(%rip), %eax
	cmpl	%eax, (%r14)
	je	.L3391
.L2865:
	movzwl	.LC57(%rip), %eax
	cmpw	%ax, (%r14)
	jne	.L2864
	movzbl	2+.LC57(%rip), %eax
	cmpb	%al, 2(%r14)
	jne	.L2864
.L2863:
	movq	-11168(%rbp), %rdi
	movabsq	$34359738368, %rax
	movq	%r15, -11080(%rbp)
	movl	$5170, -11072(%rbp)
	movq	%rax, -11088(%rbp)
	call	_gfortran_st_close@PLT
	movl	8+bas_(%rip), %r14d
	testl	%r14d, %r14d
	je	.L3392
	movslq	%r14d, %rax
	leaq	bon_(%rip), %rdx
	leaq	19999(%rax), %rcx
	movl	79996(%rdx,%rax,4), %eax
	testl	%eax, %eax
	je	.L2870
	movl	160000+bon_(%rip), %eax
	movl	$0, (%rdx,%rcx,4)
	incl	%eax
	movl	%eax, 160000+bon_(%rip)
	cltq
	movl	%r14d, 120000(%rdx,%rax,4)
.L2870:
	movq	-11208(%rbp), %rax
	movl	(%rax), %eax
	testl	%eax, %eax
	je	.L2795
	testl	%r14d, %r14d
	jle	.L3179
	vmovsd	.LC263(%rip), %xmm0
	vmovsd	240000+for_(%rip), %xmm4
	vmovsd	240016+for_(%rip), %xmm1
	vmulsd	%xmm0, %xmm4, %xmm3
	leaq	nat_(%rip), %rbx
	vxorpd	%xmm2, %xmm2, %xmm2
	leal	-1(%r14), %eax
	leaq	8(%rbx), %rdx
	vmovsd	%xmm3, -11208(%rbp)
	vmovsd	240008+for_(%rip), %xmm3
	leaq	(%rdx,%rax,8), %r15
	vmulsd	%xmm0, %xmm3, %xmm7
	vmovsd	%xmm2, -11296(%rbp)
	vmovsd	%xmm2, -11192(%rbp)
	vmovsd	%xmm2, -11176(%rbp)
	vmovsd	%xmm2, -11184(%rbp)
	vmovsd	%xmm7, -11216(%rbp)
	vmulsd	%xmm0, %xmm1, %xmm7
	vmovsd	.LC264(%rip), %xmm0
	vmovsd	%xmm2, -11160(%rbp)
	vdivsd	%xmm3, %xmm0, %xmm3
	vmovsd	%xmm2, -11168(%rbp)
	vmovsd	%xmm7, -11240(%rbp)
	leaq	-11144(%rbp), %r13
	leaq	-11152(%rbp), %r12
	vmovsd	%xmm2, -11200(%rbp)
	vdivsd	%xmm4, %xmm0, %xmm4
	vmovsd	%xmm3, -11256(%rbp)
	vdivsd	%xmm1, %xmm0, %xmm3
	vmovsd	%xmm4, -11248(%rbp)
	vmovsd	%xmm3, -11264(%rbp)
	.p2align 4,,10
	.p2align 3
.L2873:
	vmovsd	-11248(%rbp), %xmm7
	movq	%r12, %rsi
	vmulsd	(%rbx), %xmm7, %xmm0
	movq	%r13, %rdi
	addq	$8, %rbx
	call	sincos@PLT
	vmovsd	-11168(%rbp), %xmm7
	vmovsd	-11208(%rbp), %xmm3
	vmovsd	-11256(%rbp), %xmm5
	vfmadd231sd	-11152(%rbp), %xmm3, %xmm7
	vmulsd	79992(%rbx), %xmm5, %xmm0
	vmovsd	-11144(%rbp), %xmm4
	movq	%r12, %rsi
	movq	%r13, %rdi
	vmovsd	%xmm4, -11224(%rbp)
	vmovsd	%xmm7, -11168(%rbp)
	call	sincos@PLT
	vmovsd	-11160(%rbp), %xmm6
	vmovsd	-11216(%rbp), %xmm0
	vmovsd	-11144(%rbp), %xmm5
	vfmadd231sd	-11152(%rbp), %xmm0, %xmm6
	movq	%r12, %rsi
	movq	%r13, %rdi
	vmovsd	%xmm5, -11232(%rbp)
	vmovsd	%xmm6, -11160(%rbp)
	vmovsd	-11264(%rbp), %xmm6
	vmulsd	159992(%rbx), %xmm6, %xmm0
	call	sincos@PLT
	vmovsd	-11208(%rbp), %xmm7
	vmovsd	-11224(%rbp), %xmm4
	vmovsd	-11176(%rbp), %xmm6
	vfmadd213sd	-11200(%rbp), %xmm7, %xmm4
	vmovsd	-11216(%rbp), %xmm7
	vmovsd	-11240(%rbp), %xmm2
	vfmadd231sd	-11152(%rbp), %xmm2, %xmm6
	vmovsd	%xmm4, -11200(%rbp)
	vmovsd	-11232(%rbp), %xmm4
	vfmadd213sd	-11184(%rbp), %xmm7, %xmm4
	vmovsd	%xmm6, -11176(%rbp)
	vmovsd	%xmm4, -11184(%rbp)
	vmovsd	-11192(%rbp), %xmm4
	vfmadd231sd	-11144(%rbp), %xmm2, %xmm4
	vmovsd	%xmm4, -11192(%rbp)
	cmpq	%rbx, %r15
	jne	.L2873
	vmovsd	-11200(%rbp), %xmm2
.L2872:
	vxorpd	%xmm4, %xmm4, %xmm4
	vcvtsi2sdl	%r14d, %xmm4, %xmm0
	movl	36+kier_(%rip), %eax
	vmovsd	-11296(%rbp), %xmm4
	movl	%eax, -11312(%rbp)
	vmovsd	%xmm0, %xmm0, %xmm3
	vmovsd	%xmm4, -11368(%rbp)
	testl	%eax, %eax
	je	.L2874
	vmovsd	-11168(%rbp), %xmm4
	vdivsd	%xmm3, %xmm2, %xmm2
	vmovsd	%xmm3, -11168(%rbp)
	vdivsd	%xmm0, %xmm4, %xmm1
	vmovq	.LC11(%rip), %xmm0
	vxorpd	%xmm0, %xmm1, %xmm1
	vxorpd	%xmm0, %xmm2, %xmm0
	call	atan2@PLT
	vmovsd	.LC263(%rip), %xmm1
	vaddsd	.LC265(%rip), %xmm0, %xmm0
	vmulsd	240000+for_(%rip), %xmm1, %xmm1
	vmulsd	%xmm0, %xmm1, %xmm3
	vmovsd	%xmm3, -11368(%rbp)
	vmovsd	-11168(%rbp), %xmm3
.L2874:
	movl	40+kier_(%rip), %eax
	vmovsd	-11296(%rbp), %xmm4
	movl	%eax, -11308(%rbp)
	vmovsd	%xmm4, -11376(%rbp)
	testl	%eax, %eax
	je	.L2875
	vmovsd	-11160(%rbp), %xmm7
	vmovsd	-11184(%rbp), %xmm4
	vdivsd	%xmm3, %xmm7, %xmm1
	vmovq	.LC11(%rip), %xmm2
	vmovsd	%xmm3, -11160(%rbp)
	vdivsd	%xmm3, %xmm4, %xmm0
	vxorpd	%xmm2, %xmm1, %xmm1
	vxorpd	%xmm2, %xmm0, %xmm0
	call	atan2@PLT
	vmovsd	.LC263(%rip), %xmm1
	vaddsd	.LC265(%rip), %xmm0, %xmm0
	vmulsd	240008+for_(%rip), %xmm1, %xmm1
	vmulsd	%xmm0, %xmm1, %xmm3
	vmovsd	%xmm3, -11376(%rbp)
	vmovsd	-11160(%rbp), %xmm3
.L2875:
	movl	44+kier_(%rip), %eax
	vmovsd	-11296(%rbp), %xmm7
	movl	%eax, -11316(%rbp)
	vmovsd	%xmm7, -11384(%rbp)
	testl	%eax, %eax
	je	.L2876
	vmovsd	-11176(%rbp), %xmm7
	vmovsd	-11192(%rbp), %xmm4
	vdivsd	%xmm3, %xmm7, %xmm1
	vmovq	.LC11(%rip), %xmm2
	vdivsd	%xmm3, %xmm4, %xmm0
	vxorpd	%xmm2, %xmm1, %xmm1
	vxorpd	%xmm2, %xmm0, %xmm0
	call	atan2@PLT
	vmovsd	.LC263(%rip), %xmm1
	vaddsd	.LC265(%rip), %xmm0, %xmm0
	vmulsd	240016+for_(%rip), %xmm1, %xmm1
	vmulsd	%xmm0, %xmm1, %xmm3
	vmovsd	%xmm3, -11384(%rbp)
.L2876:
	movl	160000+bon_(%rip), %eax
	movl	%eax, -11320(%rbp)
	testl	%eax, %eax
	jle	.L2795
	vmovsd	240000+for_(%rip), %xmm3
	vmovsd	.LC263(%rip), %xmm0
	vmovsd	%xmm3, -11288(%rbp)
	vmulsd	%xmm3, %xmm0, %xmm4
	movq	$1, -11304(%rbp)
	leaq	nat_(%rip), %r14
	vmovsd	%xmm4, -11216(%rbp)
	vmovsd	240008+for_(%rip), %xmm4
	vmulsd	%xmm4, %xmm0, %xmm7
	vmovsd	%xmm4, -11328(%rbp)
	vmovsd	%xmm7, -11224(%rbp)
	vmovsd	240016+for_(%rip), %xmm7
	vmulsd	%xmm7, %xmm0, %xmm5
	vmovsd	.LC72(%rip), %xmm0
	vmovsd	%xmm7, -11336(%rbp)
	vmovsd	%xmm5, -11248(%rbp)
	vmulsd	%xmm3, %xmm0, %xmm5
	vmovsd	%xmm5, -11344(%rbp)
	vmulsd	%xmm4, %xmm0, %xmm5
	vmovsd	%xmm5, -11352(%rbp)
	vmulsd	%xmm7, %xmm0, %xmm5
	vmovsd	.LC264(%rip), %xmm0
	vdivsd	%xmm3, %xmm0, %xmm3
	vmovsd	%xmm5, -11360(%rbp)
	vmovsd	%xmm3, -11256(%rbp)
	vdivsd	%xmm4, %xmm0, %xmm3
	vmovsd	%xmm3, -11264(%rbp)
	vdivsd	%xmm7, %xmm0, %xmm3
	vmovsd	%xmm3, -11272(%rbp)
	.p2align 4,,10
	.p2align 3
.L2877:
	movq	-11304(%rbp), %rbx
	leaq	119996+bon_(%rip), %rax
	movl	(%rax,%rbx,4), %eax
	leaq	120000+bon_(%rip), %rdi
	movl	(%rdi,%rbx,4), %edi
	leal	1(%rax), %edx
	movl	%eax, -11280(%rbp)
	movl	%edx, -11276(%rbp)
	movl	%edi, -11160(%rbp)
	cmpl	%edi, %edx
	jg	.L3183
	movslq	%eax, %rdx
	leal	-1(%rdi), %eax
	subl	%edx, %eax
	vmovsd	-11296(%rbp), %xmm4
	addq	%rdx, %rax
	leaq	8+nat_(%rip), %rbx
	leaq	(%rbx,%rax,8), %r13
	leaq	(%r14,%rdx,8), %r15
	leaq	-11144(%rbp), %r12
	leaq	-11152(%rbp), %rbx
	vmovsd	%xmm4, -11208(%rbp)
	vmovsd	%xmm4, -11192(%rbp)
	vmovsd	%xmm4, -11200(%rbp)
	vmovsd	%xmm4, -11184(%rbp)
	vmovsd	%xmm4, -11176(%rbp)
	vmovsd	%xmm4, -11168(%rbp)
	vzeroupper
	.p2align 4,,10
	.p2align 3
.L2879:
	vmovsd	-11256(%rbp), %xmm7
	movq	%rbx, %rsi
	vmulsd	(%r15), %xmm7, %xmm0
	movq	%r12, %rdi
	addq	$8, %r15
	call	sincos@PLT
	vmovsd	-11216(%rbp), %xmm5
	vmovsd	-11176(%rbp), %xmm6
	vmovsd	-11264(%rbp), %xmm3
	vfmadd231sd	-11152(%rbp), %xmm5, %xmm6
	vmulsd	79992(%r15), %xmm3, %xmm0
	vmovsd	-11144(%rbp), %xmm7
	movq	%rbx, %rsi
	movq	%r12, %rdi
	vmovsd	%xmm7, -11240(%rbp)
	vmovsd	%xmm6, -11176(%rbp)
	call	sincos@PLT
	vmovsd	-11184(%rbp), %xmm6
	vmovsd	-11224(%rbp), %xmm3
	vmovsd	-11144(%rbp), %xmm4
	vfmadd231sd	-11152(%rbp), %xmm3, %xmm6
	movq	%rbx, %rsi
	movq	%r12, %rdi
	vmovsd	%xmm4, -11232(%rbp)
	vmovsd	%xmm6, -11184(%rbp)
	vmovsd	-11272(%rbp), %xmm6
	vmulsd	159992(%r15), %xmm6, %xmm0
	call	sincos@PLT
	vmovsd	-11216(%rbp), %xmm5
	vmovsd	-11240(%rbp), %xmm7
	vmovsd	-11192(%rbp), %xmm6
	vfmadd213sd	-11168(%rbp), %xmm5, %xmm7
	vmovsd	-11248(%rbp), %xmm0
	vmovsd	-11208(%rbp), %xmm5
	vmovsd	-11232(%rbp), %xmm4
	vfmadd231sd	-11152(%rbp), %xmm0, %xmm6
	vmovsd	%xmm7, -11168(%rbp)
	vmovsd	-11224(%rbp), %xmm7
	vfmadd231sd	-11144(%rbp), %xmm0, %xmm5
	vfmadd213sd	-11200(%rbp), %xmm7, %xmm4
	vmovsd	%xmm6, -11192(%rbp)
	vmovsd	%xmm5, -11208(%rbp)
	vmovsd	%xmm4, -11200(%rbp)
	cmpq	%r13, %r15
	jne	.L2879
	vmovsd	-11168(%rbp), %xmm2
.L2878:
	movl	-11160(%rbp), %ebx
	movl	-11312(%rbp), %eax
	subl	-11280(%rbp), %ebx
	vxorpd	%xmm7, %xmm7, %xmm7
	vcvtsi2sdl	%ebx, %xmm7, %xmm6
	vxorpd	%xmm3, %xmm3, %xmm3
	testl	%eax, %eax
	je	.L2880
	vmovsd	-11176(%rbp), %xmm7
	vdivsd	%xmm6, %xmm2, %xmm0
	vmovsd	%xmm6, -11168(%rbp)
	vdivsd	%xmm6, %xmm7, %xmm1
	vxorpd	.LC11(%rip), %xmm0, %xmm0
	vxorpd	.LC11(%rip), %xmm1, %xmm1
	vzeroupper
	call	atan2@PLT
	vaddsd	.LC265(%rip), %xmm0, %xmm3
	vmovsd	-11168(%rbp), %xmm6
	vmulsd	-11216(%rbp), %xmm3, %xmm3
.L2880:
	movl	-11308(%rbp), %r15d
	vxorpd	%xmm2, %xmm2, %xmm2
	testl	%r15d, %r15d
	je	.L2881
	vmovsd	-11184(%rbp), %xmm7
	vmovsd	-11200(%rbp), %xmm4
	vdivsd	%xmm6, %xmm7, %xmm1
	vmovsd	%xmm3, -11176(%rbp)
	vmovsd	%xmm6, -11168(%rbp)
	vdivsd	%xmm6, %xmm4, %xmm0
	vxorpd	.LC11(%rip), %xmm1, %xmm1
	vxorpd	.LC11(%rip), %xmm0, %xmm0
	vzeroupper
	call	atan2@PLT
	vaddsd	.LC265(%rip), %xmm0, %xmm2
	vmovsd	-11176(%rbp), %xmm3
	vmovsd	-11168(%rbp), %xmm6
	vmulsd	-11224(%rbp), %xmm2, %xmm2
.L2881:
	movl	-11316(%rbp), %r13d
	vxorpd	%xmm1, %xmm1, %xmm1
	testl	%r13d, %r13d
	je	.L2882
	vmovsd	-11192(%rbp), %xmm4
	vmovsd	-11208(%rbp), %xmm7
	vdivsd	%xmm6, %xmm4, %xmm1
	vmovsd	%xmm2, -11184(%rbp)
	vmovsd	%xmm3, -11176(%rbp)
	vmovsd	%xmm6, -11168(%rbp)
	vdivsd	%xmm6, %xmm7, %xmm0
	vxorpd	.LC11(%rip), %xmm1, %xmm1
	vxorpd	.LC11(%rip), %xmm0, %xmm0
	vzeroupper
	call	atan2@PLT
	vaddsd	.LC265(%rip), %xmm0, %xmm1
	vmovsd	-11184(%rbp), %xmm2
	vmovsd	-11176(%rbp), %xmm3
	vmulsd	-11248(%rbp), %xmm1, %xmm1
	vmovsd	-11168(%rbp), %xmm6
.L2882:
	movl	-11280(%rbp), %eax
	movl	-11160(%rbp), %edx
	leal	2(%rax), %r15d
	cmpl	%edx, -11276(%rbp)
	jg	.L2883
	movl	-11312(%rbp), %r12d
	testl	%r12d, %r12d
	jne	.L2884
	movl	-11316(%rbp), %r11d
	testl	%r11d, %r11d
	jne	.L2885
	movl	-11308(%rbp), %r10d
	testl	%r10d, %r10d
	je	.L2886
	movslq	%eax, %rdi
	movl	%edx, %ecx
	subl	%eax, %ecx
	leaq	10000(%rdi), %rsi
	leaq	0(,%rsi,8), %rax
	cmpl	$1, %ecx
	je	.L2887
	cmpl	$2147483647, %edx
	je	.L2887
	leal	-1(%rcx), %edx
	cmpl	$2, %edx
	jbe	.L3187
	movl	%ecx, %edi
	vbroadcastsd	-11352(%rbp), %ymm5
	vbroadcastsd	-11328(%rbp), %ymm7
	shrl	$2, %edi
	vbroadcastsd	%xmm2, %ymm4
	addq	%r14, %rax
	xorl	%edx, %edx
	jmp	.L2891
	.p2align 4,,10
	.p2align 3
.L2889:
	vcmplepd	%ymm4, %ymm3, %ymm1
	vpand	%ymm0, %ymm1, %ymm0
	vptest	%ymm0, %ymm0
	jne	.L3393
.L2890:
	incl	%edx
	addq	$32, %rax
	cmpl	%edx, %edi
	jbe	.L3394
.L2891:
	vmovupd	(%rax), %ymm3
	vsubpd	%ymm4, %ymm3, %ymm0
	vcmpltpd	%ymm3, %ymm4, %ymm1
	vandpd	.LC266(%rip), %ymm0, %ymm0
	vcmpltpd	%ymm0, %ymm5, %ymm0
	vpand	%ymm0, %ymm1, %ymm1
	vptest	%ymm1, %ymm1
	je	.L2889
	vsubpd	%ymm7, %ymm3, %ymm8
	vmaskmovpd	%ymm8, %ymm1, (%rax)
	vcmplepd	%ymm4, %ymm3, %ymm1
	vpand	%ymm0, %ymm1, %ymm0
	vptest	%ymm0, %ymm0
	je	.L2890
.L3393:
	vaddpd	%ymm7, %ymm3, %ymm3
	incl	%edx
	vmaskmovpd	%ymm3, %ymm0, (%rax)
	addq	$32, %rax
	cmpl	%edx, %edi
	ja	.L2891
.L3394:
	movl	-11276(%rbp), %eax
	movl	%ecx, %edx
	andl	$-4, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L2886
	subl	%edx, %ecx
	cmpl	$1, %ecx
	je	.L2893
.L2888:
	addq	%rsi, %rdx
	leaq	(%r14,%rdx,8), %rdx
	vmovupd	(%rdx), %xmm1
	vmovddup	%xmm2, %xmm0
	vsubpd	%xmm0, %xmm1, %xmm3
	vmovddup	-11352(%rbp), %xmm4
	vmovddup	-11328(%rbp), %xmm5
	vandpd	.LC139(%rip), %xmm3, %xmm3
	vcmpltpd	%xmm3, %xmm4, %xmm4
	vcmpltpd	%xmm1, %xmm0, %xmm3
	vpand	%xmm4, %xmm3, %xmm3
	vptest	%xmm3, %xmm3
	jne	.L3395
.L2894:
	vcmplepd	%xmm0, %xmm1, %xmm0
	vpand	%xmm4, %xmm0, %xmm0
	vptest	%xmm0, %xmm0
	jne	.L3396
.L2895:
	movl	%ecx, %edx
	andl	$-2, %edx
	addl	%edx, %eax
	cmpl	%ecx, %edx
	je	.L2886
.L2893:
	cltq
	addq	$9999, %rax
	vmovsd	(%r14,%rax,8), %xmm0
	vsubsd	%xmm2, %xmm0, %xmm1
	vandpd	.LC69(%rip), %xmm1, %xmm1
	vcomisd	-11352(%rbp), %xmm1
	jbe	.L2886
	vcomisd	%xmm2, %xmm0
	jbe	.L3397
	vsubsd	-11328(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, (%r14,%rax,8)
	.p2align 4,,10
	.p2align 3
.L2886:
	cmpl	%r15d, -11160(%rbp)
	jl	.L2984
.L3175:
	movl	%ebx, %eax
	shrl	$31, %eax
	vmovsd	-11288(%rbp), %xmm5
	vmovsd	-11328(%rbp), %xmm13
	vmovsd	-11336(%rbp), %xmm14
	addl	%eax, %ebx
	movslq	-11280(%rbp), %rax
	sarl	%ebx
	vmovddup	%xmm5, %xmm9
	movl	%ebx, -11176(%rbp)
	movl	$2, -11168(%rbp)
	vmovsd	-11344(%rbp), %xmm0
	vmovsd	-11352(%rbp), %xmm11
	vmovsd	-11360(%rbp), %xmm12
	leaq	(%r14,%rax,8), %r13
	vmovddup	%xmm13, %xmm8
	vmovddup	%xmm14, %xmm7
	vbroadcastsd	%xmm5, %ymm5
	vbroadcastsd	%xmm13, %ymm4
	vbroadcastsd	%xmm14, %ymm3
	jmp	.L2988
	.p2align 4,,10
	.p2align 3
.L3399:
	vcomisd	%xmm11, %xmm2
	ja	.L2986
	vcomisd	%xmm12, %xmm10
	ja	.L2986
.L2990:
	incl	%r15d
	incl	-11168(%rbp)
	addq	$8, %r13
	cmpl	%r15d, -11160(%rbp)
	jl	.L3398
.L2988:
	vmovsd	8(%r13), %xmm1
	vmovsd	80008(%r13), %xmm2
	vsubsd	0(%r13), %xmm1, %xmm1
	vmovsd	160008(%r13), %xmm10
	vsubsd	80000(%r13), %xmm2, %xmm2
	vandpd	.LC69(%rip), %xmm1, %xmm1
	vsubsd	160000(%r13), %xmm10, %xmm10
	vcomisd	%xmm0, %xmm1
	vandpd	.LC69(%rip), %xmm2, %xmm2
	vandpd	.LC69(%rip), %xmm10, %xmm10
	jbe	.L3399
.L2986:
	movl	-11168(%rbp), %ebx
	leal	-1(%r15), %edx
	cmpl	%ebx, -11176(%rbp)
	jl	.L3190
	movl	-11276(%rbp), %eax
	movl	%edx, %ecx
	movl	%r15d, %edx
.L2989:
	cmpl	%ecx, %eax
	jg	.L2990
	vcomisd	%xmm0, %xmm1
	ja	.L2991
	vcomisd	%xmm12, %xmm10
	ja	.L2992
	vcomisd	%xmm11, %xmm2
	jbe	.L2990
	movl	%ecx, %r8d
	subl	%eax, %r8d
	movslq	%eax, %r11
	leaq	9999(%r11), %r10
	leal	1(%r8), %r9d
	movslq	%edx, %rdx
	leaq	80000(,%rdx,8), %rbx
	movq	%r9, %rdi
	addq	%r10, %r9
	salq	$3, %r9
	leaq	-8(%rbx), %r12
	cmpq	%r12, %r9
	leaq	0(,%r10,8), %rsi
	setle	%r9b
	cmpq	%rsi, %rbx
	setle	%bl
	orb	%bl, %r9b
	je	.L2995
	cmpl	%ecx, %eax
	je	.L2995
	cmpl	$2, %r8d
	jbe	.L3191
	movl	%edi, %ecx
	shrl	$2, %ecx
	addq	%r14, %rsi
	salq	$5, %rcx
	addq	%rsi, %rcx
	leaq	9999(%rdx), %r9
	.p2align 4,,10
	.p2align 3
.L2998:
	vmovupd	(%rsi), %ymm15
	vbroadcastsd	(%r14,%r9,8), %ymm2
	vsubpd	%ymm4, %ymm15, %ymm10
	vaddpd	%ymm4, %ymm15, %ymm1
	vcmpltpd	%ymm15, %ymm2, %ymm2
	addq	$32, %rsi
	vblendvpd	%ymm2, %ymm10, %ymm1, %ymm1
	vmovupd	%ymm1, -32(%rsi)
	cmpq	%rcx, %rsi
	jne	.L2998
	movl	%edi, %ecx
	andl	$-4, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %edi
	je	.L2990
.L2996:
	subl	%ecx, %edi
	cmpl	%ecx, %r8d
	je	.L3000
	addq	%rcx, %r10
	leaq	(%r14,%r10,8), %rcx
	vmovupd	(%rcx), %xmm10
	vmovddup	79992(%r14,%rdx,8), %xmm2
	vsubpd	%xmm8, %xmm10, %xmm15
	vaddpd	%xmm8, %xmm10, %xmm1
	vcmpltpd	%xmm10, %xmm2, %xmm2
	vblendvpd	%xmm2, %xmm15, %xmm1, %xmm1
	vmovupd	%xmm1, (%rcx)
	movl	%edi, %ecx
	andl	$-2, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %edi
	je	.L2990
.L3000:
	cltq
	addq	$9999, %rax
	vmovsd	(%r14,%rax,8), %xmm1
	vcomisd	79992(%r14,%rdx,8), %xmm1
	jbe	.L3361
.L3068:
	vsubsd	%xmm13, %xmm1, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
	jmp	.L2990
	.p2align 4,,10
	.p2align 3
.L3398:
	movl	-11160(%rbp), %ebx
	cmpl	%ebx, -11276(%rbp)
	jg	.L3176
.L2984:
	movl	-11160(%rbp), %ebx
	movl	-11280(%rbp), %edi
	movl	%ebx, %eax
	subl	%edi, %eax
	movl	$1, %esi
	cmpl	%ebx, %edi
	cmovl	%eax, %esi
	decl	%eax
	cmpl	$2, %eax
	jbe	.L3198
	cmpl	%ebx, %edi
	jge	.L3198
	movslq	%edi, %rax
	movl	%esi, %edx
	salq	$3, %rax
	vxorpd	%xmm2, %xmm2, %xmm2
	shrl	$2, %edx
	leaq	(%r14,%rax), %r8
	leaq	80000(%r14,%rax), %rdi
	leaq	160000(%r14,%rax), %rcx
	salq	$5, %rdx
	xorl	%eax, %eax
	vmovapd	%ymm2, %ymm1
	vmovapd	%ymm2, %ymm0
	.p2align 4,,10
	.p2align 3
.L3122:
	vaddpd	(%r8,%rax), %ymm0, %ymm0
	vaddpd	(%rdi,%rax), %ymm1, %ymm1
	vaddpd	(%rcx,%rax), %ymm2, %ymm2
	addq	$32, %rax
	cmpq	%rdx, %rax
	jne	.L3122
	vextractf128	$0x1, %ymm2, %xmm3
	vaddpd	%xmm2, %xmm3, %xmm2
	movl	-11276(%rbp), %ebx
	movl	%esi, %eax
	vunpckhpd	%xmm2, %xmm2, %xmm3
	vaddpd	%xmm2, %xmm3, %xmm2
	vextractf128	$0x1, %ymm1, %xmm3
	vaddpd	%xmm1, %xmm3, %xmm1
	andl	$-4, %eax
	leal	(%rax,%rbx), %ecx
	vunpckhpd	%xmm1, %xmm1, %xmm3
	vaddpd	%xmm1, %xmm3, %xmm1
	vextractf128	$0x1, %ymm0, %xmm3
	vaddpd	%xmm0, %xmm3, %xmm3
	vunpckhpd	%xmm3, %xmm3, %xmm0
	vaddpd	%xmm3, %xmm0, %xmm0
	cmpl	%eax, %esi
	je	.L2985
.L3121:
	movl	-11160(%rbp), %ebx
	movslq	%ecx, %rax
	leal	1(%rcx), %edx
	vaddsd	-8(%r14,%rax,8), %xmm0, %xmm0
	vaddsd	79992(%r14,%rax,8), %xmm1, %xmm1
	vaddsd	159992(%r14,%rax,8), %xmm2, %xmm2
	cmpl	%edx, %ebx
	jl	.L2985
	addl	$2, %ecx
	vaddsd	(%r14,%rax,8), %xmm0, %xmm0
	vaddsd	80000(%r14,%rax,8), %xmm1, %xmm1
	vaddsd	160000(%r14,%rax,8), %xmm2, %xmm2
	movslq	%edx, %rdx
	cmpl	%ecx, %ebx
	jl	.L2985
	vaddsd	(%r14,%rdx,8), %xmm0, %xmm0
	vaddsd	80000(%r14,%rdx,8), %xmm1, %xmm1
	vaddsd	160000(%r14,%rdx,8), %xmm2, %xmm2
.L2985:
	movl	-11312(%rbp), %ecx
	testl	%ecx, %ecx
	je	.L3127
	vdivsd	%xmm6, %xmm0, %xmm0
	vsubsd	-11368(%rbp), %xmm0, %xmm3
	vandpd	.LC69(%rip), %xmm3, %xmm3
	vcomisd	-11344(%rbp), %xmm3
	ja	.L3400
.L3127:
	movl	-11308(%rbp), %edx
	testl	%edx, %edx
	je	.L3126
	vdivsd	%xmm6, %xmm1, %xmm1
	vsubsd	-11376(%rbp), %xmm1, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	-11352(%rbp), %xmm0
	ja	.L3401
.L3126:
	movl	-11316(%rbp), %eax
	testl	%eax, %eax
	je	.L3144
	vdivsd	%xmm6, %xmm2, %xmm2
	vsubsd	-11384(%rbp), %xmm2, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	-11360(%rbp), %xmm0
	ja	.L3402
.L3144:
	incq	-11304(%rbp)
	movq	-11304(%rbp), %rax
	cmpl	%eax, -11320(%rbp)
	jge	.L2877
	vzeroupper
.L2795:
	movq	-56(%rbp), %rax
	subq	%fs:40, %rax
	jne	.L3403
	addq	$11360, %rsp
	popq	%rbx
	popq	%r10
	.cfi_remember_state
	.cfi_def_cfa 10, 0
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	leaq	-8(%r10), %rsp
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L3391:
	.cfi_restore_state
	movzwl	4+.LC51(%rip), %eax
	cmpw	%ax, 4(%r14)
	jne	.L2865
	leaq	-177(%rbp), %rax
	movq	%rax, -10624(%rbp)
	leaq	.LC261(%rip), %rax
	movq	%rax, -10656(%rbp)
	movq	%r12, %rdi
	movabsq	$-4294946816, %rax
	movq	%rax, -10736(%rbp)
	movq	%r15, -10728(%rbp)
	movl	$5155, -10720(%rbp)
	movq	$6, -10616(%rbp)
	movq	$0, -10664(%rbp)
	movq	$7, -10648(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-205(%rbp), %rsi
	movl	$1, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character@PLT
	leaq	-11128(%rbp), %rsi
	movl	$4, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%r12, %rdi
	call	_gfortran_st_read_done@PLT
	leaq	.LC261(%rip), %rax
	leaq	-163(%rbp), %rdx
	movq	%rax, -10656(%rbp)
	movq	%r12, %rdi
	movabsq	$-4294946816, %rax
	movq	%rax, -10736(%rbp)
	movq	%rdx, -10624(%rbp)
	movq	%r15, -10728(%rbp)
	movl	$5156, -10720(%rbp)
	movq	$6, -10616(%rbp)
	movq	$0, -10664(%rbp)
	movq	$7, -10648(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-204(%rbp), %rsi
	movl	$1, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character@PLT
	movl	$4, %edx
	leaq	-11124(%rbp), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%r12, %rdi
	call	_gfortran_st_read_done@PLT
	movslq	248008+nat_(%rip), %rax
	movl	8+bas_(%rip), %ecx
	leal	1(%rax), %edx
	movl	%edx, 248008+nat_(%rip)
	testl	%ecx, %ecx
	jle	.L2865
	leaq	(%rax,%rax), %rdx
	leal	1(%rcx), %edi
	leaq	60002(%rdx), %rcx
	addq	$60003, %rdx
	movq	%rcx, -11160(%rbp)
	movq	%rdx, -11176(%rbp)
	movq	%r14, -11192(%rbp)
	movq	%r12, -11200(%rbp)
	movzbl	-205(%rbp), %r9d
	movl	-11128(%rbp), %r11d
	movzbl	-204(%rbp), %r8d
	movl	-11124(%rbp), %r10d
	movl	$1, %eax
	leaq	-10209(%rbp), %rsi
	jmp	.L2868
	.p2align 4,,10
	.p2align 3
.L2866:
	cmpb	%dl, %r8b
	je	.L3404
.L2867:
	incq	%rax
	cmpq	%rax, %rdi
	je	.L3405
.L2868:
	movzbl	(%rsi,%rax), %edx
	movl	%eax, %ecx
	cmpb	%dl, %r9b
	jne	.L2866
	leaq	-4+sequence_(%rip), %r12
	cmpl	(%r12,%rax,4), %r11d
	jne	.L2866
	movq	-11160(%rbp), %r14
	leaq	nat_(%rip), %r12
	movl	%eax, (%r12,%r14,4)
	cmpb	%dl, %r8b
	jne	.L2867
	.p2align 4,,10
	.p2align 3
.L3404:
	leaq	-4+sequence_(%rip), %rdx
	cmpl	(%rdx,%rax,4), %r10d
	jne	.L2867
	movq	-11176(%rbp), %r14
	leaq	nat_(%rip), %rdx
	incq	%rax
	movl	%ecx, (%rdx,%r14,4)
	cmpq	%rax, %rdi
	jne	.L2868
.L3405:
	movq	-11192(%rbp), %r14
	movq	-11200(%rbp), %r12
	jmp	.L2865
.L3378:
	movzbl	2+.LC256(%rip), %eax
	cmpb	%al, 2(%r14)
	jne	.L2804
	movslq	160000+bon_(%rip), %rcx
	movl	-11160(%rbp), %ebx
	leaq	bon_(%rip), %rdx
	movq	%rcx, %rax
	cmpl	%ebx, 120000(%rdx,%rcx,4)
	jge	.L2797
	incl	%eax
	movl	%eax, 160000+bon_(%rip)
	movslq	%ebx, %rcx
	cltq
	movl	$0, 79996(%rdx,%rcx,4)
	movl	%ebx, 120000(%rdx,%rax,4)
	jmp	.L2797
.L3379:
	movzbl	2+.LC161(%rip), %edx
	cmpb	%dl, 2(%rdi)
	jne	.L2814
	movl	$1, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
	.p2align 4,,10
	.p2align 3
.L3190:
	movl	-11160(%rbp), %ecx
	movl	%r15d, %eax
	jmp	.L2989
	.p2align 4,,10
	.p2align 3
.L2991:
	vcomisd	%xmm12, %xmm10
	movslq	%edx, %rdx
	ja	.L3042
	vcomisd	%xmm11, %xmm2
	ja	.L3043
	movl	%ecx, %r8d
	subl	%eax, %r8d
	movslq	%eax, %r9
	leal	1(%r8), %r11d
	leaq	0(,%rdx,8), %r10
	movq	%r11, %rdi
	addq	%r9, %r11
	leaq	-8(,%r11,8), %rbx
	leaq	-8(%r10), %r11
	cmpq	%r11, %rbx
	leaq	-8(,%r9,8), %rsi
	setle	%r11b
	cmpq	%rsi, %r10
	setle	%r10b
	orb	%r10b, %r11b
	je	.L3044
	cmpl	%ecx, %eax
	je	.L3044
	cmpl	$2, %r8d
	jbe	.L3194
	movl	%edi, %ecx
	shrl	$2, %ecx
	addq	%r14, %rsi
	salq	$5, %rcx
	addq	%rsi, %rcx
	leaq	-1(%rdx), %r10
	.p2align 4,,10
	.p2align 3
.L3047:
	vmovupd	(%rsi), %ymm15
	vbroadcastsd	(%r14,%r10,8), %ymm2
	vsubpd	%ymm5, %ymm15, %ymm10
	vaddpd	%ymm5, %ymm15, %ymm1
	vcmpltpd	%ymm15, %ymm2, %ymm2
	addq	$32, %rsi
	vblendvpd	%ymm2, %ymm10, %ymm1, %ymm1
	vmovupd	%ymm1, -32(%rsi)
	cmpq	%rcx, %rsi
	jne	.L3047
	movl	%edi, %ecx
	andl	$-4, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %edi
	je	.L2990
.L3045:
	subl	%ecx, %edi
	cmpl	%ecx, %r8d
	je	.L3049
	addq	%rcx, %r9
	leaq	-8(%r14,%r9,8), %rcx
	vmovupd	(%rcx), %xmm10
	vmovddup	-8(%r14,%rdx,8), %xmm2
	vsubpd	%xmm9, %xmm10, %xmm15
	vaddpd	%xmm9, %xmm10, %xmm1
	vcmpltpd	%xmm10, %xmm2, %xmm2
	vblendvpd	%xmm2, %xmm15, %xmm1, %xmm1
	vmovupd	%xmm1, (%rcx)
	movl	%edi, %ecx
	andl	$-2, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %edi
	je	.L2990
.L3049:
	cltq
	decq	%rax
	vmovsd	(%r14,%rax,8), %xmm1
	vcomisd	-8(%r14,%rdx,8), %xmm1
	jbe	.L3406
	vsubsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
	jmp	.L2990
	.p2align 4,,10
	.p2align 3
.L3042:
	vcomisd	%xmm11, %xmm2
	ja	.L3076
	movl	%ecx, %ebx
	subl	%eax, %ebx
	leal	1(%rbx), %r9d
	movslq	%eax, %r10
	movq	%r9, %r8
	addq	%r10, %r9
	leaq	0(,%rdx,8), %r11
	salq	$3, %r9
	leaq	159992(%r9), %r12
	leaq	0(,%r10,8), %rdi
	movl	%ebx, -11184(%rbp)
	leaq	159992(%r11), %rbx
	leaq	-8(%rdi), %rsi
	addq	$159992, %rdi
	cmpq	%rbx, %r12
	leaq	160000(%r11), %rbx
	setle	%r12b
	cmpq	%rdi, %rbx
	setle	%bl
	orl	%r12d, %ebx
	subq	$8, %r9
	leaq	-8(%r11), %r12
	cmpq	%r12, %r9
	setle	%r9b
	cmpq	%rsi, %r11
	setle	%r11b
	orl	%r11d, %r9d
	testb	%r9b, %bl
	je	.L3077
	cmpl	%ecx, %eax
	je	.L3077
	cmpl	$2, -11184(%rbp)
	jbe	.L3196
	movl	%r8d, %r9d
	shrl	$2, %r9d
	addq	%r14, %rsi
	addq	%r14, %rdi
	salq	$5, %r9
	xorl	%ecx, %ecx
	leaq	-1(%rdx), %rbx
	leaq	19999(%rdx), %r11
	.p2align 4,,10
	.p2align 3
.L3080:
	vmovupd	(%rsi,%rcx), %ymm15
	vbroadcastsd	(%r14,%rbx,8), %ymm2
	vsubpd	%ymm5, %ymm15, %ymm10
	vcmpltpd	%ymm15, %ymm2, %ymm2
	vaddpd	%ymm5, %ymm15, %ymm1
	vblendvpd	%ymm2, %ymm10, %ymm1, %ymm1
	vmovupd	%ymm1, (%rsi,%rcx)
	vmovupd	(%rdi,%rcx), %ymm15
	vbroadcastsd	(%r14,%r11,8), %ymm2
	vsubpd	%ymm3, %ymm15, %ymm10
	vaddpd	%ymm3, %ymm15, %ymm1
	vcmpltpd	%ymm15, %ymm2, %ymm2
	vblendvpd	%ymm2, %ymm10, %ymm1, %ymm1
	vmovupd	%ymm1, (%rdi,%rcx)
	addq	$32, %rcx
	cmpq	%r9, %rcx
	jne	.L3080
	movl	%r8d, %ecx
	andl	$-4, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %r8d
	je	.L2990
.L3078:
	subl	%ecx, %r8d
	cmpl	%ecx, -11184(%rbp)
	je	.L3082
	addq	%rcx, %r10
	salq	$3, %r10
	leaq	-8(%r14,%r10), %rsi
	vmovupd	(%rsi), %xmm10
	vmovddup	-8(%r14,%rdx,8), %xmm2
	vsubpd	%xmm9, %xmm10, %xmm15
	vcmpltpd	%xmm10, %xmm2, %xmm2
	vaddpd	%xmm9, %xmm10, %xmm1
	leaq	159992(%r14,%r10), %rcx
	vblendvpd	%xmm2, %xmm15, %xmm1, %xmm1
	vmovupd	%xmm1, (%rsi)
	vmovupd	(%rcx), %xmm10
	vmovddup	159992(%r14,%rdx,8), %xmm2
	vsubpd	%xmm7, %xmm10, %xmm15
	vaddpd	%xmm7, %xmm10, %xmm1
	vcmpltpd	%xmm10, %xmm2, %xmm2
	vblendvpd	%xmm2, %xmm15, %xmm1, %xmm1
	vmovupd	%xmm1, (%rcx)
	movl	%r8d, %ecx
	andl	$-2, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %r8d
	je	.L2990
.L3082:
	cltq
	decq	%rax
	vmovsd	(%r14,%rax,8), %xmm1
	leaq	-1(%rdx), %rcx
	vcomisd	-8(%r14,%rdx,8), %xmm1
	jbe	.L3407
	vsubsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
.L3107:
	addq	$20000, %rax
	vmovsd	(%r14,%rax,8), %xmm1
	vcomisd	160000(%r14,%rcx,8), %xmm1
	jbe	.L3365
.L3105:
	vsubsd	%xmm14, %xmm1, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
	jmp	.L2990
	.p2align 4,,10
	.p2align 3
.L2992:
	vcomisd	%xmm11, %xmm2
	movslq	%edx, %rdx
	ja	.L3009
	movl	%ecx, %r8d
	subl	%eax, %r8d
	movslq	%eax, %r11
	leaq	19999(%r11), %r10
	leal	1(%r8), %r9d
	leaq	160000(,%rdx,8), %rbx
	movq	%r9, %rdi
	addq	%r10, %r9
	salq	$3, %r9
	leaq	-8(%rbx), %r12
	cmpq	%r12, %r9
	leaq	0(,%r10,8), %rsi
	setle	%r9b
	cmpq	%rsi, %rbx
	setle	%bl
	orb	%bl, %r9b
	je	.L3010
	cmpl	%ecx, %eax
	je	.L3010
	cmpl	$2, %r8d
	jbe	.L3192
	movl	%edi, %ecx
	shrl	$2, %ecx
	addq	%r14, %rsi
	salq	$5, %rcx
	addq	%rsi, %rcx
	leaq	19999(%rdx), %r9
	.p2align 4,,10
	.p2align 3
.L3013:
	vmovupd	(%rsi), %ymm15
	vbroadcastsd	(%r14,%r9,8), %ymm2
	vsubpd	%ymm3, %ymm15, %ymm10
	vaddpd	%ymm3, %ymm15, %ymm1
	vcmpltpd	%ymm15, %ymm2, %ymm2
	addq	$32, %rsi
	vblendvpd	%ymm2, %ymm10, %ymm1, %ymm1
	vmovupd	%ymm1, -32(%rsi)
	cmpq	%rcx, %rsi
	jne	.L3013
	movl	%edi, %ecx
	andl	$-4, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %edi
	je	.L2990
.L3011:
	subl	%ecx, %edi
	cmpl	%ecx, %r8d
	je	.L3015
	addq	%rcx, %r10
	leaq	(%r14,%r10,8), %rcx
	vmovupd	(%rcx), %xmm10
	vmovddup	159992(%r14,%rdx,8), %xmm2
	vsubpd	%xmm7, %xmm10, %xmm15
	vaddpd	%xmm7, %xmm10, %xmm1
	vcmpltpd	%xmm10, %xmm2, %xmm2
	vblendvpd	%xmm2, %xmm15, %xmm1, %xmm1
	vmovupd	%xmm1, (%rcx)
	movl	%edi, %ecx
	andl	$-2, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %edi
	je	.L2990
.L3015:
	cltq
	addq	$19999, %rax
	vmovsd	(%r14,%rax,8), %xmm1
	vcomisd	159992(%r14,%rdx,8), %xmm1
	ja	.L3105
.L3365:
	vaddsd	%xmm1, %xmm14, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
	jmp	.L2990
.L2883:
	cmpl	%r15d, -11160(%rbp)
	jge	.L3175
.L3176:
	vxorpd	%xmm2, %xmm2, %xmm2
	vmovsd	%xmm2, %xmm2, %xmm1
	vmovsd	%xmm2, %xmm2, %xmm0
	jmp	.L2985
	.p2align 4,,10
	.p2align 3
.L3043:
	movl	%ecx, %ebx
	subl	%eax, %ebx
	leal	1(%rbx), %r9d
	movslq	%eax, %r10
	movq	%r9, %r8
	addq	%r10, %r9
	leaq	0(,%rdx,8), %r11
	salq	$3, %r9
	leaq	79992(%r9), %r12
	leaq	0(,%r10,8), %rdi
	movl	%ebx, -11184(%rbp)
	leaq	79992(%r11), %rbx
	leaq	-8(%rdi), %rsi
	addq	$79992, %rdi
	cmpq	%rbx, %r12
	leaq	80000(%r11), %rbx
	setle	%r12b
	cmpq	%rdi, %rbx
	setle	%bl
	orl	%r12d, %ebx
	subq	$8, %r9
	leaq	-8(%r11), %r12
	cmpq	%r12, %r9
	setle	%r9b
	cmpq	%rsi, %r11
	setle	%r11b
	orl	%r11d, %r9d
	testb	%r9b, %bl
	je	.L3058
	cmpl	%ecx, %eax
	je	.L3058
	cmpl	$2, -11184(%rbp)
	jbe	.L3195
	movl	%r8d, %r9d
	shrl	$2, %r9d
	addq	%r14, %rsi
	addq	%r14, %rdi
	salq	$5, %r9
	xorl	%ecx, %ecx
	leaq	-1(%rdx), %rbx
	leaq	9999(%rdx), %r11
	.p2align 4,,10
	.p2align 3
.L3061:
	vmovupd	(%rsi,%rcx), %ymm15
	vbroadcastsd	(%r14,%rbx,8), %ymm2
	vsubpd	%ymm5, %ymm15, %ymm10
	vcmpltpd	%ymm15, %ymm2, %ymm2
	vaddpd	%ymm5, %ymm15, %ymm1
	vblendvpd	%ymm2, %ymm10, %ymm1, %ymm1
	vmovupd	%ymm1, (%rsi,%rcx)
	vmovupd	(%rdi,%rcx), %ymm15
	vbroadcastsd	(%r14,%r11,8), %ymm2
	vsubpd	%ymm4, %ymm15, %ymm10
	vaddpd	%ymm4, %ymm15, %ymm1
	vcmpltpd	%ymm15, %ymm2, %ymm2
	vblendvpd	%ymm2, %ymm10, %ymm1, %ymm1
	vmovupd	%ymm1, (%rdi,%rcx)
	addq	$32, %rcx
	cmpq	%r9, %rcx
	jne	.L3061
	movl	%r8d, %ecx
	andl	$-4, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %r8d
	je	.L2990
.L3059:
	subl	%ecx, %r8d
	cmpl	%ecx, -11184(%rbp)
	je	.L3063
	addq	%rcx, %r10
	salq	$3, %r10
	leaq	-8(%r14,%r10), %rsi
	vmovupd	(%rsi), %xmm10
	vmovddup	-8(%r14,%rdx,8), %xmm2
	vsubpd	%xmm9, %xmm10, %xmm15
	vcmpltpd	%xmm10, %xmm2, %xmm2
	vaddpd	%xmm9, %xmm10, %xmm1
	leaq	79992(%r14,%r10), %rcx
	vblendvpd	%xmm2, %xmm15, %xmm1, %xmm1
	vmovupd	%xmm1, (%rsi)
	vmovupd	(%rcx), %xmm10
	vmovddup	79992(%r14,%rdx,8), %xmm2
	vsubpd	%xmm8, %xmm10, %xmm15
	vaddpd	%xmm8, %xmm10, %xmm1
	vcmpltpd	%xmm10, %xmm2, %xmm2
	vblendvpd	%xmm2, %xmm15, %xmm1, %xmm1
	vmovupd	%xmm1, (%rcx)
	movl	%r8d, %ecx
	andl	$-2, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %r8d
	je	.L2990
.L3063:
	cltq
	decq	%rax
	vmovsd	(%r14,%rax,8), %xmm1
	leaq	-1(%rdx), %rcx
	vcomisd	-8(%r14,%rdx,8), %xmm1
	jbe	.L3408
	vsubsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
.L3070:
	addq	$10000, %rax
	vmovsd	(%r14,%rax,8), %xmm1
	vcomisd	80000(%r14,%rcx,8), %xmm1
	ja	.L3068
.L3361:
	vaddsd	%xmm1, %xmm13, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
	jmp	.L2990
.L3058:
	movl	-11184(%rbp), %eax
	addq	%r14, %rsi
	addq	%rax, %r10
	leaq	(%r14,%r10,8), %rcx
	leaq	-1(%rdx), %rax
	addq	$9999, %rdx
	jmp	.L3075
	.p2align 4,,10
	.p2align 3
.L3409:
	vaddsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%rsi)
	vmovsd	80000(%rsi), %xmm1
	vcomisd	(%r14,%rdx,8), %xmm1
	ja	.L3073
.L3410:
	vaddsd	%xmm1, %xmm13, %xmm1
	vmovsd	%xmm1, 80000(%rsi)
.L3074:
	addq	$8, %rsi
	cmpq	%rsi, %rcx
	je	.L2990
.L3075:
	vmovsd	(%rsi), %xmm1
	vcomisd	(%r14,%rax,8), %xmm1
	jbe	.L3409
	vsubsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%rsi)
	vmovsd	80000(%rsi), %xmm1
	vcomisd	(%r14,%rdx,8), %xmm1
	jbe	.L3410
.L3073:
	vsubsd	%xmm13, %xmm1, %xmm1
	vmovsd	%xmm1, 80000(%rsi)
	jmp	.L3074
.L3077:
	movl	-11184(%rbp), %eax
	addq	%r14, %rsi
	addq	%rax, %r10
	leaq	(%r14,%r10,8), %rcx
	leaq	-1(%rdx), %rax
	addq	$19999, %rdx
	jmp	.L3094
	.p2align 4,,10
	.p2align 3
.L3411:
	vaddsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%rsi)
	vmovsd	160000(%rsi), %xmm1
	vcomisd	(%r14,%rdx,8), %xmm1
	ja	.L3092
.L3412:
	vaddsd	%xmm1, %xmm14, %xmm1
	vmovsd	%xmm1, 160000(%rsi)
.L3093:
	addq	$8, %rsi
	cmpq	%rcx, %rsi
	je	.L2990
.L3094:
	vmovsd	(%rsi), %xmm1
	vcomisd	(%r14,%rax,8), %xmm1
	jbe	.L3411
	vsubsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%rsi)
	vmovsd	160000(%rsi), %xmm1
	vcomisd	(%r14,%rdx,8), %xmm1
	jbe	.L3412
.L3092:
	vsubsd	%xmm14, %xmm1, %xmm1
	vmovsd	%xmm1, 160000(%rsi)
	jmp	.L3093
	.p2align 4,,10
	.p2align 3
.L3076:
	movl	%ecx, %edi
	subl	%eax, %edi
	movslq	%eax, %r12
	movl	%edi, -11184(%rbp)
	incl	%edi
	leaq	0(,%r12,8), %rsi
	movl	%edi, -11192(%rbp)
	addq	%r12, %rdi
	leaq	0(,%rdx,8), %r8
	salq	$3, %rdi
	leaq	79992(%rsi), %r10
	movq	%r10, %r11
	leaq	79992(%r8), %r9
	leaq	79992(%rdi), %r10
	cmpq	%r9, %r10
	leaq	80000(%r8), %r9
	setle	%r10b
	cmpq	%r11, %r9
	setle	%r9b
	orl	%r9d, %r10d
	movq	%r11, -11200(%rbp)
	leaq	-8(%r8), %r9
	leaq	-8(%rdi), %r11
	cmpq	%r9, %r11
	leaq	-8(%rsi), %rbx
	setle	%r9b
	cmpq	%rbx, %r8
	setle	%r11b
	orl	%r11d, %r9d
	andl	%r10d, %r9d
	cmpl	%ecx, %eax
	setne	%cl
	testb	%cl, %r9b
	je	.L3095
	leaq	159992(%r8), %rcx
	addq	$159992, %rdi
	cmpq	%rcx, %rdi
	setle	%cl
	leaq	159992(%rsi), %r10
	addq	$160000, %r8
	cmpq	%r10, %r8
	setle	%dil
	orb	%dil, %cl
	je	.L3095
	cmpl	$2, -11184(%rbp)
	jbe	.L3197
	movl	-11192(%rbp), %r9d
	movq	-11200(%rbp), %rsi
	addq	%r14, %r10
	shrl	$2, %r9d
	leaq	(%r14,%rbx), %rdi
	movq	%r10, %r8
	addq	%r14, %rsi
	salq	$5, %r9
	xorl	%ecx, %ecx
	leaq	-1(%rdx), %rbx
	leaq	9999(%rdx), %r11
	leaq	19999(%rdx), %r10
	.p2align 4,,10
	.p2align 3
.L3098:
	vmovupd	(%rdi,%rcx), %ymm15
	vbroadcastsd	(%r14,%rbx,8), %ymm2
	vsubpd	%ymm5, %ymm15, %ymm10
	vcmpltpd	%ymm15, %ymm2, %ymm2
	vaddpd	%ymm5, %ymm15, %ymm1
	vblendvpd	%ymm2, %ymm10, %ymm1, %ymm1
	vmovupd	%ymm1, (%rdi,%rcx)
	vmovupd	(%rsi,%rcx), %ymm15
	vbroadcastsd	(%r14,%r11,8), %ymm2
	vsubpd	%ymm4, %ymm15, %ymm10
	vcmpltpd	%ymm15, %ymm2, %ymm2
	vaddpd	%ymm4, %ymm15, %ymm1
	vblendvpd	%ymm2, %ymm10, %ymm1, %ymm1
	vmovupd	%ymm1, (%rsi,%rcx)
	vmovupd	(%r8,%rcx), %ymm15
	vbroadcastsd	(%r14,%r10,8), %ymm2
	vsubpd	%ymm3, %ymm15, %ymm10
	vaddpd	%ymm3, %ymm15, %ymm1
	vcmpltpd	%ymm15, %ymm2, %ymm2
	vblendvpd	%ymm2, %ymm10, %ymm1, %ymm1
	vmovupd	%ymm1, (%r8,%rcx)
	addq	$32, %rcx
	cmpq	%r9, %rcx
	jne	.L3098
	movl	-11192(%rbp), %ebx
	movl	%ebx, %ecx
	andl	$-4, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %ebx
	je	.L2990
.L3096:
	movl	-11192(%rbp), %esi
	subl	%ecx, %esi
	cmpl	%ecx, -11184(%rbp)
	je	.L3100
	addq	%rcx, %r12
	salq	$3, %r12
	leaq	-8(%r14,%r12), %r8
	vmovupd	(%r8), %xmm10
	vmovddup	-8(%r14,%rdx,8), %xmm2
	vsubpd	%xmm9, %xmm10, %xmm15
	vcmpltpd	%xmm10, %xmm2, %xmm2
	vaddpd	%xmm9, %xmm10, %xmm1
	leaq	79992(%r14,%r12), %rdi
	leaq	159992(%r14,%r12), %rcx
	vblendvpd	%xmm2, %xmm15, %xmm1, %xmm1
	vmovupd	%xmm1, (%r8)
	vmovupd	(%rdi), %xmm10
	vmovddup	79992(%r14,%rdx,8), %xmm2
	vsubpd	%xmm8, %xmm10, %xmm15
	vcmpltpd	%xmm10, %xmm2, %xmm2
	vaddpd	%xmm8, %xmm10, %xmm1
	vblendvpd	%xmm2, %xmm15, %xmm1, %xmm1
	vmovupd	%xmm1, (%rdi)
	vmovupd	(%rcx), %xmm10
	vmovddup	159992(%r14,%rdx,8), %xmm2
	vsubpd	%xmm7, %xmm10, %xmm15
	vaddpd	%xmm7, %xmm10, %xmm1
	vcmpltpd	%xmm10, %xmm2, %xmm2
	vblendvpd	%xmm2, %xmm15, %xmm1, %xmm1
	vmovupd	%xmm1, (%rcx)
	movl	%esi, %ecx
	andl	$-2, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %esi
	je	.L2990
.L3100:
	cltq
	decq	%rax
	vmovsd	(%r14,%rax,8), %xmm1
	leaq	-1(%rdx), %rcx
	vcomisd	-8(%r14,%rdx,8), %xmm1
	jbe	.L3413
	vsubsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
.L3110:
	leaq	10000(%rax), %rdx
	vmovsd	(%r14,%rdx,8), %xmm1
	vcomisd	80000(%r14,%rcx,8), %xmm1
	jbe	.L3414
	vsubsd	%xmm13, %xmm1, %xmm1
	vmovsd	%xmm1, (%r14,%rdx,8)
	jmp	.L3107
.L3095:
	movl	-11184(%rbp), %eax
	leaq	-1(%rdx), %rcx
	addq	%rax, %r12
	leaq	8+nat_(%rip), %rax
	leaq	(%rax,%r12,8), %rdi
	addq	%r14, %rsi
	leaq	9999(%rdx), %rax
	addq	$19999, %rdx
	jmp	.L3120
	.p2align 4,,10
	.p2align 3
.L3415:
	vsubsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, -8(%rsi)
	vmovsd	79992(%rsi), %xmm1
	vcomisd	(%r14,%rax,8), %xmm1
	jbe	.L3368
.L3416:
	vsubsd	%xmm13, %xmm1, %xmm1
	vmovsd	%xmm1, 79992(%rsi)
	vmovsd	159992(%rsi), %xmm1
	vcomisd	(%r14,%rdx,8), %xmm1
	jbe	.L3369
.L3417:
	vsubsd	%xmm14, %xmm1, %xmm1
	vmovsd	%xmm1, 159992(%rsi)
.L3119:
	addq	$8, %rsi
	cmpq	%rdi, %rsi
	je	.L2990
.L3120:
	vmovsd	-8(%rsi), %xmm1
	vcomisd	(%r14,%rcx,8), %xmm1
	ja	.L3415
	vaddsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, -8(%rsi)
	vmovsd	79992(%rsi), %xmm1
	vcomisd	(%r14,%rax,8), %xmm1
	ja	.L3416
.L3368:
	vaddsd	%xmm1, %xmm13, %xmm1
	vmovsd	%xmm1, 79992(%rsi)
	vmovsd	159992(%rsi), %xmm1
	vcomisd	(%r14,%rdx,8), %xmm1
	ja	.L3417
.L3369:
	vaddsd	%xmm1, %xmm14, %xmm1
	vmovsd	%xmm1, 159992(%rsi)
	jmp	.L3119
.L3010:
	addq	%r8, %r11
	leaq	8+nat_(%rip), %rbx
	leaq	-159992(%r14,%rsi), %rax
	leaq	(%rbx,%r11,8), %rcx
	addq	$19999, %rdx
	jmp	.L3023
	.p2align 4,,10
	.p2align 3
.L3418:
	vsubsd	%xmm14, %xmm1, %xmm1
	vmovsd	%xmm1, 159992(%rax)
.L3022:
	addq	$8, %rax
	cmpq	%rcx, %rax
	je	.L2990
.L3023:
	vmovsd	159992(%rax), %xmm1
	vcomisd	(%r14,%rdx,8), %xmm1
	ja	.L3418
	vaddsd	%xmm1, %xmm14, %xmm1
	vmovsd	%xmm1, 159992(%rax)
	jmp	.L3022
	.p2align 4,,10
	.p2align 3
.L3009:
	movl	%ecx, %ebx
	subl	%eax, %ebx
	leal	1(%rbx), %edi
	movslq	%eax, %r9
	leaq	9999(%r9,%rdi), %r11
	leaq	80000(,%rdx,8), %r10
	salq	$3, %r11
	leaq	80000(%r11), %r12
	leaq	79992(,%r9,8), %rsi
	movl	%ebx, -11184(%rbp)
	leaq	79992(%r10), %rbx
	cmpq	%rbx, %r12
	movq	%rdi, %r8
	leaq	80000(%r10), %rbx
	leaq	80000(%rsi), %rdi
	setle	%r12b
	cmpq	%rdi, %rbx
	setle	%bl
	orl	%r12d, %ebx
	leaq	-8(%r10), %r12
	cmpq	%r12, %r11
	setle	%r11b
	cmpq	%rsi, %r10
	setle	%r10b
	orl	%r11d, %r10d
	testb	%r10b, %bl
	je	.L3024
	cmpl	%ecx, %eax
	je	.L3024
	cmpl	$2, -11184(%rbp)
	jbe	.L3193
	movl	%r8d, %r10d
	shrl	$2, %r10d
	addq	%r14, %rsi
	addq	%r14, %rdi
	salq	$5, %r10
	xorl	%ecx, %ecx
	leaq	9999(%rdx), %rbx
	leaq	19999(%rdx), %r11
	.p2align 4,,10
	.p2align 3
.L3027:
	vmovupd	(%rsi,%rcx), %ymm15
	vbroadcastsd	(%r14,%rbx,8), %ymm2
	vsubpd	%ymm4, %ymm15, %ymm10
	vcmpltpd	%ymm15, %ymm2, %ymm2
	vaddpd	%ymm4, %ymm15, %ymm1
	vblendvpd	%ymm2, %ymm10, %ymm1, %ymm1
	vmovupd	%ymm1, (%rsi,%rcx)
	vmovupd	(%rdi,%rcx), %ymm15
	vbroadcastsd	(%r14,%r11,8), %ymm2
	vsubpd	%ymm3, %ymm15, %ymm10
	vaddpd	%ymm3, %ymm15, %ymm1
	vcmpltpd	%ymm15, %ymm2, %ymm2
	vblendvpd	%ymm2, %ymm10, %ymm1, %ymm1
	vmovupd	%ymm1, (%rdi,%rcx)
	addq	$32, %rcx
	cmpq	%r10, %rcx
	jne	.L3027
	movl	%r8d, %ecx
	andl	$-4, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %r8d
	je	.L2990
.L3025:
	subl	%ecx, %r8d
	cmpl	%ecx, -11184(%rbp)
	je	.L3029
	leaq	9999(%r9,%rcx), %rcx
	salq	$3, %rcx
	leaq	(%r14,%rcx), %rsi
	vmovupd	(%rsi), %xmm10
	vmovddup	79992(%r14,%rdx,8), %xmm2
	vsubpd	%xmm8, %xmm10, %xmm15
	vcmpltpd	%xmm10, %xmm2, %xmm2
	vaddpd	%xmm8, %xmm10, %xmm1
	leaq	80000(%r14,%rcx), %rcx
	vblendvpd	%xmm2, %xmm15, %xmm1, %xmm1
	vmovupd	%xmm1, (%rsi)
	vmovupd	(%rcx), %xmm10
	vmovddup	159992(%r14,%rdx,8), %xmm2
	vsubpd	%xmm7, %xmm10, %xmm15
	vaddpd	%xmm7, %xmm10, %xmm1
	vcmpltpd	%xmm10, %xmm2, %xmm2
	vblendvpd	%xmm2, %xmm15, %xmm1, %xmm1
	vmovupd	%xmm1, (%rcx)
	movl	%r8d, %ecx
	andl	$-2, %ecx
	addl	%ecx, %eax
	cmpl	%ecx, %r8d
	je	.L2990
.L3029:
	cltq
	leaq	-1(%rax), %rcx
	addq	$9999, %rax
	vmovsd	(%r14,%rax,8), %xmm1
	leaq	-1(%rdx), %rsi
	vcomisd	79992(%r14,%rdx,8), %xmm1
	jbe	.L3419
	vsubsd	%xmm13, %xmm1, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
.L3036:
	leaq	20000(%rcx), %rax
	vmovsd	(%r14,%rax,8), %xmm1
	vcomisd	160000(%r14,%rsi,8), %xmm1
	ja	.L3105
	jmp	.L3365
.L3024:
	movl	-11184(%rbp), %ecx
	leaq	8+nat_(%rip), %rbx
	addq	%rcx, %r9
	leaq	-79992(%r14,%rsi), %rax
	leaq	9999(%rdx), %rcx
	leaq	(%rbx,%r9,8), %rsi
	addq	$19999, %rdx
	jmp	.L3041
	.p2align 4,,10
	.p2align 3
.L3420:
	vaddsd	%xmm1, %xmm13, %xmm1
	vmovsd	%xmm1, 79992(%rax)
	vmovsd	159992(%rax), %xmm1
	vcomisd	(%r14,%rdx,8), %xmm1
	ja	.L3039
.L3421:
	vaddsd	%xmm1, %xmm14, %xmm1
	vmovsd	%xmm1, 159992(%rax)
.L3040:
	addq	$8, %rax
	cmpq	%rsi, %rax
	je	.L2990
.L3041:
	vmovsd	79992(%rax), %xmm1
	vcomisd	(%r14,%rcx,8), %xmm1
	jbe	.L3420
	vsubsd	%xmm13, %xmm1, %xmm1
	vmovsd	%xmm1, 79992(%rax)
	vmovsd	159992(%rax), %xmm1
	vcomisd	(%r14,%rdx,8), %xmm1
	jbe	.L3421
.L3039:
	vsubsd	%xmm14, %xmm1, %xmm1
	vmovsd	%xmm1, 159992(%rax)
	jmp	.L3040
.L2995:
	addq	%r8, %r11
	leaq	8+nat_(%rip), %rbx
	leaq	-79992(%r14,%rsi), %rax
	leaq	(%rbx,%r11,8), %rcx
	addq	$9999, %rdx
	jmp	.L3008
	.p2align 4,,10
	.p2align 3
.L3422:
	vsubsd	%xmm13, %xmm1, %xmm1
	vmovsd	%xmm1, 79992(%rax)
.L3007:
	addq	$8, %rax
	cmpq	%rcx, %rax
	je	.L2990
.L3008:
	vmovsd	79992(%rax), %xmm1
	vcomisd	(%r14,%rdx,8), %xmm1
	ja	.L3422
	vaddsd	%xmm1, %xmm13, %xmm1
	vmovsd	%xmm1, 79992(%rax)
	jmp	.L3007
.L3044:
	addq	%r8, %r9
	addq	%r14, %rsi
	leaq	(%r14,%r9,8), %rax
	decq	%rdx
	jmp	.L3057
	.p2align 4,,10
	.p2align 3
.L3423:
	vsubsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%rsi)
.L3056:
	addq	$8, %rsi
	cmpq	%rsi, %rax
	je	.L2990
.L3057:
	vmovsd	(%rsi), %xmm1
	vcomisd	(%r14,%rdx,8), %xmm1
	ja	.L3423
	vaddsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%rsi)
	jmp	.L3056
.L2884:
	movl	-11316(%rbp), %r8d
	testl	%r8d, %r8d
	jne	.L2934
	movl	-11308(%rbp), %edi
	testl	%edi, %edi
	jne	.L2935
	movl	%edx, %esi
	subl	%eax, %esi
	movslq	%eax, %rcx
	leaq	0(,%rcx,8), %rax
	cmpl	$1, %esi
	je	.L2936
	cmpl	$2147483647, %edx
	je	.L2936
	leal	-1(%rsi), %edx
	cmpl	$2, %edx
	jbe	.L3189
	movl	%esi, %edi
	vbroadcastsd	-11344(%rbp), %ymm5
	vbroadcastsd	-11288(%rbp), %ymm7
	shrl	$2, %edi
	vbroadcastsd	%xmm3, %ymm4
	addq	%r14, %rax
	xorl	%edx, %edx
	jmp	.L2941
	.p2align 4,,10
	.p2align 3
.L2938:
	vcmplepd	%ymm4, %ymm2, %ymm1
	vpand	%ymm0, %ymm1, %ymm0
	vptest	%ymm0, %ymm0
	jne	.L3424
.L2939:
	incl	%edx
	addq	$32, %rax
	cmpl	%edx, %edi
	jbe	.L3425
.L2941:
	vmovupd	(%rax), %ymm2
	vsubpd	%ymm4, %ymm2, %ymm0
	vcmpltpd	%ymm2, %ymm4, %ymm1
	vandpd	.LC266(%rip), %ymm0, %ymm0
	vcmpltpd	%ymm0, %ymm5, %ymm0
	vpand	%ymm0, %ymm1, %ymm1
	vptest	%ymm1, %ymm1
	je	.L2938
	vsubpd	%ymm7, %ymm2, %ymm8
	vmaskmovpd	%ymm8, %ymm1, (%rax)
	vcmplepd	%ymm4, %ymm2, %ymm1
	vpand	%ymm0, %ymm1, %ymm0
	vptest	%ymm0, %ymm0
	je	.L2939
.L3424:
	vaddpd	%ymm7, %ymm2, %ymm2
	incl	%edx
	vmaskmovpd	%ymm2, %ymm0, (%rax)
	addq	$32, %rax
	cmpl	%edx, %edi
	ja	.L2941
.L3425:
	movl	-11276(%rbp), %eax
	movl	%esi, %edx
	andl	$-4, %edx
	addl	%edx, %eax
	cmpl	%edx, %esi
	je	.L2886
	subl	%edx, %esi
	cmpl	$1, %esi
	je	.L2943
.L2937:
	addq	%rdx, %rcx
	leaq	(%r14,%rcx,8), %rdx
	vmovupd	(%rdx), %xmm1
	vmovddup	%xmm3, %xmm0
	vsubpd	%xmm0, %xmm1, %xmm2
	vmovddup	-11344(%rbp), %xmm4
	vmovddup	-11288(%rbp), %xmm5
	vandpd	.LC139(%rip), %xmm2, %xmm2
	vcmpltpd	%xmm2, %xmm4, %xmm4
	vcmpltpd	%xmm1, %xmm0, %xmm2
	vpand	%xmm4, %xmm2, %xmm2
	vptest	%xmm2, %xmm2
	jne	.L3426
.L2944:
	vcmplepd	%xmm0, %xmm1, %xmm0
	vpand	%xmm4, %xmm0, %xmm0
	vptest	%xmm0, %xmm0
	jne	.L3427
.L2945:
	movl	%esi, %edx
	andl	$-2, %edx
	addl	%edx, %eax
	cmpl	%edx, %esi
	je	.L2886
.L2943:
	cltq
	decq	%rax
	vmovsd	(%r14,%rax,8), %xmm0
	vsubsd	%xmm3, %xmm0, %xmm1
	vandpd	.LC69(%rip), %xmm1, %xmm1
	vcomisd	-11344(%rbp), %xmm1
	jbe	.L2886
	vcomisd	%xmm3, %xmm0
	jbe	.L3428
	vsubsd	-11288(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, (%r14,%rax,8)
	jmp	.L2886
	.p2align 4,,10
	.p2align 3
.L3406:
	vaddsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
	jmp	.L2990
.L2934:
	movslq	%eax, %rcx
	decl	%edx
	subl	%ecx, %edx
	movl	-11308(%rbp), %esi
	addq	%rcx, %rdx
	leaq	8+nat_(%rip), %rdi
	leaq	(%r14,%rcx,8), %rax
	leaq	(%rdi,%rdx,8), %rdx
	testl	%esi, %esi
	jne	.L2963
	vmovsd	-11344(%rbp), %xmm4
	vmovsd	-11360(%rbp), %xmm5
.L2970:
	vmovsd	(%rax), %xmm2
	vsubsd	%xmm3, %xmm2, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	%xmm4, %xmm0
	jbe	.L2964
	vcomisd	%xmm3, %xmm2
	jbe	.L3429
	vsubsd	-11288(%rbp), %xmm2, %xmm2
	vmovsd	%xmm2, (%rax)
.L2964:
	vmovsd	160000(%rax), %xmm2
	vsubsd	%xmm1, %xmm2, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	%xmm5, %xmm0
	jbe	.L2967
	vcomisd	%xmm1, %xmm2
	jbe	.L3430
	vsubsd	-11336(%rbp), %xmm2, %xmm2
	vmovsd	%xmm2, 160000(%rax)
.L2967:
	addq	$8, %rax
	cmpq	%rdx, %rax
	jne	.L2970
	jmp	.L2886
	.p2align 4,,10
	.p2align 3
.L2885:
	movl	-11308(%rbp), %r9d
	testl	%r9d, %r9d
	jne	.L2906
	movslq	%eax, %rdi
	movl	%edx, %ecx
	subl	%eax, %ecx
	leaq	20000(%rdi), %rsi
	leaq	0(,%rsi,8), %rax
	cmpl	$1, %ecx
	je	.L2907
	cmpl	$2147483647, %edx
	je	.L2907
	leal	-1(%rcx), %edx
	cmpl	$2, %edx
	jbe	.L3188
	movl	%ecx, %edi
	vbroadcastsd	-11360(%rbp), %ymm5
	vbroadcastsd	-11336(%rbp), %ymm7
	shrl	$2, %edi
	vbroadcastsd	%xmm1, %ymm4
	addq	%r14, %rax
	xorl	%edx, %edx
	jmp	.L2912
	.p2align 4,,10
	.p2align 3
.L2909:
	vcmplepd	%ymm4, %ymm3, %ymm2
	vpand	%ymm0, %ymm2, %ymm0
	vptest	%ymm0, %ymm0
	jne	.L3431
.L2910:
	incl	%edx
	addq	$32, %rax
	cmpl	%edx, %edi
	jbe	.L3432
.L2912:
	vmovupd	(%rax), %ymm3
	vsubpd	%ymm4, %ymm3, %ymm0
	vcmpltpd	%ymm3, %ymm4, %ymm2
	vandpd	.LC266(%rip), %ymm0, %ymm0
	vcmpltpd	%ymm0, %ymm5, %ymm0
	vpand	%ymm0, %ymm2, %ymm2
	vptest	%ymm2, %ymm2
	je	.L2909
	vsubpd	%ymm7, %ymm3, %ymm8
	vmaskmovpd	%ymm8, %ymm2, (%rax)
	vcmplepd	%ymm4, %ymm3, %ymm2
	vpand	%ymm0, %ymm2, %ymm0
	vptest	%ymm0, %ymm0
	je	.L2910
.L3431:
	vaddpd	%ymm7, %ymm3, %ymm3
	incl	%edx
	vmaskmovpd	%ymm3, %ymm0, (%rax)
	addq	$32, %rax
	cmpl	%edx, %edi
	ja	.L2912
.L3432:
	movl	-11276(%rbp), %eax
	movl	%ecx, %edx
	andl	$-4, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L2886
	subl	%edx, %ecx
	cmpl	$1, %ecx
	je	.L2914
.L2908:
	addq	%rsi, %rdx
	leaq	(%r14,%rdx,8), %rdx
	vmovupd	(%rdx), %xmm2
	vmovddup	%xmm1, %xmm0
	vsubpd	%xmm0, %xmm2, %xmm3
	vmovddup	-11360(%rbp), %xmm4
	vmovddup	-11336(%rbp), %xmm5
	vandpd	.LC139(%rip), %xmm3, %xmm3
	vcmpltpd	%xmm3, %xmm4, %xmm4
	vcmpltpd	%xmm2, %xmm0, %xmm3
	vpand	%xmm4, %xmm3, %xmm3
	vptest	%xmm3, %xmm3
	jne	.L3433
.L2915:
	vcmplepd	%xmm0, %xmm2, %xmm0
	vpand	%xmm4, %xmm0, %xmm0
	vptest	%xmm0, %xmm0
	jne	.L3434
.L2916:
	movl	%ecx, %edx
	andl	$-2, %edx
	addl	%edx, %eax
	cmpl	%ecx, %edx
	je	.L2886
.L2914:
	cltq
	addq	$19999, %rax
	vmovsd	(%r14,%rax,8), %xmm0
	vsubsd	%xmm1, %xmm0, %xmm2
	vandpd	.LC69(%rip), %xmm2, %xmm2
	vcomisd	-11360(%rbp), %xmm2
	jbe	.L2886
	vcomisd	%xmm1, %xmm0
	jbe	.L3435
	vsubsd	-11336(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, (%r14,%rax,8)
	jmp	.L2886
.L3407:
	vaddsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
	jmp	.L3107
.L3408:
	vaddsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
	jmp	.L3070
.L3414:
	vaddsd	%xmm1, %xmm13, %xmm1
	vmovsd	%xmm1, (%r14,%rdx,8)
	jmp	.L3107
.L3413:
	vaddsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
	jmp	.L3110
.L3419:
	vaddsd	%xmm1, %xmm13, %xmm1
	vmovsd	%xmm1, (%r14,%rax,8)
	jmp	.L3036
.L3400:
	movl	-11160(%rbp), %eax
	cmpl	%eax, -11276(%rbp)
	jg	.L3127
	vcomisd	-11368(%rbp), %xmm0
	ja	.L3129
	movl	-11280(%rbp), %ebx
	subl	%ebx, %eax
	movl	%eax, %ecx
	leal	-1(%rax), %eax
	cmpl	$2, %eax
	jbe	.L3199
	movl	%ecx, %edx
	movslq	%ebx, %rax
	shrl	$2, %edx
	leaq	(%r14,%rax,8), %rax
	salq	$5, %rdx
	vbroadcastsd	-11288(%rbp), %ymm3
	addq	%rax, %rdx
.L3132:
	vaddpd	(%rax), %ymm3, %ymm0
	addq	$32, %rax
	vmovupd	%ymm0, -32(%rax)
	cmpq	%rdx, %rax
	jne	.L3132
	movl	-11276(%rbp), %eax
	movl	%ecx, %edx
	andl	$-4, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L3127
.L3130:
	subl	%edx, %ecx
	cmpl	$1, %ecx
	je	.L3135
	movslq	-11280(%rbp), %rsi
	vmovddup	-11288(%rbp), %xmm0
	addq	%rsi, %rdx
	leaq	(%r14,%rdx,8), %rdx
	vaddpd	(%rdx), %xmm0, %xmm0
	vmovupd	%xmm0, (%rdx)
	movl	%ecx, %edx
	andl	$-2, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L3127
.L3135:
	vmovsd	-11288(%rbp), %xmm3
	cltq
	vaddsd	-8(%r14,%rax,8), %xmm3, %xmm0
	vmovsd	%xmm0, -8(%r14,%rax,8)
	jmp	.L3127
.L3401:
	movl	-11160(%rbp), %eax
	cmpl	%eax, -11276(%rbp)
	jg	.L3126
	vcomisd	-11376(%rbp), %xmm1
	ja	.L3146
	movl	-11280(%rbp), %ebx
	subl	%ebx, %eax
	movl	%eax, %ecx
	leal	-1(%rax), %eax
	cmpl	$2, %eax
	jbe	.L3201
	movl	%ecx, %edx
	movslq	%ebx, %rax
	shrl	$2, %edx
	leaq	80000(%r14,%rax,8), %rax
	salq	$5, %rdx
	vbroadcastsd	-11328(%rbp), %ymm1
	addq	%rax, %rdx
.L3149:
	vaddpd	(%rax), %ymm1, %ymm0
	addq	$32, %rax
	vmovupd	%ymm0, -32(%rax)
	cmpq	%rax, %rdx
	jne	.L3149
	movl	-11276(%rbp), %eax
	movl	%ecx, %edx
	andl	$-4, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L3126
.L3147:
	subl	%edx, %ecx
	cmpl	$1, %ecx
	je	.L3152
	movslq	-11280(%rbp), %rsi
	vmovddup	-11328(%rbp), %xmm0
	leaq	10000(%rsi,%rdx), %rdx
	leaq	(%r14,%rdx,8), %rdx
	vaddpd	(%rdx), %xmm0, %xmm0
	vmovupd	%xmm0, (%rdx)
	movl	%ecx, %edx
	andl	$-2, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L3126
.L3152:
	vmovsd	-11328(%rbp), %xmm7
	cltq
	vaddsd	79992(%r14,%rax,8), %xmm7, %xmm0
	vmovsd	%xmm0, 79992(%r14,%rax,8)
	jmp	.L3126
.L3402:
	movl	-11160(%rbp), %eax
	cmpl	%eax, -11276(%rbp)
	jg	.L3144
	vcomisd	-11384(%rbp), %xmm2
	ja	.L3161
	movl	-11280(%rbp), %ebx
	subl	%ebx, %eax
	movl	%eax, %ecx
	leal	-1(%rax), %eax
	cmpl	$2, %eax
	jbe	.L3203
	movl	%ecx, %edx
	movslq	%ebx, %rax
	shrl	$2, %edx
	leaq	160000(%r14,%rax,8), %rax
	salq	$5, %rdx
	vbroadcastsd	-11336(%rbp), %ymm1
	addq	%rax, %rdx
.L3164:
	vaddpd	(%rax), %ymm1, %ymm0
	addq	$32, %rax
	vmovupd	%ymm0, -32(%rax)
	cmpq	%rax, %rdx
	jne	.L3164
	movl	%ecx, %eax
	andl	$-4, %eax
	addl	%eax, -11276(%rbp)
	cmpl	%ecx, %eax
	je	.L3144
.L3162:
	subl	%eax, %ecx
	cmpl	$1, %ecx
	je	.L3167
	movslq	-11280(%rbp), %rdx
	vmovddup	-11336(%rbp), %xmm0
	leaq	20000(%rdx,%rax), %rax
	leaq	(%r14,%rax,8), %rax
	vaddpd	(%rax), %xmm0, %xmm0
	vmovupd	%xmm0, (%rax)
	movl	%ecx, %eax
	andl	$-2, %eax
	addl	%eax, -11276(%rbp)
	cmpl	%ecx, %eax
	je	.L3144
.L3167:
	movslq	-11276(%rbp), %rax
	vmovsd	-11336(%rbp), %xmm4
	vaddsd	159992(%r14,%rax,8), %xmm4, %xmm0
	vmovsd	%xmm0, 159992(%r14,%rax,8)
	jmp	.L3144
.L2907:
	movl	-11160(%rbp), %edx
	vmovsd	-11360(%rbp), %xmm3
	decl	%edx
	subl	-11280(%rbp), %edx
	addq	%rdi, %rdx
	leaq	8+nat_(%rip), %rdi
	leaq	-160000(%r14,%rax), %rax
	leaq	(%rdi,%rdx,8), %rdx
.L2926:
	vmovsd	160000(%rax), %xmm2
	vsubsd	%xmm1, %xmm2, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	%xmm3, %xmm0
	jbe	.L2922
	vcomisd	%xmm1, %xmm2
	jbe	.L3349
	vsubsd	-11336(%rbp), %xmm2, %xmm2
	vmovsd	%xmm2, 160000(%rax)
.L2922:
	addq	$8, %rax
	cmpq	%rdx, %rax
	jne	.L2926
	jmp	.L2886
.L2906:
	movslq	%eax, %rcx
	decl	%edx
	subl	%ecx, %edx
	addq	%rcx, %rdx
	leaq	8+nat_(%rip), %rdi
	vmovsd	-11352(%rbp), %xmm4
	vmovsd	-11360(%rbp), %xmm5
	leaq	(%r14,%rcx,8), %rax
	leaq	(%rdi,%rdx,8), %rdx
.L2933:
	vmovsd	80000(%rax), %xmm3
	vsubsd	%xmm2, %xmm3, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	%xmm4, %xmm0
	jbe	.L2927
	vcomisd	%xmm2, %xmm3
	jbe	.L3436
	vsubsd	-11328(%rbp), %xmm3, %xmm3
	vmovsd	%xmm3, 80000(%rax)
.L2927:
	vmovsd	160000(%rax), %xmm3
	vsubsd	%xmm1, %xmm3, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	%xmm5, %xmm0
	jbe	.L2930
	vcomisd	%xmm1, %xmm3
	jbe	.L3437
	vsubsd	-11336(%rbp), %xmm3, %xmm3
	vmovsd	%xmm3, 160000(%rax)
.L2930:
	addq	$8, %rax
	cmpq	%rax, %rdx
	jne	.L2933
	jmp	.L2886
.L2963:
	vmovsd	-11344(%rbp), %xmm5
	vmovsd	-11352(%rbp), %xmm7
	vmovsd	-11360(%rbp), %xmm8
.L2983:
	vmovsd	(%rax), %xmm4
	vsubsd	%xmm3, %xmm4, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	%xmm5, %xmm0
	jbe	.L2971
	vcomisd	%xmm3, %xmm4
	jbe	.L3352
	vsubsd	-11288(%rbp), %xmm4, %xmm4
	vmovsd	%xmm4, (%rax)
.L2971:
	vmovsd	80000(%rax), %xmm4
	vsubsd	%xmm2, %xmm4, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	%xmm7, %xmm0
	jbe	.L2975
	vcomisd	%xmm2, %xmm4
	jbe	.L3353
	vsubsd	-11328(%rbp), %xmm4, %xmm4
	vmovsd	%xmm4, 80000(%rax)
.L2975:
	vmovsd	160000(%rax), %xmm4
	vsubsd	%xmm1, %xmm4, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	%xmm8, %xmm0
	jbe	.L2979
	vcomisd	%xmm1, %xmm4
	jbe	.L3354
	vsubsd	-11336(%rbp), %xmm4, %xmm4
	vmovsd	%xmm4, 160000(%rax)
.L2979:
	addq	$8, %rax
	cmpq	%rax, %rdx
	jne	.L2983
	jmp	.L2886
.L2936:
	movl	-11160(%rbp), %edx
	vmovsd	-11344(%rbp), %xmm2
	decl	%edx
	subl	-11280(%rbp), %edx
	addq	%rdx, %rcx
	leaq	8+nat_(%rip), %rdx
	addq	%r14, %rax
	leaq	(%rdx,%rcx,8), %rdx
.L2955:
	vmovsd	(%rax), %xmm1
	vsubsd	%xmm3, %xmm1, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	%xmm2, %xmm0
	jbe	.L2951
	vcomisd	%xmm3, %xmm1
	jbe	.L3351
	vsubsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%rax)
.L2951:
	addq	$8, %rax
	cmpq	%rdx, %rax
	jne	.L2955
	jmp	.L2886
.L2935:
	movslq	%eax, %rcx
	decl	%edx
	subl	%ecx, %edx
	addq	%rcx, %rdx
	leaq	8+nat_(%rip), %rdi
	vmovsd	-11344(%rbp), %xmm4
	vmovsd	-11352(%rbp), %xmm5
	leaq	(%r14,%rcx,8), %rax
	leaq	(%rdi,%rdx,8), %rdx
.L2962:
	vmovsd	(%rax), %xmm1
	vsubsd	%xmm3, %xmm1, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	%xmm4, %xmm0
	jbe	.L2956
	vcomisd	%xmm3, %xmm1
	jbe	.L3438
	vsubsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%rax)
.L2956:
	vmovsd	80000(%rax), %xmm1
	vsubsd	%xmm2, %xmm1, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	%xmm5, %xmm0
	jbe	.L2959
	vcomisd	%xmm2, %xmm1
	jbe	.L3439
	vsubsd	-11328(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, 80000(%rax)
.L2959:
	addq	$8, %rax
	cmpq	%rax, %rdx
	jne	.L2962
	jmp	.L2886
.L2887:
	movl	-11160(%rbp), %edx
	vmovsd	-11352(%rbp), %xmm3
	decl	%edx
	subl	-11280(%rbp), %edx
	addq	%rdi, %rdx
	leaq	8+nat_(%rip), %rdi
	leaq	-80000(%r14,%rax), %rax
	leaq	(%rdi,%rdx,8), %rdx
.L2905:
	vmovsd	80000(%rax), %xmm1
	vsubsd	%xmm2, %xmm1, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vcomisd	%xmm3, %xmm0
	jbe	.L2901
	vcomisd	%xmm2, %xmm1
	jbe	.L3347
	vsubsd	-11328(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, 80000(%rax)
.L2901:
	addq	$8, %rax
	cmpq	%rdx, %rax
	jne	.L2905
	jmp	.L2886
.L3380:
	movzbl	2+.LC167(%rip), %edx
	cmpb	%dl, 2(%rdi)
	jne	.L2817
	movl	$2, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L3183:
	vmovsd	-11296(%rbp), %xmm4
	vmovsd	%xmm4, %xmm4, %xmm2
	vmovsd	%xmm4, -11208(%rbp)
	vmovsd	%xmm4, -11192(%rbp)
	vmovsd	%xmm4, -11200(%rbp)
	vmovsd	%xmm4, -11184(%rbp)
	vmovsd	%xmm4, -11176(%rbp)
	jmp	.L2878
.L3198:
	vxorpd	%xmm2, %xmm2, %xmm2
	movl	-11276(%rbp), %ecx
	vmovsd	%xmm2, %xmm2, %xmm1
	vmovsd	%xmm2, %xmm2, %xmm0
	jmp	.L3121
.L3161:
	movl	-11280(%rbp), %ebx
	movl	%eax, %ecx
	subl	%ebx, %ecx
	leal	-1(%rcx), %eax
	cmpl	$2, %eax
	jbe	.L3204
	movl	%ecx, %edx
	movslq	%ebx, %rax
	shrl	$2, %edx
	leaq	160000(%r14,%rax,8), %rax
	salq	$5, %rdx
	vbroadcastsd	-11336(%rbp), %ymm1
	addq	%rax, %rdx
.L3171:
	vmovupd	(%rax), %ymm7
	addq	$32, %rax
	vsubpd	%ymm1, %ymm7, %ymm0
	vmovupd	%ymm0, -32(%rax)
	cmpq	%rax, %rdx
	jne	.L3171
	movl	%ecx, %eax
	andl	$-4, %eax
	addl	%eax, -11276(%rbp)
	cmpl	%ecx, %eax
	je	.L3144
.L3169:
	subl	%eax, %ecx
	cmpl	$1, %ecx
	je	.L3173
	movslq	-11280(%rbp), %rdx
	vmovddup	-11336(%rbp), %xmm0
	leaq	20000(%rdx,%rax), %rax
	leaq	(%r14,%rax,8), %rax
	vmovupd	(%rax), %xmm4
	vsubpd	%xmm0, %xmm4, %xmm0
	vmovupd	%xmm0, (%rax)
	movl	%ecx, %eax
	andl	$-2, %eax
	addl	%eax, -11276(%rbp)
	cmpl	%ecx, %eax
	je	.L3144
.L3173:
	movslq	-11276(%rbp), %rax
	addq	$19999, %rax
	vmovsd	(%r14,%rax,8), %xmm0
	vsubsd	-11336(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, (%r14,%rax,8)
	jmp	.L3144
.L3146:
	movl	-11280(%rbp), %ebx
	movl	%eax, %ecx
	subl	%ebx, %ecx
	leal	-1(%rcx), %eax
	cmpl	$2, %eax
	jbe	.L3202
	movl	%ecx, %edx
	movslq	%ebx, %rax
	shrl	$2, %edx
	leaq	80000(%r14,%rax,8), %rax
	salq	$5, %rdx
	vbroadcastsd	-11328(%rbp), %ymm1
	addq	%rax, %rdx
.L3156:
	vmovupd	(%rax), %ymm4
	addq	$32, %rax
	vsubpd	%ymm1, %ymm4, %ymm0
	vmovupd	%ymm0, -32(%rax)
	cmpq	%rax, %rdx
	jne	.L3156
	movl	-11276(%rbp), %eax
	movl	%ecx, %edx
	andl	$-4, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L3126
.L3154:
	subl	%edx, %ecx
	cmpl	$1, %ecx
	je	.L3158
	movslq	-11280(%rbp), %rsi
	vmovddup	-11328(%rbp), %xmm0
	leaq	10000(%rsi,%rdx), %rdx
	leaq	(%r14,%rdx,8), %rdx
	vmovupd	(%rdx), %xmm3
	vsubpd	%xmm0, %xmm3, %xmm0
	vmovupd	%xmm0, (%rdx)
	movl	%ecx, %edx
	andl	$-2, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L3126
.L3158:
	cltq
	addq	$9999, %rax
	vmovsd	(%r14,%rax,8), %xmm0
	vsubsd	-11328(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, (%r14,%rax,8)
	jmp	.L3126
.L3129:
	movl	-11280(%rbp), %ebx
	movl	%eax, %ecx
	subl	%ebx, %ecx
	leal	-1(%rcx), %eax
	cmpl	$2, %eax
	jbe	.L3200
	movl	%ecx, %edx
	movslq	%ebx, %rax
	shrl	$2, %edx
	leaq	(%r14,%rax,8), %rax
	salq	$5, %rdx
	vbroadcastsd	-11288(%rbp), %ymm3
	addq	%rax, %rdx
.L3139:
	vmovupd	(%rax), %ymm7
	addq	$32, %rax
	vsubpd	%ymm3, %ymm7, %ymm0
	vmovupd	%ymm0, -32(%rax)
	cmpq	%rdx, %rax
	jne	.L3139
	movl	-11276(%rbp), %eax
	movl	%ecx, %edx
	andl	$-4, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L3127
.L3137:
	subl	%edx, %ecx
	cmpl	$1, %ecx
	je	.L3141
	movslq	-11280(%rbp), %rsi
	vmovddup	-11288(%rbp), %xmm0
	addq	%rsi, %rdx
	leaq	(%r14,%rdx,8), %rdx
	vmovupd	(%rdx), %xmm4
	vsubpd	%xmm0, %xmm4, %xmm0
	vmovupd	%xmm0, (%rdx)
	movl	%ecx, %edx
	andl	$-2, %edx
	addl	%edx, %eax
	cmpl	%edx, %ecx
	je	.L3127
.L3141:
	cltq
	decq	%rax
	vmovsd	(%r14,%rax,8), %xmm0
	vsubsd	-11288(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, (%r14,%rax,8)
	jmp	.L3127
.L3192:
	xorl	%ecx, %ecx
	jmp	.L3011
.L3381:
	movzbl	2+.LC182(%rip), %edx
	cmpb	%dl, 2(%rdi)
	jne	.L2820
	movl	$3, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L3195:
	xorl	%ecx, %ecx
	jmp	.L3059
.L3197:
	xorl	%ecx, %ecx
	jmp	.L3096
.L3191:
	xorl	%ecx, %ecx
	jmp	.L2996
.L3193:
	xorl	%ecx, %ecx
	jmp	.L3025
.L3196:
	xorl	%ecx, %ecx
	jmp	.L3078
.L3194:
	xorl	%ecx, %ecx
	jmp	.L3045
.L3382:
	movzbl	2+.LC173(%rip), %edx
	cmpb	%dl, 2(%rdi)
	jne	.L2823
	movl	$4, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L3347:
	vaddsd	-11328(%rbp), %xmm1, %xmm1
	addq	$8, %rax
	vmovsd	%xmm1, 79992(%rax)
	cmpq	%rdx, %rax
	jne	.L2905
	jmp	.L2886
.L3349:
	vaddsd	-11336(%rbp), %xmm2, %xmm2
	addq	$8, %rax
	vmovsd	%xmm2, 159992(%rax)
	cmpq	%rdx, %rax
	jne	.L2926
	jmp	.L2886
.L3430:
	vaddsd	-11336(%rbp), %xmm2, %xmm2
	addq	$8, %rax
	vmovsd	%xmm2, 159992(%rax)
	cmpq	%rdx, %rax
	jne	.L2970
	jmp	.L2886
.L3429:
	vaddsd	-11288(%rbp), %xmm2, %xmm2
	vmovsd	%xmm2, (%rax)
	jmp	.L2964
.L3439:
	vaddsd	-11328(%rbp), %xmm1, %xmm1
	addq	$8, %rax
	vmovsd	%xmm1, 79992(%rax)
	cmpq	%rax, %rdx
	jne	.L2962
	jmp	.L2886
.L3438:
	vaddsd	-11288(%rbp), %xmm1, %xmm1
	vmovsd	%xmm1, (%rax)
	jmp	.L2956
.L3351:
	vaddsd	-11288(%rbp), %xmm1, %xmm1
	addq	$8, %rax
	vmovsd	%xmm1, -8(%rax)
	cmpq	%rdx, %rax
	jne	.L2955
	jmp	.L2886
.L3354:
	vaddsd	-11336(%rbp), %xmm4, %xmm4
	addq	$8, %rax
	vmovsd	%xmm4, 159992(%rax)
	cmpq	%rax, %rdx
	jne	.L2983
	jmp	.L2886
.L3353:
	vaddsd	-11328(%rbp), %xmm4, %xmm4
	vmovsd	%xmm4, 80000(%rax)
	jmp	.L2975
.L3352:
	vaddsd	-11288(%rbp), %xmm4, %xmm4
	vmovsd	%xmm4, (%rax)
	jmp	.L2971
.L3437:
	vaddsd	-11336(%rbp), %xmm3, %xmm3
	addq	$8, %rax
	vmovsd	%xmm3, 159992(%rax)
	cmpq	%rax, %rdx
	jne	.L2933
	jmp	.L2886
.L3436:
	vaddsd	-11328(%rbp), %xmm3, %xmm3
	vmovsd	%xmm3, 80000(%rax)
	jmp	.L2927
.L3383:
	movzbl	2+.LC163(%rip), %edx
	cmpb	%dl, 2(%rdi)
	jne	.L2826
	movl	$5, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L3428:
	vaddsd	-11288(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, (%r14,%rax,8)
	jmp	.L2886
.L3397:
	vaddsd	-11328(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, (%r14,%rax,8)
	jmp	.L2886
.L3435:
	vaddsd	-11336(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, (%r14,%rax,8)
	jmp	.L2886
.L3434:
	vaddpd	%xmm5, %xmm2, %xmm2
	vmaskmovpd	%xmm2, %xmm0, (%rdx)
	jmp	.L2916
.L3396:
	vaddpd	%xmm5, %xmm1, %xmm1
	vmaskmovpd	%xmm1, %xmm0, (%rdx)
	jmp	.L2895
.L3395:
	vsubpd	%xmm5, %xmm1, %xmm7
	vmaskmovpd	%xmm7, %xmm3, (%rdx)
	jmp	.L2894
.L3433:
	vsubpd	%xmm5, %xmm2, %xmm7
	vmaskmovpd	%xmm7, %xmm3, (%rdx)
	jmp	.L2915
.L3427:
	vaddpd	%xmm5, %xmm1, %xmm1
	vmaskmovpd	%xmm1, %xmm0, (%rdx)
	jmp	.L2945
.L3426:
	vsubpd	%xmm5, %xmm1, %xmm7
	vmaskmovpd	%xmm7, %xmm2, (%rdx)
	jmp	.L2944
.L3179:
	vxorpd	%xmm2, %xmm2, %xmm2
	vmovsd	%xmm2, -11296(%rbp)
	vmovsd	%xmm2, -11192(%rbp)
	vmovsd	%xmm2, -11176(%rbp)
	vmovsd	%xmm2, -11184(%rbp)
	vmovsd	%xmm2, -11160(%rbp)
	vmovsd	%xmm2, -11168(%rbp)
	jmp	.L2872
.L3385:
	movzbl	2+.LC169(%rip), %edx
	cmpb	%dl, 2(%rdi)
	jne	.L2832
	movl	$7, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L3189:
	movl	-11276(%rbp), %eax
	xorl	%edx, %edx
	jmp	.L2937
.L3187:
	movl	-11276(%rbp), %eax
	xorl	%edx, %edx
	jmp	.L2888
.L3188:
	movl	-11276(%rbp), %eax
	xorl	%edx, %edx
	jmp	.L2908
.L3384:
	movzbl	2+.LC165(%rip), %edx
	cmpb	%dl, 2(%rdi)
	jne	.L2829
	movl	$6, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L3199:
	movl	-11276(%rbp), %eax
	xorl	%edx, %edx
	jmp	.L3130
.L3201:
	movl	-11276(%rbp), %eax
	xorl	%edx, %edx
	jmp	.L3147
.L3203:
	xorl	%eax, %eax
	jmp	.L3162
.L3202:
	movl	-11276(%rbp), %eax
	xorl	%edx, %edx
	jmp	.L3154
.L3204:
	xorl	%eax, %eax
	jmp	.L3169
.L3200:
	movl	-11276(%rbp), %eax
	xorl	%edx, %edx
	jmp	.L3137
.L3392:
	leaq	.LC27(%rip), %rax
	movq	%rax, -10656(%rbp)
	movl	$6291457, %eax
	salq	$12, %rax
	movq	%r12, %rdi
	movq	%rax, -10736(%rbp)
	movq	%r15, -10728(%rbp)
	movl	$5173, -10720(%rbp)
	movq	$5, -10648(%rbp)
	call	_gfortran_st_write@PLT
	movl	$21, %edx
	leaq	.LC262(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	-11184(%rbp), %rsi
	movl	$32, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movl	$201326593, %eax
	salq	$7, %rax
	movq	%r15, -10728(%rbp)
	movl	$5174, -10720(%rbp)
	movq	%rax, -10736(%rbp)
.L3375:
	movq	%r12, %rdi
	call	_gfortran_st_write@PLT
	movl	$16, %edx
	leaq	.LC201(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
.L3376:
	leaq	.LC238(%rip), %rax
	leaq	-10208(%rbp), %r12
	movq	%rax, -10128(%rbp)
	movl	$6291457, %eax
	salq	$12, %rax
	movq	%r12, %rdi
	movq	%rax, -10208(%rbp)
	movq	%r15, -10200(%rbp)
	movl	$5043, -10192(%rbp)
	movq	$8, -10120(%rbp)
	call	_gfortran_st_write@PLT
	movl	$22, %edx
	leaq	.LC239(%rip), %rsi
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	-11184(%rbp), %rsi
	movl	$32, %edx
	movq	%r12, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rdi
	call	_gfortran_st_write_done@PLT
	movl	$201326593, %eax
	salq	$7, %rax
	movq	%r15, -10200(%rbp)
	movl	$5044, -10192(%rbp)
	movq	%rax, -10208(%rbp)
	jmp	.L3375
.L3403:
	call	__stack_chk_fail@PLT
.L2850:
	movl	$3, %edx
	leaq	.LC186(%rip), %rsi
	movl	%r8d, -11192(%rbp)
	movq	%rdi, -11160(%rbp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	-11160(%rbp), %rdi
	movl	-11192(%rbp), %r8d
	leaq	sequence_(%rip), %rcx
	jne	.L2851
	movl	$14, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L3390:
	movzbl	2+.LC180(%rip), %eax
	cmpb	%al, 2(%rdi)
	jne	.L2847
	movl	$12, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L2851:
	movl	$3, %edx
	leaq	.LC188(%rip), %rsi
	movl	%r8d, -11192(%rbp)
	movq	%rdi, -11160(%rbp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	-11160(%rbp), %rdi
	movl	-11192(%rbp), %r8d
	leaq	sequence_(%rip), %rcx
	jne	.L2852
	movl	$15, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L3389:
	movzbl	2+.LC178(%rip), %edx
	cmpb	%dl, 2(%rdi)
	jne	.L2844
	movl	$11, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
	.p2align 4,,10
	.p2align 3
.L3387:
	movzbl	2+.LC175(%rip), %edx
	cmpb	%dl, 2(%rdi)
	jne	.L2838
	movl	$9, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L3386:
	movzbl	2+.LC171(%rip), %edx
	cmpb	%dl, 2(%rdi)
	jne	.L2835
	movl	$8, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L3388:
	movzbl	2+.LC177(%rip), %edx
	cmpb	%dl, 2(%rdi)
	jne	.L2841
	movl	$10, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L2852:
	movl	$3, %edx
	leaq	.LC190(%rip), %rsi
	movl	%r8d, -11192(%rbp)
	movq	%rdi, -11160(%rbp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	-11160(%rbp), %rdi
	movl	-11192(%rbp), %r8d
	leaq	sequence_(%rip), %rcx
	jne	.L2853
	movl	$16, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L2853:
	movl	$3, %edx
	leaq	.LC192(%rip), %rsi
	movl	%r8d, -11192(%rbp)
	movq	%rdi, -11160(%rbp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	-11160(%rbp), %rdi
	movl	-11192(%rbp), %r8d
	leaq	sequence_(%rip), %rcx
	jne	.L2854
	movl	$17, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L2854:
	movl	$3, %edx
	leaq	.LC194(%rip), %rsi
	movl	%r8d, -11192(%rbp)
	movq	%rdi, -11160(%rbp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	-11160(%rbp), %rdi
	movl	-11192(%rbp), %r8d
	leaq	sequence_(%rip), %rcx
	jne	.L2855
	movl	$18, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L2855:
	movl	$3, %edx
	leaq	.LC196(%rip), %rsi
	movl	%r8d, -11192(%rbp)
	movq	%rdi, -11160(%rbp)
	call	memcmp@PLT
	testl	%eax, %eax
	movq	-11160(%rbp), %rdi
	movl	-11192(%rbp), %r8d
	leaq	sequence_(%rip), %rcx
	jne	.L2856
	movl	$19, (%rcx,%rbx,4)
	movl	%r8d, -11160(%rbp)
	jmp	.L2797
.L2856:
	movl	$3, %edx
	leaq	.LC198(%rip), %rsi
	movl	%r8d, -11160(%rbp)
	call	memcmp@PLT
	testl	%eax, %eax
	jne	.L2797
	leaq	sequence_(%rip), %rcx
	movl	$20, (%rcx,%rbx,4)
	jmp	.L2797
	.cfi_endproc
.LFE53:
	.size	load_protein_, .-load_protein_
	.section	.rodata.str1.1
.LC274:
	.string	"backbone.txt"
	.section	.rodata.str1.8
	.align 8
.LC275:
	.string	"ERROR OPENING FILENAME backbone.txt"
	.text
	.p2align 4
	.globl	load_paramfile_
	.type	load_paramfile_, @function
load_paramfile_:
.LFB54:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register 6
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	movq	%rdi, %r12
	pushq	%rbx
	andq	$-32, %rsp
	subq	$1280, %rsp
	.cfi_offset 3, -56
	movq	%fs:40, %rax
	movq	%rax, 1272(%rsp)
	leaq	.LC2(%rip), %rax
	movq	%rdi, 192(%rsp)
	movl	$5514, 144(%rsp)
	movl	$0, 108(%rsp)
	movq	$32, 184(%rsp)
	movq	$3, 208(%rsp)
	movq	%rax, 136(%rsp)
	leaq	108(%rsp), %rax
	movq	%rax, 24(%rsp)
	movq	%rax, 168(%rsp)
	leaq	.LC237(%rip), %rax
	movq	%rax, 200(%rsp)
	movabsq	$377973900064, %rax
	movq	%rax, 128(%rsp)
	leaq	128(%rsp), %rax
	movq	%rax, %rdi
	movl	$0, 432(%rsp)
	movq	%rax, 32(%rsp)
	call	_gfortran_st_open@PLT
	movl	108(%rsp), %r10d
	testl	%r10d, %r10d
	jne	.L3506
	leaq	736(%rsp), %r15
	leaq	.LC2(%rip), %r14
	movabsq	$377957122176, %rbx
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5522, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5523, 752(%rsp)
	movq	%rbx, 736(%rsp)
	leaq	544(%rsp), %r13
	call	_gfortran_st_read@PLT
	vmovdqa	.LC267(%rip), %ymm5
	leaq	sig_(%rip), %rax
	movabsq	$3302829850624, %r12
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-1, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	vmovupd	40+sig_(%rip), %xmm5
	movq	.LC268(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, 736(%rsp)
	vmovapd	%xmm5, 48+sig_(%rip)
	movq	%r14, 744(%rsp)
	movl	$5527, 752(%rsp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5528, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC267(%rip), %ymm5
	leaq	32+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-337, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5529, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC267(%rip), %ymm5
	leaq	2592+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-17, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5530, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC267(%rip), %ymm5
	leaq	5152+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$303, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5531, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC267(%rip), %ymm5
	leaq	160+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-321, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5532, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC267(%rip), %ymm5
	leaq	2720+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-1, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5533, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC267(%rip), %ymm5
	leaq	5280+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$319, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5534, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC267(%rip), %ymm5
	leaq	288+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-305, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5535, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC267(%rip), %ymm5
	leaq	2848+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$15, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5536, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC267(%rip), %ymm5
	leaq	5408+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$335, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5539, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5540, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC269(%rip), %ymm5
	leaq	51232+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-337, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5541, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC269(%rip), %ymm5
	leaq	53792+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-17, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5542, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC269(%rip), %ymm2
	leaq	56352+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$303, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm2, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5543, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC269(%rip), %ymm5
	leaq	51360+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-321, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5544, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC269(%rip), %ymm2
	leaq	53920+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-1, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm2, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5545, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC269(%rip), %ymm5
	leaq	56480+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$319, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5546, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC269(%rip), %ymm2
	leaq	51488+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-305, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm2, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5547, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC269(%rip), %ymm5
	leaq	54048+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$15, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5548, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC269(%rip), %ymm2
	leaq	56608+ang_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$335, 552(%rsp)
	movq	$8, 560(%rsp)
	movq	%r12, 568(%rsp)
	movq	%r13, 40(%rsp)
	vmovdqa	%ymm2, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	vmovsd	40+ang_(%rip), %xmm0
	vmovsd	.LC100(%rip), %xmm3
	vmovsd	%xmm0, 96+ang_(%rip)
	vmovsd	48+ang_(%rip), %xmm0
	vmovsd	.LC83(%rip), %xmm2
	vaddsd	%xmm0, %xmm0, %xmm0
	vmovsd	.LC123(%rip), %xmm1
	movq	$0x000000000, 88+ang_(%rip)
	vmovsd	%xmm0, 104+ang_(%rip)
	vmulsd	56+ang_(%rip), %xmm3, %xmm0
	movq	$0x000000000, 216+ang_(%rip)
	movq	$0x000000000, 344+ang_(%rip)
	movq	%r15, %rdi
	movabsq	$1103806595072, %r13
	vmovsd	%xmm0, 112+ang_(%rip)
	vmulsd	64+ang_(%rip), %xmm2, %xmm0
	vmovsd	%xmm0, 120+ang_(%rip)
	vmulsd	72+ang_(%rip), %xmm1, %xmm0
	vmovsd	%xmm0, 128+ang_(%rip)
	vmovsd	.LC85(%rip), %xmm0
	vmulsd	80+ang_(%rip), %xmm0, %xmm4
	vmovsd	%xmm4, 136+ang_(%rip)
	vmovsd	168+ang_(%rip), %xmm4
	vmovsd	%xmm4, 224+ang_(%rip)
	vmovsd	176+ang_(%rip), %xmm4
	vaddsd	%xmm4, %xmm4, %xmm4
	vmovsd	%xmm4, 232+ang_(%rip)
	vmulsd	184+ang_(%rip), %xmm3, %xmm4
	vmovsd	%xmm4, 240+ang_(%rip)
	vmulsd	192+ang_(%rip), %xmm2, %xmm4
	vmovsd	%xmm4, 248+ang_(%rip)
	vmulsd	200+ang_(%rip), %xmm1, %xmm4
	vmovsd	%xmm4, 256+ang_(%rip)
	vmulsd	208+ang_(%rip), %xmm0, %xmm4
	vmovsd	%xmm4, 264+ang_(%rip)
	vmovsd	296+ang_(%rip), %xmm4
	vmovsd	%xmm4, 352+ang_(%rip)
	vmovsd	304+ang_(%rip), %xmm4
	movq	$0x000000000, 2648+ang_(%rip)
	vaddsd	%xmm4, %xmm4, %xmm4
	movq	$0x000000000, 2776+ang_(%rip)
	vmovsd	%xmm4, 360+ang_(%rip)
	vmulsd	312+ang_(%rip), %xmm3, %xmm4
	vmovsd	%xmm4, 368+ang_(%rip)
	vmulsd	320+ang_(%rip), %xmm2, %xmm4
	vmovsd	%xmm4, 376+ang_(%rip)
	vmulsd	328+ang_(%rip), %xmm1, %xmm4
	vmovsd	%xmm4, 384+ang_(%rip)
	vmulsd	336+ang_(%rip), %xmm0, %xmm4
	vmovsd	%xmm4, 392+ang_(%rip)
	vmovsd	2600+ang_(%rip), %xmm4
	vmovsd	%xmm4, 2656+ang_(%rip)
	vmovsd	2608+ang_(%rip), %xmm4
	vaddsd	%xmm4, %xmm4, %xmm4
	vmovsd	%xmm4, 2664+ang_(%rip)
	vmulsd	2616+ang_(%rip), %xmm3, %xmm4
	vmovsd	%xmm4, 2672+ang_(%rip)
	vmulsd	2624+ang_(%rip), %xmm2, %xmm4
	vmovsd	%xmm4, 2680+ang_(%rip)
	vmulsd	2632+ang_(%rip), %xmm1, %xmm4
	vmovsd	%xmm4, 2688+ang_(%rip)
	vmulsd	2640+ang_(%rip), %xmm0, %xmm4
	vmovsd	%xmm4, 2696+ang_(%rip)
	vmovsd	2728+ang_(%rip), %xmm4
	vmovsd	%xmm4, 2784+ang_(%rip)
	vmovsd	2736+ang_(%rip), %xmm4
	vaddsd	%xmm4, %xmm4, %xmm4
	vmovsd	%xmm4, 2792+ang_(%rip)
	vmulsd	2744+ang_(%rip), %xmm3, %xmm4
	vmovsd	%xmm4, 2800+ang_(%rip)
	vmulsd	2752+ang_(%rip), %xmm2, %xmm4
	vmovsd	%xmm4, 2808+ang_(%rip)
	vmulsd	2760+ang_(%rip), %xmm1, %xmm4
	movq	$0x000000000, 2904+ang_(%rip)
	movq	$0x000000000, 5208+ang_(%rip)
	movq	$0x000000000, 5336+ang_(%rip)
	vmovsd	%xmm4, 2816+ang_(%rip)
	vmulsd	2768+ang_(%rip), %xmm0, %xmm4
	vmovsd	%xmm4, 2824+ang_(%rip)
	vmovsd	2856+ang_(%rip), %xmm4
	vmovsd	%xmm4, 2912+ang_(%rip)
	vmovsd	2864+ang_(%rip), %xmm4
	vaddsd	%xmm4, %xmm4, %xmm4
	vmovsd	%xmm4, 2920+ang_(%rip)
	vmulsd	2872+ang_(%rip), %xmm3, %xmm4
	vmovsd	%xmm4, 2928+ang_(%rip)
	vmulsd	2880+ang_(%rip), %xmm2, %xmm4
	vmovsd	%xmm4, 2936+ang_(%rip)
	vmulsd	2888+ang_(%rip), %xmm1, %xmm4
	vmovsd	%xmm4, 2944+ang_(%rip)
	vmulsd	2896+ang_(%rip), %xmm0, %xmm4
	vmovsd	%xmm4, 2952+ang_(%rip)
	vmovsd	5160+ang_(%rip), %xmm4
	vmovsd	%xmm4, 5216+ang_(%rip)
	vmovsd	5168+ang_(%rip), %xmm4
	vaddsd	%xmm4, %xmm4, %xmm4
	vmovsd	%xmm4, 5224+ang_(%rip)
	vmulsd	5176+ang_(%rip), %xmm3, %xmm4
	vmovsd	%xmm4, 5232+ang_(%rip)
	vmulsd	5184+ang_(%rip), %xmm2, %xmm4
	vmovsd	%xmm4, 5240+ang_(%rip)
	vmulsd	5192+ang_(%rip), %xmm1, %xmm4
	vmovsd	%xmm4, 5248+ang_(%rip)
	vmulsd	5200+ang_(%rip), %xmm0, %xmm4
	vmovsd	%xmm4, 5256+ang_(%rip)
	vmovsd	5288+ang_(%rip), %xmm4
	vmovsd	%xmm4, 5344+ang_(%rip)
	vmovsd	5296+ang_(%rip), %xmm4
	movq	%r14, 744(%rsp)
	vaddsd	%xmm4, %xmm4, %xmm4
	movl	$5572, 752(%rsp)
	movq	%rbx, 736(%rsp)
	vmovsd	%xmm4, 5352+ang_(%rip)
	vmulsd	5304+ang_(%rip), %xmm3, %xmm4
	vmulsd	5432+ang_(%rip), %xmm3, %xmm3
	movq	$0x000000000, 5464+ang_(%rip)
	vmovsd	%xmm4, 5360+ang_(%rip)
	vmulsd	5312+ang_(%rip), %xmm2, %xmm4
	vmulsd	5440+ang_(%rip), %xmm2, %xmm2
	vmovsd	%xmm3, 5488+ang_(%rip)
	vmovsd	%xmm4, 5368+ang_(%rip)
	vmulsd	5320+ang_(%rip), %xmm1, %xmm4
	vmulsd	5448+ang_(%rip), %xmm1, %xmm1
	vmovsd	%xmm2, 5496+ang_(%rip)
	vmovsd	%xmm4, 5376+ang_(%rip)
	vmulsd	5328+ang_(%rip), %xmm0, %xmm4
	vmulsd	5456+ang_(%rip), %xmm0, %xmm0
	vmovsd	%xmm1, 5504+ang_(%rip)
	vmovsd	%xmm4, 5384+ang_(%rip)
	vmovsd	5416+ang_(%rip), %xmm4
	vmovsd	%xmm0, 5512+ang_(%rip)
	vmovsd	%xmm4, 5472+ang_(%rip)
	vmovsd	5424+ang_(%rip), %xmm4
	vaddsd	%xmm4, %xmm4, %xmm4
	vmovsd	%xmm4, 5480+ang_(%rip)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5573, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC270(%rip), %ymm5
	movq	40(%rsp), %rsi
	leaq	24+sdch_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$4, %edx
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-22, 552(%rsp)
	movq	$4, 560(%rsp)
	movq	%r13, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5574, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC270(%rip), %ymm2
	movq	40(%rsp), %rsi
	leaq	108+sdch_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$4, %edx
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$-1, 552(%rsp)
	movq	$4, 560(%rsp)
	movq	%r13, 568(%rsp)
	vmovdqa	%ymm2, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5575, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC270(%rip), %ymm5
	movq	40(%rsp), %rsi
	leaq	192+sdch_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$4, %edx
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$20, 552(%rsp)
	movq	$4, 560(%rsp)
	movq	%r13, 568(%rsp)
	vmovdqa	%ymm5, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5576, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC270(%rip), %ymm2
	movq	40(%rsp), %rsi
	leaq	276+sdch_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$4, %edx
	movq	%r15, %rdi
	movq	%rax, 544(%rsp)
	movq	$41, 552(%rsp)
	movq	$4, 560(%rsp)
	movq	%r13, 568(%rsp)
	vmovdqa	%ymm2, 576(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movl	80036+misc_(%rip), %r9d
	testl	%r9d, %r9d
	je	.L3442
.L3452:
	leaq	.LC2(%rip), %rax
	movq	32(%rsp), %rdi
	movq	%rax, 136(%rsp)
	movabsq	$377957122048, %rax
	movl	$5606, 144(%rsp)
	movq	%rax, 128(%rsp)
	call	_gfortran_st_close@PLT
	movl	2592152+mr_(%rip), %r8d
	testl	%r8d, %r8d
	jne	.L3507
.L3440:
	movq	1272(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L3508
	leaq	-40(%rbp), %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret
.L3442:
	.cfi_restore_state
	leaq	.LC2(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, %r14
	movq	%rax, 744(%rsp)
	movl	$5579, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movq	%r14, 744(%rsp)
	movl	$5580, 752(%rsp)
	movq	%rbx, 736(%rsp)
	call	_gfortran_st_read@PLT
	vmovdqa	.LC271(%rip), %ymm0
	movq	40(%rsp), %rax
	leaq	480(%rsp), %rsi
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r15, %rdi
	movq	%rax, 480(%rsp)
	movq	$-1, 488(%rsp)
	movq	$8, 496(%rsp)
	movq	%r12, 504(%rsp)
	vmovdqa	%ymm0, 512(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movl	10004076+nmapi_(%rip), %edi
	testl	%edi, %edi
	jne	.L3445
	movl	24+bas_(%rip), %esi
	vmovsd	bas_(%rip), %xmm1
	testl	%esi, %esi
	je	.L3445
.L3446:
	vmovsd	.LC8(%rip), %xmm0
	leaq	176+sig_(%rip), %rdx
	vdivsd	%xmm1, %xmm0, %xmm1
	movq	%r15, 88(%rsp)
	movq	40(%rsp), %rsi
	leaq	-8(%rdx), %r12
	movl	$22, %r13d
	movl	$21, %r8d
	movl	$168, %ebx
	movl	$1, %edi
	movl	$20, %r14d
	vmovddup	%xmm1, %xmm5
	vmulsd	.LC158(%rip), %xmm1, %xmm2
	vbroadcastsd	%xmm1, %ymm1
	vmulpd	.LC273(%rip), %xmm5, %xmm5
	vmulpd	.LC272(%rip), %ymm1, %ymm4
	jmp	.L3460
	.p2align 4,,10
	.p2align 3
.L3510:
	cmpl	$20, %edi
	je	.L3469
	movl	$20, %eax
	subl	%edi, %eax
	cmpl	$2, %eax
	jbe	.L3470
	vbroadcastsd	%xmm0, %ymm1
	vaddpd	(%rsi), %ymm1, %ymm3
	movl	%r14d, %eax
	shrl	$2, %eax
	vmulpd	%ymm4, %ymm3, %ymm3
	vextractf128	$0x1, %ymm3, %xmm6
	vmovhpd	%xmm3, 160(%rdx)
	vmovlpd	%xmm6, 328(%rdx)
	vmovhpd	%xmm6, 496(%rdx)
	vmovupd	%ymm3, -8(%rdx)
	cmpl	$1, %eax
	je	.L3455
	vaddpd	32(%rsi), %ymm1, %ymm3
	vmulpd	%ymm4, %ymm3, %ymm3
	vextractf128	$0x1, %ymm3, %xmm6
	vmovlpd	%xmm3, 664(%rdx)
	vmovhpd	%xmm3, 832(%rdx)
	vmovlpd	%xmm6, 1000(%rdx)
	vmovhpd	%xmm6, 1168(%rdx)
	vmovupd	%ymm3, 24(%rdx)
	cmpl	$2, %eax
	je	.L3455
	vaddpd	64(%rsi), %ymm1, %ymm3
	vmulpd	%ymm4, %ymm3, %ymm3
	vextractf128	$0x1, %ymm3, %xmm6
	vmovlpd	%xmm3, 1336(%rdx)
	vmovhpd	%xmm3, 1504(%rdx)
	vmovlpd	%xmm6, 1672(%rdx)
	vmovhpd	%xmm6, 1840(%rdx)
	vmovupd	%ymm3, 56(%rdx)
	cmpl	$3, %eax
	je	.L3455
	vaddpd	96(%rsi), %ymm1, %ymm3
	vmulpd	%ymm4, %ymm3, %ymm3
	vextractf128	$0x1, %ymm3, %xmm6
	vmovlpd	%xmm3, 2008(%rdx)
	vmovhpd	%xmm3, 2176(%rdx)
	vmovlpd	%xmm6, 2344(%rdx)
	vmovhpd	%xmm6, 2512(%rdx)
	vmovupd	%ymm3, 88(%rdx)
	cmpl	$4, %eax
	je	.L3455
	vaddpd	128(%rsi), %ymm1, %ymm1
	vmulpd	%ymm4, %ymm1, %ymm1
	vextractf128	$0x1, %ymm1, %xmm3
	vmovlpd	%xmm1, 2680(%rdx)
	vmovhpd	%xmm1, 2848(%rdx)
	vmovlpd	%xmm3, 3016(%rdx)
	vmovhpd	%xmm3, 3184(%rdx)
	vmovupd	%ymm1, 120(%rdx)
.L3455:
	movl	%r14d, %ecx
	andl	$-4, %ecx
	leal	(%rcx,%r10), %eax
	cmpl	%r14d, %ecx
	je	.L3459
.L3454:
	addl	%ecx, %r9d
	movl	$21, %r11d
	subl	%r9d, %r11d
	cmpl	$20, %r9d
	je	.L3457
	leaq	(%rdi,%rcx), %r15
	vmovddup	%xmm0, %xmm1
	vaddpd	536(%rsp,%r15,8), %xmm1, %xmm1
	leaq	(%rcx,%rcx,4), %r9
	leaq	(%rcx,%r9,4), %r9
	vmulpd	%xmm5, %xmm1, %xmm1
	addq	%r13, %r9
	leaq	sig_(%rip), %r15
	addq	%r13, %rcx
	vmovlpd	%xmm1, -8(%r15,%r9,8)
	vmovhpd	%xmm1, 160(%r15,%r9,8)
	leaq	-8(%r15), %r9
	vmovupd	%xmm1, (%r9,%rcx,8)
	movl	%r11d, %ecx
	andl	$-2, %ecx
	addl	%ecx, %eax
	cmpl	%r11d, %ecx
	je	.L3459
.L3457:
	leal	-1(%rax), %ecx
	movslq	%ecx, %rcx
	vaddsd	544(%rsp,%rcx,8), %xmm0, %xmm0
	leal	(%rax,%rax,4), %ecx
	leal	(%rax,%rcx,4), %ecx
	vmulsd	%xmm2, %xmm0, %xmm0
	leal	-1(%r10,%rcx), %ecx
	leal	-1(%r8,%rax), %eax
	leaq	sig_(%rip), %r11
	movslq	%ecx, %rcx
	cltq
	vmovsd	%xmm0, (%r11,%rcx,8)
	vmovsd	%xmm0, (%r11,%rax,8)
.L3459:
	incq	%rdi
	addq	$8, %rsi
	addq	$176, %rbx
	addq	$176, %rdx
	addl	$21, %r8d
	addq	$168, %r12
	addq	$22, %r13
	decl	%r14d
	je	.L3509
.L3460:
	movq	%rsi, %rax
	movq	%r12, %rcx
	leaq	sig_(%rip), %r11
	subq	40(%rsp), %rax
	subq	%r11, %rcx
	addq	$3368, %rax
	addq	$160, %rcx
	cmpq	%rcx, %rax
	cmovg	%rcx, %rax
	vmovsd	(%rsi), %xmm0
	movl	%edi, %r9d
	movl	%edi, %r10d
	cmpq	%rax, %rbx
	jge	.L3510
.L3469:
	movq	40(%rsp), %r9
	movq	%rdx, %rcx
	movq	%rdi, %rax
	.p2align 4,,10
	.p2align 3
.L3453:
	vaddsd	-8(%r9,%rax,8), %xmm0, %xmm1
	addq	$168, %rcx
	vmulsd	%xmm2, %xmm1, %xmm1
	vmovsd	%xmm1, -176(%rcx)
	vmovsd	%xmm1, -8(%r12,%rax,8)
	incq	%rax
	cmpl	$21, %eax
	jne	.L3453
	jmp	.L3459
.L3445:
	leaq	.LC2(%rip), %rax
	movq	%rax, 744(%rsp)
	movq	%r15, %rdi
	movabsq	$377957122176, %rax
	movq	%rax, 736(%rsp)
	movl	$5582, 752(%rsp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	leaq	1269(%rsp), %rax
	movq	%rax, 80(%rsp)
	leaq	120(%rsp), %rax
	movq	%rax, 72(%rsp)
	leaq	112(%rsp), %rax
	movq	$176, 48(%rsp)
	movq	$3536, 88(%rsp)
	movl	$1, 60(%rsp)
	movq	%rax, 64(%rsp)
	leaq	1266(%rsp), %r14
	leaq	-8+sig_(%rip), %rbx
	.p2align 4,,10
	.p2align 3
.L3451:
	movq	48(%rsp), %r12
	movq	%r12, %r13
	jmp	.L3450
	.p2align 4,,10
	.p2align 3
.L3512:
	movabsq	$377957122176, %rax
	movq	%r15, %rdi
	movq	%rax, 736(%rsp)
	movl	$5586, 752(%rsp)
	call	_gfortran_st_read@PLT
	movl	$3, %edx
	movq	%r14, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character@PLT
	movq	80(%rsp), %rsi
	movl	$3, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_character@PLT
	movq	72(%rsp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movq	64(%rsp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	vmovsd	112(%rsp), %xmm0
	leaq	56+nmapi_(%rip), %rax
	vmovsd	%xmm0, (%rax,%r13)
	vmovsd	%xmm0, (%rax,%r12)
.L3504:
	leaq	bas_(%rip), %rax
	vmovsd	(%rax), %xmm1
	vmovsd	120(%rsp), %xmm0
	vdivsd	%xmm1, %xmm0, %xmm0
	vmulsd	.LC158(%rip), %xmm0, %xmm0
	vmovsd	%xmm0, (%rbx,%r12)
	addq	$168, %r12
	vmovsd	%xmm0, (%rbx,%r13)
	addq	$8, %r13
	cmpq	%r12, 88(%rsp)
	je	.L3511
.L3450:
	movl	10004076+nmapi_(%rip), %ecx
	leaq	.LC2(%rip), %rax
	testl	%ecx, %ecx
	movq	%rax, 744(%rsp)
	jne	.L3512
	movabsq	$377957122176, %rax
	movq	%r15, %rdi
	movq	%rax, 736(%rsp)
	movl	$5590, 752(%rsp)
	call	_gfortran_st_read@PLT
	movq	%r14, %rsi
	movq	%r15, %rdi
	movl	$3, %edx
	call	_gfortran_transfer_character@PLT
	movq	80(%rsp), %rsi
	movq	%r15, %rdi
	movl	$3, %edx
	call	_gfortran_transfer_character@PLT
	movq	72(%rsp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3504
	.p2align 4,,10
	.p2align 3
.L3511:
	incl	60(%rsp)
	addq	$8, 88(%rsp)
	addq	$176, 48(%rsp)
	movl	60(%rsp), %eax
	cmpl	$21, %eax
	jne	.L3451
	movl	24+bas_(%rip), %edx
	testl	%edx, %edx
	je	.L3452
	jmp	.L3446
.L3507:
	leaq	.LC2(%rip), %rax
	movq	%rax, 136(%rsp)
	movq	24(%rsp), %rax
	movq	32(%rsp), %rdi
	movq	%rax, 168(%rsp)
	leaq	.LC274(%rip), %rax
	movq	%rax, 192(%rsp)
	leaq	.LC237(%rip), %rax
	movq	%rax, 200(%rsp)
	movabsq	$377973900064, %rax
	movq	%rax, 128(%rsp)
	movl	$5609, 144(%rsp)
	movl	$0, 108(%rsp)
	movq	$12, 184(%rsp)
	movq	$3, 208(%rsp)
	movl	$0, 432(%rsp)
	call	_gfortran_st_open@PLT
	movl	108(%rsp), %eax
	testl	%eax, %eax
	jne	.L3513
	xorl	%ebx, %ebx
	.p2align 4,,10
	.p2align 3
.L3461:
	leaq	.LC2(%rip), %rax
	movq	%rax, 744(%rsp)
	movq	%r15, %rdi
	movabsq	$377957122176, %rax
	movl	$5616, 752(%rsp)
	movq	%rax, 736(%rsp)
	call	_gfortran_st_read@PLT
	testb	$1, 736(%rsp)
	jne	.L3467
	movl	$1, 88(%rsp)
	movl	$1, %r14d
	leaq	480(%rsp), %r13
	xorl	%r12d, %r12d
	.p2align 4,,10
	.p2align 3
.L3464:
	movabsq	$3302829850624, %rax
	movq	%rax, 504(%rsp)
	leal	-1(%r14), %eax
	cltq
	imulq	$18001, %rax, %rax
	movslq	%r12d, %rdx
	imulq	$162009, %rdx, %rdx
	addq	%rbx, %rax
	leaq	mr_(%rip), %rsi
	addq	%rdx, %rax
	leaq	(%rsi,%rax,8), %rdx
	vmovdqa	.LC276(%rip), %ymm7
	movq	%rdx, 480(%rsp)
	subq	$234014, %rax
	xorl	%ecx, %ecx
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	movq	$8, 496(%rsp)
	movq	%rax, 488(%rsp)
	vmovdqa	%ymm7, 512(%rsp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movl	736(%rsp), %eax
	incl	%r14d
	andl	$1, %eax
	cmpl	$4, %r14d
	je	.L3472
	testb	%al, %al
	je	.L3464
.L3472:
	cmpl	$2, 88(%rsp)
	je	.L3467
	testb	%al, %al
	jne	.L3467
	movl	$2, 88(%rsp)
	movl	$1, %r14d
	movl	$1, %r12d
	jmp	.L3464
	.p2align 4,,10
	.p2align 3
.L3467:
	movq	%r15, %rdi
	incq	%rbx
	call	_gfortran_st_read_done@PLT
	cmpq	$18001, %rbx
	jne	.L3461
	leaq	.LC2(%rip), %rax
	movq	32(%rsp), %rdi
	movq	%rax, 136(%rsp)
	movabsq	$377957122048, %rax
	movq	%rax, 128(%rsp)
	movl	$5618, 144(%rsp)
	call	_gfortran_st_close@PLT
	movq	.LC277(%rip), %rax
	movq	%rax, 2592144+mr_(%rip)
	jmp	.L3440
.L3470:
	movl	%edi, %eax
	xorl	%ecx, %ecx
	jmp	.L3454
.L3509:
	movq	88(%rsp), %r15
	vzeroupper
	jmp	.L3452
.L3508:
	call	__stack_chk_fail@PLT
.L3513:
	leaq	.LC56(%rip), %rax
	movq	%rax, 816(%rsp)
	movl	$6291457, %eax
	salq	$12, %rax
	leaq	.LC2(%rip), %rbx
	movq	%r15, %rdi
	movq	%rax, 736(%rsp)
	movq	%rbx, 744(%rsp)
	movl	$5611, 752(%rsp)
	movq	$3, 824(%rsp)
	call	_gfortran_st_write@PLT
	movl	$35, %edx
	leaq	.LC275(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movl	$201326593, %eax
	salq	$7, %rax
	movq	%r15, %rdi
	movq	%rax, 736(%rsp)
	movq	%rbx, 744(%rsp)
	movl	$5612, 752(%rsp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$16, %edx
	leaq	.LC201(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
.L3505:
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
.L3506:
	leaq	.LC238(%rip), %rax
	leaq	736(%rsp), %r13
	movq	%rax, 816(%rsp)
	movl	$6291457, %eax
	salq	$12, %rax
	leaq	.LC2(%rip), %rbx
	movq	%r13, %rdi
	movq	%rax, 736(%rsp)
	movq	%rbx, 744(%rsp)
	movl	$5516, 752(%rsp)
	movq	$8, 824(%rsp)
	call	_gfortran_st_write@PLT
	movl	$22, %edx
	leaq	.LC239(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$32, %edx
	movq	%r12, %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	movl	$201326593, %eax
	salq	$7, %rax
	movq	%r13, %rdi
	movq	%rax, 736(%rsp)
	movq	%rbx, 744(%rsp)
	movl	$5517, 752(%rsp)
	call	_gfortran_st_write@PLT
	movq	%r13, %rdi
	movl	$16, %edx
	leaq	.LC201(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	jmp	.L3505
	.cfi_endproc
.LFE54:
	.size	load_paramfile_, .-load_paramfile_
	.section	.rodata
	.align 4
.LC309:
	.long	1
	.section	.rodata.str1.1
.LC310:
	.string	"RUNNING INPUTFILE "
.LC311:
	.string	"pdbfile"
.LC312:
	.string	"seqfile"
.LC313:
	.string	"outfile"
.LC314:
	.string	"savfile"
.LC315:
	.string	"rstfile"
.LC316:
	.string	"mapfile"
.LC317:
	.string	"verlcut"
.LC318:
	.string	"dnaver"
.LC319:
	.string	"factor"
.LC320:
	.string	"lconstvol"
.LC321:
	.string	"lstartpdb"
.LC322:
	.string	"lsldh"
.LC323:
	.string	"lcmap"
.LC324:
	.string	"lsink"
.LC325:
	.string	"lradii"
.LC326:
	.string	"lcdnat"
.LC327:
	.string	"ljwal"
.LC328:
	.string	"lepid"
.LC329:
	.string	"disul"
.LC330:
	.string	"dislj"
.LC331:
	.string	"epsbb"
.LC332:
	.string	"gamma"
.LC333:
	.string	"cmapf"
.LC334:
	.string	"tolerance"
.LC335:
	.string	"lcleanrst"
.LC336:
	.string	"lwritemap"
.LC337:
	.string	"lwritexyz"
.LC338:
	.string	"lwrtang"
.LC339:
	.string	"lcospid"
.LC340:
	.string	"lecperm"
.LC342:
	.string	"lrmsmax"
.LC343:
	.string	"wallmindist"
.LC344:
	.string	"lfromscratch"
.LC345:
	.string	"lwritegomap"
.LC346:
	.string	"lunwrap"
.LC347:
	.string	"lfrmscrtch"
.LC348:
	.string	"lampstrict"
.LC349:
	.string	"kconnecttime"
.LC350:
	.string	"bckbmin"
.LC351:
	.string	"bckbmax"
.LC352:
	.string	"lchargend"
.LC353:
	.string	"ampstrict"
.LC354:
	.string	"cntfct"
.LC355:
	.string	"lsqpbc"
.LC356:
	.string	"lpbcx"
.LC357:
	.string	"lpbcy"
.LC358:
	.string	"lpbcz"
.LC359:
	.string	"ldisimp"
.LC360:
	.string	"lmedian"
.LC361:
	.string	"lenetab"
.LC362:
	.string	"CBA"
.LC363:
	.string	"CDA"
.LC364:
	.string	"CDB"
.LC365:
	.string	"lmj"
.LC366:
	.string	"adiab"
.LC367:
	.string	"lvelo"
.LC368:
	.string	"lmass"
.LC369:
	.string	"langle"
.LC370:
	.string	"lchiral"
.LC371:
	.string	"lconftm"
.LC372:
	.string	"confcut"
.LC373:
	.string	"lnatend"
.LC374:
	.string	"lposcrd"
.LC375:
	.string	"lthermo"
.LC376:
	.string	"ldelrst"
.LC377:
	.string	"lnowal"
.LC378:
	.string	"lsawconftm"
.LC379:
	.string	"lmorse"
.LC380:
	.string	"lparam"
.LC381:
	.string	"ldynss"
.LC382:
	.string	"lsselj"
.LC383:
	.string	"lcintr"
.LC384:
	.string	"lsslj"
.LC385:
	.string	"ldens"
.LC386:
	.string	"tdens"
.LC387:
	.string	"sdens"
.LC388:
	.string	"kteql"
.LC389:
	.string	"ksave"
.LC390:
	.string	"kksave"
.LC391:
	.string	"ktrest"
.LC392:
	.string	"kwrite"
.LC393:
	.string	"sepmin"
.LC394:
	.string	"lwall "
.LC395:
	.string	"lwalls"
.LC396:
	.string	"lshear"
.LC397:
	.string	"paramfile"
.LC398:
	.string	"loscillate"
.LC399:
	.string	"kbperiodmax"
.LC400:
	.string	"omega"
.LC401:
	.string	"period"
.LC402:
	.string	"iseed"
.LC403:
	.string	"ntraj"
.LC404:
	.string	"mstep"
.LC405:
	.string	"lcpot"
.LC406:
	.string	"neimin"
.LC407:
	.string	"neimaxdisul"
.LC408:
	.string	"HH1"
.LC409:
	.string	"amp"
.LC410:
	.string	"cut"
.LC411:
	.string	"acos1"
.LC412:
	.string	"acos2"
.LC413:
	.string	"acos3"
.LC414:
	.string	"psi0ss"
.LC415:
	.string	"psi0bb1"
.LC416:
	.string	"psi0bb2"
.LC417:
	.string	"tstep"
.LC418:
	.string	"tstart"
.LC419:
	.string	"klenstr"
.LC420:
	.string	",a)"
.LC421:
	.string	".out"
.LC422:
	.string	".map"
.LC423:
	.string	".pdb"
.LC424:
	.string	"UNRECOGNIZED OPTION: "
	.section	.rodata.str1.8
	.align 8
.LC426:
	.string	"#I,I+2 CONTACTS PURELY REPULSIVE"
	.section	.rodata.str1.1
.LC428:
	.string	"(/,a,2x,a,/)"
.LC429:
	.string	"#PDB FILE ="
.LC430:
	.string	"#SEQ FILE ="
	.section	.rodata.str1.8
	.align 8
.LC431:
	.string	"#CONSTRUCT CONTACT-MAP BASED ON ALL-ATOM"
	.section	.rodata.str1.1
.LC432:
	.string	"(a,f6.2,a)"
	.section	.rodata.str1.8
	.align 8
.LC433:
	.string	"#CONSTRUCT CONTACTMAP BASED ON CUT-OFF ="
	.section	.rodata.str1.1
.LC434:
	.string	" ANGSTROM"
	.section	.rodata.str1.8
	.align 8
.LC435:
	.string	"#CONTACT-MAP BASED ON THE SEQUENCE FILE"
	.align 8
.LC436:
	.string	"#CONSTRUCT CONTACT-MAP BASED ON FILE "
	.section	.rodata.str1.1
.LC437:
	.string	"(a,i10)"
.LC438:
	.string	"#NUMBER OF DOMAINS"
	.section	.rodata.str1.8
	.align 8
.LC439:
	.string	"#DO NOT ALLOW CONTACTS BETWEEN DOMAINS"
	.section	.rodata.str1.1
.LC440:
	.string	"#CONSIDERING AMINO ACID MASSES"
.LC442:
	.string	"#NO NON-REPULSIVE CONTACTS"
.LC443:
	.string	"(a,f8.4)"
.LC444:
	.string	"#RELATIVE TOTAL CONTACT ORDER"
.LC445:
	.string	"#RELATIVE NATIVE CONTACT ORDER"
.LC446:
	.string	"#NO NATIVE CONTACTS"
.LC447:
	.string	"#RESIDUE "
.LC448:
	.string	" IS NOT A CYSTEINE. PLS CHECK!"
.LC449:
	.string	"(a,i4,5x,2(a3,i4,3x))"
.LC450:
	.string	"#SS BOND COULD NOT BE MADE"
.LC451:
	.string	"#NATIVE SS BOND"
	.section	.rodata.str1.8
	.align 8
.LC452:
	.string	"#USING CUSTOM ATTRACTIVE L-J CONTACT POTENTIAL!"
	.align 8
.LC453:
	.string	"#USING L-J POTENTIAL FOR NON-NATIVE SS BONDS!"
	.section	.rodata.str1.1
.LC454:
	.string	"(a,f6.2,a,f6.2)"
.LC455:
	.string	"#R_LJ="
.LC456:
	.string	" DEPTH="
	.section	.rodata.str1.8
	.align 8
.LC457:
	.string	"#USING MORSE POTENTIAL FOR NON-NATIVE SS BONDS!"
	.section	.rodata.str1.1
.LC458:
	.string	"#R_MORSE="
.LC459:
	.string	" A_MORSE="
.LC460:
	.string	"(a,f8.2)"
	.section	.rodata.str1.8
	.align 8
.LC461:
	.string	"#SS CONTACT EQUILIBRIUM DISTANCE="
	.align 8
.LC462:
	.string	"#CONTACTS BASED ON DATA FROM FILE "
	.section	.rodata.str1.1
.LC463:
	.string	"(a,f6.2)"
.LC464:
	.string	"#USING DEBYE SCREENING LENGTH"
	.section	.rodata.str1.8
	.align 8
.LC466:
	.string	"#USING HARMONIC POTENTIALS FOR NATIVE SS BONDS!"
	.section	.rodata.str1.1
.LC467:
	.string	"(a,2(a,f6.2))"
.LC468:
	.string	"#USING ANHARMONIC POTENTIAL"
.LC469:
	.string	"   H1 ="
.LC470:
	.string	"   H2 ="
.LC471:
	.string	"#USING CHIRALITY POTENTIALS"
	.section	.rodata.str1.8
	.align 8
.LC472:
	.string	"#USING POTENTIALS FOR BOND AND DIHEDRAL ANGLES"
	.align 8
.LC473:
	.string	"#USING POTENTIALS ONLY FOR BOND ANGLES"
	.align 8
.LC474:
	.string	"#DISABLE NATIVE CONTACTS (I,I+2)"
	.section	.rodata.str1.1
.LC475:
	.string	"(a,2i4,5x,2(a3,i4,3x))"
.LC476:
	.string	"#DYNAMIC SS BOND"
	.section	.rodata.str1.8
	.align 8
.LC477:
	.string	"#USING THE GO-LIKE 6-12 LJ POTENTIALS"
	.section	.rodata
	.align 4
.LC478:
	.long	22
	.align 8
.LC479:
	.long	0
	.long	1072693248
	.section	.rodata.str1.1
.LC480:
	.string	"(/,a,i10)"
.LC481:
	.string	"#TOTAL PROTEIN LENGTH      "
.LC482:
	.string	"#NUMBER OF NATIVE CONTACTS "
.LC483:
	.string	"(a,f10.4)"
.LC484:
	.string	"#AVERAGE LENGTH OF CONTACTS"
	.section	.rodata.str1.8
	.align 8
.LC485:
	.string	"#NO PDB FILE USED FOR GO MODEL CONSTRUCTION"
	.section	.rodata.str1.1
.LC486:
	.string	"(a,f10.2)"
.LC487:
	.string	"#ENERGY OF NATIVE STATE    "
.LC488:
	.string	"(a,2f10.2)"
.LC489:
	.string	"#PULLING SPRING CONSTANTS  "
.LC490:
	.string	"(a,i8,a)"
.LC491:
	.string	"#FORCE AVERAGED OVER "
.LC492:
	.string	" TAU"
.LC493:
	.string	"(a,f7.2)"
.LC494:
	.string	"#VERLET LIST CUTOFF "
.LC495:
	.string	"(a,f8.6,a,f9.1)"
.LC496:
	.string	"#ANGULAR FREQUENCY "
.LC497:
	.string	" PERIOD "
.LC498:
	.string	"(a,f7.4)"
.LC499:
	.string	"#CONSTANT VELOCITY"
.LC500:
	.string	"(a,f8.5)"
.LC501:
	.string	"#SQEEZING VELOCITY"
.LC502:
	.string	"(a,f8.5,a)"
.LC503:
	.string	"#TARGET DENSITY "
.LC504:
	.string	" RESIDUES/A^3"
.LC505:
	.string	"(a,i10,a)"
.LC506:
	.string	"#KWFORCE "
.LC507:
	.string	"#WALL POTENTIAL COEFFICIENT "
	.section	.rodata.str1.8
	.align 8
.LC508:
	.string	"#COMPUTING MEDIAN FOLDING TIMES"
	.align 8
.LC509:
	.string	"#COMPUTING THERMODYNAMIC PROPERTIES"
	.align 8
.LC510:
	.string	"#COMPUTING AVERAGED TIMES FOR CONTACT FORMATION"
	.section	.rodata.str1.1
.LC511:
	.string	"(/,a,f10.3)"
.LC512:
	.string	"#DELTA    ="
.LC513:
	.string	"(a,f10.3)"
.LC514:
	.string	"#GAMMA    ="
.LC515:
	.string	"#NUMBER OF TRAJECTORIES "
.LC516:
	.string	"#SIMULATION TIME        "
.LC517:
	.string	"#SKIPPING STEPS         "
.LC518:
	.string	"#EQUILIBRATION TIME     "
.LC519:
	.string	"#RANDOM SEED            "
.LC520:
	.string	"(/,a,7x,3f7.3)"
.LC521:
	.string	"#TSTART TEND TSTEP"
.LC522:
	.string	"(a,i6)"
.LC523:
	.string	"#NUMBER OF TEMPERATURE STEPS"
.LC526:
	.string	"(/,a,f7.3,a,i7,a,f7.3)"
.LC527:
	.string	"#Teql"
.LC528:
	.string	" for the first "
.LC529:
	.string	" Tau, then "
.LC530:
	.string	"(/,a,f7.3)"
.LC531:
	.string	"#TEMPERATURE "
	.section	.rodata
	.align 8
.LC534:
	.long	0
	.long	0
	.section	.rodata.str1.1
.LC535:
	.string	"MODEL"
.LC536:
	.string	"(//,a,i4)"
.LC537:
	.string	"#TRAJECTORY"
.LC538:
	.string	"#    TIME      EPOT      ETOT"
	.section	.rodata.str1.8
	.align 8
.LC539:
	.string	"   ICN     RG    RMSD   D(1,N)   FORCE"
	.section	.rodata.str1.1
.LC540:
	.string	"(a,a,a,a)"
	.section	.rodata.str1.8
	.align 8
.LC541:
	.string	"#S     TIME        EPOT        ETOT"
	.align 8
.LC542:
	.string	" INTRHC INTEHC INTRSC INTESC    ICN     RMSD     FZ_UP"
	.align 8
.LC543:
	.string	"    FZDOWN       |F|       SEP    FPULLZ    FPULLX"
	.align 8
.LC544:
	.string	"         W NCORD     FX_UP    FXDOWN     FY_UP    FYDOWN"
	.align 8
.LC545:
	.string	"#S     TIME      EPOT        ETOT"
	.align 8
.LC546:
	.string	"         W NCORD     XCM     YCM     ZCM   ICW"
	.section	.rodata.str1.1
.LC547:
	.string	"(a,a,a)"
	.section	.rodata.str1.8
	.align 8
.LC548:
	.string	"#    TIME          EPOT          ETOT"
	.section	.rodata.str1.1
.LC549:
	.string	"   ICN ICNss ICDss"
	.section	.rodata.str1.8
	.align 8
.LC550:
	.string	"      RG       L    RMSD NCORD     W CORDR KNOTS KNOTE"
	.align 8
.LC551:
	.string	"   ICN B1-B2 S1-S2 B1-S2 B1-B1 S1-S1 B1-S1"
	.section	.rodata.str1.1
.LC552:
	.string	"(a,4f13.9,f10.2)"
	.section	.rodata.str1.8
	.align 8
.LC556:
	.string	"(i9,2f11.2,i6,f7.2,f8.3,f8.2,f9.2)"
	.align 8
.LC557:
	.string	"(a2,i9,2f11.2,5i7,f9.2,3f10.3,4f10.2,f6.2,4f10.2)"
	.align 8
.LC558:
	.string	"(a2,i9,2f11.2,5i7,f9.2,3f10.3,4f10.2,f6.2,3f8.2,i6)"
	.align 8
.LC559:
	.string	"(i9,2f14.3,3i6,2f8.2,f8.3,3f6.2,2i6)"
	.align 8
.LC560:
	.string	"(i9,2f14.3,7i6,2f8.2,f8.3,3f6.2,2i6)"
	.section	.rodata
	.align 4
.LC561:
	.long	2
	.section	.rodata.str1.1
.LC562:
	.string	"DELETE"
.LC564:
	.string	"(f9.1,2f10.3,i6,f7.2,f8.3)"
.LC565:
	.string	"(//,a,x,5(9x,a))"
.LC566:
	.string	"E1"
.LC567:
	.string	"E2"
.LC568:
	.string	"E3"
.LC569:
	.string	"E4"
.LC570:
	.string	"W"
.LC571:
	.string	"(a,f11.2)"
.LC572:
	.string	"# "
.LC573:
	.string	"(a,4f11.5,f10.2)"
.LC574:
	.string	"(/,a)"
	.section	.rodata.str1.8
	.align 8
.LC575:
	.string	"#AVERAGE TIME NEEDED FOR FORMING EACH CONTACT"
	.align 8
.LC576:
	.string	"# ICN    I    J  J-I       t0    DISP."
	.section	.rodata.str1.1
.LC579:
	.string	"(4i5,2f11.2)"
	.section	.rodata.str1.8
	.align 8
.LC580:
	.string	"#  TEMP     TMEDIAN  NTRAJ  INOT"
	.section	.rodata.str1.1
.LC581:
	.string	"(a,f6.2,f12.2,i7,i6)"
.LC582:
	.string	"(/,a,a)"
	.section	.rodata.str1.8
	.align 8
.LC583:
	.string	"#  TEMP      PNAT    DISP/2           CV       DISP/2"
	.section	.rodata.str1.1
.LC584:
	.string	"         CHI      DISP/2"
.LC585:
	.string	"(a,f6.2,2f10.5,2f13.3,2f12.4)"
.LC586:
	.string	"(//,a)"
	.section	.rodata.str1.8
	.align 8
.LC587:
	.string	"#AVERAGED FORCE ON STRETCHING WITH CONSTANT VELOCITY"
	.align 8
.LC588:
	.string	"#    TIME  <D(1,N)>  <FORCE>  DISP./2"
	.section	.rodata.str1.1
.LC589:
	.string	"(f9.1,f10.2,2f9.2)"
	.section	.text.unlikely,"ax",@progbits
.LCOLDB598:
	.text
.LHOTB598:
	.p2align 4
	.type	MAIN__, @function
MAIN__:
.LFB55:
	.cfi_startproc
	leaq	8(%rsp), %r10
	.cfi_def_cfa 10, 0
	andq	$-32, %rsp
	pushq	-8(%r10)
	pushq	%rbp
	.cfi_escape 0x10,0x6,0x2,0x76,0
	movq	%rsp, %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%r10
	.cfi_escape 0xf,0x3,0x76,0x58,0x6
	.cfi_escape 0x10,0xf,0x2,0x76,0x78
	.cfi_escape 0x10,0xe,0x2,0x76,0x70
	.cfi_escape 0x10,0xd,0x2,0x76,0x68
	.cfi_escape 0x10,0xc,0x2,0x76,0x60
	pushq	%rbx
	subq	$28096, %rsp
	.cfi_escape 0x10,0x3,0x2,0x76,0x50
	vmovdqa	.LC592(%rip), %xmm1
	movq	%fs:40, %rax
	movq	%rax, -56(%rbp)
	xorl	%eax, %eax
	vmovdqa	%xmm1, -224(%rbp)
	vmovdqa	.LC593(%rip), %xmm1
	vmovdqa	.LC590(%rip), %xmm0
	vmovdqa	%xmm1, -352(%rbp)
	vmovdqa	.LC594(%rip), %xmm1
	vmovdqa	%xmm0, -288(%rbp)
	vmovdqa	%xmm1, -256(%rbp)
	vmovdqa	.LC595(%rip), %xmm1
	vmovdqa	.LC591(%rip), %xmm0
	vmovdqu	%xmm1, 24+restart_(%rip)
	vmovdqa	.LC596(%rip), %xmm1
	vmovdqa	%xmm0, -272(%rbp)
	vmovdqa	%xmm0, -208(%rbp)
	vmovdqa	%xmm0, -336(%rbp)
	vmovdqa	%xmm0, -240(%rbp)
	vmovdqa	%xmm1, -320(%rbp)
	vmovdqu	%xmm0, 40+restart_(%rip)
	vmovdqu	%xmm0, 56+restart_(%rip)
	vmovdqu	%xmm0, 72+restart_(%rip)
	vmovdqa	%xmm0, -304(%rbp)
	vmovdqa	.LC597(%rip), %xmm1
	vmovdqu	%xmm0, 104+restart_(%rip)
	vpxor	%xmm0, %xmm0, %xmm0
	movl	$0, -27264(%rbp)
	movl	$0, -27324(%rbp)
	movl	$0, -27272(%rbp)
	movl	$0, -27312(%rbp)
	movl	$0, -27276(%rbp)
	movl	$0, -27320(%rbp)
	movl	$1, -27288(%rbp)
	movl	$0, -27372(%rbp)
	movl	$0, -27316(%rbp)
	movl	$0, -27292(%rbp)
	movl	$1, -27340(%rbp)
	movl	$0, -27336(%rbp)
	movl	$1, -27300(%rbp)
	movl	$0, -27260(%rbp)
	movl	$0, -27256(%rbp)
	movl	$0, -27364(%rbp)
	movl	$0, -27348(%rbp)
	movl	$0, -27352(%rbp)
	movl	$0, -27304(%rbp)
	movl	$0, -27268(%rbp)
	movl	$1, -27368(%rbp)
	movl	$0, -27296(%rbp)
	movl	$1, -27308(%rbp)
	movl	$1, -27356(%rbp)
	movl	$0, -27328(%rbp)
	vmovdqu	%xmm1, 88+restart_(%rip)
	vmovdqa	%xmm0, 32+kier_(%rip)
	movl	$0, 68+wal_(%rip)
	movl	$0, 80016+neigh_(%rip)
	movl	$0, 80036+misc_(%rip)
	movl	$0, -27360(%rbp)
	movq	.LC279(%rip), %rax
	vmovdqa	.LC280(%rip), %xmm0
	movq	%rax, 80028+misc_(%rip)
	leaq	cmap_(%rip), %rax
	movl	$1, 66000008(%rax)
	movq	.LC281(%rip), %rax
	vmovdqa	%xmm0, 80016+chiral_(%rip)
	movq	%rax, 160004+bon_(%rip)
	movq	.LC284(%rip), %rax
	vmovdqa	.LC282(%rip), %xmm0
	movq	%rax, 72+pid_(%rip)
	movq	.LC265(%rip), %rax
	vmovdqu	%xmm0, 12+bas_(%rip)
	movq	%rax, 64+pid_(%rip)
	vmovdqa	.LC283(%rip), %xmm0
	movq	.LC264(%rip), %rax
	movl	$0, -27344(%rbp)
	movq	%rax, -26776(%rbp)
	movl	$0, -27280(%rbp)
	movl	$0, -27284(%rbp)
	vmovdqu	%xmm0, 52+wal_(%rip)
	movq	$0, 200000+angnat_(%rip)
	movl	$0, 240000+angtemp_(%rip)
	movq	$0, 10004068+nmapi_(%rip)
	movl	$0, 32+ssb2_(%rip)
	movl	$0, 88+pid_(%rip)
	movl	$0, 10004076+nmapi_(%rip)
	movl	$1, 102432+ang_(%rip)
	movl	$0, 28+bas_(%rip)
	movq	$1, 32+bas_(%rip)
	movq	$0, 80032+ssb_(%rip)
	movq	$0, 24+ssb2_(%rip)
	movl	$0, 2592152+mr_(%rip)
	vmovsd	.LC123(%rip), %xmm2
	vmovsd	.LC286(%rip), %xmm1
	movq	.LC285(%rip), %rax
	vmovsd	%xmm1, -26792(%rbp)
	vmovsd	%xmm1, -26832(%rbp)
	movq	%rax, equil_(%rip)
	vmovapd	.LC288(%rip), %xmm1
	movq	.LC287(%rip), %rax
	vmovapd	%xmm1, 80016+ssb_(%rip)
	movq	%rax, -26784(%rbp)
	vmovapd	.LC290(%rip), %xmm1
	movq	.LC8(%rip), %rax
	vmovsd	.LC83(%rip), %xmm0
	movq	%rax, 80000+ssb_(%rip)
	vmovapd	%xmm1, 80000+chiral_(%rip)
	movq	.LC289(%rip), %rax
	vmovapd	.LC291(%rip), %ymm1
	movl	$448, -27432(%rbp)
	movl	$1, -27228(%rbp)
	movl	$0, -27252(%rbp)
	movl	$3000000, -27248(%rbp)
	movl	$100, -27376(%rbp)
	movl	$1000, -27388(%rbp)
	movl	$1000, -27400(%rbp)
	movl	$0, -27396(%rbp)
	movl	$1, -27236(%rbp)
	movq	%rax, 80020+neigh_(%rip)
	vmovsd	%xmm2, bas_(%rip)
	vmovsd	%xmm0, 240008+verl_(%rip)
	vmovsd	%xmm0, ssb2_(%rip)
	movl	$0, 248008+nat_(%rip)
	vmovapd	%ymm1, ang_(%rip)
	vmovsd	.LC292(%rip), %xmm1
	movq	.LC8(%rip), %rax
	vmovsd	%xmm0, 32+plates_(%rip)
	movq	%rax, 240024+pull_(%rip)
	movq	.LC80(%rip), %rax
	vmovapd	.LC296(%rip), %ymm0
	movq	%rax, -26840(%rbp)
	movq	.LC294(%rip), %rax
	vmovsd	.LC293(%rip), %xmm3
	movq	%rax, -27048(%rbp)
	movq	.LC124(%rip), %rax
	vmovapd	%ymm0, pid_(%rip)
	movq	%rax, -26848(%rbp)
	movq	.LC102(%rip), %rax
	vmovapd	.LC297(%rip), %ymm0
	movq	%rax, -27192(%rbp)
	movq	.LC124(%rip), %rax
	movq	$0x000000000, -27032(%rbp)
	movq	%rax, -27184(%rbp)
	movq	.LC295(%rip), %rax
	movl	$100, -27244(%rbp)
	movq	%rax, -26912(%rbp)
	movq	.LC70(%rip), %rax
	movl	$100, -27380(%rbp)
	movl	$6, -27404(%rbp)
	vmovsd	%xmm1, -26760(%rbp)
	vmovsd	%xmm3, -26856(%rbp)
	vmovsd	%xmm3, -26928(%rbp)
	vmovsd	%xmm2, wal_(%rip)
	vmovapd	%ymm0, 32+pid_(%rip)
	movl	$9, 16+equil_(%rip)
	movl	$-1, 120008+respul_(%rip)
	movq	%rax, -27000(%rbp)
	movq	.LC298(%rip), %rax
	vmovapd	.LC302(%rip), %xmm0
	movq	%rax, 80000+neigh_(%rip)
	movq	.LC299(%rip), %rax
	vmovapd	%xmm0, 80000+misc_(%rip)
	vmovapd	.LC303(%rip), %ymm0
	movq	%rax, cmapi_(%rip)
	movq	.LC300(%rip), %rax
	vmovapd	%ymm0, sig_(%rip)
	vmovapd	.LC304(%rip), %ymm0
	movq	%rax, -27120(%rbp)
	movq	.LC301(%rip), %rax
	vmovapd	%ymm0, 32+sig_(%rip)
	vmovapd	.LC305(%rip), %ymm0
	movq	%rax, bon_(%rip)
	movq	.LC74(%rip), %rax
	vmovapd	%ymm0, hhar_(%rip)
	vmovapd	.LC306(%rip), %ymm0
	movq	%rax, -26944(%rbp)
	movq	.LC124(%rip), %rax
	vmovapd	%ymm0, 32+hhar_(%rip)
	vmovapd	.LC307(%rip), %xmm0
	movq	%rax, -26752(%rbp)
	movabsq	$4294967298, %rax
	movq	%rax, 32+restr_(%rip)
	vmovupd	%xmm0, 7924008+sig_(%rip)
	movq	.LC72(%rip), %rax
	vmovapd	.LC308(%rip), %xmm0
	movq	$0x000000000, -27040(%rbp)
	movq	%rax, 16+restr_(%rip)
	movl	$1, -27240(%rbp)
	vmovsd	%xmm1, restart_(%rip)
	vmovapd	%xmm0, restr_(%rip)
	vzeroupper
	call	_gfortran_iargc@PLT
	testl	%eax, %eax
	jg	.L4636
	leaq	.LC2(%rip), %rax
	movq	%rax, -27640(%rbp)
	leaq	-26704(%rbp), %rax
	movq	%rax, -27752(%rbp)
	leaq	-352(%rbp), %rax
	movq	%rax, -27464(%rbp)
	leaq	-26752(%rbp), %rax
	movl	$0, -27948(%rbp)
	movl	$0, -27964(%rbp)
	movq	%rax, -27776(%rbp)
	leaq	-16496(%rbp), %r15
	leaq	-27236(%rbp), %r14
.L3515:
	leaq	-320(%rbp), %rdi
	movl	$32, %esi
	call	load_paramfile_
	movl	$1, -27504(%rbp)
.L3520:
	leaq	80000+angnat_(%rip), %rdx
	movl	200000+angnat_(%rip), %ebx
	vmovapd	.LC425(%rip), %ymm0
	leaq	-80000(%rdx), %rax
.L3690:
	vmovapd	%ymm0, (%rax)
	addq	$32, %rax
	cmpq	%rax, %rdx
	jne	.L3690
	movl	$80000, %edx
	xorl	%esi, %esi
	leaq	80000+angnat_(%rip), %rdi
	vzeroupper
	call	memset@PLT
	vmovd	%ebx, %xmm0
	leaq	160000+angnat_(%rip), %rax
	vpbroadcastd	%xmm0, %ymm0
	leaq	40000(%rax), %rdx
.L3691:
	vmovdqa	%ymm0, (%rax)
	addq	$32, %rax
	cmpq	%rax, %rdx
	jne	.L3691
	movl	-27304(%rbp), %eax
	movl	$10001, -27452(%rbp)
	testl	%eax, %eax
	je	.L3692
	movabsq	$4294967297, %rax
	movl	$1, 36+kier_(%rip)
	movq	%rax, 40+kier_(%rip)
.L3692:
	leaq	cmap_(%rip), %rax
	movl	$0, 60000004(%rax)
	movl	60+wal_(%rip), %eax
	testl	%eax, %eax
	je	.L3693
	cmpl	$0, -27316(%rbp)
	je	.L4637
.L3693:
	movl	24+ssb2_(%rip), %eax
	testl	%eax, %eax
	je	.L3694
	movl	$1, 80032+ssb_(%rip)
.L3694:
	vmovsd	-27032(%rbp), %xmm0
	vxorpd	%xmm4, %xmm4, %xmm4
	vcomisd	%xmm4, %xmm0
	vmovsd	-26760(%rbp), %xmm6
	vmovsd	%xmm6, -27480(%rbp)
	jbe	.L4605
	vdivsd	%xmm6, %xmm0, %xmm0
	vzeroupper
	call	lround@PLT
	movl	%eax, -27244(%rbp)
.L3695:
	vmovsd	.LC84(%rip), %xmm1
	vmovsd	.LC11(%rip), %xmm0
	vmovsd	.LC60(%rip), %xmm2
	movq	-27048(%rbp), %r12
	vdivsd	-27480(%rbp), %xmm1, %xmm3
	vandpd	%xmm3, %xmm0, %xmm4
	vorpd	%xmm4, %xmm2, %xmm2
	vmovq	%r12, %xmm4
	vdivsd	%xmm4, %xmm1, %xmm1
	vaddsd	%xmm3, %xmm2, %xmm2
	vmovsd	.LC60(%rip), %xmm5
	movq	-27752(%rbp), %rdi
	vcvttsd2sil	%xmm2, %eax
	movl	$639, -26688(%rbp)
	movq	$32, -26648(%rbp)
	movq	$7, -26624(%rbp)
	movl	%eax, 8+equil_(%rip)
	movl	$0, -26400(%rbp)
	vmovsd	%xmm5, -27848(%rbp)
	vandpd	%xmm1, %xmm0, %xmm0
	vorpd	%xmm0, %xmm5, %xmm0
	vaddsd	%xmm1, %xmm0, %xmm0
	vcvttsd2sil	%xmm0, %eax
	movl	%eax, 12+equil_(%rip)
	movq	-27640(%rbp), %rax
	movq	%rax, -26696(%rbp)
	movq	-27464(%rbp), %rax
	movq	%rax, -26640(%rbp)
	leaq	.LC62(%rip), %rax
	movq	%rax, -26632(%rbp)
	movabsq	$4311745280, %rax
	movq	%rax, -26704(%rbp)
	call	_gfortran_st_open@PLT
	movl	20+bas_(%rip), %eax
	testl	%eax, %eax
	jne	.L4638
.L3697:
	movl	-27388(%rbp), %eax
	movl	%eax, -27520(%rbp)
	testl	%eax, %eax
	jne	.L4639
.L3698:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movabsq	$4294967424, %rax
	movq	%rax, -16496(%rbp)
	movl	$643, -16480(%rbp)
	call	_gfortran_st_write@PLT
	movl	$32, %edx
	leaq	.LC426(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	vmovsd	bas_(%rip), %xmm0
	vmovsd	.LC8(%rip), %xmm5
	vmovsd	72+pid_(%rip), %xmm4
	vdivsd	%xmm0, %xmm5, %xmm2
	vaddsd	40+hhar_(%rip), %xmm5, %xmm6
	vmovsd	16+restr_(%rip), %xmm1
	vmulsd	%xmm4, %xmm6, %xmm6
	vmulsd	%xmm1, %xmm1, %xmm1
	vunpcklpd	%xmm6, %xmm1, %xmm1
	vmovapd	%xmm1, 16+restr_(%rip)
	vmulsd	7924008+sig_(%rip), %xmm2, %xmm3
	vmulsd	-26752(%rbp), %xmm2, %xmm1
	vmulsd	7924016+sig_(%rip), %xmm2, %xmm5
	vdivsd	%xmm4, %xmm3, %xmm4
	vmovsd	%xmm3, 7924008+sig_(%rip)
	vmulsd	%xmm3, %xmm3, %xmm3
	vmovsd	%xmm1, -26752(%rbp)
	vmulsd	%xmm1, %xmm1, %xmm1
	vmovsd	%xmm5, 7924016+sig_(%rip)
	vmulsd	%xmm5, %xmm5, %xmm5
	vmovsd	%xmm3, 7924032+sig_(%rip)
	vmulsd	-27120(%rbp), %xmm2, %xmm3
	vmulsd	.LC427(%rip), %xmm1, %xmm1
	vmovsd	%xmm5, 7924024+sig_(%rip)
	vmovsd	%xmm3, -27120(%rbp)
	vmulsd	%xmm0, %xmm0, %xmm3
	vmovsd	%xmm1, 240000+verl_(%rip)
	vmulsd	%xmm3, %xmm3, %xmm1
	vunpcklpd	%xmm1, %xmm3, %xmm1
	vinsertf128	$1, %xmm1, %ymm1, %ymm1
	vmulpd	hhar_(%rip), %ymm1, %ymm1
	vmovsd	%xmm4, 4000+sig_(%rip)
	vmulsd	80000+neigh_(%rip), %xmm2, %xmm4
	vmovapd	%ymm1, hhar_(%rip)
	vmulsd	80008+misc_(%rip), %xmm2, %xmm1
	vmovsd	%xmm4, 80000+neigh_(%rip)
	vmulsd	%xmm4, %xmm4, %xmm4
	vmovsd	%xmm1, 80008+misc_(%rip)
	vmulsd	bon_(%rip), %xmm2, %xmm1
	vmovsd	%xmm4, 80008+neigh_(%rip)
	vmulsd	-27040(%rbp), %xmm2, %xmm4
	vmovsd	%xmm1, bon_(%rip)
	vmulsd	240008+verl_(%rip), %xmm2, %xmm1
	vmovsd	%xmm4, -27040(%rbp)
	vmovq	%xmm4, %rbx
	vmovsd	%xmm1, 240008+verl_(%rip)
	vmovupd	24+pid_(%rip), %xmm7
	vmovddup	%xmm0, %xmm1
	vdivpd	%xmm1, %xmm7, %xmm1
	movl	-27344(%rbp), %eax
	vmulpd	.LC273(%rip), %xmm1, %xmm1
	vmovupd	%xmm1, 24+pid_(%rip)
	vmovsd	64+pid_(%rip), %xmm1
	testl	%eax, %eax
	jne	.L3700
	vmovsd	pid_(%rip), %xmm4
	movq	.LC8(%rip), %rax
	vdivsd	%xmm1, %xmm4, %xmm4
	vmovsd	%xmm4, pid_(%rip)
	vmovsd	8+pid_(%rip), %xmm4
	vdivsd	%xmm1, %xmm4, %xmm4
	vmovsd	%xmm4, 8+pid_(%rip)
	vmovsd	16+pid_(%rip), %xmm4
	vdivsd	%xmm1, %xmm4, %xmm1
	vmovsd	%xmm1, 16+pid_(%rip)
	vmovq	%rax, %xmm1
.L3700:
	vmovsd	%xmm1, 80+pid_(%rip)
	vmulsd	-27184(%rbp), %xmm2, %xmm1
	vmulsd	%xmm3, %xmm0, %xmm0
	vmovsd	%xmm1, -27184(%rbp)
	vmulsd	-26848(%rbp), %xmm2, %xmm1
	vmulsd	-26840(%rbp), %xmm0, %xmm7
	vmulsd	-26856(%rbp), %xmm0, %xmm0
	vmovsd	%xmm1, -26848(%rbp)
	vmovsd	wal_(%rip), %xmm1
	vmovsd	%xmm7, -27472(%rbp)
	vmovsd	%xmm1, 64+sig_(%rip)
	vmulsd	%xmm2, %xmm1, %xmm1
	vmovsd	%xmm7, -26840(%rbp)
	vmovq	%r12, %xmm7
	vmovsd	%xmm0, -26856(%rbp)
	vmovsd	%xmm1, wal_(%rip)
	vmovsd	restart_(%rip), %xmm1
	vmulsd	-27480(%rbp), %xmm1, %xmm0
	vmulsd	%xmm1, %xmm7, %xmm1
	vmulsd	%xmm2, %xmm0, %xmm5
	vmulsd	%xmm2, %xmm1, %xmm4
	vmovsd	-26792(%rbp), %xmm1
	vmovsd	-26784(%rbp), %xmm2
	vmovsd	%xmm5, -27704(%rbp)
	vmovsd	%xmm4, -28064(%rbp)
	vmovsd	-26832(%rbp), %xmm4
	vmovsd	-27848(%rbp), %xmm5
	vsubsd	%xmm4, %xmm1, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vdivsd	%xmm2, %xmm0, %xmm3
	vmovsd	.LC11(%rip), %xmm0
	vandpd	%xmm3, %xmm0, %xmm0
	vorpd	%xmm0, %xmm5, %xmm0
	vaddsd	%xmm3, %xmm0, %xmm0
	vcvttsd2sil	%xmm0, %eax
	incl	%eax
	cmpl	$150, %eax
	jg	.L3701
	vcomisd	%xmm4, %xmm1
	movl	%eax, -27232(%rbp)
	ja	.L3702
.L3703:
	movl	-27232(%rbp), %eax
	movl	$1, -27452(%rbp)
	movl	%eax, -27952(%rbp)
	testl	%eax, %eax
	jle	.L3706
.L4222:
	movl	-27952(%rbp), %eax
	leal	-1(%rax), %ecx
	cmpl	$6, %ecx
	jbe	.L4225
	shrl	$3, %eax
	leaq	-25744(%rbp), %rdx
	salq	$6, %rax
	vmovdqa	.LC76(%rip), %ymm4
	vmovdqa	.LC77(%rip), %ymm3
	vbroadcastsd	%xmm2, %ymm7
	vbroadcastsd	%xmm1, %ymm6
	addq	%rdx, %rax
	vpcmpeqd	%ymm8, %ymm8, %ymm8
.L3708:
	vmovdqa	%ymm4, %ymm0
	vpaddd	%ymm8, %ymm0, %ymm0
	vcvtdq2pd	%xmm0, %ymm5
	vextracti128	$0x1, %ymm0, %xmm0
	vfmadd132pd	%ymm7, %ymm6, %ymm5
	vcvtdq2pd	%xmm0, %ymm0
	vfmadd132pd	%ymm7, %ymm6, %ymm0
	addq	$64, %rdx
	vpaddd	%ymm3, %ymm4, %ymm4
	vmovapd	%ymm5, -64(%rdx)
	vmovapd	%ymm0, -32(%rdx)
	cmpq	%rdx, %rax
	jne	.L3708
	movl	-27952(%rbp), %esi
	movl	%esi, %edx
	andl	$-8, %edx
	leal	1(%rdx), %eax
	cmpl	%edx, %esi
	je	.L3709
.L3707:
	movl	-27952(%rbp), %esi
	subl	%edx, %ecx
	subl	%edx, %esi
	cmpl	$2, %ecx
	jbe	.L3710
	vmovd	%eax, %xmm7
	vpshufd	$0, %xmm7, %xmm0
	vpaddd	.LC93(%rip), %xmm0, %xmm0
	vmovddup	%xmm2, %xmm4
	vmovddup	%xmm1, %xmm3
	vcvtdq2pd	%xmm0, %xmm5
	vpshufd	$238, %xmm0, %xmm0
	vfmadd132pd	%xmm4, %xmm3, %xmm5
	vcvtdq2pd	%xmm0, %xmm0
	vfmadd132pd	%xmm4, %xmm3, %xmm0
	leaq	-25744(%rbp,%rdx,8), %rdx
	vmovapd	%xmm5, (%rdx)
	vmovapd	%xmm0, 16(%rdx)
	movl	%esi, %edx
	andl	$-4, %edx
	addl	%edx, %eax
	cmpl	%edx, %esi
	je	.L3709
.L3710:
	leal	-1(%rax), %edx
	vxorpd	%xmm6, %xmm6, %xmm6
	vcvtsi2sdl	%edx, %xmm6, %xmm0
	movl	-27952(%rbp), %edi
	movslq	%edx, %rdx
	movslq	%eax, %rcx
	vfmadd132sd	%xmm2, %xmm1, %xmm0
	vmovsd	%xmm0, -25744(%rbp,%rdx,8)
	leal	1(%rax), %edx
	cmpl	%edi, %edx
	jg	.L3709
	vcvtsi2sdl	%eax, %xmm6, %xmm0
	addl	$2, %eax
	movslq	%edx, %rsi
	vfmadd132sd	%xmm2, %xmm1, %xmm0
	vmovsd	%xmm0, -25744(%rbp,%rcx,8)
	cmpl	%edi, %eax
	jg	.L3709
	vcvtsi2sdl	%edx, %xmm6, %xmm0
	vfmadd231sd	%xmm0, %xmm2, %xmm1
	vmovsd	%xmm1, -25744(%rbp,%rsi,8)
.L3709:
	movl	-27952(%rbp), %eax
	incl	%eax
	movl	%eax, -27452(%rbp)
.L3706:
	movl	16+bas_(%rip), %r13d
	movq	-27640(%rbp), %rax
	testl	%r13d, %r13d
	jne	.L3712
	movl	-27276(%rbp), %r12d
	testl	%r12d, %r12d
	je	.L3713
.L3712:
	movq	%rax, -16488(%rbp)
	leaq	.LC428(%rip), %rax
	movq	%rax, -16416(%rbp)
	movq	%r15, %rdi
	movabsq	$4294971392, %rax
	movl	$703, -16480(%rbp)
	movq	$12, -16408(%rbp)
	movq	%rax, -16496(%rbp)
	vzeroupper
	call	_gfortran_st_write@PLT
	leaq	-288(%rbp), %r12
	movl	$11, %edx
	leaq	.LC429(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rsi
	movl	$32, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	%r12, %rdi
	leaq	-27268(%rbp), %rsi
	movl	$32, %edx
	call	load_protein_
	movl	8+bas_(%rip), %r12d
	movl	$1, -27452(%rbp)
	testl	%r12d, %r12d
	jle	.L3715
	movslq	%r12d, %r13
	salq	$3, %r13
	movq	%r13, %rdx
	leaq	nat_(%rip), %rsi
	leaq	pos_(%rip), %rdi
	call	memcpy@PLT
	movq	%r13, %rdx
	leaq	80000+nat_(%rip), %rsi
	leaq	80000+pos_(%rip), %rdi
	call	memcpy@PLT
	incl	%r12d
	movq	%r13, %rdx
	leaq	160000+nat_(%rip), %rsi
	leaq	160000+pos_(%rip), %rdi
	call	memcpy@PLT
	movl	%r12d, -27452(%rbp)
.L3715:
	movl	-27372(%rbp), %r11d
	testl	%r11d, %r11d
	jne	.L4640
	leaq	cmap_(%rip), %rax
	movl	60000004(%rax), %r10d
	movq	-27640(%rbp), %rax
	testl	%r10d, %r10d
	movq	%rax, -16488(%rbp)
	je	.L4641
	leaq	.LC56(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%r15, %rdi
	movq	%rax, -16496(%rbp)
	movl	$729, -16480(%rbp)
	movq	$3, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$39, %edx
	leaq	.LC435(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
.L3718:
	movl	-27352(%rbp), %r9d
	testl	%r9d, %r9d
	jne	.L4642
.L3720:
	movl	120008+respul_(%rip), %r8d
	testl	%r8d, %r8d
	jns	.L3721
	movl	8+bas_(%rip), %r12d
	vxorps	%xmm5, %xmm5, %xmm5
	vcvtsi2ssl	%r12d, %xmm5, %xmm0
	call	cbrtf@PLT
	movq	.LC134(%rip), %rax
	vmovd	%xmm0, %ebx
	vmovsd	-27472(%rbp), %xmm0
	vmovq	%rax, %xmm1
	call	pow@PLT
	vmovd	%ebx, %xmm6
	vcvtss2sd	%xmm6, %xmm6, %xmm1
	vfnmadd132sd	wal_(%rip), %xmm1, %xmm0
	vmulsd	%xmm0, %xmm0, %xmm1
	vmulsd	%xmm0, %xmm1, %xmm0
	call	lround@PLT
	movq	%rax, %r8
	movl	%r12d, %eax
	subl	%r8d, %eax
	movl	$3, %ecx
	cltd
	idivl	%ecx
	movl	%eax, 120008+respul_(%rip)
.L3721:
	movl	120008+respul_(%rip), %edx
	movl	%edx, %eax
	shrl	$31, %eax
	addl	%edx, %eax
	andl	$-2, %eax
	cmpl	$1, -27240(%rbp)
	movl	%eax, 120008+respul_(%rip)
	jle	.L3722
	movq	-27640(%rbp), %r13
	movl	$1048577, %ebx
	leaq	.LC437(%rip), %rax
	salq	$12, %rbx
	movq	%r15, %rdi
	movq	%rax, -16416(%rbp)
	leaq	-27240(%rbp), %r12
	movq	%r13, -16488(%rbp)
	movl	$742, -16480(%rbp)
	movq	$7, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$18, %edx
	leaq	.LC438(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	movq	%r12, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	%r12, %rdi
	call	build_titin_
	leaq	.LC56(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, -16416(%rbp)
	movq	%r13, -16488(%rbp)
	movl	$744, -16480(%rbp)
	movq	$3, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$38, %edx
	leaq	.LC439(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	%r12, %rdi
	call	interdomain_
.L3722:
	movl	8+bas_(%rip), %ebx
	movl	-27328(%rbp), %edi
	movl	$1, 120000+respul_(%rip)
	movl	%ebx, 120004+respul_(%rip)
	testl	%edi, %edi
	jne	.L4643
	movl	$1, -27452(%rbp)
	testl	%ebx, %ebx
	jle	.L3724
	leal	-1(%rbx), %eax
	cmpl	$2, %eax
	jbe	.L4226
	movl	%ebx, %eax
	shrl	$2, %eax
	leaq	mass_(%rip), %rdx
	salq	$5, %rax
	vmovapd	.LC441(%rip), %ymm0
	movq	%rdx, %rcx
	addq	%rdx, %rax
.L3726:
	vmovapd	%ymm0, (%rcx)
	addq	$32, %rcx
	cmpq	%rcx, %rax
	jne	.L3726
	movl	%ebx, %ecx
	andl	$-4, %ecx
	leal	1(%rcx), %eax
	cmpl	%ecx, %ebx
	je	.L4644
	vzeroupper
.L3725:
	movq	.LC8(%rip), %rdi
	leal	-1(%rax), %ecx
	movslq	%ecx, %rcx
	movq	%rdi, (%rdx,%rcx,8)
	leal	1(%rax), %ecx
	movslq	%eax, %rsi
	cmpl	%ecx, %ebx
	jl	.L3727
	addl	$2, %eax
	movq	%rdi, (%rdx,%rsi,8)
	movslq	%ecx, %rcx
	cmpl	%eax, %ebx
	jl	.L3727
	movq	%rdi, (%rdx,%rcx,8)
.L3727:
	leal	1(%rbx), %eax
	movl	%eax, -27452(%rbp)
.L3724:
	leaq	cmp2_(%rip), %rax
	leal	-1(%rbx), %r12d
	movl	%ebx, %edx
	imull	%r12d, %edx
	movl	$1, 540000008(%rax)
	movl	%ebx, %eax
	subl	-27236(%rbp), %eax
	vxorpd	%xmm6, %xmm6, %xmm6
	incl	%eax
	vcvtsi2sdl	%eax, %xmm6, %xmm0
	movl	%edx, %eax
	shrl	$31, %eax
	addl	%edx, %eax
	sarl	%eax
	subl	%r12d, %eax
	movl	%eax, 80016+misc_(%rip)
	movl	%ebx, %eax
	imull	%ebx, %eax
	leal	(%rbx,%rbx,4), %edx
	vmovsd	%xmm0, -27480(%rbp)
	subl	%edx, %eax
	addl	$6, %eax
	movl	%eax, %edx
	shrl	$31, %edx
	vmovsd	%xmm0, -26920(%rbp)
	addl	%edx, %eax
	vcvtsi2sdl	%ebx, %xmm6, %xmm0
	sarl	%eax
	movl	%eax, 80020+misc_(%rip)
	movq	.LC134(%rip), %rax
	vdivsd	-27472(%rbp), %xmm0, %xmm5
	vmovq	%rax, %xmm1
	vmovsd	%xmm5, %xmm5, %xmm0
	vmovsd	%xmm5, -28032(%rbp)
	call	pow@PLT
	vmulsd	.LC100(%rip), %xmm0, %xmm5
	movl	160008+bon_(%rip), %esi
	vmovsd	%xmm5, -27872(%rbp)
	testl	%esi, %esi
	jne	.L3728
	vmovsd	pos_(%rip), %xmm2
	vmovsd	80000+pos_(%rip), %xmm1
	vmovsd	160000+pos_(%rip), %xmm0
	cmpl	$1, %ebx
	jle	.L4227
	leal	-2(%rbx), %eax
	cmpl	$3, %eax
	jbe	.L4228
	movl	%r12d, %eax
	shrl	$2, %eax
	vbroadcastsd	%xmm0, %ymm6
	vbroadcastsd	%xmm2, %ymm2
	vbroadcastsd	%xmm1, %ymm1
	leaq	8+pos_(%rip), %rdx
	salq	$5, %rax
	addq	%rdx, %rax
	vmovapd	%ymm6, %ymm5
	vmovapd	%ymm1, %ymm4
	vmovapd	%ymm2, %ymm0
.L3731:
	vmovupd	(%rdx), %ymm8
	vmovupd	80000(%rdx), %ymm7
	vmovupd	160000(%rdx), %ymm3
	addq	$32, %rdx
	vminpd	%ymm8, %ymm2, %ymm2
	vminpd	%ymm7, %ymm1, %ymm1
	vminpd	%ymm3, %ymm6, %ymm6
	vmaxpd	%ymm8, %ymm0, %ymm0
	vmaxpd	%ymm7, %ymm4, %ymm4
	vmaxpd	%ymm3, %ymm5, %ymm5
	cmpq	%rdx, %rax
	jne	.L3731
	vextractf128	$0x1, %ymm5, %xmm3
	vmaxpd	%xmm5, %xmm3, %xmm3
	movl	%r12d, %eax
	andl	$-4, %eax
	vunpckhpd	%xmm3, %xmm3, %xmm5
	vmaxpd	%xmm3, %xmm5, %xmm3
	leal	2(%rax), %edx
	vmovsd	%xmm3, %xmm3, %xmm5
	vextractf128	$0x1, %ymm4, %xmm3
	vmaxpd	%xmm4, %xmm3, %xmm3
	vunpckhpd	%xmm3, %xmm3, %xmm4
	vmaxpd	%xmm3, %xmm4, %xmm3
	vmovsd	%xmm3, %xmm3, %xmm4
	vextractf128	$0x1, %ymm0, %xmm3
	vmaxpd	%xmm0, %xmm3, %xmm3
	vunpckhpd	%xmm3, %xmm3, %xmm0
	vmaxpd	%xmm3, %xmm0, %xmm3
	vextractf128	$0x1, %ymm6, %xmm0
	vminpd	%xmm6, %xmm0, %xmm0
	vunpckhpd	%xmm0, %xmm0, %xmm6
	vminpd	%xmm0, %xmm6, %xmm0
	vextractf128	$0x1, %ymm1, %xmm6
	vminpd	%xmm1, %xmm6, %xmm1
	vunpckhpd	%xmm1, %xmm1, %xmm6
	vminpd	%xmm1, %xmm6, %xmm1
	vextractf128	$0x1, %ymm2, %xmm6
	vminpd	%xmm2, %xmm6, %xmm2
	vunpckhpd	%xmm2, %xmm2, %xmm6
	vminpd	%xmm2, %xmm6, %xmm2
	cmpl	%eax, %r12d
	je	.L4645
	vzeroupper
.L3730:
	leal	-1(%rdx), %ecx
	movslq	%ecx, %rcx
	leaq	pos_(%rip), %rax
	vmovsd	(%rax,%rcx,8), %xmm8
	vmovsd	80000(%rax,%rcx,8), %xmm7
	vmovsd	160000(%rax,%rcx,8), %xmm6
	leal	1(%rdx), %esi
	vminsd	%xmm8, %xmm2, %xmm2
	vminsd	%xmm7, %xmm1, %xmm1
	vminsd	%xmm6, %xmm0, %xmm0
	vmaxsd	%xmm8, %xmm3, %xmm3
	vmaxsd	%xmm7, %xmm4, %xmm4
	vmaxsd	%xmm6, %xmm5, %xmm5
	cmpl	%esi, %ebx
	jl	.L3732
	movslq	%edx, %rcx
	vmovsd	(%rax,%rcx,8), %xmm8
	vmovsd	80000(%rax,%rcx,8), %xmm7
	vmovsd	160000(%rax,%rcx,8), %xmm6
	leal	2(%rdx), %ecx
	vminsd	%xmm8, %xmm2, %xmm2
	vminsd	%xmm7, %xmm1, %xmm1
	vminsd	%xmm6, %xmm0, %xmm0
	vmaxsd	%xmm8, %xmm3, %xmm3
	vmaxsd	%xmm7, %xmm4, %xmm4
	vmaxsd	%xmm6, %xmm5, %xmm5
	cmpl	%ecx, %ebx
	jl	.L3732
	movslq	%esi, %rsi
	vmovsd	(%rax,%rsi,8), %xmm8
	vmovsd	80000(%rax,%rsi,8), %xmm7
	vmovsd	160000(%rax,%rsi,8), %xmm6
	addl	$3, %edx
	vminsd	%xmm8, %xmm2, %xmm2
	vminsd	%xmm7, %xmm1, %xmm1
	vminsd	%xmm6, %xmm0, %xmm0
	vmaxsd	%xmm8, %xmm3, %xmm3
	vmaxsd	%xmm7, %xmm4, %xmm4
	vmaxsd	%xmm6, %xmm5, %xmm5
	cmpl	%edx, %ebx
	jl	.L3732
	movslq	%ecx, %rcx
	vmovsd	(%rax,%rcx,8), %xmm8
	vmovsd	80000(%rax,%rcx,8), %xmm7
	vmovsd	160000(%rax,%rcx,8), %xmm6
	vminsd	%xmm8, %xmm2, %xmm2
	vminsd	%xmm7, %xmm1, %xmm1
	vminsd	%xmm6, %xmm0, %xmm0
	vmaxsd	%xmm8, %xmm3, %xmm3
	vmaxsd	%xmm7, %xmm4, %xmm4
	vmaxsd	%xmm6, %xmm5, %xmm5
.L3732:
	vmovsd	%xmm0, %xmm0, %xmm6
	vmovsd	%xmm5, %xmm5, %xmm0
	vmovsd	%xmm1, %xmm1, %xmm5
	vmovsd	%xmm4, %xmm4, %xmm1
	vmovsd	%xmm2, %xmm2, %xmm4
	vmovsd	%xmm3, %xmm3, %xmm2
.L3729:
	vmovsd	bon_(%rip), %xmm3
	vmovsd	.LC74(%rip), %xmm7
	vfmadd231sd	.LC74(%rip), %xmm3, %xmm2
	vfnmadd132sd	%xmm3, %xmm4, %xmm7
	vfmadd231sd	.LC74(%rip), %xmm3, %xmm1
	vfmadd231sd	.LC74(%rip), %xmm3, %xmm0
	vmovsd	%xmm2, 40+plates_(%rip)
	vmovsd	%xmm7, 48+plates_(%rip)
	vmovsd	.LC74(%rip), %xmm7
	vsubsd	%xmm4, %xmm2, %xmm2
	vfnmadd132sd	%xmm3, %xmm5, %xmm7
	vmovsd	%xmm1, 56+plates_(%rip)
	vmovsd	%xmm0, 8+plates_(%rip)
	vsubsd	%xmm5, %xmm1, %xmm1
	vsubsd	%xmm6, %xmm0, %xmm0
	vfmadd231sd	.LC74(%rip), %xmm3, %xmm2
	vfmadd231sd	.LC74(%rip), %xmm3, %xmm1
	vfmadd231sd	.LC74(%rip), %xmm3, %xmm0
	vmovsd	%xmm7, 64+plates_(%rip)
	vmovsd	.LC74(%rip), %xmm7
	vmovsd	%xmm2, 240000+for_(%rip)
	vfnmadd132sd	%xmm3, %xmm6, %xmm7
	vmovsd	.LC8(%rip), %xmm6
	vmovsd	%xmm1, 240008+for_(%rip)
	vdivsd	%xmm2, %xmm6, %xmm2
	vmovsd	%xmm0, 240016+for_(%rip)
	vmovsd	%xmm7, plates_(%rip)
	vdivsd	%xmm1, %xmm6, %xmm1
	vmovsd	%xmm2, 240024+for_(%rip)
	vdivsd	%xmm0, %xmm6, %xmm0
	vmovsd	%xmm1, 240032+for_(%rip)
	vmovsd	%xmm0, 240040+for_(%rip)
.L3728:
	movl	52+wal_(%rip), %ecx
	testl	%ecx, %ecx
	je	.L3733
	movl	$3, 16+equil_(%rip)
.L3733:
	movq	-27776(%rbp), %rdi
	movq	%r14, %rsi
	call	update_verlet_list_
	movl	cmap_(%rip), %ecx
	movq	$0x000000000, -27104(%rbp)
	testl	%ecx, %ecx
	jle	.L3734
	leal	-1(%rcx), %edx
	cmpl	$7, %edx
	jbe	.L4229
	movl	%edx, %esi
	shrl	$3, %esi
	leaq	(%rsi,%rsi,2), %rsi
	leaq	cmap_(%rip), %rax
	salq	$5, %rsi
	vmovdqa	.LC206(%rip), %ymm8
	vmovdqa	.LC207(%rip), %ymm7
	vmovdqa	.LC208(%rip), %ymm6
	vmovdqa	.LC209(%rip), %ymm5
	vmovdqa	.LC210(%rip), %ymm4
	vmovdqa	.LC211(%rip), %ymm3
	vmovdqa	.LC212(%rip), %ymm2
	vmovdqa	.LC213(%rip), %ymm1
	addq	%rax, %rsi
	vxorpd	%xmm9, %xmm9, %xmm9
.L3736:
	vmovdqu	4(%rax), %ymm0
	vmovdqu	36(%rax), %ymm12
	vpshufb	%ymm8, %ymm0, %ymm10
	vmovdqu	68(%rax), %ymm11
	vpermq	$78, %ymm10, %ymm13
	vpshufb	%ymm7, %ymm0, %ymm10
	vpshufb	%ymm6, %ymm12, %ymm14
	vpor	%ymm13, %ymm10, %ymm10
	vpor	%ymm14, %ymm10, %ymm10
	vpermd	%ymm11, %ymm5, %ymm13
	vpblendd	$192, %ymm13, %ymm10, %ymm10
	vpshufb	%ymm4, %ymm0, %ymm13
	vpermq	$78, %ymm13, %ymm13
	vpshufb	%ymm3, %ymm0, %ymm0
	vpshufb	%ymm2, %ymm12, %ymm12
	vpor	%ymm13, %ymm0, %ymm0
	vpor	%ymm12, %ymm0, %ymm0
	vpermd	%ymm11, %ymm1, %ymm11
	vpblendd	$224, %ymm11, %ymm0, %ymm0
	vpsubd	%ymm0, %ymm10, %ymm0
	vpabsd	%ymm0, %ymm0
	vcvtdq2pd	%xmm0, %ymm10
	vextracti128	$0x1, %ymm0, %xmm0
	vcvtdq2pd	%xmm0, %ymm0
	vaddpd	%ymm0, %ymm10, %ymm0
	addq	$96, %rax
	vaddpd	%ymm0, %ymm9, %ymm9
	cmpq	%rax, %rsi
	jne	.L3736
	vextractf128	$0x1, %ymm9, %xmm0
	vaddpd	%xmm9, %xmm0, %xmm9
	movl	%edx, %esi
	andl	$-8, %esi
	vunpckhpd	%xmm9, %xmm9, %xmm2
	vaddpd	%xmm9, %xmm2, %xmm9
	leal	1(%rsi), %eax
	vzeroupper
.L3735:
	subl	%esi, %edx
	cmpl	$3, %edx
	jbe	.L3737
	leaq	(%rsi,%rsi,2), %rsi
	leaq	cmap_(%rip), %rbx
	leaq	4(%rbx,%rsi,4), %rsi
	vmovdqu	(%rsi), %xmm1
	vmovdqu	16(%rsi), %xmm4
	vmovdqu	32(%rsi), %xmm3
	vpshufb	.LC229(%rip), %xmm4, %xmm5
	vpshufb	.LC228(%rip), %xmm1, %xmm0
	vpshufb	.LC231(%rip), %xmm4, %xmm4
	vpshufb	.LC230(%rip), %xmm1, %xmm1
	vpor	%xmm5, %xmm0, %xmm0
	vpor	%xmm4, %xmm1, %xmm1
	vpshufd	$100, %xmm3, %xmm5
	vpshufd	$164, %xmm3, %xmm3
	vpblendw	$192, %xmm3, %xmm1, %xmm1
	vpblendw	$192, %xmm5, %xmm0, %xmm0
	vpsubd	%xmm1, %xmm0, %xmm0
	vpabsd	%xmm0, %xmm0
	vcvtdq2pd	%xmm0, %xmm1
	vpshufd	$238, %xmm0, %xmm0
	vcvtdq2pd	%xmm0, %xmm0
	vaddpd	%xmm0, %xmm1, %xmm1
	andl	$-4, %edx
	addl	%edx, %eax
	vunpckhpd	%xmm1, %xmm1, %xmm0
	vaddpd	%xmm1, %xmm0, %xmm0
	vaddsd	%xmm0, %xmm9, %xmm9
.L3737:
	leal	-1(%rax), %edx
	movslq	%edx, %rdx
	leaq	(%rdx,%rdx,2), %rdx
	leaq	cmap_(%rip), %rbx
	movl	4(%rbx,%rdx,4), %esi
	vxorpd	%xmm5, %xmm5, %xmm5
	subl	8(%rbx,%rdx,4), %esi
	movl	%esi, %edi
	sarl	$31, %edi
	xorl	%edi, %esi
	subl	%edi, %esi
	vcvtsi2sdl	%esi, %xmm5, %xmm1
	leal	1(%rax), %esi
	vaddsd	%xmm9, %xmm1, %xmm0
	cmpl	%esi, %ecx
	jl	.L3738
	movl	16(%rbx,%rdx,4), %esi
	subl	20(%rbx,%rdx,4), %esi
	movl	%esi, %edi
	sarl	$31, %edi
	xorl	%edi, %esi
	subl	%edi, %esi
	vcvtsi2sdl	%esi, %xmm5, %xmm1
	leal	2(%rax), %esi
	vaddsd	%xmm1, %xmm0, %xmm0
	cmpl	%esi, %ecx
	jl	.L3738
	movl	28(%rbx,%rdx,4), %esi
	addl	$3, %eax
	subl	32(%rbx,%rdx,4), %esi
	movl	%esi, %edi
	sarl	$31, %edi
	xorl	%edi, %esi
	subl	%edi, %esi
	vcvtsi2sdl	%esi, %xmm5, %xmm1
	vaddsd	%xmm1, %xmm0, %xmm0
	cmpl	%ecx, %eax
	jg	.L3738
	movl	40(%rbx,%rdx,4), %eax
	subl	44(%rbx,%rdx,4), %eax
	cltd
	xorl	%edx, %eax
	subl	%edx, %eax
	vcvtsi2sdl	%eax, %xmm5, %xmm1
	vaddsd	%xmm1, %xmm0, %xmm0
.L3738:
	vxorpd	%xmm4, %xmm4, %xmm4
	vcvtsi2sdl	8+bas_(%rip), %xmm4, %xmm1
	vcvtsi2sdl	%ecx, %xmm4, %xmm2
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	vmulsd	%xmm2, %xmm1, %xmm1
	leaq	.LC443(%rip), %rax
	movq	%rax, -16416(%rbp)
	movabsq	$4294971392, %rax
	movq	%rax, -16496(%rbp)
	vdivsd	%xmm1, %xmm0, %xmm0
	movl	$805, -16480(%rbp)
	movq	$8, -16408(%rbp)
	vmovsd	%xmm0, -27104(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$29, %edx
	leaq	.LC444(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	leaq	-27104(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3739
.L4636:
	leaq	-448(%rbp), %r12
	movl	$32, %edx
	movq	%r12, %rsi
	leaq	.LC309(%rip), %rdi
	xorl	%eax, %eax
	call	_gfortran_getarg_i4@PLT
	leaq	.LC237(%rip), %rax
	movq	%rax, -26632(%rbp)
	movl	$117506051, %eax
	salq	$8, %rax
	movq	%rax, -26704(%rbp)
	leaq	-26704(%rbp), %rax
	leaq	.LC2(%rip), %rbx
	movq	%rax, %rdi
	leaq	-16496(%rbp), %r15
	movq	%rax, -27752(%rbp)
	movq	%rbx, -27640(%rbp)
	movq	%rbx, -26696(%rbp)
	movl	$277, -26688(%rbp)
	movq	%r12, -26640(%rbp)
	movq	$32, -26648(%rbp)
	movq	$3, -26624(%rbp)
	movl	$0, -26400(%rbp)
	call	_gfortran_st_open@PLT
	movl	$201326593, %eax
	salq	$7, %rax
	movq	%r15, %rdi
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$278, -16480(%rbp)
	call	_gfortran_st_write@PLT
	movl	$18, %edx
	leaq	.LC310(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$32, %edx
	movq	%r12, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC56(%rip), %rax
	movq	%rax, -27936(%rbp)
	leaq	-352(%rbp), %rax
	movq	%rax, -27464(%rbp)
	leaq	-27236(%rbp), %r14
	leaq	-26752(%rbp), %rax
	movl	$0, -27948(%rbp)
	movl	$0, -27964(%rbp)
	movq	%rax, -27776(%rbp)
	movq	%r14, -27472(%rbp)
	leaq	-192(%rbp), %r13
.L3516:
	movq	-27936(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16416(%rbp)
	movabsq	$30064775180, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$279, -16480(%rbp)
	movq	$3, -16408(%rbp)
	call	_gfortran_st_read@PLT
	movl	$128, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movl	-16496(%rbp), %eax
	andl	$3, %eax
	decl	%eax
	cmpl	$1, %eax
	jbe	.L3517
	cmpl	$1869374838, -192(%rbp)
	je	.L4646
	movl	.LC311(%rip), %eax
	cmpl	%eax, 0(%r13)
	je	.L4647
.L3522:
	movl	.LC312(%rip), %eax
	cmpl	%eax, 0(%r13)
	je	.L4648
.L3525:
	movl	.LC313(%rip), %eax
	cmpl	%eax, 0(%r13)
	je	.L4649
.L3528:
	movl	.LC314(%rip), %eax
	cmpl	%eax, 0(%r13)
	je	.L4650
.L3531:
	movl	$7, %edx
	leaq	.LC315(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4651
	movl	$7, %edx
	leaq	.LC316(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4652
	movl	$7, %edx
	leaq	.LC317(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4653
	movl	$6, %edx
	leaq	.LC318(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4654
	movl	$6, %edx
	leaq	.LC319(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4655
	movl	$9, %edx
	leaq	.LC320(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4656
	movl	$9, %edx
	leaq	.LC321(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4657
	movabsq	$7523655116632388460, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4658
	movl	$5, %edx
	leaq	.LC322(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4659
	movl	$5, %edx
	leaq	.LC323(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4660
	movl	$5, %edx
	leaq	.LC324(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4661
	cmpl	$1684631660, -192(%rbp)
	je	.L4662
	cmpl	$1667458668, -192(%rbp)
	je	.L4663
	cmpl	$879323500, -192(%rbp)
	je	.L4664
	cmpl	$1918984812, -192(%rbp)
	je	.L4665
	cmpl	$1953722988, -192(%rbp)
	je	.L4666
	movl	$6, %edx
	leaq	.LC325(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4667
	movl	$6, %edx
	leaq	.LC326(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4668
	movl	$5, %edx
	leaq	.LC327(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4669
	movl	$5, %edx
	leaq	.LC328(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4670
	movl	$5, %edx
	leaq	.LC329(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4671
	movl	$5, %edx
	leaq	.LC330(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4672
	movl	$5, %edx
	leaq	.LC331(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4673
	movl	$5, %edx
	leaq	.LC332(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4674
	movl	$5, %edx
	leaq	.LC333(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4675
	movl	$9, %edx
	leaq	.LC334(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4676
	movl	$9, %edx
	leaq	.LC335(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4677
	movl	$9, %edx
	leaq	.LC336(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4678
	movl	$9, %edx
	leaq	.LC337(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4679
	movl	$7, %edx
	leaq	.LC338(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4680
	movl	$7, %edx
	leaq	.LC339(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4681
	movl	$7, %edx
	leaq	.LC340(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4682
	movl	$7, %edx
	leaq	.LC342(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4683
	movl	$11, %edx
	leaq	.LC343(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4684
	movl	$12, %edx
	leaq	.LC344(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4685
	movl	$11, %edx
	leaq	.LC345(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4686
	movabsq	$8027496411470919532, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4687
	movl	$7, %edx
	leaq	.LC346(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4688
	movl	$10, %edx
	leaq	.LC347(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4689
	movl	$10, %edx
	leaq	.LC348(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4690
	movl	$12, %edx
	leaq	.LC349(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4691
	movabsq	$7305790138896050532, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4692
	movabsq	$7956002832588828780, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4693
	movabsq	$7815275201249505900, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4694
	movabsq	$7091871312802573675, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4695
	movl	$7, %edx
	leaq	.LC255(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4696
	movl	$7, %edx
	leaq	.LC350(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4697
	movl	$7, %edx
	leaq	.LC351(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4698
	movabsq	$7956010537691866227, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4699
	movabsq	$8674334678257460339, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4700
	movabsq	$7956010279893689186, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4701
	movabsq	$8674334420459283298, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4702
	movabsq	$8390876208524784236, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4703
	movabsq	$7453001568844608364, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4704
	movabsq	$7453001551598019436, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4705
	movabsq	$7523655069287277420, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4706
	movabsq	$7885649434328719724, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4707
	movl	$9, %edx
	leaq	.LC352(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4708
	movl	$9, %edx
	leaq	.LC353(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4709
	movabsq	$7378696568577486704, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4710
	movabsq	$8028903795111912804, %rax
	cmpq	%rax, -192(%rbp)
	je	.L4711
	movl	$6, %edx
	leaq	.LC354(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4712
	movl	$6, %edx
	leaq	.LC355(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4713
	movl	$5, %edx
	leaq	.LC356(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4714
	movl	$5, %edx
	leaq	.LC357(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4715
	movl	$5, %edx
	leaq	.LC358(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4716
	cmpl	$1868722028, -192(%rbp)
	je	.L4717
	cmpl	$1835627372, -192(%rbp)
	je	.L4718
	cmpl	$1952801900, -192(%rbp)
	je	.L4719
	cmpl	$1667395692, -192(%rbp)
	je	.L4720
	cmpl	$1651532652, -192(%rbp)
	je	.L4721
	cmpl	$1953327980, -192(%rbp)
	je	.L4722
	cmpl	$1751737452, -192(%rbp)
	je	.L4723
	movl	$7, %edx
	leaq	.LC359(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4724
	movl	$7, %edx
	leaq	.LC360(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4725
	movl	$7, %edx
	leaq	.LC361(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4726
	movl	$3, %edx
	leaq	.LC362(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4727
	movl	$3, %edx
	leaq	.LC363(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4728
	movl	$3, %edx
	leaq	.LC364(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4729
	movl	$3, %edx
	leaq	.LC365(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4730
	cmpl	$1819635555, -192(%rbp)
	je	.L4731
	cmpl	$829318510, -192(%rbp)
	je	.L4732
	cmpl	$1818326886, -192(%rbp)
	je	.L4733
	movl	$5, %edx
	leaq	.LC366(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4734
	movl	$5, %edx
	leaq	.LC367(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4735
	movl	$5, %edx
	leaq	.LC368(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4736
	movl	$6, %edx
	leaq	.LC369(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4737
	movl	$7, %edx
	leaq	.LC370(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4738
	movl	$7, %edx
	leaq	.LC371(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4739
	movl	$7, %edx
	leaq	.LC372(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4740
	movl	$7, %edx
	leaq	.LC373(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4741
	movl	$7, %edx
	leaq	.LC374(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4742
	movl	$7, %edx
	leaq	.LC375(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4743
	movl	$7, %edx
	leaq	.LC376(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4744
	movl	$6, %edx
	leaq	.LC377(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4745
	movl	$10, %edx
	leaq	.LC378(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4746
	cmpl	$1936878956, -192(%rbp)
	je	.L4747
	movl	$6, %edx
	leaq	.LC379(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4748
	movl	$6, %edx
	leaq	.LC380(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4749
	movl	$6, %edx
	leaq	.LC381(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4750
	movl	$6, %edx
	leaq	.LC382(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4751
	movl	$6, %edx
	leaq	.LC383(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4752
	movl	$5, %edx
	leaq	.LC384(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4753
	movl	$5, %edx
	leaq	.LC385(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4754
	movl	$5, %edx
	leaq	.LC386(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4755
	movl	$5, %edx
	leaq	.LC387(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4756
	cmpl	$1953722987, -192(%rbp)
	je	.L4757
	movl	$5, %edx
	leaq	.LC388(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4758
	movl	$5, %edx
	leaq	.LC389(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4759
	movl	$6, %edx
	leaq	.LC390(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4760
	movl	$6, %edx
	leaq	.LC391(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4761
	movl	$6, %edx
	leaq	.LC392(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4762
	movl	$6, %edx
	leaq	.LC393(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4763
	movl	$6, %edx
	leaq	.LC394(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4764
	movl	$6, %edx
	leaq	.LC395(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4765
	movl	$6, %edx
	leaq	.LC396(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4766
	movl	$9, %edx
	leaq	.LC397(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4767
	movl	$10, %edx
	leaq	.LC398(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4768
	movl	$11, %edx
	leaq	.LC399(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4769
	movl	$5, %edx
	leaq	.LC400(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4770
	movl	$6, %edx
	leaq	.LC401(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4771
	movl	$5, %edx
	leaq	.LC402(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4772
	movl	$5, %edx
	leaq	.LC403(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4773
	movl	$5, %edx
	leaq	.LC404(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4774
	movl	$5, %edx
	leaq	.LC405(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4775
	cmpl	$1650749548, -192(%rbp)
	je	.L4776
	cmpl	$1853321321, -192(%rbp)
	je	.L4777
	cmpl	$1684959074, -192(%rbp)
	je	.L4778
	cmpl	$1952542308, -192(%rbp)
	je	.L4779
	cmpl	$1953850226, -192(%rbp)
	je	.L4780
	cmpl	$1885761379, -192(%rbp)
	je	.L4781
	cmpl	$1768255090, -192(%rbp)
	je	.L4782
	movl	$6, %edx
	leaq	.LC406(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4783
	movl	$11, %edx
	leaq	.LC407(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4784
	movl	$3, %edx
	leaq	.LC408(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4785
	movl	$3, %edx
	leaq	.LC409(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4786
	movl	$3, %edx
	leaq	.LC410(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4787
	movl	$5, %edx
	leaq	.LC411(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4788
	movl	$5, %edx
	leaq	.LC412(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4789
	movl	$5, %edx
	leaq	.LC413(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4790
	movl	$6, %edx
	leaq	.LC414(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4791
	movl	$7, %edx
	leaq	.LC415(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4792
	movl	$7, %edx
	leaq	.LC416(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4793
	cmpl	$828531314, -192(%rbp)
	je	.L4794
	cmpl	$845308530, -192(%rbp)
	je	.L4795
	cmpl	$1836212834, -192(%rbp)
	je	.L4796
	cmpl	$1836217203, -192(%rbp)
	je	.L4797
	cmpl	$1836217186, -192(%rbp)
	je	.L4798
	cmpl	$1836201065, -192(%rbp)
	je	.L4799
	cmpl	$1886217588, -192(%rbp)
	je	.L4800
	cmpl	$1819370868, -192(%rbp)
	je	.L4801
	cmpl	$1684956532, -192(%rbp)
	je	.L4802
	movl	$5, %edx
	leaq	.LC417(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4803
	movl	$6, %edx
	leaq	.LC418(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4804
	movl	$7, %edx
	leaq	.LC419(%rip), %rsi
	movq	%r13, %rdi
	call	memcmp@PLT
	testl	%eax, %eax
	je	.L4805
	cmpl	$1701603686, -192(%rbp)
	movq	%rbx, -16488(%rbp)
	jne	.L3689
	leaq	-188(%rbp), %rax
	movabsq	$-4294950784, %r14
	movq	%r15, %rdi
	movq	%rax, -16384(%rbp)
	movq	%r14, -16496(%rbp)
	movl	$611, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movl	$32, %edx
	leaq	120+restart_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	leaq	88+restart_(%rip), %r12
	movq	%r15, %rdi
	movq	%r14, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$612, -16480(%rbp)
	movq	%r12, -16384(%rbp)
	movq	$32, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$2, %edx
	leaq	.LC58(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	leaq	64(%r12), %rsi
	movq	%r15, %rdi
	movl	$4, %edx
	call	_gfortran_transfer_integer_write@PLT
	movl	$3, %edx
	leaq	.LC420(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27464(%rbp), %rax
	addq	$3968, %r14
	movq	%r15, %rdi
	movq	%rax, -16384(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$613, -16480(%rbp)
	movq	$32, -16376(%rbp)
	movq	$0, -16424(%rbp)
	movq	%r12, -16416(%rbp)
	movq	$32, -16408(%rbp)
	movq	%r14, -16496(%rbp)
	call	_gfortran_st_write@PLT
	leaq	32(%r12), %rsi
	movq	%r15, %rdi
	movl	$32, %edx
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	leaq	.LC421(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	-384(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16384(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$614, -16480(%rbp)
	movq	$32, -16376(%rbp)
	movq	$0, -16424(%rbp)
	movq	%r12, -16416(%rbp)
	movq	$32, -16408(%rbp)
	movq	%r14, -16496(%rbp)
	call	_gfortran_st_write@PLT
	leaq	32(%r12), %rsi
	movq	%r15, %rdi
	movl	$32, %edx
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	leaq	.LC422(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	-256(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16384(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$615, -16480(%rbp)
	movq	$32, -16376(%rbp)
	movq	$0, -16424(%rbp)
	movq	%r12, -16416(%rbp)
	movq	$32, -16408(%rbp)
	movq	%r14, -16496(%rbp)
	call	_gfortran_st_write@PLT
	leaq	32(%r12), %rsi
	movq	%r15, %rdi
	movl	$32, %edx
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	.LC423(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3516
	.p2align 4,,10
	.p2align 3
.L4646:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$281, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-26760(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L3517:
	movq	-27640(%rbp), %rax
	movq	-27752(%rbp), %rdi
	movq	%rax, -26696(%rbp)
	movabsq	$30064771072, %rax
	movq	%rax, -26704(%rbp)
	movl	$620, -26688(%rbp)
	movq	-27472(%rbp), %r14
	call	_gfortran_st_close@PLT
	movl	-27308(%rbp), %eax
	movl	%eax, -27504(%rbp)
	testl	%eax, %eax
	je	.L3520
	jmp	.L3515
.L3713:
	movq	%rax, -16488(%rbp)
	leaq	.LC428(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%r15, %rdi
	movl	$711, -16480(%rbp)
	movq	$12, -16408(%rbp)
	movq	%rax, -16496(%rbp)
	vzeroupper
	call	_gfortran_st_write@PLT
	leaq	-224(%rbp), %r12
	movl	$11, %edx
	leaq	.LC430(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$32, %edx
	movq	%r12, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	%r12, %rdi
	movl	$32, %esi
	call	load_sequence_
	leaq	-27120(%rbp), %rsi
	leaq	-26856(%rbp), %rdi
	call	confstart_
	movl	8+bas_(%rip), %r12d
	movl	$1, -27452(%rbp)
	testl	%r12d, %r12d
	jle	.L3715
	movslq	%r12d, %r13
	salq	$3, %r13
	movq	%r13, %rdx
	leaq	pos_(%rip), %rsi
	leaq	nat_(%rip), %rdi
	call	memcpy@PLT
	movq	%r13, %rdx
	leaq	80000+pos_(%rip), %rsi
	leaq	80000+nat_(%rip), %rdi
	call	memcpy@PLT
	incl	%r12d
	movq	%r13, %rdx
	leaq	160000+pos_(%rip), %rsi
	leaq	160000+nat_(%rip), %rdi
	call	memcpy@PLT
	movl	%r12d, -27452(%rbp)
	jmp	.L3715
.L3701:
	vcomisd	%xmm4, %xmm1
	movl	$150, -27232(%rbp)
	ja	.L3702
	movl	$150, -27952(%rbp)
	jmp	.L4222
.L3702:
	vxorpd	.LC11(%rip), %xmm2, %xmm2
	jmp	.L3703
.L4639:
	movq	-27640(%rbp), %rax
	movq	-27752(%rbp), %rdi
	movq	%rax, -26696(%rbp)
	leaq	-256(%rbp), %rax
	movq	%rax, -26640(%rbp)
	leaq	.LC62(%rip), %rax
	movq	%rax, -26632(%rbp)
	movl	$33619971, %eax
	salq	$8, %rax
	movl	$641, -26688(%rbp)
	movq	$32, -26648(%rbp)
	movq	$7, -26624(%rbp)
	movl	$0, -26400(%rbp)
	movq	%rax, -26704(%rbp)
	call	_gfortran_st_open@PLT
	jmp	.L3698
.L4638:
	movq	-27640(%rbp), %rax
	movq	-27752(%rbp), %rdi
	movq	%rax, -26696(%rbp)
	leaq	-384(%rbp), %rax
	movq	%rax, -26640(%rbp)
	leaq	.LC62(%rip), %rax
	movq	%rax, -26632(%rbp)
	movl	$369164291, %eax
	salq	$8, %rax
	movl	$640, -26688(%rbp)
	movq	$32, -26648(%rbp)
	movq	$7, -26624(%rbp)
	movl	$0, -26400(%rbp)
	movq	%rax, -26704(%rbp)
	call	_gfortran_st_open@PLT
	jmp	.L3697
.L4605:
	vzeroupper
	jmp	.L3695
.L4637:
	movl	$0, 44+kier_(%rip)
	jmp	.L3693
.L4642:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC27(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	leaq	-416(%rbp), %r12
	movl	$733, -16480(%rbp)
	movq	$5, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$37, %edx
	leaq	.LC436(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r12, %rsi
	movl	$32, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movl	$32, %esi
	movq	%r12, %rdi
	call	load_cmap_
	jmp	.L3720
.L4640:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC56(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movl	$722, -16480(%rbp)
	movq	$3, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$40, %edx
	leaq	.LC431(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	-288(%rbp), %rdi
	movl	$32, %esi
	call	compute_contact_map_
	jmp	.L3718
.L4650:
	movzwl	4+.LC314(%rip), %eax
	cmpw	%ax, 4(%r13)
	jne	.L3531
	movzbl	6+.LC314(%rip), %eax
	cmpb	%al, 6(%r13)
	jne	.L3531
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$289, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-256(%rbp), %rsi
	movl	$32, %edx
	call	_gfortran_transfer_character@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4649:
	movzwl	4+.LC313(%rip), %eax
	cmpw	%ax, 4(%r13)
	jne	.L3528
	movzbl	6+.LC313(%rip), %eax
	cmpb	%al, 6(%r13)
	jne	.L3528
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$287, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	-27464(%rbp), %rsi
	movq	%r15, %rdi
	movl	$32, %edx
	call	_gfortran_transfer_character@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4648:
	movzwl	4+.LC312(%rip), %eax
	cmpw	%ax, 4(%r13)
	jne	.L3525
	movzbl	6+.LC312(%rip), %eax
	cmpb	%al, 6(%r13)
	jne	.L3525
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$285, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-224(%rbp), %rsi
	movl	$32, %edx
	call	_gfortran_transfer_character@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
	.p2align 4,,10
	.p2align 3
.L4647:
	movzwl	4+.LC311(%rip), %eax
	cmpw	%ax, 4(%r13)
	jne	.L3522
	movzbl	6+.LC311(%rip), %eax
	cmpb	%al, 6(%r13)
	jne	.L3522
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$283, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-288(%rbp), %rsi
	movl	$32, %edx
	call	_gfortran_transfer_character@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4641:
	leaq	.LC432(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%r15, %rdi
	movq	%rax, -16496(%rbp)
	movl	$726, -16480(%rbp)
	movq	$10, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$40, %edx
	leaq	.LC433(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	vmovq	%rbx, %xmm4
	vmulsd	bas_(%rip), %xmm4, %xmm0
	movq	-27752(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movl	$9, %edx
	leaq	.LC434(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	-27364(%rbp), %rsi
	leaq	-27040(%rbp), %rdi
	call	compute_cmap_
	jmp	.L3718
.L4643:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC56(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movl	$751, -16480(%rbp)
	movq	$3, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$30, %edx
	leaq	.LC440(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	call	amino_acid_mass_
	movl	8+bas_(%rip), %ebx
	jmp	.L3724
.L3734:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC56(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movl	$807, -16480(%rbp)
	movq	$3, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$26, %edx
	leaq	.LC442(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
.L3739:
	leaq	cmap_(%rip), %rbx
	movl	60000004(%rbx), %edx
	movq	-27640(%rbp), %rax
	testl	%edx, %edx
	jle	.L3740
	movq	%rax, -26696(%rbp)
	movq	-27752(%rbp), %rdi
	movl	$1, %eax
	salq	$32, %rax
	movl	$810, -26688(%rbp)
	movq	%rax, -26704(%rbp)
	call	_gfortran_st_flush@PLT
	movl	60000004(%rbx), %edx
	movq	$0x000000000, -27104(%rbp)
	testl	%edx, %edx
	jle	.L3741
	leal	-1(%rdx), %esi
	cmpl	$6, %esi
	jbe	.L4230
	movl	%edx, %eax
	shrl	$3, %eax
	imulq	$96, %rax, %rax
	vmovdqa	.LC206(%rip), %ymm8
	vmovdqa	.LC207(%rip), %ymm7
	vmovdqa	.LC208(%rip), %ymm6
	vmovdqa	.LC209(%rip), %ymm5
	vmovdqa	.LC210(%rip), %ymm4
	vmovdqa	.LC211(%rip), %ymm3
	vmovdqa	.LC212(%rip), %ymm2
	vmovdqa	.LC213(%rip), %ymm1
	movq	%rbx, %rcx
	addq	%rbx, %rax
	vxorpd	%xmm9, %xmm9, %xmm9
.L3743:
	vmovdqu	60000008(%rcx), %ymm0
	vmovdqu	60000040(%rcx), %ymm12
	vpshufb	%ymm8, %ymm0, %ymm10
	vmovdqu	60000072(%rcx), %ymm11
	vpermq	$78, %ymm10, %ymm13
	vpshufb	%ymm7, %ymm0, %ymm10
	vpshufb	%ymm6, %ymm12, %ymm14
	vpor	%ymm13, %ymm10, %ymm10
	vpor	%ymm14, %ymm10, %ymm10
	vpermd	%ymm11, %ymm5, %ymm13
	vpblendd	$192, %ymm13, %ymm10, %ymm10
	vpshufb	%ymm4, %ymm0, %ymm13
	vpermq	$78, %ymm13, %ymm13
	vpshufb	%ymm3, %ymm0, %ymm0
	vpshufb	%ymm2, %ymm12, %ymm12
	vpor	%ymm13, %ymm0, %ymm0
	vpor	%ymm12, %ymm0, %ymm0
	vpermd	%ymm11, %ymm1, %ymm11
	vpblendd	$224, %ymm11, %ymm0, %ymm0
	vpsubd	%ymm0, %ymm10, %ymm0
	vpabsd	%ymm0, %ymm0
	vcvtdq2pd	%xmm0, %ymm10
	vextracti128	$0x1, %ymm0, %xmm0
	vcvtdq2pd	%xmm0, %ymm0
	vaddpd	%ymm0, %ymm10, %ymm0
	addq	$96, %rcx
	vaddpd	%ymm0, %ymm9, %ymm9
	cmpq	%rcx, %rax
	jne	.L3743
	vextractf128	$0x1, %ymm9, %xmm0
	vaddpd	%xmm9, %xmm0, %xmm9
	movl	%edx, %eax
	andl	$-8, %eax
	vunpckhpd	%xmm9, %xmm9, %xmm2
	vaddpd	%xmm9, %xmm2, %xmm9
	leal	1(%rax), %ecx
	cmpl	%eax, %edx
	je	.L4806
	vzeroupper
.L3742:
	movl	%edx, %edi
	subl	%eax, %esi
	subl	%eax, %edi
	cmpl	$2, %esi
	jbe	.L3745
	leaq	(%rax,%rax,2), %rax
	leaq	cmap_(%rip), %rbx
	leaq	60000008(%rbx,%rax,4), %rax
	vmovdqu	(%rax), %xmm1
	vmovdqu	16(%rax), %xmm4
	vmovdqu	32(%rax), %xmm3
	vpshufb	.LC229(%rip), %xmm4, %xmm5
	vpshufb	.LC228(%rip), %xmm1, %xmm0
	vpshufb	.LC231(%rip), %xmm4, %xmm4
	vpshufb	.LC230(%rip), %xmm1, %xmm1
	vpor	%xmm5, %xmm0, %xmm0
	vpor	%xmm4, %xmm1, %xmm1
	vpshufd	$100, %xmm3, %xmm5
	vpshufd	$164, %xmm3, %xmm3
	vpblendw	$192, %xmm3, %xmm1, %xmm1
	vpblendw	$192, %xmm5, %xmm0, %xmm0
	vpsubd	%xmm1, %xmm0, %xmm0
	vpabsd	%xmm0, %xmm0
	vcvtdq2pd	%xmm0, %xmm1
	vpshufd	$238, %xmm0, %xmm0
	vcvtdq2pd	%xmm0, %xmm0
	vaddpd	%xmm0, %xmm1, %xmm1
	movl	%edi, %eax
	andl	$-4, %eax
	vunpckhpd	%xmm1, %xmm1, %xmm0
	vaddpd	%xmm1, %xmm0, %xmm0
	addl	%eax, %ecx
	vaddsd	%xmm0, %xmm9, %xmm9
	cmpl	%eax, %edi
	je	.L3744
.L3745:
	leal	-1(%rcx), %eax
	cltq
	leaq	(%rax,%rax,2), %rax
	leaq	cmap_(%rip), %rbx
	movl	60000008(%rbx,%rax,4), %esi
	vxorpd	%xmm5, %xmm5, %xmm5
	subl	60000012(%rbx,%rax,4), %esi
	movl	%esi, %edi
	sarl	$31, %edi
	xorl	%edi, %esi
	subl	%edi, %esi
	vcvtsi2sdl	%esi, %xmm5, %xmm0
	leal	1(%rcx), %esi
	vaddsd	%xmm0, %xmm9, %xmm9
	cmpl	%esi, %edx
	jl	.L3744
	movl	60000020(%rbx,%rax,4), %esi
	addl	$2, %ecx
	subl	60000024(%rbx,%rax,4), %esi
	movl	%esi, %edi
	sarl	$31, %edi
	xorl	%edi, %esi
	subl	%edi, %esi
	vcvtsi2sdl	%esi, %xmm5, %xmm0
	vaddsd	%xmm0, %xmm9, %xmm9
	cmpl	%ecx, %edx
	jl	.L3744
	movl	60000032(%rbx,%rax,4), %ecx
	subl	60000036(%rbx,%rax,4), %ecx
	movl	%ecx, %eax
	sarl	$31, %ecx
	xorl	%ecx, %eax
	subl	%ecx, %eax
	vcvtsi2sdl	%eax, %xmm5, %xmm0
	vaddsd	%xmm0, %xmm9, %xmm9
.L3744:
	vmovsd	%xmm9, -27104(%rbp)
.L3741:
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%edx, %xmm5, %xmm1
	vcvtsi2sdl	8+bas_(%rip), %xmm5, %xmm0
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	vmulsd	%xmm1, %xmm0, %xmm0
	vmovsd	-27104(%rbp), %xmm1
	leaq	.LC443(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	vdivsd	%xmm0, %xmm1, %xmm0
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movl	$817, -16480(%rbp)
	movq	$8, -16408(%rbp)
	vmovsd	%xmm0, -27104(%rbp)
	call	_gfortran_st_write@PLT
	movl	$30, %edx
	leaq	.LC445(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	leaq	-27104(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
.L3747:
	movl	248008+nat_(%rip), %eax
	movl	$1, -27392(%rbp)
	movl	%eax, -27488(%rbp)
	movl	$1, %ebx
	leaq	sequence_(%rip), %rcx
	testl	%eax, %eax
	jle	.L3766
	movq	%r14, -27512(%rbp)
.L3748:
	leaq	240000+nat_(%rip), %rax
	movl	(%rax,%rbx,8), %r10d
	addq	$4, %rax
	movl	(%rax,%rbx,8), %r11d
	movslq	%r10d, %rax
	leaq	79997(%rax,%rax,2), %r12
	leaq	-1(%rax), %rdi
	leaq	.LC173(%rip), %rax
	movzwl	(%rax), %eax
	addq	%rcx, %r12
	cmpw	%ax, (%r12)
	je	.L4807
.L3751:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movabsq	$4294967424, %rax
	movq	%rax, -16496(%rbp)
	movl	$826, -16480(%rbp)
	call	_gfortran_st_write@PLT
	leaq	.LC447(%rip), %rsi
	movl	$9, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	nat_(%rip), %rax
	leaq	240004(%rax,%rbx,4), %rsi
.L4630:
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$30, %edx
	leaq	.LC448(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
.L4807:
	movzbl	2+.LC173(%rip), %eax
	cmpb	%al, 2(%r12)
	jne	.L3751
	movslq	%r11d, %rax
	leaq	79997(%rax,%rax,2), %r13
	leaq	-1(%rax), %rsi
	leaq	.LC173(%rip), %rax
	movzwl	(%rax), %eax
	addq	%rcx, %r13
	cmpw	%ax, 0(%r13)
	je	.L4808
.L3754:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movabsq	$4294967424, %rax
	movq	%rax, -16496(%rbp)
	movl	$830, -16480(%rbp)
	call	_gfortran_st_write@PLT
	leaq	.LC447(%rip), %rsi
	movl	$9, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	nat_(%rip), %rax
	leaq	240012(%rax,%rbx,4), %rsi
	jmp	.L4630
.L4808:
	movzbl	2+.LC173(%rip), %eax
	cmpb	%al, 2(%r13)
	jne	.L3754
	movl	-27280(%rbp), %r14d
	xorl	%edx, %edx
	testl	%r14d, %r14d
	jne	.L3758
	movl	24+ssb2_(%rip), %r9d
	testl	%r9d, %r9d
	je	.L4809
.L3758:
	leal	1(%rbx), %eax
	incq	%rbx
	movl	%eax, -27392(%rbp)
	cmpl	%ebx, -27488(%rbp)
	jge	.L3748
	movq	-27512(%rbp), %r14
.L3766:
	movl	80032+misc_(%rip), %eax
	testl	%eax, %eax
	jne	.L3749
	leaq	.LC56(%rip), %rax
	movq	%rax, -27936(%rbp)
.L3750:
	vmovsd	bas_(%rip), %xmm1
	vmovsd	.LC8(%rip), %xmm5
	vmovapd	48+hhar_(%rip), %xmm6
	vdivsd	%xmm1, %xmm5, %xmm0
	vmovddup	%xmm1, %xmm5
	vmulsd	%xmm1, %xmm1, %xmm2
	vmulsd	80016+ssb_(%rip), %xmm1, %xmm3
	movl	36+restr_(%rip), %r8d
	vmulsd	.LC465(%rip), %xmm2, %xmm2
	vmovsd	%xmm3, 80016+ssb_(%rip)
	vdivpd	%xmm5, %xmm6, %xmm5
	vmulsd	56+hhar_(%rip), %xmm0, %xmm4
	vmovapd	%xmm5, 48+hhar_(%rip)
	testl	%r8d, %r8d
	jne	.L3772
	vdivsd	%xmm1, %xmm4, %xmm1
	vmovsd	%xmm1, 56+hhar_(%rip)
.L3772:
	vmulsd	%xmm3, %xmm3, %xmm3
	vmulsd	80024+ssb_(%rip), %xmm0, %xmm1
	vmovupd	56+sig_(%rip), %xmm7
	movq	-27640(%rbp), %r13
	movq	-27936(%rbp), %rax
	vdivsd	%xmm3, %xmm2, %xmm2
	vmovsd	%xmm1, 80024+ssb_(%rip)
	vmulsd	.LC158(%rip), %xmm1, %xmm1
	movabsq	$4294971392, %rbx
	movq	%r15, %rdi
	movl	$10, -27452(%rbp)
	movq	%r13, -16488(%rbp)
	vmovsd	%xmm1, 696+sig_(%rip)
	vmovsd	%xmm1, 16+ssb2_(%rip)
	vmovapd	.LC272(%rip), %ymm1
	movl	$886, -16480(%rbp)
	vmulpd	24+sig_(%rip), %ymm1, %ymm1
	movq	%rax, -16416(%rbp)
	movq	$3, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	vmovsd	%xmm2, 80008+ssb_(%rip)
	vbroadcastsd	%xmm0, %ymm2
	vmulpd	%ymm2, %ymm1, %ymm1
	vmovddup	%xmm0, %xmm0
	vmovupd	%ymm1, 24+sig_(%rip)
	vmulpd	.LC273(%rip), %xmm7, %xmm1
	vmulpd	%xmm0, %xmm1, %xmm0
	vmovupd	%xmm0, 56+sig_(%rip)
	vzeroupper
	call	_gfortran_st_write@PLT
	movl	$47, %edx
	leaq	.LC466(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	-27432(%rbp), %rax
	movq	%rax, %rdi
	movq	%rax, -27512(%rbp)
	call	ran2_
	leaq	.LC467(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, -16416(%rbp)
	movq	%r13, -16488(%rbp)
	movl	$889, -16480(%rbp)
	movq	$13, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$27, %edx
	leaq	.LC468(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$7, %edx
	leaq	.LC469(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	vmovsd	bas_(%rip), %xmm0
	vmovsd	16+hhar_(%rip), %xmm1
	vmulsd	%xmm0, %xmm0, %xmm0
	movq	-27752(%rbp), %r13
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	vdivsd	%xmm0, %xmm1, %xmm0
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movl	$7, %edx
	leaq	.LC470(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	vmovsd	bas_(%rip), %xmm0
	vmovsd	24+hhar_(%rip), %xmm1
	vmulsd	%xmm0, %xmm0, %xmm0
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	vmulsd	%xmm0, %xmm0, %xmm0
	vdivsd	%xmm0, %xmm1, %xmm0
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movl	80016+chiral_(%rip), %edi
	testl	%edi, %edi
	jne	.L4810
.L3773:
	movl	80020+chiral_(%rip), %esi
	testl	%esi, %esi
	je	.L3774
	cmpl	$0, 200000+angnat_(%rip)
	je	.L3775
	movl	$0, 102432+ang_(%rip)
.L3776:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	-27936(%rbp), %rax
	movl	$901, -16480(%rbp)
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movq	$3, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$38, %edx
	leaq	.LC473(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
.L3774:
	movl	16+bas_(%rip), %ecx
	testl	%ecx, %ecx
	jne	.L4811
.L3777:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	-27936(%rbp), %rax
	movl	$907, -16480(%rbp)
	movq	%rax, -16416(%rbp)
	movabsq	$4294971392, %rax
	movq	%rax, -16496(%rbp)
	movq	$3, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$32, %edx
	leaq	.LC474(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	cmap_(%rip), %rax
	movl	60000004(%rax), %r10d
	testl	%r10d, %r10d
	jle	.L4232
	movq	%r14, -27504(%rbp)
	leaq	60000008(%rax), %r8
	movl	$1, %r13d
	xorl	%r9d, %r9d
	leaq	bon_(%rip), %r11
	leaq	sequence_(%rip), %r12
	movq	%r8, %rbx
.L3784:
	movslq	(%rbx), %rcx
	movl	4(%rbx), %eax
	movl	80036+ssb_(%rip), %r8d
	movl	%eax, %edi
	leaq	-1(%rcx), %rsi
	movl	%ecx, -27452(%rbp)
	movl	%eax, -27420(%rbp)
	movq	%rsi, -27464(%rbp)
	movq	%rcx, %r14
	subl	%ecx, %edi
	testl	%r8d, %r8d
	je	.L3779
	cmpl	$4, 39996(%r12,%rcx,4)
	je	.L4812
.L3779:
	movq	-27464(%rbp), %rsi
	testb	$1, 80000(%r11,%rsi,4)
	je	.L3782
	cmpl	$2, %edi
	jle	.L3781
.L3782:
	movslq	%r9d, %rdx
	leaq	(%rdx,%rdx,2), %rdx
	leaq	cmap_(%rip), %rsi
	movl	%r14d, 60000008(%rsi,%rdx,4)
	movl	%eax, 60000012(%rsi,%rdx,4)
	incl	%r9d
	movl	8(%rbx), %eax
	movl	%eax, 60000016(%rsi,%rdx,4)
.L3781:
	incl	%r13d
	cmpl	%r10d, %r13d
	jg	.L4596
	addq	$12, %rbx
	testl	%r8d, %r8d
	jne	.L3784
	movslq	%r13d, %rax
	imulq	$12, %rax, %rax
	leaq	cmap_(%rip), %rbx
	movq	-27504(%rbp), %r14
	addq	%rbx, %rax
	jmp	.L3787
	.p2align 4,,10
	.p2align 3
.L4809:
	leaq	cmap_(%rip), %rax
	movl	60000004(%rax), %r8d
	leaq	(%rcx,%rsi,4), %rsi
	movq	%rsi, -27464(%rbp)
	leaq	(%rcx,%rdi,4), %r14
	addq	$60000008, %rax
	movl	$1, %r9d
	testl	%r8d, %r8d
	jle	.L3765
	movq	%rbx, -27528(%rbp)
	movq	%rax, %rbx
.L3764:
	movl	(%rbx), %edi
	movl	4(%rbx), %esi
	cmpl	%edi, %r10d
	jne	.L4276
	cmpl	%esi, %r11d
	je	.L3761
.L4276:
	cmpl	%edi, %r11d
	jne	.L3763
	cmpl	%esi, %r10d
	jne	.L3763
.L3761:
	movl	8(%rbx), %edx
	movq	-27640(%rbp), %rax
	sarl	$31, %edx
	leal	631(%rdx), %esi
	xorl	%esi, %edx
	movl	%edx, 8(%rbx)
	movq	%rax, -16488(%rbp)
	leaq	.LC449(%rip), %rax
	movq	%rax, -16416(%rbp)
	movq	%r15, %rdi
	movabsq	$4294971392, %rax
	movl	%r8d, -27552(%rbp)
	movl	%r11d, -27600(%rbp)
	movl	%r10d, -27544(%rbp)
	movl	%r9d, -27536(%rbp)
	movq	%rax, -16496(%rbp)
	movl	$842, -16480(%rbp)
	movq	$21, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$15, %edx
	leaq	.LC451(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	-27392(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$3, %edx
	movq	%r12, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	movq	%r14, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$3, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	-27464(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movl	-27552(%rbp), %r8d
	movl	-27600(%rbp), %r11d
	movl	-27544(%rbp), %r10d
	movl	-27536(%rbp), %r9d
	movl	$1, %edx
	leaq	sequence_(%rip), %rcx
.L3763:
	incl	%r9d
	addq	$12, %rbx
	cmpl	%r8d, %r9d
	jle	.L3764
	movq	-27528(%rbp), %rbx
	testl	%edx, %edx
	jne	.L3758
.L3765:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC449(%rip), %rax
	movq	%rax, -16416(%rbp)
	movabsq	$4294971392, %rax
	movq	%rax, -16496(%rbp)
	movl	$847, -16480(%rbp)
	movq	$21, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$26, %edx
	leaq	.LC450(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	-27392(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$3, %edx
	movq	%r12, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	movq	%r14, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$3, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	-27464(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	sequence_(%rip), %rcx
	jmp	.L3758
.L4812:
	movslq	%eax, %rdx
	leaq	-1(%rdx), %rsi
	cmpl	$4, 39996(%r12,%rdx,4)
	movq	%rsi, -27488(%rbp)
	jne	.L3779
	movl	8(%rbx), %edx
	movl	%edx, %esi
	sarl	$31, %esi
	xorl	%esi, %edx
	subl	%esi, %edx
	cmpl	$631, %edx
	jne	.L3779
	movl	%eax, -27528(%rbp)
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC475(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%r11, -27560(%rbp)
	movl	%r10d, -27552(%rbp)
	movl	%r9d, -27600(%rbp)
	movq	%rcx, -27544(%rbp)
	movl	%r8d, -27536(%rbp)
	movq	%rax, -16496(%rbp)
	movl	$917, -16480(%rbp)
	movq	$22, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$16, %edx
	leaq	.LC476(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	-27452(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	leaq	-27420(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	imulq	$3, -27464(%rbp), %rdx
	movq	%r15, %rdi
	leaq	80000(%r12,%rdx), %rsi
	movl	$3, %edx
	call	_gfortran_transfer_character_write@PLT
	movq	-27464(%rbp), %rax
	movl	$4, %edx
	leaq	(%r12,%rax,4), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	imulq	$3, -27488(%rbp), %rdx
	movq	%r15, %rdi
	leaq	80000(%r12,%rdx), %rsi
	movl	$3, %edx
	call	_gfortran_transfer_character_write@PLT
	movq	-27488(%rbp), %rax
	movl	$4, %edx
	leaq	(%r12,%rax,4), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27544(%rbp), %rcx
	movq	-27560(%rbp), %r11
	movl	-27528(%rbp), %eax
	cmpl	$0, 79996(%r11,%rcx,4)
	movl	-27536(%rbp), %r8d
	movl	-27600(%rbp), %r9d
	movl	-27552(%rbp), %r10d
	je	.L3782
	incl	%r13d
	cmpl	%r13d, %r10d
	jl	.L4596
	addq	$12, %rbx
	jmp	.L3784
.L4811:
	call	compute_native_angles_
	jmp	.L3777
.L4596:
	movq	-27504(%rbp), %r14
.L3778:
	movl	8+bas_(%rip), %ebx
	leaq	cmap_(%rip), %rax
	movl	%r9d, 60000004(%rax)
	testl	%ebx, %ebx
	jle	.L4233
	movl	56+wal_(%rip), %edx
	movl	%ebx, %esi
	leaq	0(,%rsi,8), %r12
	leal	-1(%rbx), %r13d
	testl	%edx, %edx
	movq	%rsi, -27504(%rbp)
	movl	%r13d, -27464(%rbp)
	movq	%r12, %rdx
	leaq	nat_(%rip), %rsi
	leaq	pos_(%rip), %rdi
	jne	.L3789
	call	memcpy@PLT
	movq	%r12, %rdx
	leaq	80000+nat_(%rip), %rsi
	leaq	80000+pos_(%rip), %rdi
	call	memcpy@PLT
	movq	%r12, %rdx
	leaq	160000+nat_(%rip), %rsi
	leaq	160000+pos_(%rip), %rdi
	call	memcpy@PLT
	xorl	%esi, %esi
	movq	%r12, %rdx
	leaq	misc_(%rip), %rdi
	call	memset@PLT
	movq	%r12, %rdx
	leaq	160000+nat_(%rip), %rsi
	leaq	respul_(%rip), %rdi
	call	memcpy@PLT
	cmpl	$6, -27464(%rbp)
	jbe	.L4234
	movl	%ebx, %eax
	shrl	$3, %eax
	leaq	80000+respul_(%rip), %rdx
	salq	$5, %rax
	vmovdqa	.LC76(%rip), %ymm0
	vmovdqa	.LC77(%rip), %ymm3
	addq	%rdx, %rax
.L3791:
	vmovdqa	%ymm0, %ymm1
	vmovdqa	%ymm1, (%rdx)
	addq	$32, %rdx
	vpaddd	%ymm3, %ymm0, %ymm0
	cmpq	%rax, %rdx
	jne	.L3791
	movl	%ebx, %edx
	andl	$-8, %edx
	leal	1(%rdx), %eax
	cmpl	%edx, %ebx
	je	.L4813
	vzeroupper
.L3790:
	leal	-1(%rax), %ecx
	movslq	%ecx, %rcx
	leaq	respul_(%rip), %rdx
	movl	%eax, 80000(%rdx,%rcx,4)
	leal	1(%rax), %ecx
	cmpl	%ecx, %ebx
	jl	.L3792
	movslq	%eax, %rsi
	movl	%ecx, 80000(%rdx,%rsi,4)
	leal	2(%rax), %esi
	cmpl	%esi, %ebx
	jl	.L3792
	movslq	%ecx, %rcx
	movl	%esi, 80000(%rdx,%rcx,4)
	leal	3(%rax), %ecx
	cmpl	%ecx, %ebx
	jl	.L3792
	movslq	%esi, %rsi
	movl	%ecx, 80000(%rdx,%rsi,4)
	leal	4(%rax), %esi
	cmpl	%ebx, %esi
	jg	.L3792
	movslq	%ecx, %rcx
	movl	%esi, 80000(%rdx,%rcx,4)
	leal	5(%rax), %ecx
	cmpl	%ebx, %ecx
	jg	.L3792
	movslq	%esi, %rsi
	addl	$6, %eax
	movl	%ecx, 80000(%rdx,%rsi,4)
	cmpl	%eax, %ebx
	jl	.L3792
	movslq	%ecx, %rcx
	movl	%eax, 80000(%rdx,%rcx,4)
.L3792:
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	pull_(%rip), %rdi
	call	memset@PLT
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	80000+pull_(%rip), %rdi
	call	memset@PLT
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	160000+pull_(%rip), %rdi
	call	memset@PLT
	salq	$3, %r13
	leaq	8+neigh_(%rip), %rdx
	addq	%r13, %rdx
	leaq	neigh_(%rip), %rax
.L3793:
	movl	$0, (%rax)
	addq	$8, %rax
	cmpq	%rax, %rdx
	jne	.L3793
	leaq	4+neigh_(%rip), %rax
	leaq	8(%rax), %rdx
	addq	%rdx, %r13
.L3794:
	movl	$0, (%rax)
	addq	$8, %rax
	cmpq	%rax, %r13
	jne	.L3794
	leaq	sdch_(%rip), %rsi
	xorl	%eax, %eax
	leaq	40000+sequence_(%rip), %rcx
	leaq	360(%rsi), %rdx
.L3796:
	movslq	(%rcx,%rax,4), %rdi
	movl	20(%rsi,%rdi,4), %edi
	movl	%edi, (%rdx,%rax,4)
	incq	%rax
	cmpq	-27504(%rbp), %rax
	jne	.L3796
.L3795:
	leal	1(%rbx), %eax
	movl	%eax, -27764(%rbp)
.L3788:
	movl	-27360(%rbp), %r12d
	movl	160000+bon_(%rip), %r9d
	testl	%r12d, %r12d
	je	.L3803
	testl	%r9d, %r9d
	jle	.L4238
	leaq	120004+bon_(%rip), %rcx
	leal	-1(%r9), %eax
	leaq	4(%rcx), %rdx
	leaq	(%rdx,%rax,4), %rdi
	movslq	120000+bon_(%rip), %rax
	leaq	sdch_(%rip), %rsi
.L3809:
	xorl	%edx, %edx
	cmpl	$4, 360(%rsi,%rax,4)
	setne	%dl
	leal	2(%rdx,%rdx,2), %edx
	movl	%edx, 360(%rsi,%rax,4)
	movslq	(%rcx), %rax
	cmpl	$5, 356(%rsi,%rax,4)
	leaq	89(%rax), %rdx
	je	.L4814
	addq	$4, %rcx
	movl	$4, (%rsi,%rdx,4)
	cmpq	%rcx, %rdi
	jne	.L3809
.L3807:
	movq	$0x000000000, bon_(%rip)
	jmp	.L4215
.L4810:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	-27936(%rbp), %rax
	movl	$892, -16480(%rbp)
	movq	%rax, -16416(%rbp)
	movq	$3, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$27, %edx
	leaq	.LC471(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	call	model_chirality_
	jmp	.L3773
.L3775:
	cmpl	$0, 102432+ang_(%rip)
	je	.L3776
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	-27936(%rbp), %rax
	movl	$899, -16480(%rbp)
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movq	$3, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$46, %edx
	leaq	.LC472(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3774
.L3749:
	movq	-27640(%rbp), %r13
	movl	$1048577, %ebx
	leaq	.LC56(%rip), %r12
	salq	$12, %rbx
	movq	%r15, %rdi
	movq	%r13, -16488(%rbp)
	movl	$853, -16480(%rbp)
	movq	%r12, -27936(%rbp)
	movq	%r12, -16416(%rbp)
	movq	$3, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$47, %edx
	leaq	.LC452(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	cmpl	$0, 24+ssb2_(%rip)
	jne	.L4815
	movq	-27936(%rbp), %rax
	movq	-27640(%rbp), %r13
	movq	%r15, %rdi
	movq	%rax, -16416(%rbp)
	movq	%r13, -16488(%rbp)
	movl	$858, -16480(%rbp)
	movq	$3, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$47, %edx
	leaq	.LC457(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC454(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, -16416(%rbp)
	movq	%r13, -16488(%rbp)
	movl	$859, -16480(%rbp)
	movq	$15, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$9, %edx
	leaq	.LC458(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	leaq	80024+ssb_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$9, %edx
	leaq	.LC459(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	80016+ssb_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
.L3768:
	cmpl	$0, 80036+misc_(%rip)
	jne	.L3769
	cmpl	$1, 80032+misc_(%rip)
	jne	.L3770
	cmpl	$0, -27504(%rbp)
	je	.L3769
.L3770:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC27(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movl	$865, -16480(%rbp)
	movq	$5, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$34, %edx
	leaq	.LC462(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	leaq	-320(%rbp), %rsi
	movl	$32, %edx
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
.L3771:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC463(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movl	$867, -16480(%rbp)
	movq	$8, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$29, %edx
	leaq	.LC464(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	48+hhar_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3750
.L3740:
	movq	%rax, -16488(%rbp)
	leaq	.LC56(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%r15, %rdi
	movq	%rax, -16496(%rbp)
	movl	$819, -16480(%rbp)
	movq	$3, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$19, %edx
	leaq	.LC446(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3747
.L3789:
	call	memcpy@PLT
	movq	%r12, %rdx
	leaq	80000+nat_(%rip), %rsi
	leaq	80000+pos_(%rip), %rdi
	call	memcpy@PLT
	movq	%r12, %rdx
	leaq	160000+nat_(%rip), %rsi
	leaq	160000+pos_(%rip), %rdi
	call	memcpy@PLT
	xorl	%esi, %esi
	movq	%r12, %rdx
	leaq	misc_(%rip), %rdi
	call	memset@PLT
	xorl	%esi, %esi
	movq	%r12, %rdx
	leaq	respul_(%rip), %rdi
	call	memset@PLT
	cmpl	$6, -27464(%rbp)
	jbe	.L4235
	movl	%ebx, %eax
	shrl	$3, %eax
	leaq	80000+respul_(%rip), %rdx
	salq	$5, %rax
	vmovdqa	.LC76(%rip), %ymm0
	vmovdqa	.LC77(%rip), %ymm3
	addq	%rdx, %rax
.L3798:
	vmovdqa	%ymm0, %ymm1
	vmovdqa	%ymm1, (%rdx)
	addq	$32, %rdx
	vpaddd	%ymm3, %ymm0, %ymm0
	cmpq	%rax, %rdx
	jne	.L3798
	movl	%ebx, %edx
	andl	$-8, %edx
	leal	1(%rdx), %eax
	cmpl	%edx, %ebx
	je	.L4816
	vzeroupper
.L3797:
	leal	-1(%rax), %ecx
	movslq	%ecx, %rcx
	leaq	respul_(%rip), %rdx
	movl	%eax, 80000(%rdx,%rcx,4)
	leal	1(%rax), %ecx
	cmpl	%ebx, %ecx
	jg	.L3799
	movslq	%eax, %rsi
	movl	%ecx, 80000(%rdx,%rsi,4)
	leal	2(%rax), %esi
	cmpl	%ebx, %esi
	jg	.L3799
	movslq	%ecx, %rcx
	movl	%esi, 80000(%rdx,%rcx,4)
	leal	3(%rax), %ecx
	cmpl	%ecx, %ebx
	jl	.L3799
	movslq	%esi, %rsi
	movl	%ecx, 80000(%rdx,%rsi,4)
	leal	4(%rax), %esi
	cmpl	%esi, %ebx
	jl	.L3799
	movslq	%ecx, %rcx
	movl	%esi, 80000(%rdx,%rcx,4)
	leal	5(%rax), %ecx
	cmpl	%ecx, %ebx
	jl	.L3799
	movslq	%esi, %rsi
	addl	$6, %eax
	movl	%ecx, 80000(%rdx,%rsi,4)
	cmpl	%eax, %ebx
	jl	.L3799
	movslq	%ecx, %rcx
	movl	%eax, 80000(%rdx,%rcx,4)
.L3799:
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	pull_(%rip), %rdi
	call	memset@PLT
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	80000+pull_(%rip), %rdi
	call	memset@PLT
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	160000+pull_(%rip), %rdi
	call	memset@PLT
	salq	$3, %r13
	leaq	8+neigh_(%rip), %rdx
	addq	%r13, %rdx
	leaq	neigh_(%rip), %rax
.L3800:
	movl	$0, (%rax)
	addq	$8, %rax
	cmpq	%rax, %rdx
	jne	.L3800
	leaq	4+neigh_(%rip), %rax
	leaq	8(%rax), %rdx
	addq	%rdx, %r13
.L3801:
	movl	$0, (%rax)
	addq	$8, %rax
	cmpq	%rax, %r13
	jne	.L3801
	leaq	sdch_(%rip), %rsi
	xorl	%eax, %eax
	leaq	40000+sequence_(%rip), %rcx
	leaq	360(%rsi), %rdx
.L3802:
	movslq	(%rcx,%rax,4), %rdi
	movl	20(%rsi,%rdi,4), %edi
	movl	%edi, (%rdx,%rax,4)
	incq	%rax
	cmpq	-27504(%rbp), %rax
	jne	.L3802
	jmp	.L3795
.L4814:
	addq	$4, %rcx
	movl	$2, (%rsi,%rdx,4)
	cmpq	%rcx, %rdi
	jne	.L3809
	jmp	.L3807
.L3803:
	movq	$0x000000000, bon_(%rip)
	testl	%r9d, %r9d
	jle	.L4238
.L4215:
	movl	$1, %ebx
	vxorpd	%xmm0, %xmm0, %xmm0
	leaq	nat_(%rip), %r10
.L3812:
	leaq	119996+bon_(%rip), %rax
	movslq	(%rax,%rbx,4), %rax
	leaq	120000+bon_(%rip), %rsi
	movl	(%rsi,%rbx,4), %ecx
	leal	1(%rax), %r11d
	cmpl	%r11d, %ecx
	jle	.L3816
	subl	%eax, %ecx
	leal	-2(%rcx), %edx
	leal	-1(%rcx), %esi
	cmpl	$2, %edx
	jbe	.L4239
	movslq	%eax, %rdx
	salq	$3, %rdx
	leaq	8(%rdx), %rdi
	leaq	(%r10,%rdi), %r8
	leaq	80008(%r10,%rdx), %r12
	movq	%r8, -27544(%rbp)
	movq	%r12, -27488(%rbp)
	leaq	(%r10,%rdx), %r13
	leaq	160000(%r10,%rdx), %r12
	leaq	80000(%r10,%rdx), %r8
	leaq	160008(%r10,%rdx), %rdx
	movq	%rdx, -27504(%rbp)
	leaq	bon_(%rip), %rdx
	addq	%rdx, %rdi
	movl	%esi, %edx
	shrl	$2, %edx
	movq	%r12, -27528(%rbp)
	salq	$5, %rdx
	movq	%rdx, -27536(%rbp)
	vxorpd	%xmm4, %xmm4, %xmm4
	xorl	%edx, %edx
.L3815:
	vmovupd	0(%r13,%rdx), %ymm5
	movq	-27544(%rbp), %r12
	vmovupd	(%r8,%rdx), %ymm6
	vsubpd	(%r12,%rdx), %ymm5, %ymm2
	movq	-27488(%rbp), %r12
	vsubpd	(%r12,%rdx), %ymm6, %ymm3
	movq	-27528(%rbp), %r12
	vmulpd	%ymm3, %ymm3, %ymm3
	vmovupd	(%r12,%rdx), %ymm7
	movq	-27504(%rbp), %r12
	vmovapd	%ymm7, -27600(%rbp)
	vsubpd	(%r12,%rdx), %ymm7, %ymm1
	vfmadd132pd	%ymm2, %ymm3, %ymm2
	vfmadd132pd	%ymm1, %ymm2, %ymm1
	vsqrtpd	%ymm1, %ymm1
	vmovupd	%ymm1, (%rdi,%rdx)
	addq	$32, %rdx
	vaddpd	%ymm1, %ymm4, %ymm4
	cmpq	-27536(%rbp), %rdx
	jne	.L3815
	vextractf128	$0x1, %ymm4, %xmm1
	vaddpd	%xmm4, %xmm1, %xmm2
	movl	%esi, %edi
	andl	$-4, %edi
	vunpckhpd	%xmm2, %xmm2, %xmm1
	vaddpd	%xmm2, %xmm1, %xmm1
	leal	(%rdi,%r11), %edx
	vaddsd	%xmm1, %xmm0, %xmm0
	cmpl	%edi, %esi
	je	.L3817
.L3813:
	movl	%ecx, %r8d
	subl	%edi, %r8d
	leal	-1(%r8), %esi
	cmpl	$2, %r8d
	je	.L3818
	addq	%rdi, %rax
	vmovupd	(%r10,%rax,8), %xmm4
	leaq	80000+nat_(%rip), %rdi
	vsubpd	8(%r10,%rax,8), %xmm4, %xmm2
	vmovupd	(%rdi,%rax,8), %xmm4
	addq	$8, %rdi
	vsubpd	(%rdi,%rax,8), %xmm4, %xmm3
	addq	$79992, %rdi
	vmovupd	(%rdi,%rax,8), %xmm7
	vmulpd	%xmm3, %xmm3, %xmm3
	addq	$8, %rdi
	vsubpd	(%rdi,%rax,8), %xmm7, %xmm1
	leaq	bon_(%rip), %rdi
	vmovapd	%xmm7, -27504(%rbp)
	vfmadd132pd	%xmm2, %xmm3, %xmm2
	vfmadd132pd	%xmm1, %xmm2, %xmm1
	vsqrtpd	%xmm1, %xmm1
	vunpckhpd	%xmm1, %xmm1, %xmm2
	vmovupd	%xmm1, 8(%rdi,%rax,8)
	vaddpd	%xmm1, %xmm2, %xmm1
	movl	%esi, %eax
	andl	$-2, %eax
	vaddsd	%xmm1, %xmm0, %xmm0
	addl	%eax, %edx
	cmpl	%eax, %esi
	je	.L3817
.L3818:
	movslq	%edx, %rax
	vmovsd	79992(%r10,%rax,8), %xmm3
	vmovsd	-8(%r10,%rax,8), %xmm2
	vsubsd	80000(%r10,%rax,8), %xmm3, %xmm3
	vsubsd	(%r10,%rax,8), %xmm2, %xmm2
	vmovsd	159992(%r10,%rax,8), %xmm1
	vmulsd	%xmm3, %xmm3, %xmm3
	vsubsd	160000(%r10,%rax,8), %xmm1, %xmm1
	leaq	bon_(%rip), %rsi
	vfmadd132sd	%xmm2, %xmm3, %xmm2
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vsqrtsd	%xmm1, %xmm1, %xmm1
	vaddsd	%xmm1, %xmm0, %xmm0
	vmovsd	%xmm1, (%rsi,%rax,8)
.L3817:
	leal	-1(%r11,%rcx), %r11d
.L3816:
	incq	%rbx
	cmpl	%ebx, %r9d
	jge	.L3812
	movl	%r11d, -27452(%rbp)
	vzeroupper
.L3804:
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	-27464(%rbp), %xmm5, %xmm1
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	vdivsd	%xmm1, %xmm0, %xmm0
	movq	-27936(%rbp), %rax
	movl	$976, -16480(%rbp)
	movq	%rax, -16416(%rbp)
	movabsq	$4294971392, %rax
	movq	%rax, -16496(%rbp)
	movq	$3, -16408(%rbp)
	vmovsd	%xmm0, bon_(%rip)
	call	_gfortran_st_write@PLT
	movl	$37, %edx
	leaq	.LC477(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movl	16+bas_(%rip), %ebx
	testl	%ebx, %ebx
	jne	.L4817
.L3820:
	movl	-27260(%rbp), %r11d
	testl	%r11d, %r11d
	jne	.L4818
	leaq	-27024(%rbp), %r12
	movq	%r12, %rdi
	call	prepare_
	leaq	-27136(%rbp), %rax
	movq	%rax, %rsi
	movq	%r12, %rdi
	movq	%rax, -27536(%rbp)
	call	evalgo_
	movl	60+wal_(%rip), %r10d
	testl	%r10d, %r10d
	je	.L3822
	cmpl	$0, -27316(%rbp)
	je	.L4819
.L3822:
	movl	10004072+nmapi_(%rip), %r9d
	testl	%r9d, %r9d
	je	.L3823
	leaq	-27000(%rbp), %rdx
	leaq	-27344(%rbp), %rsi
	movq	%r12, %rdi
	call	evalimproper_
.L3824:
	movl	80020+chiral_(%rip), %r8d
	testl	%r8d, %r8d
	jne	.L3825
	cmpl	$0, 20+bas_(%rip)
	jne	.L3825
	cmpl	$0, 80016+chiral_(%rip)
	jne	.L4213
.L3829:
	movq	-27640(%rbp), %r13
	leaq	.LC480(%rip), %rax
	movabsq	$4294971392, %rbx
	movq	%r15, %rdi
	movq	%rax, -16416(%rbp)
	movq	%r13, -16488(%rbp)
	movl	$1002, -16480(%rbp)
	movq	$9, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$27, %edx
	leaq	.LC481(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	leaq	8+bas_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	%r13, -27640(%rbp)
	movq	%r13, -16488(%rbp)
	movq	%r15, %rdi
	leaq	.LC437(%rip), %r13
	movl	$1003, -16480(%rbp)
	movq	%r13, -16416(%rbp)
	movq	$7, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$27, %edx
	leaq	.LC482(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	cmap_(%rip), %rsi
	addq	$60000004, %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movl	16+bas_(%rip), %esi
	movq	-27640(%rbp), %rax
	testl	%esi, %esi
	movq	%rax, -16488(%rbp)
	je	.L3830
	leaq	.LC483(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, -16416(%rbp)
	movl	$1005, -16480(%rbp)
	movq	$9, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$27, %edx
	leaq	.LC484(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	vmovsd	-27168(%rbp), %xmm0
	movq	-27752(%rbp), %rsi
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movq	%r15, %rdi
	movl	$8, %edx
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
.L3831:
	movq	-27640(%rbp), %rax
	leaq	.LC486(%rip), %rbx
	movq	%rbx, -16416(%rbp)
	movq	%r15, %rdi
	movabsq	$4294971392, %rbx
	movq	%rax, -16488(%rbp)
	movl	$1009, -16480(%rbp)
	movq	$9, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$27, %edx
	leaq	.LC487(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	movq	%r12, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movabsq	$4294967424, %rax
	movq	%rax, -16496(%rbp)
	movl	$1010, -16480(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movl	-27264(%rbp), %eax
	movl	%eax, -27488(%rbp)
	testl	%eax, %eax
	jne	.L4820
.L3832:
	movl	-27244(%rbp), %r12d
	testl	%r12d, %r12d
	jne	.L4821
.L3833:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movabsq	$4294971392, %rbx
	leaq	.LC493(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1016, -16480(%rbp)
	movq	$8, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$20, %edx
	leaq	.LC494(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	vmovsd	-26752(%rbp), %xmm0
	movq	-27752(%rbp), %rsi
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movl	$8, %edx
	movq	%r15, %rdi
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movl	-27312(%rbp), %ecx
	testl	%ecx, %ecx
	jne	.L4822
	cmpl	$0, -27488(%rbp)
	jne	.L3836
	cmpl	$0, 60+wal_(%rip)
	je	.L3835
.L3836:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC498(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movl	$1021, -16480(%rbp)
	movq	$8, -16408(%rbp)
	call	_gfortran_st_write@PLT
	leaq	.LC499(%rip), %rsi
	movl	$18, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	-26760(%rbp), %rsi
.L4620:
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
.L3835:
	movl	68+wal_(%rip), %edx
	testl	%edx, %edx
	jne	.L4823
.L3837:
	movl	-27488(%rbp), %eax
	testl	%eax, %eax
	jne	.L4824
.L3838:
	movl	60+wal_(%rip), %eax
	testl	%eax, %eax
	jne	.L4825
.L3839:
	movl	-27324(%rbp), %eax
	testl	%eax, %eax
	jne	.L4826
.L3840:
	movl	-27272(%rbp), %eax
	movl	%eax, -28044(%rbp)
	testl	%eax, %eax
	jne	.L4827
.L3841:
	movl	80028+misc_(%rip), %eax
	testl	%eax, %eax
	jne	.L4828
.L3842:
	movq	-27640(%rbp), %rax
	leaq	.LC511(%rip), %rbx
	movq	%rbx, -16416(%rbp)
	movq	%r15, %rdi
	movabsq	$4294971392, %rbx
	movq	%rax, -16488(%rbp)
	movq	%rbx, -16496(%rbp)
	movl	$1047, -16480(%rbp)
	movq	$11, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$11, %edx
	leaq	.LC512(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	leaq	restart_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27640(%rbp), %rax
	leaq	.LC513(%rip), %rsi
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	%rsi, -16416(%rbp)
	movq	%rbx, -16496(%rbp)
	movl	$1048, -16480(%rbp)
	movq	$9, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$11, %edx
	leaq	.LC514(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	leaq	-26944(%rbp), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27640(%rbp), %rax
	leaq	.LC480(%rip), %rsi
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	%rsi, -16416(%rbp)
	movq	%rbx, -16496(%rbp)
	movl	$1049, -16480(%rbp)
	movq	$9, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$24, %edx
	leaq	.LC515(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	-27228(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	%r13, -16416(%rbp)
	movq	%rbx, -16496(%rbp)
	movl	$1050, -16480(%rbp)
	movq	$7, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$24, %edx
	leaq	.LC516(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	-27248(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	%r13, -16416(%rbp)
	movq	%rbx, -16496(%rbp)
	movl	$1051, -16480(%rbp)
	movq	$7, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$24, %edx
	leaq	.LC517(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	-27252(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	%r13, -16416(%rbp)
	movq	%rbx, -16496(%rbp)
	movl	$1052, -16480(%rbp)
	movq	$7, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$24, %edx
	leaq	.LC518(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	leaq	equil_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	%r13, -16416(%rbp)
	movq	%rbx, -16496(%rbp)
	movl	$1053, -16480(%rbp)
	movq	$7, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$24, %edx
	leaq	.LC519(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	-27512(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27640(%rbp), %r13
	leaq	.LC520(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, -16416(%rbp)
	movq	%rbx, -16496(%rbp)
	movq	%r13, -16488(%rbp)
	movl	$1054, -16480(%rbp)
	movq	$14, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$18, %edx
	leaq	.LC521(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	-26792(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	-26832(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	-26784(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC522(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, -16416(%rbp)
	movq	%rbx, -16496(%rbp)
	movq	%r13, -16488(%rbp)
	movl	$1055, -16480(%rbp)
	movq	$6, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movl	$28, %edx
	leaq	.LC523(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	-27232(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	vmovsd	restart_(%rip), %xmm2
	vmovsd	.LC8(%rip), %xmm7
	vmovsd	.LC11(%rip), %xmm0
	vdivsd	%xmm2, %xmm7, %xmm3
	vmovsd	-27848(%rbp), %xmm4
	vmovsd	.LC427(%rip), %xmm5
	vmulsd	%xmm2, %xmm2, %xmm7
	vmovsd	%xmm7, -27880(%rbp)
	vandpd	%xmm3, %xmm0, %xmm1
	vorpd	%xmm1, %xmm4, %xmm1
	vaddsd	%xmm3, %xmm1, %xmm1
	vmovsd	.LC100(%rip), %xmm4
	vcvttsd2sil	%xmm1, %eax
	movl	%eax, %ecx
	movl	%eax, -28096(%rbp)
	imull	%eax, %r12d
	movl	%eax, %ebx
	imull	-27396(%rbp), %eax
	vmovd	%ecx, %xmm6
	vpshufd	$0, %xmm6, %xmm1
	movl	%eax, -27396(%rbp)
	movl	-27252(%rbp), %eax
	vpmulld	equil_(%rip), %xmm1, %xmm1
	imull	%ecx, %eax
	vmovdqa	%xmm1, equil_(%rip)
	vmulsd	-26912(%rbp), %xmm5, %xmm1
	movl	%eax, -27252(%rbp)
	movl	-27376(%rbp), %eax
	vmovsd	.LC60(%rip), %xmm6
	imull	%ecx, %eax
	vandpd	%xmm1, %xmm0, %xmm0
	vorpd	%xmm0, %xmm6, %xmm0
	movl	%eax, -27376(%rbp)
	movl	-27520(%rbp), %eax
	vaddsd	%xmm1, %xmm0, %xmm0
	imull	%ecx, %eax
	imull	-27248(%rbp), %ebx
	vmovsd	%xmm6, -27848(%rbp)
	movl	%eax, -27388(%rbp)
	movl	-27400(%rbp), %eax
	vmulsd	%xmm7, %xmm4, %xmm6
	imull	%ecx, %eax
	movl	%ebx, -27472(%rbp)
	movl	%ebx, -27248(%rbp)
	movl	%eax, -27400(%rbp)
	vcvttsd2sil	%xmm0, %eax
	vmulsd	-26928(%rbp), %xmm2, %xmm0
	movl	%ecx, %ebx
	imull	-27380(%rbp), %ebx
	imull	%ecx, %eax
	movl	%r12d, -27244(%rbp)
	vmovsd	%xmm0, -26928(%rbp)
	movl	%eax, -28092(%rbp)
	movl	%ebx, -27380(%rbp)
	vmovsd	%xmm6, -28088(%rbp)
	vmovsd	.LC72(%rip), %xmm5
	movq	.LC525(%rip), %rax
	vmulsd	%xmm7, %xmm5, %xmm0
	movq	-27512(%rbp), %rdi
	movq	%rax, 32+parm_(%rip)
	vmovsd	%xmm0, -27056(%rbp)
	vmovapd	.LC524(%rip), %ymm0
	vmovapd	%ymm0, parm_(%rip)
	call	ran2_
	movl	-27952(%rbp), %eax
	testl	%eax, %eax
	jle	.L3843
	vmovsd	-28032(%rbp), %xmm6
	leaq	-25744(%rbp), %rax
	vaddsd	%xmm6, %xmm6, %xmm6
	movq	%rax, -27864(%rbp)
	leaq	-26800(%rbp), %rax
	vmovsd	%xmm6, -27960(%rbp)
	vmovsd	.LC72(%rip), %xmm6
	movl	$1, -28048(%rbp)
	vdivsd	%xmm7, %xmm6, %xmm7
	vmulsd	-28064(%rbp), %xmm6, %xmm5
	movq	%rax, -28056(%rbp)
	movq	%r14, -27464(%rbp)
	movq	%r15, -27976(%rbp)
	leaq	-26272(%rbp), %r13
	vmovsd	%xmm5, -28128(%rbp)
	vmovsd	-27704(%rbp), %xmm5
	movl	%ebx, %r12d
	vmovsd	%xmm5, -27760(%rbp)
	vmovsd	%xmm7, -27712(%rbp)
.L4195:
	movl	-27948(%rbp), %r15d
	testl	%r15d, %r15d
	je	.L3844
	movl	equil_(%rip), %r14d
	testl	%r14d, %r14d
	jg	.L4829
.L3844:
	movq	-27864(%rbp), %rax
	movq	%r13, %rdi
	vmovsd	(%rax), %xmm0
	movq	-27640(%rbp), %rax
	vmovsd	%xmm0, -26800(%rbp)
	movq	%rax, -26264(%rbp)
	leaq	.LC530(%rip), %rax
	movq	%rax, -26192(%rbp)
	movabsq	$4294971392, %rax
	movq	%rax, -26272(%rbp)
	vmovsd	%xmm0, -27504(%rbp)
	movl	$1094, -26256(%rbp)
	movq	$10, -26184(%rbp)
	call	_gfortran_st_write@PLT
	movl	$13, %edx
	leaq	.LC531(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	-28056(%rbp), %rsi
	movl	$8, %edx
.L4621:
	movq	%r13, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	restart_(%rip), %rax
	vmovsd	(%rax), %xmm2
	vmovsd	-26944(%rbp), %xmm1
	vmovsd	-27504(%rbp), %xmm0
	vdivsd	%xmm2, %xmm1, %xmm3
	vmulsd	%xmm2, %xmm1, %xmm1
	movl	80028+misc_(%rip), %ecx
	vmovsd	%xmm3, -26936(%rbp)
	vaddsd	%xmm0, %xmm0, %xmm3
	vmulsd	-27480(%rbp), %xmm0, %xmm0
	vmulsd	%xmm3, %xmm1, %xmm1
	vmulsd	-28088(%rbp), %xmm0, %xmm0
	vsqrtsd	%xmm1, %xmm1, %xmm1
	vmulsd	%xmm1, %xmm2, %xmm1
	vmovsd	%xmm0, -27200(%rbp)
	vmovsd	%xmm1, -27112(%rbp)
	testl	%ecx, %ecx
	jne	.L4830
.L3847:
	movl	-28044(%rbp), %ebx
	movl	$0, -27448(%rbp)
	testl	%ebx, %ebx
	je	.L3849
	movq	$0x000000000, -28024(%rbp)
	movq	$0x000000000, -28016(%rbp)
	movq	$0x000000000, -28008(%rbp)
	movq	$0x000000000, -28000(%rbp)
	movq	$0x000000000, -27992(%rbp)
	movq	$0x000000000, -27984(%rbp)
.L3849:
	movl	-27472(%rbp), %eax
	movl	-27488(%rbp), %r11d
	cltd
	idivl	%r12d
	vmovd	%eax, %xmm0
	movl	%eax, %ebx
	vmovd	%xmm0, -28080(%rbp)
	vmovd	%xmm0, -28040(%rbp)
	testl	%r11d, %r11d
	jne	.L3850
	movl	60+wal_(%rip), %r10d
	testl	%r10d, %r10d
	jne	.L3850
.L3851:
	movl	-27228(%rbp), %eax
	movl	-27324(%rbp), %ebx
	movl	$0, -27428(%rbp)
	movl	%eax, -28036(%rbp)
	movl	$1, -27424(%rbp)
	movl	%ebx, -27520(%rbp)
	testl	%eax, %eax
	jle	.L4241
	movl	$1, %r15d
	movq	-27464(%rbp), %r14
	movl	%r15d, -27472(%rbp)
	movq	%r13, %r15
	movl	%ecx, %r13d
.L4168:
	movl	-27948(%rbp), %r9d
	testl	%r9d, %r9d
	je	.L3854
	vmovsd	-26824(%rbp), %xmm0
	leaq	restart_(%rip), %rax
	vmulsd	-26944(%rbp), %xmm0, %xmm2
	vmovsd	(%rax), %xmm1
	vmovsd	%xmm0, -26800(%rbp)
	vaddsd	%xmm1, %xmm1, %xmm3
	vmulsd	-26920(%rbp), %xmm0, %xmm0
	vmulsd	%xmm3, %xmm2, %xmm2
	vmulsd	-28088(%rbp), %xmm0, %xmm0
	vsqrtsd	%xmm2, %xmm2, %xmm2
	vmulsd	%xmm2, %xmm1, %xmm1
	vmovsd	%xmm0, -27200(%rbp)
	vmovsd	%xmm1, -27112(%rbp)
.L3854:
	movl	248008+nat_(%rip), %eax
	vmovsd	-27760(%rbp), %xmm5
	movl	%eax, 2000016+cmapi_(%rip)
	vmovdqa	.LC532(%rip), %ymm4
	leaq	verl_(%rip), %rax
	vandpd	.LC69(%rip), %xmm5, %xmm7
	movl	-27520(%rbp), %r8d
	movq	$0, 120240016(%rax)
	leaq	cmp2_(%rip), %rax
	movl	$0, 40+wal_(%rip)
	movq	$0x000000000, -26960(%rbp)
	movq	$0x000000000, -26952(%rbp)
	movq	$0x000000000, 8+restart_(%rip)
	movl	$1, 48+kier_(%rip)
	movl	$0, 2000024+cmapi_(%rip)
	movq	$0, 8+ssb2_(%rip)
	movq	$0x000000000, -27128(%rbp)
	movq	$0x000000000, 24+kier_(%rip)
	movl	$0, 60000004(%rax)
	movl	$1, 540000008(%rax)
	vmovdqu	%ymm4, 8+wal_(%rip)
	vmovsd	%xmm7, -27464(%rbp)
	testl	%r8d, %r8d
	je	.L3855
	testl	%r13d, %r13d
	jne	.L3855
	movl	-28044(%rbp), %edi
	testl	%edi, %edi
	jne	.L3855
	movl	-27228(%rbp), %edx
	movl	%edx, %eax
	shrl	$31, %eax
	addl	%edx, %eax
	sarl	%eax
	incl	%eax
	cmpl	-27448(%rbp), %eax
	jl	.L4242
.L3855:
	movl	-27428(%rbp), %eax
	movl	$1, -27452(%rbp)
	movl	%eax, -27968(%rbp)
	incl	%eax
	movl	%eax, -27428(%rbp)
	leaq	cmap_(%rip), %rax
	movslq	60000004(%rax), %rax
	testl	%eax, %eax
	jle	.L3857
	leaq	0(,%rax,4), %r12
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	kbt.6(%rip), %rdi
	vzeroupper
	call	memset@PLT
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	kut.5(%rip), %rdi
	call	memset@PLT
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	8+cmapi_(%rip), %rdi
	call	memset@PLT
.L3857:
	movq	-27976(%rbp), %rax
	movl	-27272(%rbp), %esi
	vpxor	%xmm0, %xmm0, %xmm0
	vmovdqa	%xmm0, (%rax)
	vmovdqa	%xmm0, 16(%rax)
	testl	%esi, %esi
	je	.L3858
	movq	$0x000000000, -26904(%rbp)
	movq	$0x000000000, -27784(%rbp)
	movq	$0x000000000, -27800(%rbp)
	movq	$0x000000000, -27808(%rbp)
	movq	$0x000000000, -27792(%rbp)
.L3858:
	testl	%r13d, %r13d
	jne	.L4278
	movl	-27520(%rbp), %ecx
	testl	%ecx, %ecx
	jne	.L4278
	movl	16+bas_(%rip), %eax
	testl	%eax, %eax
	jne	.L3869
	movl	-27276(%rbp), %eax
	testl	%eax, %eax
	je	.L3870
.L3869:
	movl	8+bas_(%rip), %r12d
	movl	$1, -27452(%rbp)
	leaq	bon_(%rip), %rbx
	testl	%r12d, %r12d
	jle	.L3868
	movslq	%r12d, %r13
	salq	$3, %r13
	movq	%r13, %rdx
	leaq	nat_(%rip), %rsi
	leaq	pos_(%rip), %rdi
	vzeroupper
	call	memcpy@PLT
	movq	%r13, %rdx
	leaq	80000+nat_(%rip), %rsi
	leaq	80000+pos_(%rip), %rdi
	call	memcpy@PLT
	incl	%r12d
	movq	%r13, %rdx
	leaq	160000+nat_(%rip), %rsi
	leaq	160000+pos_(%rip), %rdi
	call	memcpy@PLT
	movl	%r12d, -27452(%rbp)
.L3868:
	movl	-27964(%rbp), %eax
	testl	%eax, %eax
	jne	.L4831
.L3872:
	movl	160008+bon_(%rip), %r13d
	leaq	plates_(%rip), %rax
	movq	%rax, -27608(%rbp)
	testl	%r13d, %r13d
	je	.L4832
.L3873:
	movl	60+wal_(%rip), %eax
	testl	%eax, %eax
	jne	.L3880
	vmovsd	40+plates_(%rip), %xmm4
	vmovsd	48+plates_(%rip), %xmm6
	movq	-27608(%rbp), %rax
	vmovsd	56+plates_(%rip), %xmm7
	vmovsd	64+plates_(%rip), %xmm5
	vmovsd	%xmm4, -27656(%rbp)
	vmovsd	%xmm6, -27648(%rbp)
	vmovsd	8+plates_(%rip), %xmm4
	vmovsd	(%rax), %xmm6
	vmovsd	%xmm7, -27672(%rbp)
	vmovsd	%xmm5, -27664(%rbp)
	vmovsd	%xmm4, -27688(%rbp)
	vmovsd	%xmm6, -27680(%rbp)
.L3881:
	movl	-27488(%rbp), %r13d
	testl	%r13d, %r13d
	je	.L3901
	movslq	120004+respul_(%rip), %rcx
	leaq	nat_(%rip), %rax
	movslq	120000+respul_(%rip), %rdx
	vmovsd	79992(%rax,%rcx,8), %xmm5
	vmovsd	-8(%rax,%rcx,8), %xmm6
	vsubsd	79992(%rax,%rdx,8), %xmm5, %xmm2
	vsubsd	-8(%rax,%rdx,8), %xmm6, %xmm3
	vmovsd	159992(%rax,%rcx,8), %xmm4
	vmulsd	%xmm2, %xmm2, %xmm0
	vsubsd	159992(%rax,%rdx,8), %xmm4, %xmm1
	vmovsd	.LC8(%rip), %xmm7
	vmovsd	%xmm6, pull_(%rip)
	vmovsd	%xmm5, 80000+pull_(%rip)
	vfmadd231sd	%xmm3, %xmm3, %xmm0
	vmovsd	%xmm4, 160000+pull_(%rip)
	vfmadd231sd	%xmm1, %xmm1, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vdivsd	%xmm0, %xmm7, %xmm0
	vmovsd	-27704(%rbp), %xmm7
	vmulsd	%xmm0, %xmm3, %xmm3
	vmulsd	%xmm0, %xmm2, %xmm2
	vmulsd	%xmm0, %xmm1, %xmm0
	vmovsd	%xmm3, kier_(%rip)
	vmovsd	%xmm2, 8+kier_(%rip)
	vmovsd	%xmm0, 16+kier_(%rip)
	vmulsd	%xmm7, %xmm0, %xmm0
	vmulsd	%xmm7, %xmm3, %xmm3
	vmulsd	%xmm7, %xmm2, %xmm2
	vxorpd	%xmm7, %xmm7, %xmm7
	vmovsd	%xmm0, 240016+pull_(%rip)
	vcvtsi2sdl	8+bas_(%rip), %xmm7, %xmm0
	vmovsd	%xmm3, 240000+pull_(%rip)
	vmovsd	%xmm2, 240008+pull_(%rip)
	vmovsd	%xmm0, %xmm0, %xmm1
	vmovsd	.LC533(%rip), %xmm0
	vmulsd	(%rbx), %xmm0, %xmm0
	vmulsd	%xmm0, %xmm1, %xmm7
	vmovsd	%xmm7, -27872(%rbp)
.L3901:
	leaq	-26920(%rbp), %rsi
	leaq	-27200(%rbp), %rdi
	movq	%r14, %rdx
	vzeroupper
	call	intvel3d_
	movl	8+bas_(%rip), %edx
	movq	$0x000000000, 16+restart_(%rip)
	movl	$1, -27452(%rbp)
	testl	%edx, %edx
	jle	.L3902
	movslq	-27764(%rbp), %rax
	leaq	-2(%rax,%rax), %r10
	leal	-1(%rdx), %eax
	leaq	1(%r10), %r11
	cmpl	$6, %eax
	jbe	.L4248
	movl	%edx, %esi
	shrl	$3, %esi
	leaq	ssb_(%rip), %r12
	salq	$5, %rsi
	movq	%r12, %rcx
	leaq	40360+sdch_(%rip), %rax
	addq	%r12, %rsi
	vpxor	%xmm0, %xmm0, %xmm0
	.p2align 4,,10
	.p2align 3
.L3904:
	vmovdqa	%ymm0, 40000(%rcx)
	vmovdqa	%ymm0, (%rcx)
	addq	$32, %rcx
	vmovdqu	%ymm0, (%rax)
	vmovdqu	%ymm0, 32(%rax)
	vmovdqu	%ymm0, 64(%rax)
	vmovdqu	%ymm0, 96(%rax)
	subq	$-128, %rax
	cmpq	%rsi, %rcx
	jne	.L3904
	movl	%edx, %eax
	andl	$-8, %eax
	leal	1(%rax), %esi
	cmpl	%edx, %eax
	je	.L4833
	vzeroupper
.L3903:
	movl	%edx, %r8d
	subl	%eax, %r8d
	leal	-1(%r8), %ecx
	leaq	sdch_(%rip), %rdi
	cmpl	$2, %ecx
	jbe	.L3906
	vpxor	%xmm0, %xmm0, %xmm0
	movl	%eax, %ecx
	leaq	-40000+ssb_(%rip), %r9
	addl	$10000, %eax
	vmovdqa	%xmm0, (%r12,%rax,4)
	salq	$4, %rcx
	vmovdqa	%xmm0, (%r9,%rax,4)
	leaq	sdch_(%rip), %rdi
	movl	%r8d, %eax
	leaq	40360(%rdi,%rcx), %rcx
	andl	$-4, %eax
	vmovdqu	%xmm0, (%rcx)
	vmovdqu	%xmm0, 16(%rcx)
	vmovdqu	%xmm0, 32(%rcx)
	vmovdqu	%xmm0, 48(%rcx)
	addl	%eax, %esi
	cmpl	%r8d, %eax
	je	.L3905
.L3906:
	leal	-1(%rsi), %eax
	cltq
	movl	$0, 40000(%r12,%rax,4)
	movl	$0, (%r12,%rax,4)
	vpxor	%xmm0, %xmm0, %xmm0
	salq	$2, %rax
	leal	1(%rsi), %ecx
	movslq	%esi, %r8
	vmovdqu	%xmm0, 40360(%rdi,%rax,4)
	cmpl	%ecx, %edx
	jl	.L3905
	addl	$2, %esi
	movl	$0, 40000(%r12,%r8,4)
	movl	$0, (%r12,%r8,4)
	movslq	%ecx, %rcx
	vmovdqu	%xmm0, 40376(%rdi,%rax,4)
	cmpl	%edx, %esi
	jg	.L3905
	movl	$0, 40000(%r12,%rcx,4)
	movl	$0, (%r12,%rcx,4)
	vmovdqu	%xmm0, 40392(%rdi,%rax,4)
.L3905:
	leaq	neigh_(%rip), %rax
	incl	%edx
	movl	$0, (%rax,%r10,4)
	movl	%edx, -27452(%rbp)
	movl	$0, (%rax,%r11,4)
.L3902:
	movl	80036+ssb_(%rip), %r12d
	testl	%r12d, %r12d
	je	.L4834
.L3909:
	cmpl	$1, -27472(%rbp)
	jle	.L3912
	leaq	equil_(%rip), %rax
	vmovsd	-27464(%rbp), %xmm5
	movl	$0, -27292(%rbp)
	movq	%rax, -27480(%rbp)
	vmovsd	%xmm5, -27760(%rbp)
	xorl	%ebx, %ebx
.L3913:
	movq	-27608(%rbp), %rax
	vmovsd	40+plates_(%rip), %xmm2
	vmovsd	56+plates_(%rip), %xmm1
	vmovsd	8+plates_(%rip), %xmm0
	vsubsd	48+plates_(%rip), %xmm2, %xmm2
	vsubsd	(%rax), %xmm0, %xmm0
	vsubsd	64+plates_(%rip), %xmm1, %xmm1
	vmovsd	.LC8(%rip), %xmm4
	vmovsd	%xmm2, 240000+for_(%rip)
	vmovsd	%xmm1, 240008+for_(%rip)
	vdivsd	%xmm2, %xmm4, %xmm2
	vmovsd	%xmm0, 240016+for_(%rip)
	movq	-27776(%rbp), %rdi
	movq	%r14, %rsi
	leaq	-27008(%rbp), %r12
	vdivsd	%xmm1, %xmm4, %xmm1
	vmovsd	%xmm2, 240024+for_(%rip)
	vdivsd	%xmm0, %xmm4, %xmm0
	vmovsd	%xmm1, 240032+for_(%rip)
	vmovsd	%xmm0, 240040+for_(%rip)
	call	update_verlet_list_
	movq	%r12, %rdi
	call	prepare_
	movq	-27536(%rbp), %rsi
	movq	%r12, %rdi
	call	evalgo_
	movl	60+wal_(%rip), %eax
	testl	%eax, %eax
	je	.L3943
	movl	-27316(%rbp), %r13d
	testl	%r13d, %r13d
	je	.L4835
.L3943:
	movl	10004072+nmapi_(%rip), %r11d
	testl	%r11d, %r11d
	je	.L3944
	leaq	-27000(%rbp), %rdx
	leaq	-27344(%rbp), %rsi
	movq	%r12, %rdi
	call	evalimproper_
	movl	80016+chiral_(%rip), %r10d
	testl	%r10d, %r10d
	jne	.L4836
.L3946:
	movl	80020+chiral_(%rip), %r9d
	testl	%r9d, %r9d
	jne	.L3947
	movl	20+bas_(%rip), %r8d
	testl	%r8d, %r8d
	je	.L3948
.L3947:
	leaq	-27284(%rbp), %rsi
	leaq	.LC534(%rip), %rdx
	movq	%r12, %rdi
	call	evalangles_
.L3948:
	movl	8+bas_(%rip), %ecx
	movl	$1, -27452(%rbp)
	testl	%ecx, %ecx
	jle	.L3949
	leal	-1(%rcx), %eax
	vmovsd	-27056(%rbp), %xmm0
	cmpl	$2, %eax
	jbe	.L4253
	movl	%ecx, %esi
	shrl	$2, %esi
	leaq	160000+der_(%rip), %rax
	salq	$5, %rsi
	vbroadcastsd	%xmm0, %ymm1
	leaq	160000+for_(%rip), %rdx
	addq	%rax, %rsi
	.p2align 4,,10
	.p2align 3
.L3951:
	vmulpd	-160000(%rdx), %ymm1, %ymm2
	addq	$32, %rax
	addq	$32, %rdx
	vmovapd	%ymm2, -160032(%rax)
	vmulpd	-80032(%rdx), %ymm1, %ymm2
	vmovapd	%ymm2, -80032(%rax)
	vmulpd	-32(%rdx), %ymm1, %ymm2
	vmovapd	%ymm2, -32(%rax)
	cmpq	%rax, %rsi
	jne	.L3951
	movl	%ecx, %edx
	andl	$-4, %edx
	leal	1(%rdx), %eax
	cmpl	%ecx, %edx
	je	.L4837
	vzeroupper
.L3950:
	movl	%ecx, %r9d
	subl	%edx, %r9d
	leaq	der_(%rip), %rsi
	leaq	for_(%rip), %rdi
	cmpl	$1, %r9d
	je	.L3953
	vmovddup	%xmm0, %xmm1
	leaq	for_(%rip), %rdi
	vmulpd	(%rdi,%rdx,8), %xmm1, %xmm2
	leaq	der_(%rip), %rsi
	leaq	0(,%rdx,8), %r8
	vmovapd	%xmm2, (%rsi,%rdx,8)
	vmulpd	80000(%rdi,%rdx,8), %xmm1, %xmm2
	movl	%r9d, %edx
	andl	$-2, %edx
	addl	%edx, %eax
	vmovapd	%xmm2, 80000(%rsi,%r8)
	vmulpd	160000(%rdi,%r8), %xmm1, %xmm1
	vmovapd	%xmm1, 160000(%rsi,%r8)
	cmpl	%r9d, %edx
	je	.L3952
.L3953:
	decl	%eax
	cltq
	vmulsd	(%rdi,%rax,8), %xmm0, %xmm1
	vmovsd	%xmm1, (%rsi,%rax,8)
	vmulsd	80000(%rdi,%rax,8), %xmm0, %xmm1
	vmulsd	160000(%rdi,%rax,8), %xmm0, %xmm0
	vmovsd	%xmm1, 80000(%rsi,%rax,8)
	vmovsd	%xmm0, 160000(%rsi,%rax,8)
.L3952:
	incl	%ecx
	movl	%ecx, -27452(%rbp)
.L3949:
	movl	-27388(%rbp), %eax
	movl	%eax, -27628(%rbp)
	testl	%eax, %eax
	jne	.L4838
.L3955:
	movl	-27376(%rbp), %eax
	movl	%eax, -27632(%rbp)
	testl	%eax, %eax
	jne	.L4839
.L3956:
	movl	-27328(%rbp), %eax
	movl	-27296(%rbp), %esi
	movl	%eax, -27472(%rbp)
	movl	-27320(%rbp), %eax
	movl	%esi, -27696(%rbp)
	movl	%eax, -27528(%rbp)
	movl	-27252(%rbp), %eax
	movl	$1, -27464(%rbp)
	movl	%eax, -27504(%rbp)
	movl	-27396(%rbp), %eax
	movq	$0x000000000, -27912(%rbp)
	movl	%eax, -27692(%rbp)
	addl	%eax, %eax
	movl	%eax, -27768(%rbp)
	leaq	-27112(%rbp), %rax
	movq	%rax, -27544(%rbp)
	leaq	-26936(%rbp), %rax
	movq	%rax, -27600(%rbp)
	leaq	-26776(%rbp), %rax
	movq	%rax, -27552(%rbp)
	leaq	-27056(%rbp), %rax
	movq	$0x000000000, -27904(%rbp)
	movq	$0x000000000, -27896(%rbp)
	movq	$0x000000000, -27888(%rbp)
	movq	$0x000000000, -27824(%rbp)
	movq	$0x000000000, -27928(%rbp)
	movq	$0x000000000, -27856(%rbp)
	movq	$0x000000000, -27816(%rbp)
	movq	$0x000000000, -27744(%rbp)
	movq	$0x000000000, -27736(%rbp)
	movq	$0x000000000, -27728(%rbp)
	movq	$0x000000000, -27720(%rbp)
	movq	$0x000000000, -27624(%rbp)
	movq	$0x000000000, -27840(%rbp)
	movq	$0x000000000, -27832(%rbp)
	movq	$0x000000000, -27616(%rbp)
	movq	%rax, -27560(%rbp)
	.p2align 4,,10
	.p2align 3
.L3961:
	movl	-27472(%rbp), %r11d
	incl	%ebx
	movl	%ebx, -27408(%rbp)
	movq	-27544(%rbp), %rdx
	movq	-27600(%rbp), %rsi
	movq	-27552(%rbp), %rdi
	movq	%r14, %rcx
	testl	%r11d, %r11d
	je	.L3962
	call	lang_mass_
.L3963:
	movq	-27560(%rbp), %rdi
	movq	%r14, %rsi
	call	corr_
	movq	%r14, %rdi
	call	predct_
	movq	%r12, %rdi
	call	prepare_
	movq	-27536(%rbp), %rsi
	movq	%r12, %rdi
	call	evalgo_
	movl	60+wal_(%rip), %r10d
	testl	%r10d, %r10d
	je	.L3964
	movl	-27316(%rbp), %r9d
	testl	%r9d, %r9d
	je	.L4840
.L3964:
	movl	10004072+nmapi_(%rip), %r8d
	testl	%r8d, %r8d
	je	.L3965
	movq	%r12, %rdi
	leaq	-27000(%rbp), %rdx
	leaq	-27344(%rbp), %rsi
	call	evalimproper_
	movl	80016+chiral_(%rip), %edi
	testl	%edi, %edi
	jne	.L4841
.L3967:
	movl	80020+chiral_(%rip), %esi
	testl	%esi, %esi
	jne	.L3968
	movl	20+bas_(%rip), %ecx
	testl	%ecx, %ecx
	je	.L3969
.L3968:
	movl	-27284(%rbp), %edx
	testl	%edx, %edx
	je	.L3970
	vxorpd	%xmm4, %xmm4, %xmm4
	vcvtsi2sdl	%ebx, %xmm4, %xmm0
	vmovsd	80000+misc_(%rip), %xmm1
	vcomisd	%xmm0, %xmm1
	jb	.L3970
	vdivsd	%xmm1, %xmm0, %xmm0
	vmovsd	%xmm0, -27128(%rbp)
.L3970:
	leaq	-27128(%rbp), %rdx
	leaq	-27284(%rbp), %rsi
	movq	%r12, %rdi
	call	evalangles_
.L3969:
	movl	-27472(%rbp), %eax
	testl	%eax, %eax
	jne	.L4842
.L3972:
	movq	-27480(%rbp), %rax
	movl	60+wal_(%rip), %r13d
	movl	(%rax), %eax
	cmpl	%eax, %ebx
	jg	.L4843
	movl	$8261, %edx
	movw	%dx, -450(%rbp)
	jne	.L4048
	testl	%eax, %eax
	jg	.L4844
.L4048:
	testl	%r13d, %r13d
	je	.L4049
	movl	-27244(%rbp), %ecx
	testl	%ecx, %ecx
	je	.L4049
	movl	%ebx, %eax
	cltd
	idivl	%ecx
	vmovsd	-27624(%rbp), %xmm6
	vmovsd	-27616(%rbp), %xmm5
	movl	64+wal_(%rip), %eax
	vaddsd	16+plates_(%rip), %xmm6, %xmm7
	vaddsd	24+plates_(%rip), %xmm5, %xmm4
	vmovsd	%xmm7, -27624(%rbp)
	vmovsd	%xmm4, -27616(%rbp)
	testl	%edx, %edx
	jne	.L4052
	vxorpd	%xmm7, %xmm7, %xmm7
	vcvtsi2sdl	%ecx, %xmm7, %xmm0
	vmovsd	%xmm4, %xmm4, %xmm6
.L4219:
	vmovsd	-27624(%rbp), %xmm4
	vdivsd	%xmm0, %xmm6, %xmm5
	vdivsd	%xmm0, %xmm4, %xmm7
	vmovsd	%xmm5, -27816(%rbp)
	vmovsd	%xmm7, -27824(%rbp)
	testl	%eax, %eax
	jne	.L4053
	movq	$0x000000000, -27624(%rbp)
	movq	$0x000000000, -27616(%rbp)
	xorl	%edx, %edx
.L4197:
	movl	68+wal_(%rip), %r10d
	testl	%r10d, %r10d
	je	.L4049
	movl	8+wal_(%rip), %r9d
	testl	%r9d, %r9d
	jne	.L4049
	movl	12+bas_(%rip), %r8d
	testl	%r8d, %r8d
	jne	.L4049
	vmovsd	-27728(%rbp), %xmm6
	vaddsd	xyforces_(%rip), %xmm6, %xmm5
	vmovsd	-27744(%rbp), %xmm6
	vmovsd	%xmm5, -27728(%rbp)
	vmovsd	-27720(%rbp), %xmm5
	vaddsd	16+xyforces_(%rip), %xmm6, %xmm4
	vaddsd	8+xyforces_(%rip), %xmm5, %xmm7
	vmovsd	-27736(%rbp), %xmm5
	vmovsd	%xmm4, -27744(%rbp)
	vmovsd	%xmm7, -27720(%rbp)
	vaddsd	24+xyforces_(%rip), %xmm5, %xmm7
	vmovsd	%xmm7, -27736(%rbp)
	testl	%edx, %edx
	jne	.L4049
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%ecx, %xmm5, %xmm0
	.p2align 4,,10
	.p2align 3
.L4198:
	vmovsd	.LC8(%rip), %xmm5
	vdivsd	%xmm0, %xmm5, %xmm0
	vmulsd	-27728(%rbp), %xmm0, %xmm4
	vmulsd	-27720(%rbp), %xmm0, %xmm5
	vmulsd	-27744(%rbp), %xmm0, %xmm6
	movq	$0x000000000, -27728(%rbp)
	movq	$0x000000000, -27744(%rbp)
	vmovsd	%xmm4, -27896(%rbp)
	vmulsd	-27736(%rbp), %xmm0, %xmm4
	movq	$0x000000000, -27720(%rbp)
	movq	$0x000000000, -27736(%rbp)
	vmovsd	%xmm5, -27888(%rbp)
	vmovsd	%xmm6, -27912(%rbp)
	vmovsd	%xmm4, -27904(%rbp)
	.p2align 4,,10
	.p2align 3
.L4049:
	movl	-27528(%rbp), %edi
	testl	%edi, %edi
	je	.L4054
	movl	-27520(%rbp), %esi
	testl	%esi, %esi
	jne	.L4054
	movl	80036+ssb_(%rip), %ecx
	leaq	cmap_(%rip), %rax
	movl	2000008+cmapi_(%rip), %edx
	movl	60000004(%rax), %eax
	testl	%ecx, %ecx
	je	.L4627
	addl	8+ssb2_(%rip), %edx
	addl	248008+nat_(%rip), %eax
.L4627:
	cmpl	%eax, %edx
	setl	%al
	movzbl	%al, %eax
	movl	%eax, -27464(%rbp)
.L4054:
	cmpl	%ebx, -27504(%rbp)
	jg	.L4616
	movl	8+bas_(%rip), %esi
	testl	%esi, %esi
	jle	.L4260
	leal	-1(%rsi), %eax
	cmpl	$2, %eax
	jbe	.L4261
	movl	%esi, %edi
	shrl	$2, %edi
	leaq	mass_(%rip), %rdx
	salq	$5, %rdi
	movq	%rdx, %rcx
	leaq	160000+vel_(%rip), %rax
	addq	%rdx, %rdi
	vxorpd	%xmm2, %xmm2, %xmm2
	.p2align 4,,10
	.p2align 3
.L4059:
	vmovapd	-80000(%rax), %ymm1
	vmovapd	-160000(%rax), %ymm0
	vmulpd	%ymm1, %ymm1, %ymm1
	addq	$32, %rcx
	addq	$32, %rax
	vfmadd231pd	%ymm0, %ymm0, %ymm1
	vmovapd	-32(%rax), %ymm0
	vfmadd132pd	%ymm0, %ymm1, %ymm0
	vfmadd231pd	-32(%rcx), %ymm0, %ymm2
	cmpq	%rcx, %rdi
	jne	.L4059
	vextractf128	$0x1, %ymm2, %xmm0
	vaddpd	%xmm2, %xmm0, %xmm2
	movl	%esi, %edi
	andl	$-4, %edi
	vunpckhpd	%xmm2, %xmm2, %xmm0
	vaddpd	%xmm2, %xmm0, %xmm2
	leal	1(%rdi), %eax
	cmpl	%esi, %edi
	je	.L4060
.L4058:
	movl	%esi, %r8d
	subl	%edi, %r8d
	leaq	vel_(%rip), %rcx
	cmpl	$1, %r8d
	je	.L4061
	leaq	80000(%rcx), %r9
	vmovapd	(%r9,%rdi,8), %xmm1
	leaq	160000(%rcx), %r9
	vmovapd	(%r9,%rdi,8), %xmm3
	vmovapd	(%rcx,%rdi,8), %xmm0
	vmulpd	%xmm3, %xmm3, %xmm3
	vfmadd132pd	%xmm1, %xmm3, %xmm1
	vfmadd132pd	%xmm0, %xmm1, %xmm0
	vmulpd	(%rdx,%rdi,8), %xmm0, %xmm0
	movl	%r8d, %edi
	andl	$-2, %edi
	addl	%edi, %eax
	vunpckhpd	%xmm0, %xmm0, %xmm1
	vaddpd	%xmm0, %xmm1, %xmm0
	vaddsd	%xmm0, %xmm2, %xmm2
	cmpl	%r8d, %edi
	je	.L4060
.L4061:
	decl	%eax
	cltq
	vmovsd	80000(%rcx,%rax,8), %xmm0
	vmovsd	(%rcx,%rax,8), %xmm1
	vmulsd	%xmm0, %xmm0, %xmm0
	vfmadd132sd	%xmm1, %xmm0, %xmm1
	vmovsd	160000(%rcx,%rax,8), %xmm0
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vfmadd231sd	(%rdx,%rax,8), %xmm0, %xmm2
.L4060:
	vmulsd	-27712(%rbp), %xmm2, %xmm5
	vmovsd	%xmm5, -27568(%rbp)
	vmovsd	%xmm5, %xmm5, %xmm7
.L4057:
	vxorps	%xmm6, %xmm6, %xmm6
	vcvtsi2ssl	80024+misc_(%rip), %xmm6, %xmm0
	vcvtsi2ssl	%esi, %xmm6, %xmm1
	vaddsd	-27008(%rbp), %xmm7, %xmm5
	movl	80028+misc_(%rip), %r13d
	vdivss	%xmm1, %xmm0, %xmm0
	vmovsd	%xmm5, -27512(%rbp)
	vmovsd	%xmm5, -26992(%rbp)
	vaddss	.LC553(%rip), %xmm0, %xmm0
	vcvtss2sd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm0, -27176(%rbp)
	testl	%r13d, %r13d
	jne	.L4845
.L4063:
	movl	36+kier_(%rip), %eax
	vmovsd	240000+verl_(%rip), %xmm3
	testl	%eax, %eax
	je	.L4073
	vmovsd	48+plates_(%rip), %xmm0
	vmovsd	-27656(%rbp), %xmm5
	vsubsd	-27648(%rbp), %xmm0, %xmm0
	vsubsd	40+plates_(%rip), %xmm5, %xmm1
	vxorpd	%xmm4, %xmm4, %xmm4
	vmaxsd	%xmm4, %xmm0, %xmm0
	vmaxsd	%xmm4, %xmm1, %xmm1
	vaddsd	%xmm1, %xmm0, %xmm0
	vsubsd	%xmm0, %xmm3, %xmm3
.L4073:
	movl	40+kier_(%rip), %r13d
	testl	%r13d, %r13d
	je	.L4074
	vmovsd	64+plates_(%rip), %xmm0
	vmovsd	-27672(%rbp), %xmm5
	vsubsd	-27664(%rbp), %xmm0, %xmm0
	vsubsd	56+plates_(%rip), %xmm5, %xmm1
	vxorpd	%xmm4, %xmm4, %xmm4
	vmaxsd	%xmm4, %xmm0, %xmm0
	vmaxsd	%xmm4, %xmm1, %xmm1
	vaddsd	%xmm1, %xmm0, %xmm0
	vsubsd	%xmm0, %xmm3, %xmm3
.L4074:
	movl	44+kier_(%rip), %r11d
	testl	%r11d, %r11d
	je	.L4075
	movq	-27608(%rbp), %rax
	vmovsd	-27688(%rbp), %xmm5
	vmovsd	(%rax), %xmm0
	vsubsd	8+plates_(%rip), %xmm5, %xmm1
	vsubsd	-27680(%rbp), %xmm0, %xmm0
	vxorpd	%xmm4, %xmm4, %xmm4
	vmaxsd	%xmm4, %xmm1, %xmm1
	vmaxsd	%xmm4, %xmm0, %xmm0
	vaddsd	%xmm1, %xmm0, %xmm0
	vsubsd	%xmm0, %xmm3, %xmm3
.L4075:
	movl	$1, -27452(%rbp)
	testl	%esi, %esi
	jle	.L4076
	leaq	pos_(%rip), %rdx
	leaq	verl_(%rip), %rax
	movl	$1, %ecx
	jmp	.L4079
	.p2align 4,,10
	.p2align 3
.L4586:
	incl	%ecx
	addq	$8, %rdx
	addq	$24, %rax
	cmpl	%esi, %ecx
	jg	.L4846
.L4079:
	vmovsd	80000(%rdx), %xmm2
	vmovsd	(%rdx), %xmm1
	vsubsd	8(%rax), %xmm2, %xmm2
	vsubsd	(%rax), %xmm1, %xmm1
	vmovsd	160000(%rdx), %xmm0
	vmulsd	%xmm2, %xmm2, %xmm2
	vsubsd	16(%rax), %xmm0, %xmm0
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vcomisd	%xmm3, %xmm0
	jbe	.L4586
	movq	-27776(%rbp), %rdi
	movq	%r14, %rsi
	movl	%ecx, -27452(%rbp)
	vzeroupper
	call	update_verlet_list_
	vmovsd	40+plates_(%rip), %xmm6
	vmovsd	48+plates_(%rip), %xmm4
	movq	-27608(%rbp), %rax
	vmovsd	56+plates_(%rip), %xmm5
	vmovsd	64+plates_(%rip), %xmm7
	vmovsd	%xmm6, -27656(%rbp)
	vmovsd	%xmm4, -27648(%rbp)
	vmovsd	8+plates_(%rip), %xmm6
	vmovsd	(%rax), %xmm4
	vmovsd	%xmm5, -27672(%rbp)
	vmovsd	%xmm7, -27664(%rbp)
	vmovsd	%xmm6, -27688(%rbp)
	vmovsd	%xmm4, -27680(%rbp)
.L4076:
	movl	-27488(%rbp), %r10d
	movl	60+wal_(%rip), %ecx
	testl	%r10d, %r10d
	je	.L4080
	movl	%ebx, %eax
	cltd
	idivl	-27380(%rbp)
	testl	%edx, %edx
	jne	.L4082
	movslq	120000+respul_(%rip), %rdi
	leaq	pos_(%rip), %rsi
	movslq	120004+respul_(%rip), %rdx
	vmovsd	79992(%rsi,%rdi,8), %xmm2
	vmovsd	-8(%rsi,%rdi,8), %xmm1
	vsubsd	79992(%rsi,%rdx,8), %xmm2, %xmm2
	vsubsd	-8(%rsi,%rdx,8), %xmm1, %xmm1
	vmovsd	159992(%rsi,%rdi,8), %xmm0
	vmulsd	%xmm2, %xmm2, %xmm2
	vsubsd	159992(%rsi,%rdx,8), %xmm0, %xmm0
	cltq
	leaq	aree.9(%rip), %rsi
	movl	-27244(%rbp), %r9d
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	leaq	-1(%rax), %rdx
	leaq	aufres2.10(%rip), %rdi
	vmovsd	(%rdi,%rdx,8), %xmm2
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm0, -26888(%rbp)
	vaddsd	-8(%rsi,%rax,8), %xmm0, %xmm0
	leaq	aufres.11(%rip), %rax
	vmovsd	(%rax,%rdx,8), %xmm1
	vmovsd	%xmm0, (%rsi,%rdx,8)
	testl	%r9d, %r9d
	jne	.L4083
	vmovsd	-26960(%rbp), %xmm3
	vfmadd231sd	%xmm3, %xmm3, %xmm2
	vaddsd	%xmm1, %xmm3, %xmm1
	vmovsd	%xmm1, (%rax,%rdx,8)
	vmovsd	%xmm2, (%rdi,%rdx,8)
	testl	%ecx, %ecx
	je	.L4082
	vaddsd	240016+for_(%rip), %xmm0, %xmm0
	leaq	adfres2.7(%rip), %rcx
	vmovsd	(%rcx,%rdx,8), %xmm4
	vmovsd	%xmm0, (%rsi,%rdx,8)
	leaq	adfres.8(%rip), %rsi
	vmovsd	(%rsi,%rdx,8), %xmm0
.L4217:
	vmovsd	16+plates_(%rip), %xmm3
	vaddsd	%xmm1, %xmm3, %xmm1
	vfmadd132sd	%xmm3, %xmm2, %xmm3
	vmovsd	%xmm1, (%rax,%rdx,8)
	vmovsd	24+plates_(%rip), %xmm1
	vaddsd	%xmm0, %xmm1, %xmm0
	vfmadd132sd	%xmm1, %xmm4, %xmm1
	vmovsd	%xmm3, (%rdi,%rdx,8)
	vmovsd	%xmm0, (%rsi,%rdx,8)
	vmovsd	%xmm1, (%rcx,%rdx,8)
	.p2align 4,,10
	.p2align 3
.L4082:
	movl	-27632(%rbp), %esi
	testl	%esi, %esi
	je	.L4088
	cmpl	$1, %ebx
	je	.L4089
	movl	%ebx, %eax
	cltd
	idivl	%esi
	testl	%edx, %edx
	je	.L4089
	testb	$1, -27464(%rbp)
	je	.L4089
	movl	$1, -27464(%rbp)
.L4088:
	movl	-27628(%rbp), %esi
	testl	%esi, %esi
	je	.L4103
	movq	-27480(%rbp), %rax
	cmpl	%ebx, (%rax)
	jg	.L4104
	movl	%ebx, %eax
	cltd
	idivl	%esi
	testl	%edx, %edx
	je	.L4105
	cmpl	$1, %ebx
	je	.L4105
	.p2align 4,,10
	.p2align 3
.L4103:
	movl	-27692(%rbp), %esi
	testl	%esi, %esi
	je	.L4111
	movl	%ebx, %eax
	cltd
	idivl	%esi
	testl	%edx, %edx
	jne	.L4111
	movl	-27356(%rbp), %edx
	testl	%edx, %edx
	jne	.L4847
.L4112:
	leaq	-27424(%rbp), %r13
	leaq	-27408(%rbp), %rdi
	movq	%r13, %rsi
	vzeroupper
	call	print_restart_
	movl	-27340(%rbp), %eax
	testl	%eax, %eax
	je	.L4111
	movl	-27408(%rbp), %eax
	vxorpd	%xmm6, %xmm6, %xmm6
	subl	-27768(%rbp), %eax
	vcvtsi2sdl	%eax, %xmm6, %xmm0
	leaq	restart_(%rip), %rax
	vxorpd	%xmm5, %xmm5, %xmm5
	vmulsd	(%rax), %xmm0, %xmm0
	vcomisd	%xmm5, %xmm0
	vmovsd	%xmm0, -26816(%rbp)
	vmovsd	%xmm0, -27920(%rbp)
	ja	.L4848
	.p2align 4,,10
	.p2align 3
.L4111:
	movl	-27272(%rbp), %r13d
	testl	%r13d, %r13d
	je	.L4125
	movq	-27480(%rbp), %rax
	movl	(%rax), %eax
	cmpl	%eax, -27408(%rbp)
	jle	.L4125
	vmovsd	-27512(%rbp), %xmm7
	vmovsd	-27808(%rbp), %xmm6
	vmovsd	-27792(%rbp), %xmm5
	vfmadd231sd	%xmm7, %xmm7, %xmm6
	leaq	cmap_(%rip), %rax
	vaddsd	%xmm7, %xmm5, %xmm4
	movl	60000004(%rax), %eax
	cmpl	%eax, 2000008+cmapi_(%rip)
	vmovsd	%xmm4, -27792(%rbp)
	vmovsd	%xmm6, -27808(%rbp)
	jne	.L4126
	vmovsd	.LC8(%rip), %xmm6
	vaddsd	-26904(%rbp), %xmm6, %xmm0
	vmovsd	%xmm0, -26904(%rbp)
.L4126:
	vmovsd	-27136(%rbp), %xmm0
	vaddsd	-27800(%rbp), %xmm0, %xmm7
	vfmadd213sd	-27784(%rbp), %xmm0, %xmm0
	vmovsd	%xmm7, -27800(%rbp)
	vmovsd	%xmm0, -27784(%rbp)
.L4125:
	vmovsd	-27512(%rbp), %xmm4
	movl	$0, %eax
	vandpd	.LC69(%rip), %xmm4, %xmm0
	vcomisd	.LC563(%rip), %xmm0
	cmovbe	-27464(%rbp), %eax
	movl	%eax, -27464(%rbp)
	movl	-27696(%rbp), %eax
	testl	%eax, %eax
	jne	.L4849
.L4129:
	movl	-27520(%rbp), %eax
	testl	%eax, %eax
	jne	.L4131
	movl	-27504(%rbp), %eax
	movl	-27408(%rbp), %ebx
	addl	-27248(%rbp), %eax
	cmpl	%ebx, %eax
	jle	.L4132
	testb	$1, -27464(%rbp)
	je	.L4132
	movl	$1, -27464(%rbp)
	vzeroupper
	jmp	.L3961
.L4239:
	movl	%r11d, %edx
	xorl	%edi, %edi
	jmp	.L3813
	.p2align 4,,10
	.p2align 3
.L4849:
	vmovsd	-26872(%rbp), %xmm0
	vmulsd	bas_(%rip), %xmm0, %xmm0
	vcomisd	.LC124(%rip), %xmm0
	jbe	.L4129
	movl	-27520(%rbp), %eax
	testl	%eax, %eax
	je	.L4132
	movl	$0, -27464(%rbp)
	.p2align 4,,10
	.p2align 3
.L4131:
	leaq	cmap_(%rip), %rax
	movl	60000004(%rax), %eax
	cmpl	%eax, 2000008+cmapi_(%rip)
	jge	.L4132
	movl	-27504(%rbp), %eax
	movl	-27408(%rbp), %ebx
	addl	-27248(%rbp), %eax
	cmpl	%ebx, %eax
	jle	.L4132
.L4616:
	vzeroupper
	jmp	.L3961
	.p2align 4,,10
	.p2align 3
.L3965:
	movq	%r12, %rdi
	call	evalcpot_
	movl	80016+chiral_(%rip), %edi
	testl	%edi, %edi
	je	.L3967
.L4841:
	leaq	-27016(%rbp), %rdi
	call	eval_chirality_
	vmovsd	-27008(%rbp), %xmm0
	vaddsd	-27016(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, -27008(%rbp)
	jmp	.L3967
	.p2align 4,,10
	.p2align 3
.L3962:
	call	lang_
	jmp	.L3963
	.p2align 4,,10
	.p2align 3
.L4843:
	testl	%r13d, %r13d
	je	.L3979
	movl	68+wal_(%rip), %ecx
	vmovsd	16+plates_(%rip), %xmm1
	vmovsd	24+plates_(%rip), %xmm3
	vmovsd	-26960(%rbp), %xmm5
	testl	%ecx, %ecx
	je	.L3980
	movl	8+wal_(%rip), %edx
	testl	%edx, %edx
	jne	.L3981
	vmovsd	240000+for_(%rip), %xmm0
	vmovsd	-27960(%rbp), %xmm4
	vmulsd	240008+for_(%rip), %xmm0, %xmm0
	movl	%ebx, %r8d
	subl	%eax, %r8d
	movl	12+equil_(%rip), %edi
	vmulsd	240016+for_(%rip), %xmm0, %xmm0
	vcomisd	%xmm0, %xmm4
	jb	.L4580
	vmovsd	-27760(%rbp), %xmm6
	vmovsd	%xmm6, -27704(%rbp)
	cmpl	%r8d, %edi
	jle	.L3984
	vxorps	%xmm4, %xmm4, %xmm4
	vcvtsi2ssl	%r8d, %xmm4, %xmm2
	movl	$8275, %eax
	movw	%ax, -450(%rbp)
	vcvtss2sd	%xmm2, %xmm2, %xmm2
	vmulsd	%xmm6, %xmm2, %xmm2
	vxorpd	%xmm6, %xmm6, %xmm6
	vcvtsi2sdl	%edi, %xmm6, %xmm4
	vdivsd	%xmm4, %xmm2, %xmm7
	vmovsd	%xmm7, -27704(%rbp)
.L3984:
	vmovsd	-28032(%rbp), %xmm4
	vcomisd	%xmm0, %xmm4
	jnb	.L3985
	vmovsd	.LC72(%rip), %xmm4
	movl	32+kier_(%rip), %esi
	vmulsd	-27704(%rbp), %xmm4, %xmm4
	vmovsd	8+restart_(%rip), %xmm2
	movl	36+wal_(%rip), %edx
	.p2align 4,,10
	.p2align 3
.L3986:
	testl	%esi, %esi
	je	.L4027
.L4206:
	movl	20+wal_(%rip), %eax
	testl	%eax, %eax
	jle	.L4027
	vmovsd	-27704(%rbp), %xmm5
	vaddsd	24+kier_(%rip), %xmm4, %xmm4
	vfmadd231sd	-26952(%rbp), %xmm5, %xmm2
	vmovsd	240016+for_(%rip), %xmm0
	vmovsd	%xmm4, 24+kier_(%rip)
	vmovsd	%xmm2, 8+restart_(%rip)
.L4032:
	vmovsd	-26848(%rbp), %xmm1
	vcomisd	%xmm1, %xmm0
	seta	%al
	testl	%edx, %edx
	jle	.L4850
	vmovsd	-27872(%rbp), %xmm4
	xorl	%edx, %edx
	vcomisd	%xmm0, %xmm4
	seta	%dl
	andl	%eax, %edx
	movl	%edx, -27464(%rbp)
.L4036:
	vmovsd	-27760(%rbp), %xmm5
	vxorpd	%xmm6, %xmm6, %xmm6
	vcomisd	%xmm6, %xmm5
	jbe	.L3979
	andl	$1, %ecx
	je	.L4851
	.p2align 4,,10
	.p2align 3
.L3979:
	leaq	verl_(%rip), %rax
	movl	120240020(%rax), %eax
	movl	%eax, %edx
	shrl	$31, %edx
	addl	%eax, %edx
	sarl	%edx
	cmpl	$1, %eax
	jle	.L4044
	movslq	8+bas_(%rip), %rdi
	movq	-27608(%rbp), %rsi
	leal	(%rdi,%rdx), %r10d
	vmovsd	(%rsi), %xmm2
	movq	%rdi, %rsi
	movslq	%r10d, %rcx
	notq	%rsi
	addq	%rcx, %rsi
	vmovsd	8+plates_(%rip), %xmm3
	movq	%rdi, %r9
	cmpq	$2, %rsi
	jbe	.L4041
	cmpl	$7, %eax
	jle	.L4041
	leaq	pos_(%rip), %rsi
	leaq	160000(%rsi,%rdi,8), %r8
	leaq	160000(%rsi,%rcx,8), %rdi
	movl	%edx, %ecx
	shrl	$2, %ecx
	vbroadcastsd	%xmm2, %ymm1
	vbroadcastsd	%xmm3, %ymm0
	salq	$5, %rcx
	xorl	%eax, %eax
	.p2align 4,,10
	.p2align 3
.L4043:
	vmovupd	%ymm1, (%r8,%rax)
	vmovupd	%ymm0, (%rdi,%rax)
	addq	$32, %rax
	cmpq	%rax, %rcx
	jne	.L4043
	movl	%edx, %eax
	andl	$-4, %eax
	leal	1(%rax), %edi
	cmpl	%edx, %eax
	je	.L4044
	leal	-1(%r9,%rdi), %ecx
	movslq	%ecx, %rcx
	vmovsd	%xmm2, 160000(%rsi,%rcx,8)
	leal	-1(%r10,%rdi), %ecx
	movslq	%ecx, %rcx
	vmovsd	%xmm3, 160000(%rsi,%rcx,8)
	leal	2(%rax), %ecx
	cmpl	%edx, %ecx
	jg	.L4044
	leal	-1(%rcx,%r9), %edi
	leal	-1(%rcx,%r10), %ecx
	movslq	%edi, %rdi
	movslq	%ecx, %rcx
	addl	$3, %eax
	vmovsd	%xmm2, 160000(%rsi,%rdi,8)
	vmovsd	%xmm3, 160000(%rsi,%rcx,8)
	cmpl	%eax, %edx
	jl	.L4044
	leal	-1(%r9,%rax), %edx
	leal	-1(%r10,%rax), %eax
	movslq	%edx, %rdx
	cltq
	vmovsd	%xmm2, 160000(%rsi,%rdx,8)
	vmovsd	%xmm3, 160000(%rsi,%rax,8)
.L4044:
	movl	-27488(%rbp), %r8d
	testl	%r8d, %r8d
	jne	.L4039
	movslq	16+equil_(%rip), %rdx
	leaq	wal_(%rip), %rax
	movl	4(%rax,%rdx,4), %edi
	movl	60+wal_(%rip), %r13d
	testl	%edi, %edi
	jle	.L4048
.L4039:
	leaq	-26952(%rbp), %rsi
	leaq	-26960(%rbp), %rdi
	movq	%r12, %rdx
	vzeroupper
	call	vafm_
	movl	-27244(%rbp), %ecx
	testl	%ecx, %ecx
	je	.L4049
	movl	%ebx, %eax
	cltd
	idivl	%ecx
	vmovsd	-27832(%rbp), %xmm4
	vmovsd	-27840(%rbp), %xmm7
	vaddsd	-26960(%rbp), %xmm4, %xmm4
	vaddsd	-26952(%rbp), %xmm7, %xmm5
	vmovsd	%xmm4, -27832(%rbp)
	vmovsd	%xmm5, -27840(%rbp)
	testl	%edx, %edx
	jne	.L4050
	vxorpd	%xmm6, %xmm6, %xmm6
	vcvtsi2sdl	%ecx, %xmm6, %xmm0
	movl	60+wal_(%rip), %esi
	vdivsd	%xmm0, %xmm4, %xmm4
	vdivsd	%xmm0, %xmm5, %xmm5
	vmovsd	%xmm4, -27856(%rbp)
	vmovsd	%xmm5, -27928(%rbp)
	testl	%esi, %esi
	jne	.L4051
	movq	$0x000000000, -27840(%rbp)
	movq	$0x000000000, -27832(%rbp)
	jmp	.L4049
	.p2align 4,,10
	.p2align 3
.L4842:
	movl	8+bas_(%rip), %esi
	testl	%esi, %esi
	jle	.L4254
	leal	-1(%rsi), %eax
	cmpl	$2, %eax
	jbe	.L4255
	movl	%esi, %edi
	shrl	$2, %edi
	leaq	160000+for_(%rip), %rax
	leaq	mass_(%rip), %rdx
	salq	$5, %rdi
	movq	%rdx, %rcx
	addq	%rax, %rdi
	.p2align 4,,10
	.p2align 3
.L3974:
	vmovapd	.LC441(%rip), %ymm7
	addq	$32, %rax
	vdivpd	(%rcx), %ymm7, %ymm0
	vmulpd	-160032(%rax), %ymm0, %ymm1
	addq	$32, %rcx
	vmovapd	%ymm1, -160032(%rax)
	vmulpd	-80032(%rax), %ymm0, %ymm1
	vmulpd	-32(%rax), %ymm0, %ymm0
	vmovapd	%ymm1, -80032(%rax)
	vmovapd	%ymm0, -32(%rax)
	cmpq	%rax, %rdi
	jne	.L3974
	movl	%esi, %ecx
	andl	$-4, %ecx
	leal	1(%rcx), %eax
	cmpl	%esi, %ecx
	je	.L3975
	movl	%esi, %r9d
	subl	%ecx, %r9d
	cmpl	$1, %r9d
	je	.L4852
.L4579:
	movl	%ecx, %r8d
	leaq	0(,%r8,8), %rdi
	leaq	for_(%rip), %rcx
	vmovapd	.LC68(%rip), %xmm0
	leaq	(%rcx,%rdi), %r11
	vdivpd	(%rdx,%r8,8), %xmm0, %xmm0
	vmulpd	(%r11), %xmm0, %xmm1
	leaq	80000(%rcx,%rdi), %r10
	leaq	160000(%rcx,%rdi), %rdi
	vmovapd	%xmm1, (%r11)
	vmulpd	(%r10), %xmm0, %xmm1
	vmovapd	%xmm1, (%r10)
	vmulpd	(%rdi), %xmm0, %xmm0
	vmovapd	%xmm0, (%rdi)
	movl	%r9d, %edi
	andl	$-2, %edi
	addl	%edi, %eax
	cmpl	%r9d, %edi
	je	.L3975
.L3976:
	vmovsd	.LC8(%rip), %xmm6
	decl	%eax
	cltq
	vdivsd	(%rdx,%rax,8), %xmm6, %xmm0
	vmulsd	(%rcx,%rax,8), %xmm0, %xmm1
	vmovsd	%xmm1, (%rcx,%rax,8)
	vmulsd	80000(%rcx,%rax,8), %xmm0, %xmm1
	vmulsd	160000(%rcx,%rax,8), %xmm0, %xmm0
	vmovsd	%xmm1, 80000(%rcx,%rax,8)
	vmovsd	%xmm0, 160000(%rcx,%rax,8)
.L3975:
	leal	1(%rsi), %eax
	movl	%eax, -27764(%rbp)
	jmp	.L3972
	.p2align 4,,10
	.p2align 3
.L4080:
	testl	%ecx, %ecx
	je	.L4082
	movl	%ebx, %eax
	cltd
	idivl	-27380(%rbp)
	testl	%edx, %edx
	jne	.L4082
	cltq
	vmovsd	240016+for_(%rip), %xmm0
	leaq	-1(%rax), %rdx
	leaq	aree.9(%rip), %rcx
	vaddsd	(%rcx,%rdx,8), %xmm0, %xmm0
	movl	-27244(%rbp), %r8d
	leaq	aufres.11(%rip), %rax
	vmovsd	%xmm0, (%rcx,%rdx,8)
	leaq	aufres2.10(%rip), %rdi
	leaq	adfres.8(%rip), %rsi
	leaq	adfres2.7(%rip), %rcx
	vmovsd	(%rax,%rdx,8), %xmm1
	vmovsd	(%rdi,%rdx,8), %xmm2
	vmovsd	(%rsi,%rdx,8), %xmm0
	vmovsd	(%rcx,%rdx,8), %xmm4
	testl	%r8d, %r8d
	je	.L4217
.L4087:
	vmovsd	-27824(%rbp), %xmm6
	vmovsd	-27816(%rbp), %xmm7
	vfmadd231sd	%xmm6, %xmm6, %xmm2
	vfmadd231sd	%xmm7, %xmm7, %xmm4
	vaddsd	%xmm6, %xmm1, %xmm1
	vaddsd	%xmm7, %xmm0, %xmm0
	vmovsd	%xmm1, (%rax,%rdx,8)
	vmovsd	%xmm2, (%rdi,%rdx,8)
	vmovsd	%xmm0, (%rsi,%rdx,8)
	vmovsd	%xmm4, (%rcx,%rdx,8)
	jmp	.L4082
	.p2align 4,,10
	.p2align 3
.L4132:
	movl	-27628(%rbp), %ebx
	testl	%ebx, %ebx
	je	.L4135
	movl	-27408(%rbp), %ecx
	movl	%ecx, %eax
	cltd
	idivl	%ebx
	testl	%edx, %edx
	jne	.L4853
.L4135:
	movl	80028+misc_(%rip), %r11d
	testl	%r11d, %r11d
	jne	.L4138
.L4141:
	movl	-27520(%rbp), %r10d
	testl	%r10d, %r10d
	je	.L4157
	movl	-27408(%rbp), %eax
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%eax, %xmm5, %xmm0
	leaq	restart_(%rip), %rbx
	movslq	-27968(%rbp), %rdx
	vmulsd	(%rbx), %xmm0, %xmm0
	leaq	cmap_(%rip), %rbx
	movl	60000004(%rbx), %ebx
	cmpl	%ebx, 2000008+cmapi_(%rip)
	vmovsd	%xmm0, -26816(%rbp)
	vmovsd	%xmm0, -24528(%rbp,%rdx,8)
	je	.L4158
	incl	-27448(%rbp)
.L4158:
	movl	-27632(%rbp), %r9d
	testl	%r9d, %r9d
	je	.L4157
	movl	-27504(%rbp), %edx
	addl	-27248(%rbp), %edx
	cmpl	%edx, %eax
	jl	.L4854
.L4157:
	movl	-27312(%rbp), %r8d
	movl	-27488(%rbp), %ebx
	testl	%r8d, %r8d
	jne	.L4855
.L4159:
	testl	%r13d, %r13d
	je	.L4166
	movl	-27408(%rbp), %eax
	movq	-27480(%rbp), %rsi
	vxorpd	%xmm4, %xmm4, %xmm4
	subl	(%rsi), %eax
	subl	-27504(%rbp), %eax
	vcvtsi2sdl	%eax, %xmm4, %xmm0
	vmovsd	.LC8(%rip), %xmm5
	vmovsd	-26800(%rbp), %xmm3
	vdivsd	%xmm0, %xmm5, %xmm0
	vmulsd	%xmm3, %xmm3, %xmm3
	vmulsd	-27792(%rbp), %xmm0, %xmm4
	vmulsd	-27808(%rbp), %xmm0, %xmm6
	vmulsd	-26904(%rbp), %xmm0, %xmm2
	vmovsd	%xmm4, %xmm4, %xmm1
	vfnmadd132sd	%xmm4, %xmm6, %xmm1
	vmovsd	%xmm6, -27808(%rbp)
	vmulsd	-27800(%rbp), %xmm0, %xmm6
	vmovsd	%xmm4, -27792(%rbp)
	vmulsd	-27784(%rbp), %xmm0, %xmm4
	vdivsd	%xmm3, %xmm1, %xmm1
	vaddsd	-28016(%rbp), %xmm2, %xmm5
	vmovsd	%xmm6, %xmm6, %xmm0
	vmovsd	%xmm2, -26904(%rbp)
	vfnmadd132sd	%xmm6, %xmm4, %xmm0
	vfmadd213sd	-28024(%rbp), %xmm2, %xmm2
	vmovsd	%xmm5, -28016(%rbp)
	vmovsd	%xmm4, -27784(%rbp)
	vmovsd	%xmm6, -27800(%rbp)
	vaddsd	-27984(%rbp), %xmm0, %xmm4
	vmovsd	%xmm0, -27072(%rbp)
	vfmadd213sd	-27992(%rbp), %xmm0, %xmm0
	vmovsd	%xmm2, -28024(%rbp)
	vmovsd	%xmm4, -27984(%rbp)
	vmovsd	%xmm0, -27992(%rbp)
	vaddsd	-28000(%rbp), %xmm1, %xmm5
	vmovsd	%xmm1, -27096(%rbp)
	vfmadd213sd	-28008(%rbp), %xmm1, %xmm1
	vmovsd	%xmm5, -28000(%rbp)
	vmovsd	%xmm1, -28008(%rbp)
.L4166:
	movl	-27488(%rbp), %edi
	testl	%edi, %edi
	je	.L4167
	movl	-27408(%rbp), %eax
	cltd
	idivl	-27380(%rbp)
	vmovd	%eax, %xmm0
	vpminsd	-28080(%rbp), %xmm0, %xmm7
	vmovd	%xmm7, -28080(%rbp)
	vmovd	%xmm7, -28040(%rbp)
.L4167:
	movl	-27424(%rbp), %eax
	movl	80028+misc_(%rip), %r13d
	incl	%eax
	movl	%eax, -27472(%rbp)
	movl	%eax, -27424(%rbp)
	cmpl	-28036(%rbp), %eax
	jg	.L4856
	movl	%ebx, -27488(%rbp)
	jmp	.L4168
	.p2align 4,,10
	.p2align 3
.L4846:
	movl	%ecx, -27452(%rbp)
	jmp	.L4076
	.p2align 4,,10
	.p2align 3
.L4840:
	movq	%r12, %rdi
	call	evalwall_
	jmp	.L3964
	.p2align 4,,10
	.p2align 3
.L4104:
	cmpl	$1, %ebx
	je	.L4105
	movl	%ebx, %eax
	cltd
	idivl	-27400(%rbp)
	testl	%edx, %edx
	jne	.L4103
	.p2align 4,,10
	.p2align 3
.L4105:
	vxorpd	%xmm4, %xmm4, %xmm4
	vcvtsi2sdl	%ebx, %xmm4, %xmm0
	leaq	restart_(%rip), %rax
	leaq	-26872(%rbp), %rcx
	vmovq	%xmm0, %r13
	vmulsd	(%rax), %xmm0, %xmm0
	movl	-27628(%rbp), %eax
	cltd
	idivl	-27632(%rbp)
	vmovsd	%xmm0, -26816(%rbp)
	testl	%edx, %edx
	jne	.L4857
	vzeroupper
.L4107:
	movl	-27256(%rbp), %r8d
	leaq	-26816(%rbp), %rsi
	movq	%r12, %rdx
	leaq	.LC561(%rip), %rdi
	testl	%r8d, %r8d
	je	.L4108
	call	print_conf_xyz_.constprop.0
	movl	20+bas_(%rip), %ecx
	testl	%ecx, %ecx
	jne	.L4858
.L4110:
	leaq	.LC561(%rip), %rdi
	xorl	%eax, %eax
	call	_gfortran_flush_i4@PLT
	jmp	.L4103
	.p2align 4,,10
	.p2align 3
.L4844:
	movq	-27864(%rbp), %rax
	vmovsd	.LC100(%rip), %xmm6
	vmovsd	(%rax), %xmm0
	leaq	restart_(%rip), %rax
	vmovsd	(%rax), %xmm2
	vaddsd	%xmm0, %xmm0, %xmm3
	vmulsd	-26944(%rbp), %xmm2, %xmm1
	vmovsd	%xmm0, -26800(%rbp)
	vmulsd	-27880(%rbp), %xmm0, %xmm0
	movl	-27488(%rbp), %r11d
	vmulsd	%xmm3, %xmm1, %xmm1
	vsqrtsd	%xmm1, %xmm1, %xmm1
	vmulsd	%xmm1, %xmm2, %xmm1
	vmovsd	%xmm1, -27112(%rbp)
	vmulsd	-26920(%rbp), %xmm6, %xmm1
	vmulsd	%xmm0, %xmm1, %xmm0
	vmovsd	%xmm0, -27200(%rbp)
	testl	%r11d, %r11d
	je	.L4048
	movslq	120004+respul_(%rip), %rdx
	leaq	pos_(%rip), %rsi
	movslq	120000+respul_(%rip), %rax
	vmovsd	79992(%rsi,%rdx,8), %xmm5
	vmovsd	-8(%rsi,%rdx,8), %xmm6
	vsubsd	79992(%rsi,%rax,8), %xmm5, %xmm2
	vsubsd	-8(%rsi,%rax,8), %xmm6, %xmm3
	vmovsd	159992(%rsi,%rdx,8), %xmm4
	vmulsd	%xmm2, %xmm2, %xmm0
	vsubsd	159992(%rsi,%rax,8), %xmm4, %xmm1
	vmovsd	.LC8(%rip), %xmm7
	movl	8+bas_(%rip), %ecx
	movl	$1, -27452(%rbp)
	vfmadd231sd	%xmm3, %xmm3, %xmm0
	vmovsd	%xmm6, pull_(%rip)
	vmovsd	%xmm5, 80000+pull_(%rip)
	vmovsd	%xmm4, 160000+pull_(%rip)
	vfmadd231sd	%xmm1, %xmm1, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vdivsd	%xmm0, %xmm7, %xmm0
	vmovsd	-27704(%rbp), %xmm7
	vmulsd	%xmm0, %xmm3, %xmm3
	vmulsd	%xmm0, %xmm2, %xmm2
	vmulsd	%xmm0, %xmm1, %xmm0
	vmovsd	%xmm3, kier_(%rip)
	vmovsd	%xmm2, 8+kier_(%rip)
	vmulsd	%xmm7, %xmm3, %xmm3
	vmulsd	%xmm7, %xmm2, %xmm2
	vmovsd	%xmm0, 16+kier_(%rip)
	vmulsd	%xmm7, %xmm0, %xmm0
	vmovsd	%xmm3, 240000+pull_(%rip)
	vmovsd	%xmm2, 240008+pull_(%rip)
	vmovsd	%xmm0, 240016+pull_(%rip)
	testl	%ecx, %ecx
	jle	.L4048
	movslq	%ecx, %rdx
	salq	$3, %rdx
	leaq	nat_(%rip), %rdi
	movl	%ecx, -27568(%rbp)
	movq	%rdx, -27512(%rbp)
	vzeroupper
	call	memcpy@PLT
	movq	-27512(%rbp), %rdx
	leaq	80000+pos_(%rip), %rsi
	leaq	80000+nat_(%rip), %rdi
	call	memcpy@PLT
	movq	-27512(%rbp), %rdx
	leaq	160000+pos_(%rip), %rsi
	leaq	160000+nat_(%rip), %rdi
	call	memcpy@PLT
	movl	-27568(%rbp), %ecx
	incl	%ecx
	movl	%ecx, -27452(%rbp)
	jmp	.L4048
	.p2align 4,,10
	.p2align 3
.L4845:
	leaq	cmap_(%rip), %rax
	movl	60000004(%rax), %r9d
	testl	%r9d, %r9d
	jle	.L4063
	leal	-1(%r9), %ecx
	cmpl	$7, %ecx
	jbe	.L4262
	movl	%ecx, %edi
	shrl	$3, %edi
	leaq	kbt.6(%rip), %r8
	vmovd	%ebx, %xmm4
	salq	$5, %rdi
	vpbroadcastd	%xmm4, %ymm4
	movq	%r8, %rax
	leaq	8+cmapi_(%rip), %rdx
	addq	%r8, %rdi
	vpxor	%xmm3, %xmm3, %xmm3
	.p2align 4,,10
	.p2align 3
.L4065:
	vmovdqa	(%rax), %ymm0
	vmovdqu	(%rdx), %ymm7
	vpcmpeqd	%ymm3, %ymm0, %ymm2
	vpcmpeqd	.LC554(%rip), %ymm7, %ymm1
	addq	$32, %rax
	addq	$32, %rdx
	vpand	%ymm2, %ymm1, %ymm1
	vpblendvb	%ymm1, %ymm4, %ymm0, %ymm0
	vmovdqa	%ymm0, -32(%rax)
	cmpq	%rdi, %rax
	jne	.L4065
	movl	%ecx, %edx
	andl	$-8, %edx
	leal	1(%rdx), %eax
.L4064:
	subl	%edx, %ecx
	cmpl	$3, %ecx
	jbe	.L4066
	leaq	(%r8,%rdx,4), %rdi
	vmovdqa	(%rdi), %xmm1
	vmovdqa	.LC555(%rip), %xmm0
	leaq	8+cmapi_(%rip), %r10
	vpxor	%xmm2, %xmm2, %xmm2
	vpcmpeqd	(%r10,%rdx,4), %xmm0, %xmm0
	vpcmpeqd	%xmm2, %xmm1, %xmm2
	vmovd	%ebx, %xmm5
	andl	$-4, %ecx
	vpand	%xmm2, %xmm0, %xmm0
	vpshufd	$0, %xmm5, %xmm2
	vpblendvb	%xmm0, %xmm2, %xmm1, %xmm0
	vmovdqa	%xmm0, (%rdi)
	addl	%ecx, %eax
.L4066:
	leal	-1(%rax), %edx
	movslq	%edx, %rdx
	movslq	%eax, %rcx
	movl	(%r8,%rdx,4), %r11d
	leaq	(%rcx,%rcx,2), %r10
	leaq	cmap_(%rip), %rdi
	movl	60000000(%rdi,%r10,4), %edi
	testl	%r11d, %r11d
	jne	.L4067
	leaq	cmapi_(%rip), %r11
	cmpl	$1, 8(%r11,%rdx,4)
	jne	.L4067
	movl	%ebx, (%r8,%rdx,4)
	.p2align 4,,10
	.p2align 3
.L4067:
	leal	1(%rax), %edx
	cmpl	%edx, %r9d
	jl	.L4068
	movl	(%r8,%rcx,4), %r13d
	leaq	cmap_(%rip), %rdi
	movl	60000012(%rdi,%r10,4), %edi
	movslq	%edx, %rdx
	testl	%r13d, %r13d
	jne	.L4069
	leaq	cmapi_(%rip), %r11
	cmpl	$1, 8(%r11,%rcx,4)
	jne	.L4069
	movl	%ebx, (%r8,%rcx,4)
	.p2align 4,,10
	.p2align 3
.L4069:
	leal	2(%rax), %ecx
	cmpl	%r9d, %ecx
	jg	.L4068
	movl	(%r8,%rdx,4), %r11d
	leaq	cmap_(%rip), %rdi
	movl	60000024(%rdi,%r10,4), %edi
	movslq	%ecx, %rcx
	testl	%r11d, %r11d
	jne	.L4070
	leaq	cmapi_(%rip), %r11
	cmpl	$1, 8(%r11,%rdx,4)
	jne	.L4070
	movl	%ebx, (%r8,%rdx,4)
	.p2align 4,,10
	.p2align 3
.L4070:
	addl	$3, %eax
	cmpl	%eax, %r9d
	jl	.L4068
	leaq	cmap_(%rip), %rax
	movl	60000036(%rax,%r10,4), %edi
	movl	(%r8,%rcx,4), %eax
	testl	%eax, %eax
	jne	.L4068
	leaq	cmapi_(%rip), %rax
	cmpl	$1, 8(%rax,%rcx,4)
	jne	.L4068
	movl	%ebx, (%r8,%rcx,4)
	.p2align 4,,10
	.p2align 3
.L4068:
	movl	%edi, -27420(%rbp)
	jmp	.L4063
	.p2align 4,,10
	.p2align 3
.L4089:
	vxorpd	%xmm7, %xmm7, %xmm7
	vcvtsi2sdl	%ebx, %xmm7, %xmm0
	leaq	restart_(%rip), %rax
	vmovsd	-27848(%rbp), %xmm4
	leaq	-26880(%rbp), %rdi
	vmulsd	(%rax), %xmm0, %xmm1
	vmovsd	.LC11(%rip), %xmm0
	vandpd	%xmm1, %xmm0, %xmm0
	vorpd	%xmm0, %xmm4, %xmm0
	vaddsd	%xmm1, %xmm0, %xmm0
	vcvttsd2sil	%xmm0, %eax
	movl	%eax, -27384(%rbp)
	vzeroupper
	call	gyration_
	call	cgyration_
	leaq	-26872(%rbp), %rcx
	movq	%rcx, %rdi
	call	compute_rmsd_
	movl	60+wal_(%rip), %edi
	testl	%edi, %edi
	jne	.L4091
	movslq	120000+respul_(%rip), %rdx
	leaq	pos_(%rip), %rsi
	movslq	120004+respul_(%rip), %rax
	vmovsd	79992(%rsi,%rdx,8), %xmm2
	vmovsd	-8(%rsi,%rdx,8), %xmm1
	vsubsd	79992(%rsi,%rax,8), %xmm2, %xmm2
	vsubsd	-8(%rsi,%rax,8), %xmm1, %xmm1
	vmovsd	159992(%rsi,%rdx,8), %xmm0
	vmulsd	%xmm2, %xmm2, %xmm2
	vsubsd	159992(%rsi,%rax,8), %xmm0, %xmm0
	vfmadd132sd	%xmm1, %xmm2, %xmm1
	vfmadd132sd	%xmm0, %xmm1, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm0, -26888(%rbp)
.L4091:
	leaq	cmp2_(%rip), %r11
	movl	60000004(%r11), %esi
	testl	%esi, %esi
	jle	.L4264
	movslq	540000008(%r11), %rax
	vxorpd	%xmm1, %xmm1, %xmm1
	imulq	$15000000, %rax, %rcx
	movq	%rcx, %rax
	salq	$4, %rax
	leaq	-179999992(%r11,%rax), %rdx
	leal	-1(%rsi), %eax
	addq	%rcx, %rax
	salq	$4, %rax
	leaq	-179999976(%r11,%rax), %rsi
	xorl	%ecx, %ecx
	.p2align 4,,10
	.p2align 3
.L4094:
	movl	12(%rdx), %eax
	movl	%eax, %r8d
	sarl	$31, %r8d
	xorl	%r8d, %eax
	subl	%r8d, %eax
	cmpl	$1, %eax
	jle	.L4093
	movl	(%rdx), %eax
	vxorpd	%xmm4, %xmm4, %xmm4
	subl	4(%rdx), %eax
	movl	%eax, %r8d
	sarl	$31, %r8d
	xorl	%r8d, %eax
	subl	%r8d, %eax
	vcvtsi2sdl	%eax, %xmm4, %xmm0
	incl	%ecx
	vaddsd	%xmm0, %xmm1, %xmm1
.L4093:
	addq	$16, %rdx
	cmpq	%rsi, %rdx
	jne	.L4094
	testl	%ecx, %ecx
	je	.L4092
	vxorpd	%xmm4, %xmm4, %xmm4
	vcvtsi2sdl	%ecx, %xmm4, %xmm0
	vdivsd	%xmm0, %xmm1, %xmm1
.L4092:
	vxorpd	%xmm6, %xmm6, %xmm6
	vcvtsi2sdl	8+bas_(%rip), %xmm6, %xmm0
	movl	-27488(%rbp), %eax
	movq	-26872(%rbp), %r13
	vdivsd	%xmm0, %xmm1, %xmm1
	vmovsd	%xmm1, -27104(%rbp)
	testl	%eax, %eax
	je	.L4095
	vmovsd	-26888(%rbp), %xmm0
	vmovsd	-27872(%rbp), %xmm5
	xorl	%eax, %eax
	vcomisd	%xmm0, %xmm5
	vmovsd	-26880(%rbp), %xmm1
	vmovsd	%xmm0, -27920(%rbp)
	seta	%al
	movl	%eax, -27464(%rbp)
	movl	-27244(%rbp), %eax
	vmovsd	%xmm1, -27944(%rbp)
	testl	%eax, %eax
	movq	-27640(%rbp), %rax
	movq	%rax, -26264(%rbp)
	jne	.L4096
	leaq	.LC556(%rip), %rax
	movq	%rax, -26192(%rbp)
	movq	%r15, %rdi
	movabsq	$4294971392, %rax
	movq	%rax, -26272(%rbp)
	movl	$2029, -26256(%rbp)
	movq	$34, -26184(%rbp)
	call	_gfortran_st_write@PLT
	leaq	-27384(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$8, %edx
	movq	%r12, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	-26992(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$4, %edx
	leaq	2000008+cmapi_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	vmovsd	-27944(%rbp), %xmm1
	movq	-27752(%rbp), %rsi
	vmulsd	bas_(%rip), %xmm1, %xmm1
	movl	$8, %edx
	movq	%r15, %rdi
	vmovsd	%xmm1, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovq	%r13, %xmm5
	vmulsd	bas_(%rip), %xmm5, %xmm1
	movq	-27752(%rbp), %r13
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	vmovsd	%xmm1, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	-27920(%rbp), %xmm0
	movl	$8, %edx
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movq	%r13, %rsi
	movq	%r15, %rdi
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	-26960(%rbp), %xmm0
	vdivsd	bas_(%rip), %xmm0, %xmm0
.L4628:
	movq	%r15, %rdi
	movl	$8, %edx
	movq	%r13, %rsi
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
.L4097:
	leaq	.LC309(%rip), %rdi
	xorl	%eax, %eax
	call	_gfortran_flush_i4@PLT
	jmp	.L4088
	.p2align 4,,10
	.p2align 3
.L4050:
	movl	60+wal_(%rip), %eax
	testl	%eax, %eax
	je	.L4049
	vmovsd	-27624(%rbp), %xmm5
	movl	64+wal_(%rip), %eax
	vaddsd	16+plates_(%rip), %xmm5, %xmm7
	vmovsd	-27616(%rbp), %xmm5
	vmovsd	%xmm7, -27624(%rbp)
	vaddsd	24+plates_(%rip), %xmm5, %xmm7
	vmovsd	%xmm7, -27616(%rbp)
	.p2align 4,,10
	.p2align 3
.L4052:
	testl	%eax, %eax
	je	.L4197
	vmovsd	-27728(%rbp), %xmm7
	vmovsd	-27720(%rbp), %xmm5
	vaddsd	xyforces_(%rip), %xmm7, %xmm4
	vaddsd	8+xyforces_(%rip), %xmm5, %xmm6
	vmovsd	-27744(%rbp), %xmm7
	vmovsd	-27736(%rbp), %xmm5
	vmovsd	%xmm4, -27728(%rbp)
	vmovsd	%xmm6, -27720(%rbp)
	vaddsd	16+xyforces_(%rip), %xmm7, %xmm4
	vaddsd	24+xyforces_(%rip), %xmm5, %xmm6
	vmovsd	%xmm4, -27744(%rbp)
	vmovsd	%xmm6, -27736(%rbp)
	jmp	.L4049
.L4003:
	movl	-27312(%rbp), %edi
	testl	%edi, %edi
	jne	.L4859
	movl	32+wal_(%rip), %esi
	cmpl	%esi, %eax
	jg	.L4200
.L4202:
	vmovsd	-27704(%rbp), %xmm4
	vmovsd	-27760(%rbp), %xmm6
	movl	-27300(%rbp), %eax
	vcomisd	%xmm6, %xmm4
	movl	32+kier_(%rip), %esi
	movl	36+wal_(%rip), %edx
	vmovsd	8+restart_(%rip), %xmm2
	jbe	.L4582
	testl	%eax, %eax
	je	.L4259
	vxorps	%xmm4, %xmm4, %xmm4
	vcvtsi2ssl	%edx, %xmm4, %xmm0
	movl	$8272, %r9d
	incl	%edx
	movl	%edx, 36+wal_(%rip)
	vcvtss2sd	%xmm0, %xmm0, %xmm0
	vmulsd	%xmm6, %xmm0, %xmm0
	vxorpd	%xmm6, %xmm6, %xmm6
	vcvtsi2sdl	8+equil_(%rip), %xmm6, %xmm4
	movw	%r9w, -450(%rbp)
	vdivsd	%xmm4, %xmm0, %xmm7
	vmovsd	%xmm7, -27704(%rbp)
	testl	%esi, %esi
	je	.L4026
	vmovsd	240016+for_(%rip), %xmm0
	vmovsd	%xmm0, 16+restart_(%rip)
.L4026:
	vmovsd	.LC72(%rip), %xmm4
	movl	$0, 20+wal_(%rip)
	vmulsd	-27704(%rbp), %xmm4, %xmm4
	movl	%eax, %ecx
	.p2align 4,,10
	.p2align 3
.L4027:
	vaddsd	%xmm3, %xmm1, %xmm1
	vmovsd	-27704(%rbp), %xmm15
	vmovsd	8+plates_(%rip), %xmm0
	vaddsd	%xmm5, %xmm1, %xmm1
	movq	-27608(%rbp), %rax
	vsubsd	%xmm4, %xmm0, %xmm0
	vfmadd132sd	%xmm15, %xmm2, %xmm1
	vaddsd	(%rax), %xmm4, %xmm7
	vmovsd	40+plates_(%rip), %xmm3
	vmovsd	48+plates_(%rip), %xmm6
	vmovsd	56+plates_(%rip), %xmm2
	vmovsd	64+plates_(%rip), %xmm5
	vmovsd	%xmm0, 8+plates_(%rip)
	vmovsd	%xmm7, (%rax)
	vmovsd	%xmm1, 8+restart_(%rip)
	testl	%ecx, %ecx
	je	.L4033
	movl	8+wal_(%rip), %eax
	testl	%eax, %eax
	jne	.L4033
	vmovsd	16+xyforces_(%rip), %xmm8
	vmovsd	xyforces_(%rip), %xmm9
	vaddsd	24+xyforces_(%rip), %xmm8, %xmm8
	vaddsd	8+xyforces_(%rip), %xmm9, %xmm9
	vsubsd	%xmm4, %xmm3, %xmm3
	vaddsd	%xmm4, %xmm6, %xmm6
	vaddsd	%xmm9, %xmm8, %xmm8
	vsubsd	%xmm4, %xmm2, %xmm2
	vaddsd	%xmm4, %xmm5, %xmm5
	vfmadd231sd	%xmm15, %xmm8, %xmm1
	vunpcklpd	%xmm5, %xmm2, %xmm4
	vmovsd	%xmm1, 8+restart_(%rip)
	vunpcklpd	%xmm6, %xmm3, %xmm1
	vinsertf128	$0x1, %xmm4, %ymm1, %ymm1
	vmovupd	%ymm1, 40+plates_(%rip)
.L4034:
	vsubsd	%xmm6, %xmm3, %xmm3
	vsubsd	%xmm5, %xmm2, %xmm2
	vsubsd	%xmm7, %xmm0, %xmm0
	vmovsd	.LC8(%rip), %xmm7
	vunpcklpd	%xmm2, %xmm3, %xmm1
	vmovapd	%xmm1, 240000+for_(%rip)
	vmovapd	.LC68(%rip), %xmm1
	vunpcklpd	%xmm0, %xmm2, %xmm2
	vdivsd	%xmm3, %xmm7, %xmm3
	vmovsd	%xmm0, 240016+for_(%rip)
	vdivpd	%xmm2, %xmm1, %xmm2
	vmovsd	%xmm3, 240024+for_(%rip)
	vmovapd	%xmm2, 240032+for_(%rip)
	jmp	.L4032
	.p2align 4,,10
	.p2align 3
.L4108:
	call	print_conformation_
	movl	20+bas_(%rip), %ecx
	testl	%ecx, %ecx
	je	.L4110
.L4858:
	leaq	restart_(%rip), %rax
	vmovq	%r13, %xmm4
	vmulsd	(%rax), %xmm4, %xmm0
	vmovsd	.LC11(%rip), %xmm1
	vmovsd	-27848(%rbp), %xmm7
	movq	-27752(%rbp), %rsi
	leaq	.LC478(%rip), %rdi
	vandpd	%xmm0, %xmm1, %xmm1
	vorpd	%xmm1, %xmm7, %xmm1
	vaddsd	%xmm0, %xmm1, %xmm0
	vcvttsd2sil	%xmm0, %eax
	movl	%eax, -26704(%rbp)
	call	print_map_
	jmp	.L4110
	.p2align 4,,10
	.p2align 3
.L4033:
	movl	-27348(%rbp), %r13d
	testl	%r13d, %r13d
	je	.L4034
	testl	%edx, %edx
	jne	.L4034
	movl	16+wal_(%rip), %r11d
	testl	%r11d, %r11d
	jle	.L4034
	vmovsd	-27704(%rbp), %xmm4
	vmovsd	.LC8(%rip), %xmm14
	vdivsd	240016+for_(%rip), %xmm4, %xmm4
	vaddsd	.LC8(%rip), %xmm4, %xmm4
	vmovsd	16+xyforces_(%rip), %xmm8
	vmovsd	xyforces_(%rip), %xmm9
	vsqrtsd	%xmm4, %xmm4, %xmm4
	vaddsd	24+xyforces_(%rip), %xmm8, %xmm8
	vaddsd	8+xyforces_(%rip), %xmm9, %xmm9
	vdivsd	%xmm4, %xmm14, %xmm4
	vaddsd	%xmm9, %xmm8, %xmm8
	vsubsd	%xmm14, %xmm4, %xmm4
	vmulsd	240000+for_(%rip), %xmm4, %xmm4
	vfnmadd231sd	.LC72(%rip), %xmm4, %xmm3
	vfmadd231sd	.LC72(%rip), %xmm4, %xmm6
	vfnmadd231sd	.LC72(%rip), %xmm4, %xmm2
	vfmadd231sd	.LC72(%rip), %xmm4, %xmm5
	vfmadd231sd	%xmm4, %xmm8, %xmm1
	vmovsd	%xmm3, 40+plates_(%rip)
	vmovsd	%xmm6, 48+plates_(%rip)
	vmovsd	%xmm2, 56+plates_(%rip)
	vmovsd	%xmm5, 64+plates_(%rip)
	vmovsd	%xmm1, 8+restart_(%rip)
	jmp	.L4034
	.p2align 4,,10
	.p2align 3
.L3980:
	vmovsd	-27760(%rbp), %xmm6
	vmovsd	8+restart_(%rip), %xmm2
	vandpd	.LC69(%rip), %xmm6, %xmm0
	movl	32+kier_(%rip), %esi
	vcomisd	-27704(%rbp), %xmm0
	movl	36+wal_(%rip), %edx
	ja	.L4028
	vmovsd	.LC72(%rip), %xmm4
	vmovsd	%xmm6, -27704(%rbp)
	vmulsd	%xmm6, %xmm4, %xmm4
	jmp	.L3986
	.p2align 4,,10
	.p2align 3
.L4095:
	testl	%edi, %edi
	je	.L4098
	vmovsd	bas_(%rip), %xmm1
	vmovsd	.LC8(%rip), %xmm5
	movl	32+kier_(%rip), %eax
	vdivsd	%xmm1, %xmm5, %xmm0
	vmulsd	-27824(%rbp), %xmm0, %xmm2
	vmovsd	%xmm2, -26768(%rbp)
	vmulsd	-27816(%rbp), %xmm0, %xmm2
	vmovsd	%xmm2, -27080(%rbp)
	vmulsd	-27856(%rbp), %xmm0, %xmm2
	vxorpd	.LC11(%rip), %xmm2, %xmm2
	vmovsd	%xmm2, -26984(%rbp)
	vmulsd	-27928(%rbp), %xmm0, %xmm2
	vxorpd	.LC11(%rip), %xmm2, %xmm2
	vmovsd	%xmm2, -26976(%rbp)
	testl	%eax, %eax
	je	.L4099
	movl	20+wal_(%rip), %r11d
	testl	%r11d, %r11d
	jle	.L4099
	vmulsd	24+kier_(%rip), %xmm1, %xmm1
	vaddsd	%xmm1, %xmm1, %xmm1
.L4100:
	movl	64+wal_(%rip), %r10d
	vmovsd	%xmm1, -26712(%rbp)
	testl	%r10d, %r10d
	je	.L4101
	vmovsd	-27896(%rbp), %xmm4
	vmovsd	-27888(%rbp), %xmm6
	vmulsd	%xmm4, %xmm0, %xmm1
	vmovsd	-27904(%rbp), %xmm5
	vmovsd	-27912(%rbp), %xmm7
	vsubsd	%xmm6, %xmm4, %xmm2
	vsubsd	%xmm5, %xmm7, %xmm3
	vmovsd	%xmm1, -26736(%rbp)
	vmulsd	%xmm6, %xmm0, %xmm1
	vmulsd	%xmm0, %xmm3, %xmm3
	vmovsd	-27824(%rbp), %xmm4
	vmulsd	%xmm0, %xmm2, %xmm2
	movq	-27640(%rbp), %rax
	vmovsd	%xmm1, -26744(%rbp)
	vmulsd	%xmm7, %xmm0, %xmm1
	vmulsd	%xmm3, %xmm3, %xmm3
	movq	%rax, -26264(%rbp)
	leaq	.LC557(%rip), %rax
	movq	%rax, -26192(%rbp)
	vmovsd	%xmm1, -26720(%rbp)
	vmulsd	%xmm5, %xmm0, %xmm1
	vfmadd132sd	%xmm2, %xmm3, %xmm2
	movabsq	$4294971392, %rax
	movq	%r15, %rdi
	movq	%rax, -26272(%rbp)
	vmovsd	%xmm1, -26728(%rbp)
	vsubsd	-27816(%rbp), %xmm4, %xmm1
	movl	$2070, -26256(%rbp)
	movq	$49, -26184(%rbp)
	vmulsd	%xmm0, %xmm1, %xmm0
	vfmadd132sd	%xmm0, %xmm2, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmovsd	%xmm0, -27224(%rbp)
	call	_gfortran_st_write@PLT
	leaq	-450(%rbp), %rsi
	movq	%r15, %rdi
	movl	$2, %edx
	call	_gfortran_transfer_character_write@PLT
	leaq	-27384(%rbp), %rsi
	movq	%r15, %rdi
	movl	$4, %edx
	call	_gfortran_transfer_integer_write@PLT
	movq	%r12, %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26992(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	2000012+cmapi_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	2000020+cmapi_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	2000016+cmapi_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	2000024+cmapi_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	2000008+cmapi_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	vmovq	%r13, %xmm7
	vmulsd	bas_(%rip), %xmm7, %xmm0
	movq	-27752(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	leaq	-26768(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-27080(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-27224(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26712(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26984(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26976(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	8+restart_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	leaq	-27176(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26736(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26744(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26720(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	leaq	-26728(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L4097
	.p2align 4,,10
	.p2align 3
.L4083:
	vmovsd	-27856(%rbp), %xmm5
	vfmadd231sd	%xmm5, %xmm5, %xmm2
	vaddsd	%xmm5, %xmm1, %xmm1
	vmovsd	%xmm1, (%rax,%rdx,8)
	vmovsd	%xmm2, (%rdi,%rdx,8)
	testl	%ecx, %ecx
	je	.L4082
	vaddsd	240016+for_(%rip), %xmm0, %xmm0
	leaq	adfres2.7(%rip), %rcx
	vmovsd	(%rcx,%rdx,8), %xmm4
	vmovsd	%xmm0, (%rsi,%rdx,8)
	leaq	adfres.8(%rip), %rsi
	vmovsd	(%rsi,%rdx,8), %xmm0
	jmp	.L4087
	.p2align 4,,10
	.p2align 3
.L4053:
	vmovsd	-27728(%rbp), %xmm7
	vmovsd	-27720(%rbp), %xmm5
	vaddsd	xyforces_(%rip), %xmm7, %xmm4
	vaddsd	8+xyforces_(%rip), %xmm5, %xmm6
	vmovsd	-27744(%rbp), %xmm7
	vmovsd	-27736(%rbp), %xmm5
	vmovsd	%xmm4, -27728(%rbp)
	vmovsd	%xmm6, -27720(%rbp)
	vaddsd	16+xyforces_(%rip), %xmm7, %xmm4
	vaddsd	24+xyforces_(%rip), %xmm5, %xmm6
	movq	$0x000000000, -27624(%rbp)
	movq	$0x000000000, -27616(%rbp)
	vmovsd	%xmm4, -27744(%rbp)
	vmovsd	%xmm6, -27736(%rbp)
	jmp	.L4198
	.p2align 4,,10
	.p2align 3
.L4260:
	movq	$0x000000000, -27568(%rbp)
	vmovsd	-27568(%rbp), %xmm7
	jmp	.L4057
	.p2align 4,,10
	.p2align 3
.L4850:
	movzbl	%al, %eax
	movl	%eax, -27464(%rbp)
	jmp	.L4036
	.p2align 4,,10
	.p2align 3
.L4857:
	movq	%rcx, %rdi
	movq	%rcx, -27920(%rbp)
	vzeroupper
	call	compute_rmsd_
	call	cgyration_
	movq	-27920(%rbp), %rcx
	jmp	.L4107
	.p2align 4,,10
	.p2align 3
.L4041:
	leaq	pos_(%rip), %rsi
	leaq	(%rsi,%rdi,8), %rdi
	leaq	(%rsi,%rcx,8), %rcx
	movl	$1, %eax
	.p2align 4,,10
	.p2align 3
.L4047:
	vmovsd	%xmm2, 159992(%rdi,%rax,8)
	vmovsd	%xmm3, 159992(%rcx,%rax,8)
	incq	%rax
	cmpl	%eax, %edx
	jge	.L4047
	jmp	.L4044
.L4261:
	xorl	%edi, %edi
	vxorpd	%xmm2, %xmm2, %xmm2
	movl	$1, %eax
	leaq	mass_(%rip), %rdx
	jmp	.L4058
.L4851:
	movl	120008+respul_(%rip), %edx
	movl	%edx, %eax
	shrl	$31, %eax
	addl	%edx, %eax
	sarl	%eax
	cmpl	%eax, 44+wal_(%rip)
	jl	.L3979
	cmpl	48+wal_(%rip), %eax
	jg	.L3979
	vxorpd	.LC11(%rip), %xmm5, %xmm5
	movl	56+wal_(%rip), %r10d
	vmovsd	%xmm5, -27760(%rbp)
	testl	%r10d, %r10d
	je	.L4860
.L4037:
	movl	36+bas_(%rip), %r9d
	testl	%r9d, %r9d
	je	.L3979
	vzeroupper
	call	make_fcc_
	jmp	.L3979
.L4847:
	movl	8+bas_(%rip), %ecx
	movl	$0, 2000016+cmapi_(%rip)
	movl	$0, 2000024+cmapi_(%rip)
	movq	$0, 8+ssb2_(%rip)
	testl	%ecx, %ecx
	jle	.L4265
	leal	-1(%rcx), %eax
	cmpl	$6, %eax
	jbe	.L4266
	movl	%ecx, %esi
	shrl	$3, %esi
	leaq	ssb_(%rip), %rdi
	salq	$5, %rsi
	movq	%rdi, %rdx
	leaq	40360+sdch_(%rip), %rax
	addq	%rdi, %rsi
	vpxor	%xmm0, %xmm0, %xmm0
	.p2align 4,,10
	.p2align 3
.L4115:
	vmovdqu	%ymm0, (%rax)
	vmovdqu	%ymm0, 32(%rax)
	vmovdqu	%ymm0, 64(%rax)
	vmovdqu	%ymm0, 96(%rax)
	addq	$32, %rdx
	vmovdqa	%ymm0, 39968(%rdx)
	vmovdqa	%ymm0, -32(%rdx)
	subq	$-128, %rax
	cmpq	%rdx, %rsi
	jne	.L4115
	movl	%ecx, %eax
	andl	$-8, %eax
	leal	1(%rax), %esi
	cmpl	%ecx, %eax
	je	.L4116
.L4114:
	movl	%ecx, %r9d
	subl	%eax, %r9d
	leal	-1(%r9), %edx
	leaq	sdch_(%rip), %r8
	cmpl	$2, %edx
	jbe	.L4117
	movl	%eax, %edx
	salq	$4, %rdx
	leaq	sdch_(%rip), %r8
	vpxor	%xmm0, %xmm0, %xmm0
	leaq	40360(%r8,%rdx), %rdx
	addl	$10000, %eax
	vmovdqu	%xmm0, (%rdx)
	vmovdqu	%xmm0, 16(%rdx)
	vmovdqu	%xmm0, 32(%rdx)
	vmovdqu	%xmm0, 48(%rdx)
	leaq	-40000+ssb_(%rip), %rdx
	vmovdqa	%xmm0, (%rdi,%rax,4)
	vmovdqa	%xmm0, (%rdx,%rax,4)
	movl	%r9d, %eax
	andl	$-4, %eax
	addl	%eax, %esi
	cmpl	%r9d, %eax
	je	.L4116
.L4117:
	leal	-1(%rsi), %eax
	cltq
	leaq	0(,%rax,4), %rdx
	vpxor	%xmm0, %xmm0, %xmm0
	vmovdqu	%xmm0, 40360(%r8,%rdx,4)
	movl	$0, 40000(%rdi,%rax,4)
	movl	$0, (%rdi,%rax,4)
	leal	1(%rsi), %eax
	movslq	%esi, %r9
	cmpl	%eax, %ecx
	jl	.L4116
	movslq	%eax, %r10
	leal	2(%rsi), %eax
	vmovdqu	%xmm0, 40376(%r8,%rdx,4)
	movl	$0, 40000(%rdi,%r9,4)
	movl	$0, (%rdi,%r9,4)
	cmpl	%eax, %ecx
	jl	.L4116
	vmovdqu	%xmm0, 40392(%r8,%rdx,4)
	movl	$0, 40000(%rdi,%r10,4)
	movl	$0, (%rdi,%r10,4)
.L4116:
	leal	1(%rcx), %eax
	movl	%eax, -27764(%rbp)
.L4113:
	leaq	cmp2_(%rip), %rbx
	movl	540000008(%rbx), %eax
	movl	60000004(%rbx), %r11d
	movl	$3, %edx
	subl	%eax, %edx
	testl	%r11d, %r11d
	jle	.L4112
	movslq	%edx, %rdx
	imulq	$15000000, %rdx, %rdi
	movslq	%eax, %rcx
	imulq	$15000000, %rcx, %r9
	movq	%rdi, %rdx
	leal	-1(%r11), %r8d
	subq	%r9, %rdx
	leaq	31(,%rdx,4), %rdx
	cmpq	$62, %rdx
	jbe	.L4119
	cmpl	$9, %r8d
	jbe	.L4119
	negl	%eax
	movslq	%eax, %rdx
	imulq	$240000000, %rdx, %rdx
	imulq	$240000000, %rcx, %rcx
	movl	%r8d, %r10d
	shrl	$3, %r10d
	leaq	540000016(%rbx,%rdx), %rax
	salq	$7, %r10
	leaq	540000020(%rbx,%rdx), %rsi
	addq	%rax, %r10
	leaq	-179999984(%rbx,%rcx), %rdx
	leaq	-179999980(%rbx,%rcx), %rcx
	.p2align 4,,10
	.p2align 3
.L4120:
	vmovdqu	32(%rcx), %ymm2
	vmovdqu	(%rcx), %ymm1
	vmovdqu	96(%rcx), %ymm3
	vperm2i128	$32, %ymm2, %ymm1, %ymm0
	vperm2i128	$49, %ymm2, %ymm1, %ymm1
	vpshufd	$216, %ymm1, %ymm1
	vpshufd	$216, %ymm0, %ymm0
	vpunpcklqdq	%ymm1, %ymm0, %ymm0
	vmovdqu	64(%rcx), %ymm1
	movl	$0, (%rdx)
	vperm2i128	$32, %ymm3, %ymm1, %ymm2
	vperm2i128	$49, %ymm3, %ymm1, %ymm1
	vpshufd	$216, %ymm1, %ymm1
	vpshufd	$216, %ymm2, %ymm2
	vpunpcklqdq	%ymm1, %ymm2, %ymm2
	vperm2i128	$32, %ymm2, %ymm0, %ymm1
	vperm2i128	$49, %ymm2, %ymm0, %ymm0
	vpshufd	$216, %ymm1, %ymm1
	vpshufd	$216, %ymm0, %ymm0
	vpunpcklqdq	%ymm0, %ymm1, %ymm0
	vpsrad	$31, %ymm0, %ymm1
	vpaddd	.LC554(%rip), %ymm1, %ymm0
	movl	$0, 16(%rdx)
	movl	$0, 32(%rdx)
	movl	$0, 48(%rdx)
	movl	$0, 64(%rdx)
	movl	$0, 80(%rdx)
	movl	$0, 96(%rdx)
	movl	$0, 112(%rdx)
	vpxor	%ymm1, %ymm0, %ymm0
	vmovd	%xmm0, 4(%rdx)
	vpextrd	$1, %xmm0, 20(%rdx)
	vpextrd	$2, %xmm0, 36(%rdx)
	vpextrd	$3, %xmm0, 52(%rdx)
	vextracti128	$0x1, %ymm0, %xmm0
	vmovd	%xmm0, 68(%rdx)
	vpextrd	$1, %xmm0, 84(%rdx)
	vpextrd	$2, %xmm0, 100(%rdx)
	vpextrd	$3, %xmm0, 116(%rdx)
	vmovdqu	32(%rsi), %ymm2
	vmovdqu	(%rsi), %ymm1
	vmovdqu	96(%rsi), %ymm3
	vperm2i128	$32, %ymm2, %ymm1, %ymm0
	vperm2i128	$49, %ymm2, %ymm1, %ymm1
	vpshufd	$216, %ymm1, %ymm1
	vpshufd	$216, %ymm0, %ymm0
	vpunpcklqdq	%ymm1, %ymm0, %ymm0
	vmovdqu	64(%rsi), %ymm1
	movl	$0, (%rax)
	vperm2i128	$32, %ymm3, %ymm1, %ymm2
	vperm2i128	$49, %ymm3, %ymm1, %ymm1
	vpshufd	$216, %ymm1, %ymm1
	vpshufd	$216, %ymm2, %ymm2
	vpunpcklqdq	%ymm1, %ymm2, %ymm2
	vperm2i128	$32, %ymm2, %ymm0, %ymm1
	vperm2i128	$49, %ymm2, %ymm0, %ymm0
	vpshufd	$216, %ymm1, %ymm1
	vpshufd	$216, %ymm0, %ymm0
	vpunpcklqdq	%ymm0, %ymm1, %ymm0
	vpsrad	$31, %ymm0, %ymm1
	vpaddd	.LC554(%rip), %ymm1, %ymm0
	movl	$0, 16(%rax)
	vpxor	%ymm1, %ymm0, %ymm0
	movl	$0, 32(%rax)
	movl	$0, 48(%rax)
	movl	$0, 64(%rax)
	movl	$0, 80(%rax)
	movl	$0, 96(%rax)
	vmovd	%xmm0, 4(%rax)
	vpextrd	$1, %xmm0, 20(%rax)
	vpextrd	$2, %xmm0, 36(%rax)
	vpextrd	$3, %xmm0, 52(%rax)
	vextracti128	$0x1, %ymm0, %xmm0
	movl	$0, 112(%rax)
	vmovd	%xmm0, 68(%rax)
	vpextrd	$1, %xmm0, 84(%rax)
	vpextrd	$2, %xmm0, 100(%rax)
	vpextrd	$3, %xmm0, 116(%rax)
	subq	$-128, %rax
	subq	$-128, %rsi
	subq	$-128, %rdx
	subq	$-128, %rcx
	cmpq	%rax, %r10
	jne	.L4120
	andl	$-8, %r8d
	leal	1(%r8), %edx
	movslq	%edx, %rdx
	leaq	(%r9,%rdx), %rax
	leaq	cmp2_(%rip), %rbx
	salq	$2, %rax
	movl	$0, -180000000(%rbx,%rax,4)
	subq	$44999999, %rax
	movl	(%rbx,%rax,4), %esi
	addq	%rdi, %rdx
	movl	%esi, %ecx
	sarl	$31, %ecx
	leal	1(%rcx), %esi
	xorl	%esi, %ecx
	movl	%ecx, (%rbx,%rax,4)
	salq	$2, %rdx
	movl	$0, -180000000(%rbx,%rdx,4)
	subq	$44999999, %rdx
	movl	(%rbx,%rdx,4), %eax
	movl	%eax, -27920(%rbp)
	sarl	$31, %eax
	leal	1(%rax), %ecx
	xorl	%ecx, %eax
	movl	%eax, (%rbx,%rdx,4)
	leal	2(%r8), %eax
	cmpl	%r11d, %eax
	jg	.L4112
	cltq
	leaq	(%r9,%rax), %rdx
	salq	$2, %rdx
	movl	$0, -180000000(%rbx,%rdx,4)
	subq	$44999999, %rdx
	movl	(%rbx,%rdx,4), %esi
	addq	%rdi, %rax
	movl	%esi, %ecx
	sarl	$31, %ecx
	leal	1(%rcx), %esi
	xorl	%esi, %ecx
	movl	%ecx, (%rbx,%rdx,4)
	salq	$2, %rax
	movl	$0, -180000000(%rbx,%rax,4)
	subq	$44999999, %rax
	movl	(%rbx,%rax,4), %esi
	movl	%esi, %edx
	sarl	$31, %edx
	leal	1(%rdx), %ecx
	xorl	%ecx, %edx
	movl	%edx, (%rbx,%rax,4)
	leal	3(%r8), %eax
	movl	%esi, -27920(%rbp)
	cmpl	%r11d, %eax
	jg	.L4112
	cltq
	leaq	(%r9,%rax), %rdx
	salq	$2, %rdx
	movl	$0, -180000000(%rbx,%rdx,4)
	subq	$44999999, %rdx
	movl	(%rbx,%rdx,4), %esi
	addq	%rdi, %rax
	movl	%esi, %ecx
	sarl	$31, %ecx
	leal	1(%rcx), %esi
	xorl	%esi, %ecx
	movl	%ecx, (%rbx,%rdx,4)
	salq	$2, %rax
	movl	$0, -180000000(%rbx,%rax,4)
	subq	$44999999, %rax
	movl	(%rbx,%rax,4), %esi
	movl	%esi, %edx
	sarl	$31, %edx
	leal	1(%rdx), %ecx
	xorl	%ecx, %edx
	movl	%edx, (%rbx,%rax,4)
	leal	4(%r8), %eax
	movl	%esi, -27920(%rbp)
	cmpl	%r11d, %eax
	jg	.L4112
	cltq
	leaq	(%rax,%r9), %rdx
	salq	$2, %rdx
	movl	$0, -180000000(%rbx,%rdx,4)
	subq	$44999999, %rdx
	movl	(%rbx,%rdx,4), %esi
	addq	%rdi, %rax
	movl	%esi, %ecx
	sarl	$31, %ecx
	leal	1(%rcx), %esi
	xorl	%esi, %ecx
	movl	%ecx, (%rbx,%rdx,4)
	salq	$2, %rax
	movl	$0, -180000000(%rbx,%rax,4)
	subq	$44999999, %rax
	movl	(%rbx,%rax,4), %esi
	movl	%esi, %edx
	sarl	$31, %edx
	leal	1(%rdx), %ecx
	xorl	%ecx, %edx
	movl	%edx, (%rbx,%rax,4)
	leal	5(%r8), %eax
	movl	%esi, -27920(%rbp)
	cmpl	%eax, %r11d
	jl	.L4112
	cltq
	leaq	(%r9,%rax), %rdx
	salq	$2, %rdx
	movl	$0, -180000000(%rbx,%rdx,4)
	subq	$44999999, %rdx
	movl	(%rbx,%rdx,4), %esi
	addq	%rdi, %rax
	movl	%esi, %ecx
	sarl	$31, %ecx
	leal	1(%rcx), %esi
	xorl	%esi, %ecx
	movl	%ecx, (%rbx,%rdx,4)
	salq	$2, %rax
	movl	$0, -180000000(%rbx,%rax,4)
	subq	$44999999, %rax
	movl	(%rbx,%rax,4), %esi
	movl	%esi, %edx
	sarl	$31, %edx
	leal	1(%rdx), %ecx
	xorl	%ecx, %edx
	movl	%edx, (%rbx,%rax,4)
	leal	6(%r8), %eax
	movl	%esi, -27920(%rbp)
	cmpl	%r11d, %eax
	jg	.L4112
	cltq
	leaq	(%r9,%rax), %rdx
	salq	$2, %rdx
	movl	$0, -180000000(%rbx,%rdx,4)
	subq	$44999999, %rdx
	movl	(%rbx,%rdx,4), %esi
	addq	%rdi, %rax
	movl	%esi, %ecx
	sarl	$31, %ecx
	leal	1(%rcx), %esi
	xorl	%esi, %ecx
	movl	%ecx, (%rbx,%rdx,4)
	salq	$2, %rax
	movl	$0, -180000000(%rbx,%rax,4)
	subq	$44999999, %rax
	movl	(%rbx,%rax,4), %esi
	movl	%esi, %edx
	sarl	$31, %edx
	leal	1(%rdx), %ecx
	xorl	%ecx, %edx
	movl	%edx, (%rbx,%rax,4)
	leal	7(%r8), %eax
	movl	%esi, -27920(%rbp)
	cmpl	%r11d, %eax
	jg	.L4112
	cltq
	leaq	(%r9,%rax), %rdx
	salq	$2, %rdx
	movl	$0, -180000000(%rbx,%rdx,4)
	subq	$44999999, %rdx
	movl	(%rbx,%rdx,4), %esi
	addq	%rdi, %rax
	movl	%esi, %ecx
	sarl	$31, %ecx
	leal	1(%rcx), %esi
	xorl	%esi, %ecx
	movl	%ecx, (%rbx,%rdx,4)
	salq	$2, %rax
	movl	$0, -180000000(%rbx,%rax,4)
	subq	$44999999, %rax
	movl	(%rbx,%rax,4), %esi
	movl	%esi, %edx
	sarl	$31, %edx
	leal	1(%rdx), %ecx
	xorl	%ecx, %edx
	movl	%edx, (%rbx,%rax,4)
	leal	8(%r8), %eax
	movl	%esi, -27920(%rbp)
	cmpl	%r11d, %eax
	jg	.L4112
	cltq
	leaq	(%r9,%rax), %rdx
	salq	$2, %rdx
	movl	$0, -180000000(%rbx,%rdx,4)
	subq	$44999999, %rdx
	movl	(%rbx,%rdx,4), %esi
	addq	%rdi, %rax
	movl	%esi, %ecx
	sarl	$31, %ecx
	leal	1(%rcx), %esi
	xorl	%esi, %ecx
	movl	%ecx, (%rbx,%rdx,4)
	salq	$2, %rax
	movl	$0, -180000000(%rbx,%rax,4)
	subq	$44999999, %rax
	movl	(%rbx,%rax,4), %esi
	movl	%esi, %edx
	sarl	$31, %edx
	leal	1(%rdx), %ecx
	xorl	%ecx, %edx
	movl	%esi, -27920(%rbp)
	movl	%edx, (%rbx,%rax,4)
	jmp	.L4112
.L4028:
	vmovsd	%xmm6, %xmm6, %xmm7
	vxorpd	%xmm6, %xmm6, %xmm6
	vcomisd	%xmm6, %xmm7
	jbe	.L4583
	movl	%ebx, %edi
	vxorps	%xmm4, %xmm4, %xmm4
	subl	%eax, %edi
	vcvtsi2ssl	%edi, %xmm4, %xmm0
	vxorpd	%xmm6, %xmm6, %xmm6
	vcvtsi2sdl	8+equil_(%rip), %xmm6, %xmm4
	movl	$8275, %r8d
	vcvtss2sd	%xmm0, %xmm0, %xmm0
	vmulsd	%xmm7, %xmm0, %xmm0
	movw	%r8w, -450(%rbp)
	vdivsd	%xmm4, %xmm0, %xmm6
	vmovsd	.LC72(%rip), %xmm4
	vmovsd	%xmm6, -27704(%rbp)
	vmulsd	%xmm6, %xmm4, %xmm4
	jmp	.L3986
.L3981:
	movl	4+equil_(%rip), %eax
	cmpl	%eax, %edx
	jge	.L3990
	vmovsd	.LC72(%rip), %xmm7
	incl	%edx
	movl	%edx, 8+wal_(%rip)
	vmulsd	-27704(%rbp), %xmm7, %xmm4
	movl	32+kier_(%rip), %esi
	vmovsd	8+restart_(%rip), %xmm2
	movl	36+wal_(%rip), %edx
	jmp	.L3986
.L4096:
	leaq	.LC556(%rip), %rax
	movq	%rax, -26192(%rbp)
	movq	%r15, %rdi
	movabsq	$4294971392, %rax
	movq	%rax, -26272(%rbp)
	movl	$2032, -26256(%rbp)
	movq	$34, -26184(%rbp)
	call	_gfortran_st_write@PLT
	leaq	-27384(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$8, %edx
	movq	%r12, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	-26992(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$4, %edx
	leaq	2000008+cmapi_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	vmovsd	-27944(%rbp), %xmm1
	movq	-27752(%rbp), %rsi
	vmulsd	bas_(%rip), %xmm1, %xmm1
	movl	$8, %edx
	movq	%r15, %rdi
	vmovsd	%xmm1, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovq	%r13, %xmm5
	vmulsd	bas_(%rip), %xmm5, %xmm1
	movq	-27752(%rbp), %r13
	movl	$8, %edx
	movq	%r13, %rsi
	movq	%r15, %rdi
	vmovsd	%xmm1, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	-27920(%rbp), %xmm0
	movl	$8, %edx
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movq	%r13, %rsi
	movq	%r15, %rdi
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	-27856(%rbp), %xmm4
	vdivsd	bas_(%rip), %xmm4, %xmm0
	jmp	.L4628
.L4098:
	movl	80036+ssb_(%rip), %r9d
	vmovsd	-26880(%rbp), %xmm1
	vmovsd	-26888(%rbp), %xmm0
	movq	-27640(%rbp), %rax
	testl	%r9d, %r9d
	movq	%rax, -26264(%rbp)
	vmovsd	%xmm0, -27944(%rbp)
	vmovsd	%xmm1, -27920(%rbp)
	je	.L4102
	leaq	.LC559(%rip), %rax
	movq	%rax, -26192(%rbp)
	movq	%r15, %rdi
	movabsq	$4294971392, %rax
	movq	%rax, -26272(%rbp)
	movl	$2097, -26256(%rbp)
	movq	$36, -26184(%rbp)
	call	_gfortran_st_write@PLT
	leaq	-27384(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$8, %edx
	movq	%r12, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	-26992(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$4, %edx
	leaq	2000008+cmapi_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	8+ssb2_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	12+ssb2_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	vmovsd	-27920(%rbp), %xmm1
	movq	-27752(%rbp), %rsi
	vmulsd	bas_(%rip), %xmm1, %xmm1
	movl	$8, %edx
	movq	%r15, %rdi
	vmovsd	%xmm1, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	-27944(%rbp), %xmm0
	movq	-27752(%rbp), %rsi
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movl	$8, %edx
	movq	%r15, %rdi
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovq	%r13, %xmm7
	vmulsd	bas_(%rip), %xmm7, %xmm0
.L4629:
	movq	-27752(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	leaq	-27176(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	400000+gyr_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	leaq	-27104(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	480000+gyr_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	480004+gyr_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L4097
.L4254:
	movl	$1, -27764(%rbp)
	jmp	.L3972
.L4848:
	movq	-27640(%rbp), %rbx
	addq	$88, %rax
	movq	%rax, -26160(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -26272(%rbp)
	movq	%rbx, -26264(%rbp)
	movl	$2153, -26256(%rbp)
	movq	$32, -26152(%rbp)
	movq	$0, -26200(%rbp)
	call	_gfortran_st_write@PLT
	movl	$2, %edx
	leaq	.LC58(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$4, %edx
	leaq	152+restart_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$15, %edx
	leaq	.LC59(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	%rbx, -27640(%rbp)
	movq	%rbx, -26264(%rbp)
	leaq	24+restart_(%rip), %rbx
	leaq	64(%rbx), %rax
	movabsq	$-4294946816, %rsi
	movq	%r15, %rdi
	movq	%rax, -26192(%rbp)
	movq	%rsi, -26272(%rbp)
	movl	$2154, -26256(%rbp)
	movq	%rbx, -26160(%rbp)
	movq	$64, -26152(%rbp)
	movq	$0, -26200(%rbp)
	movq	$32, -26184(%rbp)
	call	_gfortran_st_write@PLT
	movl	$32, %edx
	leaq	96(%rbx), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	vmovsd	-27920(%rbp), %xmm0
	vmovsd	.LC11(%rip), %xmm1
	vmovsd	-27848(%rbp), %xmm5
	vandpd	%xmm0, %xmm1, %xmm1
	vorpd	%xmm1, %xmm5, %xmm1
	vaddsd	%xmm0, %xmm1, %xmm0
	movq	-27752(%rbp), %r13
	movl	$4, %edx
	vcvttsd2sil	%xmm0, %eax
	movq	%r13, %rsi
	movq	%r15, %rdi
	movl	%eax, -26704(%rbp)
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	.LC61(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27640(%rbp), %rax
	movq	%r13, %rdi
	movq	%rax, -26696(%rbp)
	leaq	-27440(%rbp), %rax
	movq	%rax, -26664(%rbp)
	leaq	.LC62(%rip), %rax
	movq	%rax, -26632(%rbp)
	movabsq	$163225535264, %rax
	movq	%rax, -26704(%rbp)
	movl	$2155, -26688(%rbp)
	movl	$0, -27440(%rbp)
	movq	%rbx, -26640(%rbp)
	movq	$64, -26648(%rbp)
	movq	$7, -26624(%rbp)
	movl	$0, -26400(%rbp)
	call	_gfortran_st_open@PLT
	movl	-27440(%rbp), %eax
	testl	%eax, %eax
	jne	.L4111
	movq	-27640(%rbp), %rax
	movq	-27752(%rbp), %rdi
	movq	%rax, -26696(%rbp)
	leaq	.LC562(%rip), %rax
	movq	%rax, -26656(%rbp)
	movabsq	$163208757376, %rax
	movl	$2156, -26688(%rbp)
	movq	$6, -26648(%rbp)
	movq	%rax, -26704(%rbp)
	call	_gfortran_st_close@PLT
	jmp	.L4111
.L4051:
	vmovsd	-27624(%rbp), %xmm6
	vmovsd	-27616(%rbp), %xmm5
	vaddsd	16+plates_(%rip), %xmm6, %xmm4
	vaddsd	24+plates_(%rip), %xmm5, %xmm7
	movq	$0x000000000, -27840(%rbp)
	movq	$0x000000000, -27832(%rbp)
	movl	64+wal_(%rip), %eax
	vmovsd	%xmm4, -27624(%rbp)
	vmovsd	%xmm7, %xmm7, %xmm6
	jmp	.L4219
.L4255:
	xorl	%ecx, %ecx
	movl	%esi, %r9d
	subl	%ecx, %r9d
	movl	$1, %eax
	leaq	mass_(%rip), %rdx
	cmpl	$1, %r9d
	jne	.L4579
.L4852:
	leaq	for_(%rip), %rcx
	jmp	.L3976
.L4099:
	vmulsd	240016+for_(%rip), %xmm1, %xmm1
	jmp	.L4100
.L4580:
	vmovsd	8+restart_(%rip), %xmm2
	movl	32+kier_(%rip), %esi
	movl	36+wal_(%rip), %edx
	cmpl	%r8d, %edi
	jle	.L4257
	vxorps	%xmm6, %xmm6, %xmm6
	vcvtsi2ssl	%r8d, %xmm6, %xmm0
	vxorpd	%xmm4, %xmm4, %xmm4
	vcvtsi2sdl	%edi, %xmm4, %xmm4
	vmovsd	.LC72(%rip), %xmm7
	vcvtss2sd	%xmm0, %xmm0, %xmm0
	vmulsd	-28064(%rbp), %xmm0, %xmm0
	movl	$8275, %eax
	movw	%ax, -450(%rbp)
	vdivsd	%xmm4, %xmm0, %xmm6
	vmulsd	%xmm6, %xmm7, %xmm4
	vmovsd	%xmm6, -27704(%rbp)
	jmp	.L3986
.L3990:
	movl	16+wal_(%rip), %edx
	testl	%edx, %edx
	jne	.L3991
	movl	12+wal_(%rip), %eax
	cmpl	8+equil_(%rip), %eax
	jge	.L3992
	incl	%eax
	movl	%eax, 12+wal_(%rip)
	movl	$8269, %eax
	movw	%ax, -450(%rbp)
.L3992:
	movl	52+wal_(%rip), %r13d
	testl	%r13d, %r13d
	je	.L3993
	movl	56+wal_(%rip), %r11d
	movl	$8258, %r10d
	movw	%r10w, -450(%rbp)
	testl	%r11d, %r11d
	je	.L4861
.L3994:
	movl	120004+respul_(%rip), %eax
	addl	120000+respul_(%rip), %eax
	cmpl	120008+respul_(%rip), %eax
	jge	.L3993
.L4623:
	movl	32+kier_(%rip), %esi
.L4625:
	vxorpd	%xmm4, %xmm4, %xmm4
	vmovsd	8+restart_(%rip), %xmm2
	movl	68+wal_(%rip), %ecx
	movl	36+wal_(%rip), %edx
	vmovsd	%xmm4, -27704(%rbp)
	jmp	.L3986
.L4102:
	leaq	.LC560(%rip), %rax
	movq	%rax, -26192(%rbp)
	movq	%r15, %rdi
	movabsq	$4294971392, %rax
	movq	%rax, -26272(%rbp)
	movl	$2103, -26256(%rbp)
	movq	$36, -26184(%rbp)
	call	_gfortran_st_write@PLT
	leaq	-27384(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$8, %edx
	movq	%r12, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	-26992(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$4, %edx
	leaq	2000008+cmapi_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	sdch_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	4+sdch_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	8+sdch_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	12+sdch_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	16+sdch_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	$4, %edx
	leaq	20+sdch_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	vmovsd	-27920(%rbp), %xmm1
	movq	-27752(%rbp), %rsi
	vmulsd	bas_(%rip), %xmm1, %xmm1
	movl	$8, %edx
	movq	%r15, %rdi
	vmovsd	%xmm1, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	-27944(%rbp), %xmm0
	movq	-27752(%rbp), %rsi
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movl	$8, %edx
	movq	%r15, %rdi
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovq	%r13, %xmm5
	vmulsd	bas_(%rip), %xmm5, %xmm0
	jmp	.L4629
.L4101:
	vmovsd	-27816(%rbp), %xmm5
	vmulsd	.LC72(%rip), %xmm0, %xmm0
	vaddsd	-27824(%rbp), %xmm5, %xmm1
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	vmulsd	%xmm1, %xmm0, %xmm0
	leaq	.LC558(%rip), %rax
	movq	%rax, -26192(%rbp)
	movabsq	$4294971392, %rax
	movq	%rax, -26272(%rbp)
	vmovsd	%xmm0, -27224(%rbp)
	movl	$2076, -26256(%rbp)
	movq	$51, -26184(%rbp)
	call	_gfortran_st_write@PLT
	leaq	-450(%rbp), %rsi
	movq	%r15, %rdi
	movl	$2, %edx
	call	_gfortran_transfer_character_write@PLT
	leaq	-27384(%rbp), %rsi
	movq	%r15, %rdi
	movl	$4, %edx
	call	_gfortran_transfer_integer_write@PLT
	movq	%r12, %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26992(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	2000012+cmapi_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	2000020+cmapi_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	2000016+cmapi_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	2000024+cmapi_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	2000008+cmapi_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	vmovq	%r13, %xmm6
	vmulsd	bas_(%rip), %xmm6, %xmm0
	movq	-27752(%rbp), %r13
	movq	%r15, %rdi
	movq	%r13, %rsi
	movl	$8, %edx
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	leaq	-26768(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-27080(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-27224(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26712(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26984(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26976(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	8+restart_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	leaq	-27176(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	vmovsd	24+masscenter_(%rip), %xmm0
	movq	%r13, %rsi
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movq	%r15, %rdi
	movl	$8, %edx
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	32+masscenter_(%rip), %xmm0
	movq	%r13, %rsi
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movq	%r15, %rdi
	movl	$8, %edx
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	40+masscenter_(%rip), %xmm0
	movq	%r13, %rsi
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movq	%r15, %rdi
	movl	$8, %edx
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movl	48+wal_(%rip), %eax
	movq	%r15, %rdi
	addl	44+wal_(%rip), %eax
	movl	$4, %edx
	movq	%r13, %rsi
	movl	%eax, -26704(%rbp)
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L4097
.L4583:
	movl	16+wal_(%rip), %eax
	cmpl	4+equil_(%rip), %eax
	jg	.L4031
	movl	$8274, %edi
	incl	%eax
	movw	%di, -450(%rbp)
	movl	%eax, 16+wal_(%rip)
	movq	$0x000000000, -27704(%rbp)
	vxorpd	%xmm4, %xmm4, %xmm4
	jmp	.L3986
.L4264:
	vxorpd	%xmm1, %xmm1, %xmm1
	jmp	.L4092
.L3944:
	movq	%r12, %rdi
	call	evalcpot_
	movl	80016+chiral_(%rip), %r10d
	testl	%r10d, %r10d
	je	.L3946
.L4836:
	leaq	-27016(%rbp), %rdi
	call	eval_chirality_
	vmovsd	-27008(%rbp), %xmm0
	vaddsd	-27016(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, -27008(%rbp)
	jmp	.L3946
.L4278:
	movl	8+bas_(%rip), %r12d
	movl	$1, -27452(%rbp)
	leaq	bon_(%rip), %rbx
	testl	%r12d, %r12d
	jle	.L3861
	movl	%r12d, %r13d
	vmovsd	bon_(%rip), %xmm4
	salq	$3, %r13
	movq	%r13, %rdx
	xorl	%esi, %esi
	leaq	pos_(%rip), %rdi
	vmovsd	%xmm4, -27480(%rbp)
	vzeroupper
	call	memset@PLT
	xorl	%esi, %esi
	movq	%r13, %rdx
	leaq	80000+pos_(%rip), %rdi
	call	memset@PLT
	leal	-1(%r12), %eax
	cmpl	$6, %eax
	vmovsd	-27480(%rbp), %xmm4
	jbe	.L4243
	movl	%r12d, %edx
	shrl	$3, %edx
	leaq	160000+pos_(%rip), %rax
	salq	$6, %rdx
	vmovdqa	.LC76(%rip), %ymm2
	vbroadcastsd	%xmm4, %ymm3
	addq	%rax, %rdx
	vpcmpeqd	%ymm5, %ymm5, %ymm5
	.p2align 4,,10
	.p2align 3
.L3863:
	vmovdqa	%ymm2, %ymm0
	vpaddd	%ymm5, %ymm0, %ymm0
	vcvtdq2pd	%xmm0, %ymm1
	vextracti128	$0x1, %ymm0, %xmm0
	vmulpd	%ymm3, %ymm1, %ymm1
	vcvtdq2pd	%xmm0, %ymm0
	vmulpd	%ymm3, %ymm0, %ymm0
	addq	$64, %rax
	vpaddd	.LC77(%rip), %ymm2, %ymm2
	vmovapd	%ymm1, -64(%rax)
	vmovapd	%ymm0, -32(%rax)
	cmpq	%rax, %rdx
	jne	.L3863
	movl	%r12d, %eax
	andl	$-8, %eax
	leal	1(%rax), %ecx
	cmpl	%r12d, %eax
	je	.L3864
	movl	%r12d, %esi
	subl	%eax, %esi
	leal	-1(%rsi), %edx
	cmpl	$2, %edx
	jbe	.L4862
.L4569:
	vmovd	%ecx, %xmm5
	vpshufd	$0, %xmm5, %xmm0
	vpaddd	.LC93(%rip), %xmm0, %xmm0
	vmovddup	%xmm4, %xmm1
	vcvtdq2pd	%xmm0, %xmm2
	vpshufd	$238, %xmm0, %xmm0
	vmulpd	%xmm1, %xmm2, %xmm2
	vcvtdq2pd	%xmm0, %xmm0
	vmulpd	%xmm1, %xmm0, %xmm0
	leal	20000(%rax), %edx
	leaq	pos_(%rip), %rax
	leaq	(%rax,%rdx,8), %rdx
	vmovapd	%xmm2, (%rdx)
	vmovapd	%xmm0, 16(%rdx)
	movl	%esi, %edx
	andl	$-4, %edx
	addl	%edx, %ecx
	cmpl	%edx, %esi
	je	.L3864
.L3865:
	leal	-1(%rcx), %edx
	vxorpd	%xmm6, %xmm6, %xmm6
	vcvtsi2sdl	%edx, %xmm6, %xmm0
	movslq	%edx, %rdi
	movslq	%ecx, %rsi
	vmulsd	%xmm4, %xmm0, %xmm0
	vmovsd	%xmm0, 160000(%rax,%rdi,8)
	leal	1(%rcx), %edi
	cmpl	%edi, %r12d
	jl	.L3864
	vcvtsi2sdl	%ecx, %xmm6, %xmm0
	addl	$2, %ecx
	movslq	%edi, %rdx
	vmulsd	%xmm4, %xmm0, %xmm0
	vmovsd	%xmm0, 160000(%rax,%rsi,8)
	cmpl	%ecx, %r12d
	jl	.L3864
	vcvtsi2sdl	%edi, %xmm6, %xmm0
	vmulsd	%xmm4, %xmm0, %xmm4
	vmovsd	%xmm4, 160000(%rax,%rdx,8)
.L3864:
	incl	%r12d
	movl	%r12d, -27452(%rbp)
.L3861:
	movl	-27288(%rbp), %edx
	testl	%edx, %edx
	je	.L3868
	leaq	-27120(%rbp), %rsi
	leaq	-26856(%rbp), %rdi
	vzeroupper
	call	confstart_
	movl	-27964(%rbp), %eax
	testl	%eax, %eax
	je	.L3872
.L4831:
	leaq	-27160(%rbp), %rdx
	leaq	-27416(%rbp), %rsi
	leaq	-27444(%rbp), %rdi
	vzeroupper
	call	displace_
	jmp	.L3872
.L4262:
	xorl	%edx, %edx
	movl	$1, %eax
	leaq	kbt.6(%rip), %r8
	jmp	.L4064
.L3912:
	movl	-27292(%rbp), %ebx
	testl	%ebx, %ebx
	je	.L4249
	leaq	24+restart_(%rip), %rax
	movq	-27640(%rbp), %rbx
	movq	%rax, -26640(%rbp)
	movq	-27752(%rbp), %rdi
	leaq	.LC62(%rip), %rax
	movq	%rax, -26632(%rbp)
	movabsq	$90211091200, %rax
	movq	%rax, -26704(%rbp)
	movq	%rbx, -26696(%rbp)
	movabsq	$90194313344, %r13
	movl	$1384, -26688(%rbp)
	movq	$64, -26648(%rbp)
	movq	$7, -26624(%rbp)
	movl	$0, -26400(%rbp)
	movl	-27312(%rbp), %r12d
	call	_gfortran_st_open@PLT
	movq	%r15, %rdi
	movq	%rbx, -27640(%rbp)
	movq	%rbx, -26264(%rbp)
	movl	$1385, -26256(%rbp)
	movq	%r13, -26272(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-26816(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movl	$8, %edx
	leaq	8+restart_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	vmovsd	-26816(%rbp), %xmm0
	leaq	restart_(%rip), %rsi
	vdivsd	(%rsi), %xmm0, %xmm0
	vcvttsd2sil	%xmm0, %ebx
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	addl	%ebx, -27248(%rbp)
	movl	$1388, -26256(%rbp)
	movq	%r13, -26272(%rbp)
	call	_gfortran_st_read@PLT
	movl	$8, %edx
	leaq	8+plates_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movl	$8, %edx
	leaq	plates_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movl	$8, %edx
	leaq	56+plates_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movl	$8, %edx
	leaq	64+plates_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movl	$8, %edx
	leaq	40+plates_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movl	$8, %edx
	leaq	48+plates_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movl	$8, %edx
	leaq	16+restart_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movl	$8, %edx
	leaq	24+kier_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movl	-27368(%rbp), %r11d
	testl	%r11d, %r11d
	je	.L3914
	vmovsd	-27184(%rbp), %xmm0
	vdivsd	16+restart_(%rip), %xmm0, %xmm0
	vmovsd	%xmm0, -27192(%rbp)
.L3914:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	movabsq	$90194313344, %rax
	movq	%rax, -26272(%rbp)
	movl	$1390, -26256(%rbp)
	call	_gfortran_st_read@PLT
	leaq	8+wal_(%rip), %rax
	movq	%rax, -26352(%rbp)
	movabsq	$1103806595072, %rax
	movq	%rax, -26328(%rbp)
	vmovdqa	.LC66(%rip), %ymm0
	leaq	-26352(%rbp), %rax
	xorl	%ecx, %ecx
	movl	$4, %edx
	movq	%rax, %rsi
	movq	%r15, %rdi
	movq	$-1, -26344(%rbp)
	movq	$4, -26336(%rbp)
	movq	%rax, -27472(%rbp)
	vmovdqa	%ymm0, -26320(%rbp)
	vzeroupper
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movl	8+wal_(%rip), %r10d
	movl	$8261, %r9d
	movw	%r9w, -450(%rbp)
	testl	%r10d, %r10d
	jle	.L3915
	vmovsd	-27464(%rbp), %xmm6
	vxorpd	.LC11(%rip), %xmm6, %xmm4
	vmovsd	%xmm4, -27464(%rbp)
.L3915:
	movslq	16+equil_(%rip), %rax
	leaq	wal_(%rip), %r13
	movl	4(%r13,%rax,4), %edx
	testl	%r12d, %r12d
	je	.L3916
	movl	16+wal_(%rip), %r8d
	testl	%r8d, %r8d
	jle	.L3917
	vmovsd	-27464(%rbp), %xmm4
	vxorpd	.LC11(%rip), %xmm4, %xmm7
	vmovsd	%xmm7, -27464(%rbp)
.L3917:
	testl	%edx, %edx
	jle	.L4204
.L4203:
	movl	36+bas_(%rip), %edi
	testl	%edi, %edi
	jne	.L4863
.L3918:
	movl	8(%r13,%rax,4), %esi
	testl	%esi, %esi
	jne	.L3919
	movl	$8258, %ecx
	movw	%cx, -450(%rbp)
.L3919:
	vmovsd	-27464(%rbp), %xmm5
	vmovsd	%xmm5, -27760(%rbp)
	testl	%r12d, %r12d
	je	.L3920
.L4204:
	vmovsd	-27464(%rbp), %xmm4
	cmpl	$-1, 28+wal_(%rip)
	vmovsd	%xmm4, -27760(%rbp)
	jl	.L3920
	movl	$8271, %edx
	vxorpd	.LC11(%rip), %xmm4, %xmm6
	movw	%dx, -450(%rbp)
	vmovsd	%xmm6, -27760(%rbp)
.L3920:
	movl	36+wal_(%rip), %eax
	testl	%eax, %eax
	jle	.L3921
	movl	$8272, %eax
	movw	%ax, -450(%rbp)
.L3921:
	movl	-27336(%rbp), %eax
	testl	%eax, %eax
	je	.L3922
	leaq	equil_(%rip), %rax
	movq	%rax, -27480(%rbp)
	movl	4+equil_(%rip), %eax
	movl	8+bas_(%rip), %ecx
	addl	%ebx, %eax
	movl	%eax, equil_(%rip)
	movl	$1, -27452(%rbp)
	testl	%ecx, %ecx
	jle	.L3923
	movq	-27608(%rbp), %rax
	vmovsd	48+plates_(%rip), %xmm2
	vmovsd	(%rax), %xmm0
	leal	-1(%rcx), %eax
	vmovsd	64+plates_(%rip), %xmm1
	cmpl	$2, %eax
	jbe	.L4252
	movl	%ecx, %edx
	shrl	$2, %edx
	leaq	160000+pos_(%rip), %rax
	salq	$5, %rdx
	vbroadcastsd	%xmm2, %ymm6
	vbroadcastsd	%xmm1, %ymm5
	vbroadcastsd	%xmm0, %ymm4
	addq	%rax, %rdx
.L3925:
	vaddpd	-160000(%rax), %ymm6, %ymm3
	addq	$32, %rax
	vmovapd	%ymm3, -160032(%rax)
	vaddpd	-80032(%rax), %ymm5, %ymm3
	vmovapd	%ymm3, -80032(%rax)
	vaddpd	-32(%rax), %ymm4, %ymm3
	vmovapd	%ymm3, -32(%rax)
	cmpq	%rdx, %rax
	jne	.L3925
	movl	%ecx, %eax
	andl	$-4, %eax
	leal	1(%rax), %edx
	cmpl	%ecx, %eax
	je	.L4864
	vzeroupper
	movl	%ecx, %edi
	subl	%eax, %edi
	cmpl	$1, %edi
	je	.L4865
.L4574:
	leaq	0(,%rax,8), %rsi
	leaq	pos_(%rip), %rax
	leaq	(%rax,%rsi), %r9
	vmovddup	%xmm2, %xmm3
	vaddpd	(%r9), %xmm3, %xmm3
	leaq	80000(%rax,%rsi), %r8
	leaq	160000(%rax,%rsi), %rsi
	vmovapd	%xmm3, (%r9)
	vmovddup	%xmm1, %xmm3
	vaddpd	(%r8), %xmm3, %xmm3
	vmovapd	%xmm3, (%r8)
	vmovddup	%xmm0, %xmm3
	vaddpd	(%rsi), %xmm3, %xmm3
	vmovapd	%xmm3, (%rsi)
	movl	%edi, %esi
	andl	$-2, %esi
	addl	%esi, %edx
	cmpl	%edi, %esi
	je	.L3926
.L3927:
	decl	%edx
	movslq	%edx, %rdx
	vaddsd	(%rax,%rdx,8), %xmm2, %xmm2
	vaddsd	80000(%rax,%rdx,8), %xmm1, %xmm1
	vaddsd	160000(%rax,%rdx,8), %xmm0, %xmm0
	vmovsd	%xmm2, (%rax,%rdx,8)
	vmovsd	%xmm1, 80000(%rax,%rdx,8)
	vmovsd	%xmm0, 160000(%rax,%rdx,8)
.L3926:
	incl	%ecx
	movl	%ecx, -27452(%rbp)
.L3923:
	movq	-27640(%rbp), %rax
	movq	-27752(%rbp), %rdi
	movq	%rax, -26696(%rbp)
	movabsq	$90194313216, %rax
	movl	$1443, -26688(%rbp)
	movq	%rax, -26704(%rbp)
	call	_gfortran_st_close@PLT
	jmp	.L3913
.L4839:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	movabsq	$4294971392, %r13
	leaq	.LC536(%rip), %rax
	movq	%rax, -26192(%rbp)
	movl	$1482, -26256(%rbp)
	movq	$9, -26184(%rbp)
	movq	%r13, -26272(%rbp)
	call	_gfortran_st_write@PLT
	movl	$11, %edx
	leaq	.LC537(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	-27428(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movl	-27488(%rbp), %edi
	movq	-27640(%rbp), %rax
	testl	%edi, %edi
	jne	.L4866
	movl	60+wal_(%rip), %esi
	testl	%esi, %esi
	je	.L3958
	movl	64+wal_(%rip), %ecx
	movq	%rax, -26264(%rbp)
	testl	%ecx, %ecx
	je	.L3959
	leaq	.LC540(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, -26192(%rbp)
	movl	$1494, -26256(%rbp)
	movq	$9, -26184(%rbp)
	movq	%r13, -26272(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$35, %edx
	leaq	.LC541(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$54, %edx
	leaq	.LC542(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$50, %edx
	leaq	.LC543(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$56, %edx
	leaq	.LC544(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3956
.L4838:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	leaq	.LC140(%rip), %rax
	movq	%rax, -26192(%rbp)
	movabsq	$8589938688, %rax
	movq	%rax, -26272(%rbp)
	movl	$1480, -26256(%rbp)
	movq	$6, -26184(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$5, %edx
	leaq	.LC535(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	leaq	-27428(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3955
.L4257:
	vmovsd	-28064(%rbp), %xmm7
	vmovsd	-28128(%rbp), %xmm4
	vmovsd	%xmm7, -27704(%rbp)
	jmp	.L3986
.L3991:
	cmpl	%edx, %eax
	jle	.L4003
	vmovsd	.LC72(%rip), %xmm6
	incl	%edx
	movl	%edx, 16+wal_(%rip)
	vmulsd	-27704(%rbp), %xmm6, %xmm4
	movl	32+kier_(%rip), %esi
	vmovsd	8+restart_(%rip), %xmm2
	movl	36+wal_(%rip), %edx
	jmp	.L3986
.L4138:
	leaq	cmap_(%rip), %rax
	movl	60000004(%rax), %eax
	movl	%eax, -27528(%rbp)
	testl	%eax, %eax
	jle	.L4141
	leaq	restart_(%rip), %rbx
	vmovsd	(%rbx), %xmm5
	movl	%eax, %ebx
	movl	%eax, -27544(%rbp)
	leal	-1(%rax), %eax
	cmpl	$2147483647, %ebx
	je	.L4142
	cmpl	$2, %eax
	jbe	.L4142
	cmpl	$6, %eax
	jbe	.L4269
	movl	%ebx, %eax
	shrl	$3, %eax
	movl	%eax, -27464(%rbp)
	leaq	fut.4(%rip), %rax
	leaq	fut2.3(%rip), %r8
	movq	%rax, -27472(%rbp)
	movq	%rax, %rcx
	leaq	fbt.14(%rip), %rbx
	leaq	fbt2.13(%rip), %rax
	movq	%rax, -27512(%rbp)
	movq	%rax, %rdx
	movq	%r8, -27544(%rbp)
	vmovdqa	.LC554(%rip), %ymm6
	vbroadcastsd	%xmm5, %ymm3
	movq	%r8, %rsi
	movq	%rbx, %rax
	xorl	%edi, %edi
	xorl	%r9d, %r9d
	leaq	kbt.6(%rip), %r10
	leaq	kut.5(%rip), %r11
	vpxor	%xmm4, %xmm4, %xmm4
	jmp	.L4146
.L4144:
	incl	%r9d
	addq	$32, %rdi
	addq	$64, %rsi
	addq	$64, %rcx
	addq	$64, %rdx
	addq	$64, %rax
	cmpl	-27464(%rbp), %r9d
	jnb	.L4867
.L4146:
	vmovdqa	(%r10,%rdi), %ymm7
	vmovapd	(%rax), %ymm11
	vcvtdq2pd	%xmm7, %ymm1
	vmulpd	%ymm3, %ymm1, %ymm1
	vextracti128	$0x1, %ymm7, %xmm0
	vcvtdq2pd	%xmm0, %ymm0
	vpcmpeqd	%ymm4, %ymm7, %ymm7
	vmulpd	%ymm3, %ymm0, %ymm0
	vaddpd	%ymm1, %ymm11, %ymm2
	vmovapd	32(%rax), %ymm10
	vpmovsxdq	%xmm7, %ymm9
	vblendvpd	%ymm9, %ymm11, %ymm2, %ymm2
	vmovapd	%ymm2, (%rax)
	vaddpd	%ymm0, %ymm10, %ymm2
	vextracti128	$0x1, %ymm7, %xmm8
	vpmovsxdq	%xmm8, %ymm8
	vblendvpd	%ymm8, %ymm10, %ymm2, %ymm2
	vmovapd	%ymm2, 32(%rax)
	vmovapd	32(%rdx), %ymm2
	vmovapd	(%rdx), %ymm10
	vfmadd132pd	%ymm0, %ymm2, %ymm0
	vfmadd132pd	%ymm1, %ymm10, %ymm1
	vblendvpd	%ymm8, %ymm2, %ymm0, %ymm0
	vmovdqa	(%r11,%rdi), %ymm2
	vblendvpd	%ymm9, %ymm10, %ymm1, %ymm1
	vmovapd	%ymm1, (%rdx)
	vcvtdq2pd	%xmm2, %ymm1
	vmulpd	%ymm3, %ymm1, %ymm1
	vmovapd	%ymm0, 32(%rdx)
	vmovapd	(%rcx), %ymm11
	vextracti128	$0x1, %ymm2, %xmm0
	vcvtdq2pd	%xmm0, %ymm0
	vmulpd	%ymm3, %ymm0, %ymm0
	vaddpd	%ymm1, %ymm11, %ymm2
	vmovapd	32(%rcx), %ymm10
	vblendvpd	%ymm9, %ymm11, %ymm2, %ymm2
	vmovapd	%ymm2, (%rcx)
	vaddpd	%ymm0, %ymm10, %ymm2
	vblendvpd	%ymm8, %ymm10, %ymm2, %ymm2
	vmovapd	%ymm2, 32(%rcx)
	vmovapd	32(%rsi), %ymm2
	vmovapd	(%rsi), %ymm10
	vfmadd132pd	%ymm0, %ymm2, %ymm0
	vfmadd132pd	%ymm1, %ymm10, %ymm1
	vblendvpd	%ymm8, %ymm2, %ymm0, %ymm0
	vmovapd	%ymm0, 32(%rsi)
	vpcmpeqd	%ymm4, %ymm7, %ymm0
	vblendvpd	%ymm9, %ymm10, %ymm1, %ymm1
	vmovapd	%ymm1, (%rsi)
	vptest	%ymm0, %ymm0
	je	.L4144
	leaq	mtraj.12(%rip), %r8
	vpmaskmovd	(%r8,%rdi), %ymm0, %ymm1
	vpaddd	%ymm6, %ymm1, %ymm1
	vpmaskmovd	%ymm1, %ymm0, (%r8,%rdi)
	jmp	.L4144
.L3880:
	movl	68+wal_(%rip), %r11d
	movl	8+bas_(%rip), %r12d
	xorl	$1, %r11d
	movq	$0, 120000+respul_(%rip)
	leaq	respul_(%rip), %rdx
	orl	%r13d, %r11d
	testl	%r12d, %r12d
	jle	.L3882
	movl	56+wal_(%rip), %eax
	leal	-1(%r12), %r13d
	testl	%eax, %eax
	jne	.L3883
	cmpl	$6, %r13d
	jbe	.L4246
	movl	%r12d, %esi
	shrl	$3, %esi
	salq	$6, %rsi
	vmovdqa	.LC76(%rip), %ymm2
	movq	%rdx, %rax
	leaq	160000+pos_(%rip), %rcx
	leaq	80000(%rdx), %rdi
	addq	%rdx, %rsi
	vpxor	%xmm3, %xmm3, %xmm3
.L3885:
	vmovapd	(%rcx), %ymm5
	vmovdqa	%ymm2, %ymm0
	vmovapd	%ymm5, (%rax)
	vmovapd	32(%rcx), %ymm5
	vpunpckldq	%ymm0, %ymm3, %ymm1
	vmovapd	%ymm5, 32(%rax)
	vmovdqa	%ymm0, (%rdi)
	vpunpckhdq	%ymm0, %ymm3, %ymm0
	vperm2i128	$32, %ymm0, %ymm1, %ymm4
	vperm2i128	$49, %ymm0, %ymm1, %ymm0
	vmovdqu	%ymm4, 120012(%rax)
	vmovdqu	%ymm0, 120044(%rax)
	addq	$64, %rax
	vpaddd	.LC77(%rip), %ymm2, %ymm2
	addq	$64, %rcx
	addq	$32, %rdi
	cmpq	%rsi, %rax
	jne	.L3885
	movl	%r12d, %eax
	andl	$-8, %eax
	leal	1(%rax), %ecx
	cmpl	%r12d, %eax
	je	.L3886
.L3884:
	movl	%r12d, %esi
	subl	%eax, %esi
	leal	-1(%rsi), %edi
	cmpl	$2, %edi
	jbe	.L4868
	leal	20000(%rax), %r10d
	leaq	0(,%r10,8), %rdi
	leaq	pos_(%rip), %rax
	leaq	(%rax,%rdi), %r9
	vmovapd	(%r9), %xmm0
	leaq	-160000(%rdx,%rdi), %r8
	vmovd	%ecx, %xmm4
	vmovapd	16(%r9), %xmm7
	vmovapd	%xmm0, (%r8)
	vpshufd	$0, %xmm4, %xmm0
	vpaddd	.LC78(%rip), %xmm0, %xmm0
	vmovapd	%xmm7, 16(%r8)
	vmovdqa	%xmm0, (%rdx,%r10,4)
	leal	1(%rcx), %r8d
	vpxor	%xmm0, %xmm0, %xmm0
	vpinsrd	$1, %r8d, %xmm0, %xmm2
	vpinsrd	$1, %ecx, %xmm0, %xmm1
	leaq	-39988(%rdx,%rdi), %rdi
	vpunpcklqdq	%xmm2, %xmm1, %xmm1
	leal	2(%rcx), %r9d
	leal	3(%rcx), %r8d
	vmovdqu	%xmm1, (%rdi)
	vpinsrd	$1, %r8d, %xmm0, %xmm1
	vpinsrd	$1, %r9d, %xmm0, %xmm0
	vpunpcklqdq	%xmm1, %xmm0, %xmm0
	vmovdqu	%xmm0, 16(%rdi)
	movl	%esi, %edi
	andl	$-4, %edi
	addl	%edi, %ecx
	cmpl	%esi, %edi
	je	.L3886
.L3887:
	leal	-1(%rcx), %esi
	movslq	%esi, %rsi
	leaq	20000(%rsi), %rdi
	vmovsd	(%rax,%rdi,8), %xmm0
	movl	%ecx, (%rdx,%rdi,4)
	vmovsd	%xmm0, (%rdx,%rsi,8)
	leal	1(%rcx), %edi
	addq	%rsi, %rsi
	movl	$0, 120012(%rdx,%rsi,4)
	movl	%ecx, 120016(%rdx,%rsi,4)
	movslq	%ecx, %r9
	cmpl	%r12d, %edi
	jg	.L3886
	leaq	20000(%r9), %r8
	vmovsd	(%rax,%r8,8), %xmm0
	addl	$2, %ecx
	movl	%edi, (%rdx,%r8,4)
	movl	$0, 120020(%rdx,%rsi,4)
	movl	%edi, 120024(%rdx,%rsi,4)
	movslq	%edi, %r10
	vmovsd	%xmm0, (%rdx,%r9,8)
	cmpl	%ecx, %r12d
	jl	.L3886
	leaq	20000(%r10), %rdi
	vmovsd	(%rax,%rdi,8), %xmm0
	movl	%ecx, (%rdx,%rdi,4)
	movl	$0, 120028(%rdx,%rsi,4)
	movl	%ecx, 120032(%rdx,%rsi,4)
	vmovsd	%xmm0, (%rdx,%r10,8)
.L3886:
	leal	1(%r12), %eax
	movl	%eax, -27764(%rbp)
	testl	%r11d, %r11d
	je	.L4210
.L4872:
	vmovsd	40+plates_(%rip), %xmm5
	vmovsd	48+plates_(%rip), %xmm6
	movq	-27608(%rbp), %rax
	vmovsd	56+plates_(%rip), %xmm7
	vmovsd	64+plates_(%rip), %xmm4
	vmovsd	%xmm5, -27656(%rbp)
	vmovsd	%xmm6, -27648(%rbp)
	vmovsd	8+plates_(%rip), %xmm5
	vmovsd	(%rax), %xmm6
	movq	$0x000000000, -27704(%rbp)
	vmovsd	%xmm7, -27672(%rbp)
	vmovsd	%xmm4, -27664(%rbp)
	vmovsd	%xmm5, -27688(%rbp)
	vmovsd	%xmm6, -27680(%rbp)
	jmp	.L3881
.L4832:
	movl	8+bas_(%rip), %r12d
	vxorpd	%xmm7, %xmm7, %xmm7
	vcvtsi2sdl	%r12d, %xmm7, %xmm0
	movq	.LC134(%rip), %rax
	vmovq	%rax, %xmm1
	vdivsd	-26856(%rbp), %xmm0, %xmm0
	vzeroupper
	call	pow@PLT
	vmulsd	.LC72(%rip), %xmm0, %xmm0
	vxorpd	.LC11(%rip), %xmm0, %xmm1
	testl	%r12d, %r12d
	jle	.L4244
	vmovsd	(%rbx), %xmm7
	leal	-1(%r12), %eax
	vaddsd	%xmm7, %xmm7, %xmm7
	cmpl	$2, %eax
	jbe	.L4245
	movl	%r12d, %edx
	shrl	$2, %edx
	vbroadcastsd	%xmm0, %ymm0
	vbroadcastsd	%xmm1, %ymm5
	leaq	160000+pos_(%rip), %rax
	salq	$5, %rdx
	vbroadcastsd	%xmm7, %ymm4
	addq	%rax, %rdx
	vmovapd	%ymm5, %ymm8
	vmovapd	%ymm0, %ymm10
	vmovapd	%ymm5, %ymm6
	vmovapd	%ymm0, %ymm9
.L3876:
	vmovapd	-160000(%rax), %ymm3
	vmovapd	-80000(%rax), %ymm2
	vsubpd	%ymm4, %ymm3, %ymm1
	vaddpd	%ymm3, %ymm4, %ymm3
	addq	$32, %rax
	vminpd	%ymm1, %ymm5, %ymm5
	vsubpd	%ymm4, %ymm2, %ymm1
	vaddpd	%ymm2, %ymm4, %ymm2
	vmaxpd	%ymm3, %ymm0, %ymm0
	vminpd	%ymm1, %ymm6, %ymm6
	vmovapd	-32(%rax), %ymm1
	vmaxpd	%ymm2, %ymm9, %ymm9
	vsubpd	%ymm4, %ymm1, %ymm11
	vaddpd	%ymm1, %ymm4, %ymm1
	vminpd	%ymm11, %ymm8, %ymm8
	vmaxpd	%ymm1, %ymm10, %ymm10
	cmpq	%rdx, %rax
	jne	.L3876
	vextractf128	$0x1, %ymm10, %xmm1
	vmaxpd	%xmm10, %xmm1, %xmm10
	vextractf128	$0x1, %ymm9, %xmm1
	vmaxpd	%xmm9, %xmm1, %xmm9
	vextractf128	$0x1, %ymm0, %xmm1
	vmaxpd	%xmm0, %xmm1, %xmm0
	vunpckhpd	%xmm10, %xmm10, %xmm2
	vunpckhpd	%xmm9, %xmm9, %xmm3
	vunpckhpd	%xmm0, %xmm0, %xmm1
	vmaxpd	%xmm0, %xmm1, %xmm0
	vextractf128	$0x1, %ymm8, %xmm1
	vminpd	%xmm8, %xmm1, %xmm8
	vextractf128	$0x1, %ymm6, %xmm1
	vminpd	%xmm6, %xmm1, %xmm6
	vunpckhpd	%xmm8, %xmm8, %xmm4
	vmaxpd	%xmm10, %xmm2, %xmm10
	vunpckhpd	%xmm6, %xmm6, %xmm1
	vminpd	%xmm6, %xmm1, %xmm6
	vextractf128	$0x1, %ymm5, %xmm1
	vminpd	%xmm5, %xmm1, %xmm1
	vmaxpd	%xmm9, %xmm3, %xmm9
	vminpd	%xmm8, %xmm4, %xmm8
	movl	%r12d, %eax
	vunpckhpd	%xmm1, %xmm1, %xmm5
	andl	$-4, %eax
	vminpd	%xmm1, %xmm5, %xmm1
	vmovsd	%xmm10, %xmm10, %xmm2
	vmovsd	%xmm9, %xmm9, %xmm3
	vmovsd	%xmm8, %xmm8, %xmm4
	leal	1(%rax), %edx
	cmpl	%r12d, %eax
	je	.L3877
	movl	%r12d, %ecx
	subl	%eax, %ecx
	leal	-1(%rcx), %esi
	cmpl	$1, %esi
	jbe	.L4869
.L4570:
	movl	%eax, %esi
	leaq	pos_(%rip), %rax
	vmovapd	(%rax,%rsi,8), %xmm8
	vmovddup	%xmm7, %xmm5
	vsubpd	%xmm5, %xmm8, %xmm9
	vmovddup	%xmm1, %xmm1
	leaq	80000(%rax), %rdi
	vminpd	%xmm1, %xmm9, %xmm9
	vmovapd	(%rdi,%rsi,8), %xmm1
	leaq	160000(%rax), %rdi
	vsubpd	%xmm5, %xmm1, %xmm10
	vmovapd	(%rdi,%rsi,8), %xmm11
	vmovddup	%xmm6, %xmm6
	vminpd	%xmm6, %xmm10, %xmm6
	vsubpd	%xmm5, %xmm11, %xmm10
	vmovddup	%xmm4, %xmm4
	vmovddup	%xmm0, %xmm0
	vminpd	%xmm4, %xmm10, %xmm10
	vaddpd	%xmm5, %xmm8, %xmm4
	vaddpd	%xmm1, %xmm5, %xmm1
	vmovddup	%xmm3, %xmm3
	vmaxpd	%xmm0, %xmm4, %xmm4
	vaddpd	%xmm11, %xmm5, %xmm0
	vmovddup	%xmm2, %xmm2
	vmaxpd	%xmm3, %xmm1, %xmm1
	vmaxpd	%xmm2, %xmm0, %xmm0
	movl	%ecx, %esi
	vunpckhpd	%xmm1, %xmm1, %xmm3
	vunpckhpd	%xmm0, %xmm0, %xmm2
	vmaxpd	%xmm0, %xmm2, %xmm0
	vmaxpd	%xmm1, %xmm3, %xmm1
	andl	$-2, %esi
	vmovsd	%xmm0, %xmm0, %xmm2
	vmovsd	%xmm1, %xmm1, %xmm3
	vunpckhpd	%xmm4, %xmm4, %xmm0
	vunpckhpd	%xmm6, %xmm6, %xmm1
	vmaxpd	%xmm4, %xmm0, %xmm0
	vminpd	%xmm6, %xmm1, %xmm6
	vunpckhpd	%xmm10, %xmm10, %xmm4
	vunpckhpd	%xmm9, %xmm9, %xmm1
	vminpd	%xmm10, %xmm4, %xmm4
	vminpd	%xmm9, %xmm1, %xmm1
	addl	%esi, %edx
	cmpl	%esi, %ecx
	je	.L3877
.L3878:
	leal	-1(%rdx), %ecx
	movslq	%ecx, %rcx
	vmovsd	(%rax,%rcx,8), %xmm9
	vmovsd	80000(%rax,%rcx,8), %xmm8
	vsubsd	%xmm7, %xmm9, %xmm5
	vaddsd	%xmm9, %xmm7, %xmm9
	vminsd	%xmm5, %xmm1, %xmm1
	vsubsd	%xmm7, %xmm8, %xmm5
	vaddsd	%xmm8, %xmm7, %xmm8
	vmaxsd	%xmm9, %xmm0, %xmm0
	vminsd	%xmm5, %xmm6, %xmm6
	vmovsd	160000(%rax,%rcx,8), %xmm5
	vmaxsd	%xmm8, %xmm3, %xmm3
	vsubsd	%xmm7, %xmm5, %xmm10
	vaddsd	%xmm5, %xmm7, %xmm5
	vminsd	%xmm10, %xmm4, %xmm4
	vmaxsd	%xmm5, %xmm2, %xmm2
	cmpl	%edx, %r12d
	jle	.L3877
	movslq	%edx, %rdx
	vmovsd	(%rax,%rdx,8), %xmm9
	vmovsd	80000(%rax,%rdx,8), %xmm8
	vsubsd	%xmm7, %xmm9, %xmm5
	vaddsd	%xmm9, %xmm7, %xmm9
	vminsd	%xmm5, %xmm1, %xmm1
	vsubsd	%xmm7, %xmm8, %xmm5
	vaddsd	%xmm8, %xmm7, %xmm8
	vmaxsd	%xmm9, %xmm0, %xmm0
	vminsd	%xmm5, %xmm6, %xmm6
	vmovsd	160000(%rax,%rdx,8), %xmm5
	vmaxsd	%xmm8, %xmm3, %xmm3
	vsubsd	%xmm7, %xmm5, %xmm10
	vaddsd	%xmm7, %xmm5, %xmm5
	vminsd	%xmm10, %xmm4, %xmm4
	vmaxsd	%xmm5, %xmm2, %xmm2
.L3877:
	leal	1(%r12), %eax
	movl	%eax, -27764(%rbp)
.L3874:
	vunpcklpd	%xmm6, %xmm3, %xmm7
	vunpcklpd	%xmm1, %xmm0, %xmm5
	vinsertf128	$0x1, %xmm7, %ymm5, %ymm5
	vsubsd	%xmm1, %xmm0, %xmm0
	vsubsd	%xmm6, %xmm3, %xmm3
	vmovupd	%ymm5, 40+plates_(%rip)
	vunpcklpd	%xmm2, %xmm4, %xmm5
	vsubsd	%xmm4, %xmm2, %xmm2
	vmovsd	.LC8(%rip), %xmm4
	vmovsd	%xmm0, 240000+for_(%rip)
	vmovsd	%xmm3, 240008+for_(%rip)
	vdivsd	%xmm0, %xmm4, %xmm0
	vmovsd	%xmm2, 240016+for_(%rip)
	leaq	plates_(%rip), %rax
	movq	%rax, -27608(%rbp)
	vmovapd	%xmm5, plates_(%rip)
	vdivsd	%xmm3, %xmm4, %xmm3
	vmovsd	%xmm0, 240024+for_(%rip)
	vdivsd	%xmm2, %xmm4, %xmm2
	vmovsd	%xmm3, 240032+for_(%rip)
	vmovsd	%xmm2, 240040+for_(%rip)
	jmp	.L3873
.L4834:
	movl	248008+nat_(%rip), %r9d
	movl	$1, -27392(%rbp)
	testl	%r9d, %r9d
	jle	.L3909
	leaq	240008+nat_(%rip), %rax
	leal	-1(%r9), %edx
	leaq	8(%rax), %rcx
	leaq	(%rcx,%rdx,8), %r8
	leaq	ssb_(%rip), %r12
	.p2align 4,,10
	.p2align 3
.L3911:
	movslq	(%rax), %rsi
	movslq	4(%rax), %rdx
	addq	$8, %rax
	movl	$1, 39996(%r12,%rsi,4)
	movl	%edx, -4(%r12,%rsi,4)
	movl	$1, 39996(%r12,%rdx,4)
	movl	%esi, -4(%r12,%rdx,4)
	cmpq	%r8, %rax
	jne	.L3911
	leal	1(%r9), %eax
	movl	%eax, -27392(%rbp)
	jmp	.L3909
.L4031:
	vxorps	%xmm7, %xmm7, %xmm7
	vcvtsi2ssl	%edx, %xmm7, %xmm0
	vxorpd	%xmm7, %xmm7, %xmm7
	vcvtsi2sdl	8+equil_(%rip), %xmm7, %xmm4
	vmovsd	.LC72(%rip), %xmm6
	vcvtss2sd	%xmm0, %xmm0, %xmm0
	vmulsd	-27760(%rbp), %xmm0, %xmm0
	movl	$8272, %eax
	incl	%edx
	movw	%ax, -450(%rbp)
	movl	%edx, 36+wal_(%rip)
	vdivsd	%xmm4, %xmm0, %xmm4
	vmovsd	%xmm4, -27704(%rbp)
	vmulsd	%xmm4, %xmm6, %xmm4
	jmp	.L3986
.L4142:
	movl	-27528(%rbp), %ebx
	xorl	%eax, %eax
	leaq	kbt.6(%rip), %r10
	leaq	fbt.14(%rip), %r11
	leaq	fbt2.13(%rip), %r9
	leaq	kut.5(%rip), %r8
	leaq	fut.4(%rip), %rdi
	leaq	fut2.3(%rip), %rsi
	leaq	mtraj.12(%rip), %rcx
.L4156:
	movl	(%r10,%rax,4), %edx
	testl	%edx, %edx
	je	.L4155
	vxorpd	%xmm6, %xmm6, %xmm6
	vcvtsi2sdl	%edx, %xmm6, %xmm0
	incl	(%rcx,%rax,4)
	vmulsd	%xmm5, %xmm0, %xmm0
	vaddsd	(%r11,%rax,8), %xmm0, %xmm1
	vfmadd213sd	(%r9,%rax,8), %xmm0, %xmm0
	vmovsd	%xmm1, (%r11,%rax,8)
	vmovsd	%xmm0, (%r9,%rax,8)
	vcvtsi2sdl	(%r8,%rax,4), %xmm6, %xmm0
	vmulsd	%xmm5, %xmm0, %xmm0
	vaddsd	(%rdi,%rax,8), %xmm0, %xmm1
	vfmadd213sd	(%rsi,%rax,8), %xmm0, %xmm0
	vmovsd	%xmm1, (%rdi,%rax,8)
	vmovsd	%xmm0, (%rsi,%rax,8)
.L4155:
	incq	%rax
	cmpq	%rax, %rbx
	jne	.L4156
	jmp	.L4141
.L4867:
	movl	-27528(%rbp), %eax
	movq	-27544(%rbp), %r8
	movl	%eax, %esi
	andl	$-8, %esi
	leal	1(%rsi), %edi
	movl	%edi, -27464(%rbp)
	cmpl	%eax, %esi
	je	.L4141
	subl	%esi, %eax
	movl	%eax, -27544(%rbp)
	decl	%eax
	cmpl	$2, %eax
	jbe	.L4148
.L4143:
	vmovdqa	(%r10,%rsi,4), %xmm3
	vmovddup	%xmm5, %xmm0
	vpxor	%xmm4, %xmm4, %xmm4
	vcvtdq2pd	%xmm3, %xmm2
	vmulpd	%xmm0, %xmm2, %xmm2
	leaq	0(,%rsi,8), %rax
	vpshufd	$238, %xmm3, %xmm1
	vpcmpeqd	%xmm4, %xmm3, %xmm3
	leaq	(%rbx,%rax), %r9
	vmovapd	(%r9), %xmm10
	vmovapd	%xmm0, %xmm8
	vcvtdq2pd	%xmm1, %xmm1
	vmulpd	%xmm0, %xmm1, %xmm1
	vpsrldq	$8, %xmm3, %xmm0
	vpmovsxdq	%xmm0, %xmm6
	vaddpd	%xmm2, %xmm10, %xmm0
	vmovapd	16(%r9), %xmm9
	vpmovsxdq	%xmm3, %xmm7
	vblendvpd	%xmm7, %xmm10, %xmm0, %xmm0
	vmovapd	%xmm0, (%r9)
	vaddpd	%xmm1, %xmm9, %xmm0
	movq	-27512(%rbp), %rdi
	movq	-27472(%rbp), %rcx
	vblendvpd	%xmm6, %xmm9, %xmm0, %xmm0
	vmovapd	%xmm0, 16(%r9)
	addq	%rax, %rdi
	vmovapd	16(%rdi), %xmm0
	vmovapd	(%rdi), %xmm9
	vfmadd132pd	%xmm1, %xmm0, %xmm1
	vfmadd132pd	%xmm2, %xmm9, %xmm2
	addq	%rax, %rcx
	addq	%r8, %rax
	leaq	mtraj.12(%rip), %rdx
	vblendvpd	%xmm6, %xmm0, %xmm1, %xmm1
	vmovdqa	(%r11,%rsi,4), %xmm0
	vmovapd	%xmm1, 16(%rdi)
	vcvtdq2pd	%xmm0, %xmm1
	vmulpd	%xmm8, %xmm1, %xmm1
	vblendvpd	%xmm7, %xmm9, %xmm2, %xmm2
	vmovapd	%xmm2, (%rdi)
	vmovapd	(%rcx), %xmm9
	vpshufd	$238, %xmm0, %xmm0
	vcvtdq2pd	%xmm0, %xmm0
	vmulpd	%xmm8, %xmm0, %xmm0
	vaddpd	%xmm1, %xmm9, %xmm2
	vmovapd	16(%rcx), %xmm8
	leaq	(%rdx,%rsi,4), %rdx
	vblendvpd	%xmm7, %xmm9, %xmm2, %xmm2
	vmovapd	%xmm2, (%rcx)
	vaddpd	%xmm0, %xmm8, %xmm2
	vblendvpd	%xmm6, %xmm8, %xmm2, %xmm2
	vmovapd	%xmm2, 16(%rcx)
	vmovapd	16(%rax), %xmm2
	vmovapd	(%rax), %xmm8
	vfmadd132pd	%xmm0, %xmm2, %xmm0
	vfmadd132pd	%xmm1, %xmm8, %xmm1
	vblendvpd	%xmm6, %xmm2, %xmm0, %xmm0
	vmovapd	%xmm0, 16(%rax)
	vpcmpeqd	%xmm4, %xmm3, %xmm0
	vblendvpd	%xmm7, %xmm8, %xmm1, %xmm1
	vmovapd	%xmm1, (%rax)
	vptest	%xmm0, %xmm0
	jne	.L4870
.L4149:
	movl	-27544(%rbp), %esi
	movl	%esi, %eax
	andl	$-4, %eax
	addl	%eax, -27464(%rbp)
	cmpl	%esi, %eax
	je	.L4141
.L4148:
	movl	-27464(%rbp), %eax
	decl	%eax
	cltq
	movl	(%r10,%rax,4), %edx
	testl	%edx, %edx
	je	.L4151
	vxorpd	%xmm6, %xmm6, %xmm6
	vcvtsi2sdl	%edx, %xmm6, %xmm0
	movq	-27512(%rbp), %rsi
	leaq	mtraj.12(%rip), %rdx
	incl	(%rdx,%rax,4)
	vmulsd	%xmm5, %xmm0, %xmm0
	vaddsd	(%rbx,%rax,8), %xmm0, %xmm1
	vfmadd213sd	(%rsi,%rax,8), %xmm0, %xmm0
	vmovsd	%xmm1, (%rbx,%rax,8)
	vmovsd	%xmm0, (%rsi,%rax,8)
	vcvtsi2sdl	(%r11,%rax,4), %xmm6, %xmm0
	movq	-27472(%rbp), %rsi
	vmulsd	%xmm5, %xmm0, %xmm0
	vaddsd	(%rsi,%rax,8), %xmm0, %xmm1
	vfmadd213sd	(%r8,%rax,8), %xmm0, %xmm0
	vmovsd	%xmm1, (%rsi,%rax,8)
	vmovsd	%xmm0, (%r8,%rax,8)
.L4151:
	movslq	-27464(%rbp), %rax
	leal	1(%rax), %ecx
	cmpl	%ecx, -27528(%rbp)
	jl	.L4141
	movl	(%r10,%rax,4), %edx
	testl	%edx, %edx
	je	.L4152
	vxorpd	%xmm7, %xmm7, %xmm7
	vcvtsi2sdl	%edx, %xmm7, %xmm0
	movq	-27512(%rbp), %rsi
	leaq	mtraj.12(%rip), %rdx
	incl	(%rdx,%rax,4)
	vmulsd	%xmm5, %xmm0, %xmm0
	vaddsd	(%rbx,%rax,8), %xmm0, %xmm1
	vfmadd213sd	(%rsi,%rax,8), %xmm0, %xmm0
	vmovsd	%xmm1, (%rbx,%rax,8)
	vmovsd	%xmm0, (%rsi,%rax,8)
	vcvtsi2sdl	(%r11,%rax,4), %xmm7, %xmm0
	movq	-27472(%rbp), %rsi
	vmulsd	%xmm5, %xmm0, %xmm0
	vaddsd	(%rsi,%rax,8), %xmm0, %xmm1
	vfmadd213sd	(%r8,%rax,8), %xmm0, %xmm0
	vmovsd	%xmm1, (%rsi,%rax,8)
	vmovsd	%xmm0, (%r8,%rax,8)
.L4152:
	movl	-27464(%rbp), %eax
	addl	$2, %eax
	cmpl	%eax, -27528(%rbp)
	jl	.L4141
	movslq	%ecx, %rcx
	movl	(%r10,%rcx,4), %eax
	testl	%eax, %eax
	je	.L4141
	vxorpd	%xmm4, %xmm4, %xmm4
	vcvtsi2sdl	%eax, %xmm4, %xmm0
	movq	-27512(%rbp), %rax
	leaq	mtraj.12(%rip), %rdx
	incl	(%rdx,%rcx,4)
	vmulsd	%xmm5, %xmm0, %xmm0
	vaddsd	(%rbx,%rcx,8), %xmm0, %xmm1
	vfmadd213sd	(%rax,%rcx,8), %xmm0, %xmm0
	vmovsd	%xmm1, (%rbx,%rcx,8)
	vmovsd	%xmm0, (%rax,%rcx,8)
	vcvtsi2sdl	(%r11,%rcx,4), %xmm4, %xmm0
	movq	-27472(%rbp), %rax
	vmulsd	%xmm5, %xmm0, %xmm5
	vaddsd	(%rax,%rcx,8), %xmm5, %xmm0
	vfmadd213sd	(%r8,%rcx,8), %xmm5, %xmm5
	vmovsd	%xmm0, (%rax,%rcx,8)
	vmovsd	%xmm5, (%r8,%rcx,8)
	jmp	.L4141
.L4119:
	movl	%r8d, %edx
	movq	%r9, %rax
	addq	%r9, %rdx
	movq	%r9, %rcx
	leaq	cmp2_(%rip), %rbx
	salq	$4, %rax
	salq	$4, %rdx
	negq	%rcx
	leaq	-179999980(%rbx,%rax), %rax
	leaq	-179999964(%rbx,%rdx), %r8
	salq	$4, %rcx
	salq	$4, %rdi
	.p2align 4,,10
	.p2align 3
.L4123:
	movl	(%rax), %edx
	movl	$0, -4(%rax)
	sarl	$31, %edx
	leal	1(%rdx), %esi
	xorl	%esi, %edx
	movl	%edx, (%rax)
	leaq	(%rcx,%rax), %rsi
	addq	$16, %rax
	movl	(%rsi,%rdi), %edx
	movl	$0, -4(%rsi,%rdi)
	sarl	$31, %edx
	leal	1(%rdx), %r9d
	xorl	%r9d, %edx
	movl	%edx, (%rsi,%rdi)
	cmpq	%rax, %r8
	jne	.L4123
	jmp	.L4112
.L4837:
	vzeroupper
	jmp	.L3952
.L3985:
	leaq	-27424(%rbp), %rsi
	leaq	-27408(%rbp), %rdi
	vmovsd	%xmm5, -27568(%rbp)
	vmovsd	%xmm3, -27512(%rbp)
	vmovsd	%xmm1, -27464(%rbp)
	vzeroupper
	call	print_restart_
	vmovsd	-27760(%rbp), %xmm4
	cmpl	$1, 16+equil_(%rip)
	vxorpd	.LC11(%rip), %xmm4, %xmm5
	movl	$1, 8+wal_(%rip)
	vmovsd	%xmm5, -27760(%rbp)
	vmovsd	-27464(%rbp), %xmm1
	vmovsd	-27512(%rbp), %xmm3
	vmovsd	-27568(%rbp), %xmm5
	je	.L4635
	movl	$8261, %eax
	movw	%ax, -450(%rbp)
	movq	$0x000000000, -27704(%rbp)
	movl	32+kier_(%rip), %esi
	vmovsd	8+restart_(%rip), %xmm2
	movl	68+wal_(%rip), %ecx
	movl	36+wal_(%rip), %edx
	movl	-27408(%rbp), %ebx
	vxorpd	%xmm4, %xmm4, %xmm4
	jmp	.L3986
.L3993:
	leaq	-27424(%rbp), %rsi
	leaq	-27408(%rbp), %rdi
	vmovsd	%xmm5, -27568(%rbp)
	vmovsd	%xmm3, -27512(%rbp)
	vmovsd	%xmm1, -27464(%rbp)
	vzeroupper
	call	print_restart_
	movl	32+kier_(%rip), %esi
	movl	$1, 16+wal_(%rip)
	testl	%esi, %esi
	vmovsd	240016+for_(%rip), %xmm2
	vmovsd	-27464(%rbp), %xmm1
	vmovsd	-27512(%rbp), %xmm3
	vmovsd	-27568(%rbp), %xmm5
	je	.L3996
	vmovsd	240000+for_(%rip), %xmm2
.L3996:
	movl	-27368(%rbp), %r9d
	vmovsd	%xmm2, 16+restart_(%rip)
	testl	%r9d, %r9d
	je	.L3997
	vmovsd	-27184(%rbp), %xmm0
	vdivsd	%xmm2, %xmm0, %xmm0
	vmovsd	%xmm0, -27192(%rbp)
.L3997:
	movl	-27312(%rbp), %r8d
	testl	%r8d, %r8d
	je	.L3998
	vmovsd	-27760(%rbp), %xmm4
	vxorpd	.LC11(%rip), %xmm4, %xmm6
	vmovsd	%xmm6, -27760(%rbp)
.L3998:
	movl	52+wal_(%rip), %edi
	movl	-27408(%rbp), %ebx
	testl	%edi, %edi
	jne	.L4625
	cmpl	$3, 16+equil_(%rip)
	je	.L4871
	movl	4+equil_(%rip), %eax
	movl	%eax, 16+wal_(%rip)
	movl	$8261, %eax
	movw	%ax, -450(%rbp)
	jmp	.L4625
.L3916:
	testl	%edx, %edx
	jg	.L4203
	vmovsd	-27464(%rbp), %xmm5
	vmovsd	%xmm5, -27760(%rbp)
	jmp	.L3920
.L4835:
	movq	%r12, %rdi
	call	evalwall_
	jmp	.L3943
.L4853:
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%ecx, %xmm5, %xmm0
	leaq	restart_(%rip), %rax
	leaq	-26872(%rbp), %rcx
	movq	%rcx, %rdi
	vmulsd	(%rax), %xmm0, %xmm0
	movq	%rcx, -27464(%rbp)
	vmovsd	%xmm0, -26816(%rbp)
	vzeroupper
	call	compute_rmsd_
	call	cgyration_
	movl	-27256(%rbp), %ebx
	movq	-27464(%rbp), %rcx
	testl	%ebx, %ebx
	leaq	-26816(%rbp), %rsi
	movq	%r12, %rdx
	leaq	.LC561(%rip), %rdi
	je	.L4136
	call	print_conf_xyz_.constprop.0
.L4137:
	leaq	.LC561(%rip), %rdi
	xorl	%eax, %eax
	call	_gfortran_flush_i4@PLT
	jmp	.L4135
.L4855:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	leaq	.LC565(%rip), %rax
	movq	%rax, -26192(%rbp)
	movabsq	$4294971392, %rax
	movl	$2234, -26256(%rbp)
	movq	$16, -26184(%rbp)
	movq	%rax, -26272(%rbp)
	vzeroupper
	call	_gfortran_st_write@PLT
	movl	$1, %edx
	leaq	.LC130(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$2, %edx
	leaq	.LC566(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$2, %edx
	leaq	.LC567(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$2, %edx
	leaq	.LC568(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$2, %edx
	leaq	.LC569(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$1, %edx
	leaq	.LC570(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movslq	48+kier_(%rip), %rax
	cmpl	$1, %eax
	jle	.L4162
	salq	$2, %rax
	movq	%rax, -27512(%rbp)
	movq	$4, -27464(%rbp)
	movq	%r14, -27528(%rbp)
	leaq	-20512(%rbp), %rbx
	movl	%r13d, -27520(%rbp)
	movq	-27752(%rbp), %r13
	movq	%rbx, -27472(%rbp)
	leaq	-16464(%rbp), %rbx
.L4163:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	leaq	.LC573(%rip), %rax
	movq	%rax, -26192(%rbp)
	movabsq	$4294971392, %rax
	movq	%rax, -26272(%rbp)
	movl	$2237, -26256(%rbp)
	movq	$16, -26184(%rbp)
	call	_gfortran_st_write@PLT
	movl	$2, %edx
	leaq	.LC572(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$2, %r14d
	movl	$1, -27420(%rbp)
	leaq	bas_(%rip), %r12
	testb	$1, -26272(%rbp)
	jne	.L4164
	.p2align 4,,10
	.p2align 3
.L4161:
	vmovsd	(%r12), %xmm1
	movl	$8, %edx
	vmulsd	%xmm1, %xmm1, %xmm0
	movq	%r13, %rsi
	movq	%r15, %rdi
	vmulsd	%xmm1, %xmm0, %xmm1
	vmovsd	-48(%rbx,%r14,8), %xmm0
	vdivsd	%xmm1, %xmm0, %xmm0
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movl	%r14d, -27420(%rbp)
	testb	$1, -26272(%rbp)
	jne	.L4164
	incq	%r14
	cmpq	$6, %r14
	jne	.L4161
.L4164:
	movq	-27472(%rbp), %r14
	movl	$8, %edx
	movq	%r14, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	addq	$4, -27464(%rbp)
	movq	%r14, %rax
	addq	$8, %rax
	movq	%rax, -27472(%rbp)
	movq	-27464(%rbp), %rax
	addq	$32, %rbx
	cmpq	-27512(%rbp), %rax
	jne	.L4163
	movl	-27520(%rbp), %r13d
	movq	-27528(%rbp), %r14
.L4162:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	leaq	.LC571(%rip), %rax
	movq	%rax, -26192(%rbp)
	movabsq	$4294971392, %rax
	movq	%rax, -26272(%rbp)
	movl	$2239, -26256(%rbp)
	movq	$9, -26184(%rbp)
	call	_gfortran_st_write@PLT
	movl	$2, %edx
	leaq	.LC572(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$8, %edx
	leaq	8+restart_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movl	-27324(%rbp), %eax
	movl	-27264(%rbp), %ebx
	movl	%eax, -27520(%rbp)
	movl	-27272(%rbp), %eax
	movl	%eax, -28044(%rbp)
	jmp	.L4159
.L4265:
	movl	$1, -27764(%rbp)
	jmp	.L4113
.L3870:
	leaq	-27120(%rbp), %rsi
	leaq	-26856(%rbp), %rdi
	vzeroupper
	call	confstart_
	movl	8+bas_(%rip), %r12d
	movl	$1, -27452(%rbp)
	leaq	bon_(%rip), %rbx
	testl	%r12d, %r12d
	jle	.L3868
	movslq	%r12d, %r13
	salq	$3, %r13
	movq	%r13, %rdx
	leaq	pos_(%rip), %rsi
	leaq	nat_(%rip), %rdi
	call	memcpy@PLT
	movq	%r13, %rdx
	leaq	80000+pos_(%rip), %rsi
	leaq	80000+nat_(%rip), %rdi
	call	memcpy@PLT
	incl	%r12d
	movq	%r13, %rdx
	leaq	160000+pos_(%rip), %rsi
	leaq	160000+nat_(%rip), %rdi
	call	memcpy@PLT
	movl	%r12d, -27452(%rbp)
	jmp	.L3868
.L3883:
	cmpl	$6, %r13d
	jbe	.L4247
	movl	%r12d, %ecx
	shrl	$3, %ecx
	leaq	120012+respul_(%rip), %rax
	salq	$6, %rcx
	vmovdqa	.LC76(%rip), %ymm2
	leaq	-40012(%rax), %rsi
	addq	%rax, %rcx
	vxorpd	%xmm4, %xmm4, %xmm4
	vpxor	%xmm3, %xmm3, %xmm3
.L3891:
	vmovdqa	%ymm2, %ymm0
	vpunpckldq	%ymm0, %ymm3, %ymm1
	vmovapd	%ymm4, -120012(%rax)
	vmovapd	%ymm4, -119980(%rax)
	vmovdqa	%ymm0, (%rsi)
	vpunpckhdq	%ymm0, %ymm3, %ymm0
	vperm2i128	$32, %ymm0, %ymm1, %ymm5
	vperm2i128	$49, %ymm0, %ymm1, %ymm0
	vmovdqu	%ymm5, (%rax)
	vmovdqu	%ymm0, 32(%rax)
	addq	$64, %rax
	vpaddd	.LC77(%rip), %ymm2, %ymm2
	addq	$32, %rsi
	cmpq	%rax, %rcx
	jne	.L3891
	movl	%r12d, %ecx
	andl	$-8, %ecx
	leal	1(%rcx), %eax
	cmpl	%r12d, %ecx
	je	.L3886
.L3889:
	movl	%r12d, %esi
	subl	%ecx, %esi
	leal	-1(%rsi), %edi
	cmpl	$2, %edi
	jbe	.L3894
	movl	%ecx, %edi
	salq	$3, %rdi
	leaq	(%rdx,%rdi), %r8
	vxorpd	%xmm0, %xmm0, %xmm0
	vmovd	%eax, %xmm5
	vmovapd	%xmm0, (%r8)
	vmovapd	%xmm0, 16(%r8)
	vpshufd	$0, %xmm5, %xmm0
	vpaddd	.LC78(%rip), %xmm0, %xmm0
	addl	$20000, %ecx
	vmovdqa	%xmm0, (%rdx,%rcx,4)
	vpxor	%xmm0, %xmm0, %xmm0
	leal	1(%rax), %ecx
	vpinsrd	$1, %ecx, %xmm0, %xmm2
	vpinsrd	$1, %eax, %xmm0, %xmm1
	leal	3(%rax), %ecx
	leaq	120012(%rdx,%rdi), %rdi
	vpunpcklqdq	%xmm2, %xmm1, %xmm1
	leal	2(%rax), %r8d
	vmovdqu	%xmm1, (%rdi)
	vpinsrd	$1, %ecx, %xmm0, %xmm1
	vpinsrd	$1, %r8d, %xmm0, %xmm0
	movl	%esi, %ecx
	vpunpcklqdq	%xmm1, %xmm0, %xmm0
	andl	$-4, %ecx
	vmovdqu	%xmm0, 16(%rdi)
	addl	%ecx, %eax
	cmpl	%esi, %ecx
	je	.L3886
.L3894:
	leal	-1(%rax), %ecx
	movslq	%ecx, %rcx
	movq	$0x000000000, (%rdx,%rcx,8)
	movl	%eax, 80000(%rdx,%rcx,4)
	leal	1(%rax), %r8d
	addq	%rcx, %rcx
	movl	$0, 120012(%rdx,%rcx,4)
	movl	%eax, 120016(%rdx,%rcx,4)
	movslq	%eax, %rsi
	cmpl	%r8d, %r12d
	jl	.L3886
	addl	$2, %eax
	movq	$0x000000000, (%rdx,%rsi,8)
	movl	%r8d, 80000(%rdx,%rsi,4)
	movl	$0, 120020(%rdx,%rcx,4)
	movl	%r8d, 120024(%rdx,%rcx,4)
	movslq	%r8d, %rdi
	cmpl	%eax, %r12d
	jl	.L3886
	movl	%eax, 80000(%rdx,%rdi,4)
	movl	%eax, 120032(%rdx,%rcx,4)
	leal	1(%r12), %eax
	movq	$0x000000000, (%rdx,%rdi,8)
	movl	$0, 120028(%rdx,%rcx,4)
	movl	%eax, -27764(%rbp)
	testl	%r11d, %r11d
	jne	.L4872
.L4210:
	vxorpd	%xmm4, %xmm4, %xmm4
	vcvtsi2sdl	%r12d, %xmm4, %xmm0
	movq	.LC134(%rip), %rax
	vmovq	%rax, %xmm1
	vdivsd	-26856(%rbp), %xmm0, %xmm0
	vzeroupper
	call	pow@PLT
	vmulsd	.LC72(%rip), %xmm0, %xmm4
	vmovsd	(%rbx), %xmm2
	vaddsd	%xmm2, %xmm2, %xmm2
	vxorpd	.LC11(%rip), %xmm4, %xmm5
	vmovsd	%xmm4, -27656(%rbp)
	vmovsd	%xmm5, -27648(%rbp)
	cmpl	$2, %r13d
	jbe	.L4274
	movl	%r12d, %eax
	shrl	$2, %eax
	leaq	160000+pos_(%rip), %rdx
	salq	$5, %rax
	vbroadcastsd	%xmm4, %ymm0
	vbroadcastsd	%xmm2, %ymm1
	vbroadcastsd	%xmm5, %ymm4
	addq	%rdx, %rax
.L3900:
	vmovapd	-160000(%rdx), %ymm6
	vmovapd	-80000(%rdx), %ymm3
	vsubpd	%ymm1, %ymm6, %ymm8
	vsubpd	%ymm1, %ymm3, %ymm7
	vmovapd	(%rdx), %ymm5
	vaddpd	%ymm1, %ymm3, %ymm3
	vminpd	%ymm8, %ymm7, %ymm7
	vaddpd	%ymm6, %ymm1, %ymm6
	vsubpd	%ymm1, %ymm5, %ymm8
	vaddpd	%ymm1, %ymm5, %ymm5
	vmaxpd	%ymm6, %ymm3, %ymm3
	vminpd	%ymm4, %ymm8, %ymm4
	vmaxpd	%ymm0, %ymm5, %ymm0
	addq	$32, %rdx
	vminpd	%ymm4, %ymm7, %ymm4
	vmaxpd	%ymm0, %ymm3, %ymm0
	cmpq	%rdx, %rax
	jne	.L3900
	vextractf128	$0x1, %ymm0, %xmm1
	vmaxpd	%xmm0, %xmm1, %xmm0
	movl	%r12d, %eax
	andl	$-4, %eax
	vunpckhpd	%xmm0, %xmm0, %xmm1
	vmaxpd	%xmm0, %xmm1, %xmm0
	leal	1(%rax), %edx
	vmovlpd	%xmm0, -27656(%rbp)
	vextractf128	$0x1, %ymm4, %xmm0
	vminpd	%xmm4, %xmm0, %xmm4
	vunpckhpd	%xmm4, %xmm4, %xmm0
	vminpd	%xmm4, %xmm0, %xmm4
	vmovlpd	%xmm4, -27648(%rbp)
	cmpl	%r12d, %eax
	je	.L4211
.L4209:
	subl	%eax, %r12d
	cmpl	$1, %r12d
	je	.L4873
	movl	%eax, %ecx
	leaq	pos_(%rip), %rax
	leaq	80000(%rax), %rsi
	vmovapd	(%rsi,%rcx,8), %xmm4
	leaq	160000(%rax), %rsi
	vmovapd	(%rsi,%rcx,8), %xmm1
	vmovddup	%xmm2, %xmm0
	vsubpd	%xmm0, %xmm4, %xmm5
	vsubpd	%xmm0, %xmm1, %xmm3
	vmovapd	(%rax,%rcx,8), %xmm6
	vaddpd	%xmm0, %xmm4, %xmm4
	vminpd	%xmm5, %xmm3, %xmm3
	vaddpd	%xmm0, %xmm1, %xmm1
	vsubpd	%xmm0, %xmm6, %xmm5
	vaddpd	%xmm6, %xmm0, %xmm0
	vmaxpd	%xmm4, %xmm1, %xmm1
	vmovddup	-27656(%rbp), %xmm4
	vmaxpd	%xmm4, %xmm0, %xmm0
	vmovddup	-27648(%rbp), %xmm7
	vminpd	%xmm7, %xmm5, %xmm5
	vmaxpd	%xmm0, %xmm1, %xmm0
	movl	%r12d, %ecx
	vminpd	%xmm5, %xmm3, %xmm3
	vunpckhpd	%xmm0, %xmm0, %xmm1
	vmaxpd	%xmm0, %xmm1, %xmm0
	andl	$-2, %ecx
	addl	%ecx, %edx
	vmovlpd	%xmm0, -27656(%rbp)
	vunpckhpd	%xmm3, %xmm3, %xmm0
	vminpd	%xmm3, %xmm0, %xmm3
	vmovlpd	%xmm3, -27648(%rbp)
	cmpl	%r12d, %ecx
	je	.L4211
.L3897:
	decl	%edx
	movslq	%edx, %rdx
	vmovsd	(%rax,%rdx,8), %xmm3
	vmovsd	80000(%rax,%rdx,8), %xmm1
	vmovsd	160000(%rax,%rdx,8), %xmm0
	vsubsd	%xmm2, %xmm1, %xmm5
	vsubsd	%xmm2, %xmm0, %xmm4
	vsubsd	%xmm2, %xmm3, %xmm6
	vaddsd	%xmm0, %xmm2, %xmm0
	vaddsd	%xmm1, %xmm2, %xmm1
	vaddsd	%xmm3, %xmm2, %xmm2
	vminsd	-27648(%rbp), %xmm4, %xmm4
	vmaxsd	-27656(%rbp), %xmm0, %xmm0
	vminsd	%xmm6, %xmm5, %xmm5
	vmaxsd	%xmm2, %xmm1, %xmm1
	vminsd	%xmm4, %xmm5, %xmm4
	vmaxsd	%xmm0, %xmm1, %xmm7
	vmovsd	%xmm4, -27648(%rbp)
	vmovsd	%xmm7, -27656(%rbp)
.L4211:
	vmovsd	-27656(%rbp), %xmm7
	vmovsd	-27648(%rbp), %xmm4
	vmovhpd	-27648(%rbp), %xmm7, %xmm0
	vinsertf128	$1, %xmm0, %ymm0, %ymm0
	movq	-27608(%rbp), %rax
	vmovupd	%ymm0, 40+plates_(%rip)
	vunpcklpd	%xmm7, %xmm4, %xmm0
	vmovapd	%xmm0, (%rax)
	vsubsd	%xmm4, %xmm7, %xmm0
	vmovsd	.LC8(%rip), %xmm5
	movq	$0x000000000, -27704(%rbp)
	vmovsd	%xmm0, 240000+for_(%rip)
	vmovsd	%xmm0, 240008+for_(%rip)
	vmovsd	%xmm0, 240016+for_(%rip)
	vdivsd	%xmm0, %xmm5, %xmm0
	vmovsd	%xmm4, -27680(%rbp)
	vmovsd	%xmm7, -27688(%rbp)
	vmovsd	%xmm4, -27664(%rbp)
	vmovsd	%xmm7, -27672(%rbp)
	vmovsd	%xmm0, 240024+for_(%rip)
	vmovsd	%xmm0, 240032+for_(%rip)
	vmovsd	%xmm0, 240040+for_(%rip)
	jmp	.L3881
.L4860:
	vzeroupper
	call	connect_to_wal_
	jmp	.L4037
.L3922:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	movabsq	$90194313344, %rax
	movq	%rax, -26272(%rbp)
	movl	$1413, -26256(%rbp)
	call	_gfortran_st_read@PLT
	movl	$4, %edx
	leaq	2000016+cmapi_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer@PLT
	movl	$4, %edx
	leaq	2000024+cmapi_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movl	2000024+cmapi_(%rip), %eax
	addl	2000016+cmapi_(%rip), %eax
	addl	%eax, %eax
	testl	%eax, %eax
	jle	.L3932
	incl	%eax
	leaq	ssb_(%rip), %r12
	movl	%eax, -27464(%rbp)
	leaq	-27420(%rbp), %rsi
	leaq	-27452(%rbp), %rax
	movl	%ebx, -27480(%rbp)
	movq	%r14, -27504(%rbp)
	movl	$1, %r13d
	movq	%r12, %r14
	movq	%rax, %rbx
	movq	%rsi, %r12
.L3933:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	movabsq	$90194313344, %rax
	movq	%rax, -26272(%rbp)
	movl	$1415, -26256(%rbp)
	call	_gfortran_st_read@PLT
	movl	$4, %edx
	movq	%rbx, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer@PLT
	movl	$4, %edx
	movq	%r12, %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movslq	-27452(%rbp), %rdi
	movslq	-27420(%rbp), %rdx
	incl	%r13d
	movl	$1, 39996(%r14,%rdi,4)
	movl	%edx, -4(%r14,%rdi,4)
	movl	$1, 39996(%r14,%rdx,4)
	movl	%edi, -4(%r14,%rdx,4)
	cmpl	-27464(%rbp), %r13d
	jne	.L3933
	movl	-27480(%rbp), %ebx
	movq	-27504(%rbp), %r14
.L3932:
	movq	-27640(%rbp), %r13
	movabsq	$90194313344, %r12
	movq	%r15, %rdi
	movq	%r13, -26264(%rbp)
	movl	$1421, -26256(%rbp)
	movq	%r12, -26272(%rbp)
	call	_gfortran_st_read@PLT
	movslq	8+bas_(%rip), %rax
	movq	-27472(%rbp), %rsi
	movq	%rax, -26296(%rbp)
	leaq	80000+respul_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$4, %edx
	movq	%rax, -26352(%rbp)
	movq	%r15, %rdi
	movabsq	$1103806595072, %rax
	movq	%rax, -26328(%rbp)
	movq	$-1, -26344(%rbp)
	movq	$4, -26336(%rbp)
	movq	$4, -26320(%rbp)
	movq	$1, -26312(%rbp)
	movq	$1, -26304(%rbp)
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	%r15, %rdi
	movl	$1, -27420(%rbp)
	movq	%r13, -26264(%rbp)
	movl	$1433, -26256(%rbp)
	movq	%r12, -26272(%rbp)
	call	_gfortran_st_read@PLT
	movl	8+bas_(%rip), %eax
	movl	$1, -27452(%rbp)
	movl	%eax, -27464(%rbp)
	testb	$1, -26272(%rbp)
	jne	.L3930
	movl	$1, %r13d
	movl	%ebx, %eax
	leaq	pull_(%rip), %r12
	movl	%r13d, %ebx
	movl	%eax, %r13d
	jmp	.L3936
.L4874:
	movq	%r12, %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	leaq	80000(%r12), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	incl	%ebx
	leaq	160000(%r12), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	addq	$8, %r12
	movl	%ebx, -27452(%rbp)
	testb	$1, -26272(%rbp)
	jne	.L4597
.L3936:
	cmpl	%ebx, -27464(%rbp)
	jge	.L4874
.L4597:
	movl	%r13d, %ebx
.L3930:
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	movabsq	$90194313344, %rax
	movq	%rax, -26272(%rbp)
	movl	$1434, -26256(%rbp)
	call	_gfortran_st_read@PLT
	movl	8+bas_(%rip), %eax
	movl	$1, -27452(%rbp)
	movl	%eax, -27464(%rbp)
	testb	$1, -26272(%rbp)
	jne	.L3934
	movl	$1, %r13d
	movl	%ebx, %eax
	leaq	pos_(%rip), %r12
	movl	%r13d, %ebx
	movl	%eax, %r13d
	jmp	.L3939
.L4875:
	movq	%r12, %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	leaq	80000(%r12), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	incl	%ebx
	leaq	160000(%r12), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	addq	$8, %r12
	movl	%ebx, -27452(%rbp)
	testb	$1, -26272(%rbp)
	jne	.L4598
.L3939:
	cmpl	%ebx, -27464(%rbp)
	jge	.L4875
.L4598:
	movl	%r13d, %ebx
.L3934:
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	movabsq	$90194313344, %rax
	movq	%rax, -26272(%rbp)
	movl	$1435, -26256(%rbp)
	call	_gfortran_st_read@PLT
	movl	8+bas_(%rip), %eax
	movl	$1, -27452(%rbp)
	movl	%eax, -27464(%rbp)
	testb	$1, -26272(%rbp)
	jne	.L3937
	movl	$1, %r13d
	movl	%ebx, %eax
	leaq	vel_(%rip), %r12
	movl	%r13d, %ebx
	movl	%eax, %r13d
	jmp	.L3942
.L4876:
	movq	%r12, %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	leaq	80000(%r12), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	incl	%ebx
	leaq	160000(%r12), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	addq	$8, %r12
	movl	%ebx, -27452(%rbp)
	testb	$1, -26272(%rbp)
	jne	.L4599
.L3942:
	cmpl	%ebx, -27464(%rbp)
	jge	.L4876
.L4599:
	movl	%r13d, %ebx
.L3937:
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movabsq	$90194313344, %r12
	movq	%rax, -26264(%rbp)
	movl	$1436, -26256(%rbp)
	movq	%r12, -26272(%rbp)
	call	_gfortran_st_read@PLT
	movl	$4, %edx
	leaq	8+ssb2_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer@PLT
	movl	$4, %edx
	leaq	12+ssb2_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer@PLT
	movl	$4, %edx
	leaq	120000+respul_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer@PLT
	movl	$4, %edx
	leaq	120004+respul_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movl	60+wal_(%rip), %eax
	testl	%eax, %eax
	jne	.L4877
.L3941:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	movabsq	$90194313344, %rax
	movq	%rax, -26272(%rbp)
	movl	$1441, -26256(%rbp)
	call	_gfortran_st_read@PLT
	movl	$4, %edx
	leaq	48+kier_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	leaq	equil_(%rip), %rax
	movq	%rax, -27480(%rbp)
	jmp	.L3923
.L4266:
	xorl	%eax, %eax
	movl	$1, %esi
	leaq	ssb_(%rip), %rdi
	jmp	.L4114
.L3958:
	movl	80036+ssb_(%rip), %edx
	movq	%rax, -26264(%rbp)
	testl	%edx, %edx
	je	.L3960
	leaq	.LC547(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, -26192(%rbp)
	movl	$1508, -26256(%rbp)
	movq	$7, -26184(%rbp)
	movq	%r13, -26272(%rbp)
	call	_gfortran_st_write@PLT
	movl	$37, %edx
	leaq	.LC548(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$18, %edx
	leaq	.LC549(%rip), %rsi
.L4622:
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$54, %edx
	leaq	.LC550(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3956
.L4866:
	movq	%rax, -26264(%rbp)
	movq	%r15, %rdi
	leaq	.LC27(%rip), %rax
	movq	%rax, -26192(%rbp)
	movl	$1488, -26256(%rbp)
	movq	$5, -26184(%rbp)
	movq	%r13, -26272(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$29, %edx
	leaq	.LC538(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$38, %edx
	leaq	.LC539(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3956
.L4833:
	vzeroupper
	jmp	.L3905
.L4248:
	xorl	%eax, %eax
	movl	$1, %esi
	leaq	ssb_(%rip), %r12
	jmp	.L3903
.L4253:
	xorl	%edx, %edx
	movl	$1, %eax
	jmp	.L3950
.L4854:
	vmovsd	-27568(%rbp), %xmm5
	leaq	-26880(%rbp), %rdi
	vaddsd	-27008(%rbp), %xmm5, %xmm0
	vmovsd	%xmm0, -26992(%rbp)
	vzeroupper
	call	gyration_
	leaq	-26872(%rbp), %rcx
	movq	%rcx, %rdi
	call	compute_rmsd_
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	leaq	.LC564(%rip), %rax
	movq	%rax, -26192(%rbp)
	movabsq	$4294971392, %rax
	movq	%rax, -26272(%rbp)
	movl	$2227, -26256(%rbp)
	movq	$26, -26184(%rbp)
	call	_gfortran_st_write@PLT
	leaq	-26816(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26992(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	2000008+cmapi_(%rip), %rsi
	call	_gfortran_transfer_integer_write@PLT
	vmovsd	-26880(%rbp), %xmm0
	movq	-27752(%rbp), %rbx
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movq	%rbx, %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	-26872(%rbp), %xmm0
	movl	$8, %edx
	vmulsd	bas_(%rip), %xmm0, %xmm0
	movq	%rbx, %rsi
	movq	%r15, %rdi
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC309(%rip), %rdi
	xorl	%eax, %eax
	call	_gfortran_flush_i4@PLT
	jmp	.L4157
.L4859:
	movl	24+wal_(%rip), %edx
	testl	%edx, %edx
	jne	.L4005
	movl	32+kier_(%rip), %esi
	vmovsd	16+restart_(%rip), %xmm0
	vmovsd	-27192(%rbp), %xmm2
	testl	%esi, %esi
	jne	.L4006
	vmovsd	.LC8(%rip), %xmm4
	vsubsd	%xmm2, %xmm4, %xmm2
	vmulsd	%xmm0, %xmm2, %xmm0
	vcomisd	240016+for_(%rip), %xmm0
	jnb	.L4008
	movl	20+wal_(%rip), %eax
	movl	8+equil_(%rip), %edx
	cmpl	%eax, %edx
	jg	.L4205
	vmovsd	-27760(%rbp), %xmm6
	vmovsd	.LC72(%rip), %xmm7
	vmovsd	8+restart_(%rip), %xmm2
	vmulsd	%xmm6, %xmm7, %xmm4
	movl	36+wal_(%rip), %edx
	movl	%edi, %ecx
	vmovsd	%xmm6, -27704(%rbp)
	jmp	.L4027
.L4136:
	call	print_conformation_
	jmp	.L4137
.L4249:
	vmovsd	-27464(%rbp), %xmm7
	leaq	equil_(%rip), %rax
	movq	%rax, -27480(%rbp)
	vmovsd	%xmm7, -27760(%rbp)
	xorl	%ebx, %ebx
	jmp	.L3913
.L4870:
	vpmaskmovd	(%rdx), %xmm0, %xmm1
	vpaddd	.LC555(%rip), %xmm1, %xmm1
	vpmaskmovd	%xmm1, %xmm0, (%rdx)
	jmp	.L4149
.L4863:
	call	make_fcc_
	movslq	16+equil_(%rip), %rax
	jmp	.L3918
.L4861:
	vmovsd	%xmm3, -27512(%rbp)
	vmovsd	%xmm1, -27464(%rbp)
	call	connect_to_wal_one_by_one_
	vmovsd	-27512(%rbp), %xmm3
	vmovsd	-27464(%rbp), %xmm1
	jmp	.L3994
.L4635:
	movl	56+wal_(%rip), %eax
	testl	%eax, %eax
	je	.L4878
.L4011:
	movl	36+bas_(%rip), %eax
	testl	%eax, %eax
	jne	.L4879
.L4012:
	movl	$8258, %r13d
	movw	%r13w, -450(%rbp)
.L4624:
	vxorpd	%xmm4, %xmm4, %xmm4
	movl	32+kier_(%rip), %esi
	vmovsd	8+restart_(%rip), %xmm2
	movl	68+wal_(%rip), %ecx
	movl	36+wal_(%rip), %edx
	movl	-27408(%rbp), %ebx
	vmovsd	%xmm4, -27704(%rbp)
	jmp	.L3986
.L3959:
	leaq	.LC540(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, -26192(%rbp)
	movl	$1503, -26256(%rbp)
	movq	$9, -26184(%rbp)
	movq	%r13, -26272(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$33, %edx
	leaq	.LC545(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$54, %edx
	leaq	.LC542(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$50, %edx
	leaq	.LC543(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$46, %edx
	leaq	.LC546(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3956
.L4864:
	vzeroupper
	jmp	.L3926
.L4856:
	movl	%r13d, %ecx
	movq	%r15, %r13
	movq	%r14, -27464(%rbp)
	vzeroupper
.L3853:
	testl	%ecx, %ecx
	jne	.L4880
.L3856:
	movl	-27520(%rbp), %esi
	testl	%esi, %esi
	jne	.L4881
.L4189:
	movl	-28044(%rbp), %ecx
	testl	%ecx, %ecx
	jne	.L4882
.L4190:
	testl	%ebx, %ebx
	je	.L4193
	movl	-27428(%rbp), %r15d
	cmpl	$1, %r15d
	jg	.L4883
.L4193:
	incl	-28048(%rbp)
	addq	$8, -27864(%rbp)
	movl	-28048(%rbp), %eax
	cmpl	-27952(%rbp), %eax
	jg	.L3843
	vmovsd	-26920(%rbp), %xmm4
	movl	-27248(%rbp), %eax
	movl	%ebx, -27488(%rbp)
	movl	%eax, -27472(%rbp)
	movl	-27380(%rbp), %r12d
	vmovsd	%xmm4, -27480(%rbp)
	jmp	.L4195
.L4005:
	cmpl	%edx, %eax
	jle	.L4884
	vmovsd	.LC72(%rip), %xmm7
	incl	%edx
	movl	%edx, 24+wal_(%rip)
	vmulsd	-27704(%rbp), %xmm7, %xmm4
	movl	32+kier_(%rip), %esi
	vmovsd	8+restart_(%rip), %xmm2
	movl	36+wal_(%rip), %edx
	movl	%edi, %ecx
	jmp	.L3986
.L3960:
	leaq	.LC547(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, -26192(%rbp)
	movl	$1512, -26256(%rbp)
	movq	$7, -26184(%rbp)
	movq	%r13, -26272(%rbp)
	call	_gfortran_st_write@PLT
	movl	$37, %edx
	leaq	.LC548(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	$42, %edx
	leaq	.LC551(%rip), %rsi
	jmp	.L4622
.L4884:
	movl	28+wal_(%rip), %r8d
	cmpl	$-2, %r8d
	je	.L4885
	movl	48+kier_(%rip), %esi
	cmpl	-27404(%rbp), %esi
	movl	%esi, -28112(%rbp)
	jg	.L4014
	leal	1(%r8), %r13d
	vxorpd	%xmm7, %xmm7, %xmm7
	vcvtsi2sdl	%r13d, %xmm7, %xmm0
	vmovsd	-26928(%rbp), %xmm2
	vmovsd	%xmm5, -27944(%rbp)
	vmovsd	-27192(%rbp), %xmm5
	vmulsd	%xmm2, %xmm0, %xmm0
	movl	%edi, -28104(%rbp)
	movl	%r13d, 28+wal_(%rip)
	vmovsd	%xmm3, -27920(%rbp)
	vmovsd	%xmm1, -27568(%rbp)
	vmovsd	%xmm5, -27464(%rbp)
	vmovsd	%xmm2, -27512(%rbp)
	vzeroupper
	call	sin@PLT
	movl	%r13d, %eax
	cltd
	idivl	-28092(%rbp)
	vmovsd	-27464(%rbp), %xmm5
	vmovsd	-27512(%rbp), %xmm2
	vmovsd	-27568(%rbp), %xmm1
	vmovsd	-27920(%rbp), %xmm3
	movl	-28104(%rbp), %edi
	movl	-28112(%rbp), %esi
	vmovsd	%xmm0, %xmm0, %xmm4
	vmulsd	%xmm4, %xmm2, %xmm2
	vmulsd	16+restart_(%rip), %xmm5, %xmm0
	vmovsd	.LC72(%rip), %xmm5
	vmulsd	%xmm2, %xmm0, %xmm2
	vxorpd	.LC11(%rip), %xmm2, %xmm4
	vmovsd	8+restart_(%rip), %xmm2
	testl	%edx, %edx
	vmovsd	%xmm4, -27704(%rbp)
	vmulsd	%xmm4, %xmm5, %xmm4
	vmovsd	-27944(%rbp), %xmm5
	jne	.L4626
	cltd
	shrl	$30, %edx
	leal	(%rax,%rdx), %r13d
	andl	$3, %r13d
	subl	%edx, %r13d
	movslq	%esi, %rcx
	testb	$3, %al
	je	.L4886
.L4016:
	vmovsd	-27816(%rbp), %xmm6
	vmovsd	-27464(%rbp), %xmm7
	vaddsd	-27856(%rbp), %xmm6, %xmm0
	vmulsd	240000+for_(%rip), %xmm7, %xmm6
	leal	1(%r13), %eax
	vaddsd	-27824(%rbp), %xmm0, %xmm0
	cltq
	leaq	-5(%rax,%rcx,4), %rax
	vmulsd	240008+for_(%rip), %xmm6, %xmm6
	vdivsd	%xmm6, %xmm0, %xmm0
	vmovsd	%xmm0, -16496(%rbp,%rax,8)
.L4626:
	movl	32+kier_(%rip), %esi
	movl	36+wal_(%rip), %edx
	movl	%edi, %ecx
	jmp	.L3986
.L4877:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	movl	$1438, -26256(%rbp)
	movq	%r12, -26272(%rbp)
	call	_gfortran_st_read@PLT
	leaq	120012+respul_(%rip), %rsi
	movslq	8+bas_(%rip), %rax
	movq	%rsi, -26352(%rbp)
	movq	-27472(%rbp), %rsi
	xorl	%ecx, %ecx
	movl	$4, %edx
	movabsq	$1103806595072, %r13
	movq	%r15, %rdi
	movq	%rax, -26296(%rbp)
	movq	$-3, -26344(%rbp)
	movq	$4, -26336(%rbp)
	movq	%r13, -26328(%rbp)
	movq	$4, -26320(%rbp)
	movq	$2, -26312(%rbp)
	movq	$1, -26304(%rbp)
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -26264(%rbp)
	movl	$1439, -26256(%rbp)
	movq	%r12, -26272(%rbp)
	call	_gfortran_st_read@PLT
	movslq	8+bas_(%rip), %rax
	movq	-27472(%rbp), %rsi
	movq	%rax, -26296(%rbp)
	movq	%r15, %rdi
	leaq	120016+respul_(%rip), %rax
	xorl	%ecx, %ecx
	movl	$4, %edx
	movq	%rax, -26352(%rbp)
	movq	$-2, -26344(%rbp)
	movq	$4, -26336(%rbp)
	movq	%r13, -26328(%rbp)
	movq	$4, -26320(%rbp)
	movq	$2, -26312(%rbp)
	movq	$1, -26304(%rbp)
	call	_gfortran_transfer_array@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3941
.L4871:
	movl	56+wal_(%rip), %ecx
	testl	%ecx, %ecx
	je	.L4887
.L4001:
	movl	36+bas_(%rip), %edx
	testl	%edx, %edx
	jne	.L4888
.L4002:
	movl	$8258, %eax
	movw	%ax, -450(%rbp)
	jmp	.L4623
.L3850:
	movl	$1, -27452(%rbp)
	testl	%ebx, %ebx
	jle	.L3851
	movslq	%ebx, %r12
	salq	$3, %r12
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	aufres.11(%rip), %rdi
	movl	%ecx, -27472(%rbp)
	call	memset@PLT
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	aufres2.10(%rip), %rdi
	call	memset@PLT
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	aree.9(%rip), %rdi
	call	memset@PLT
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	adfres.8(%rip), %rdi
	call	memset@PLT
	incl	%ebx
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	adfres2.7(%rip), %rdi
	call	memset@PLT
	movl	%ebx, -27452(%rbp)
	movl	-27472(%rbp), %ecx
	jmp	.L3851
.L4244:
	movl	$1, -27764(%rbp)
	vmovsd	%xmm1, %xmm1, %xmm4
	vmovsd	%xmm0, %xmm0, %xmm2
	vmovsd	%xmm1, %xmm1, %xmm6
	vmovsd	%xmm0, %xmm0, %xmm3
	jmp	.L3874
.L4243:
	xorl	%eax, %eax
	movl	%r12d, %esi
	subl	%eax, %esi
	leal	-1(%rsi), %edx
	movl	$1, %ecx
	cmpl	$2, %edx
	ja	.L4569
.L4862:
	leaq	pos_(%rip), %rax
	jmp	.L3865
.L3882:
	testl	%r11d, %r11d
	je	.L4212
	vmovsd	40+plates_(%rip), %xmm5
	vmovsd	48+plates_(%rip), %xmm6
	movq	-27608(%rbp), %rax
	vmovsd	56+plates_(%rip), %xmm7
	vmovsd	64+plates_(%rip), %xmm4
	vmovsd	%xmm5, -27656(%rbp)
	vmovsd	%xmm6, -27648(%rbp)
	vmovsd	8+plates_(%rip), %xmm5
	vmovsd	(%rax), %xmm6
	movq	$0x000000000, -27704(%rbp)
	movl	$1, -27764(%rbp)
	vmovsd	%xmm7, -27672(%rbp)
	vmovsd	%xmm4, -27664(%rbp)
	vmovsd	%xmm5, -27688(%rbp)
	vmovsd	%xmm6, -27680(%rbp)
	jmp	.L3881
.L4245:
	xorl	%eax, %eax
	movl	%r12d, %ecx
	subl	%eax, %ecx
	leal	-1(%rcx), %esi
	vmovsd	%xmm1, %xmm1, %xmm4
	vmovsd	%xmm0, %xmm0, %xmm2
	vmovsd	%xmm1, %xmm1, %xmm6
	vmovsd	%xmm0, %xmm0, %xmm3
	movl	$1, %edx
	cmpl	$1, %esi
	ja	.L4570
.L4869:
	leaq	pos_(%rip), %rax
	jmp	.L3878
.L4868:
	leaq	pos_(%rip), %rax
	jmp	.L3887
.L4246:
	xorl	%eax, %eax
	movl	$1, %ecx
	jmp	.L3884
.L4200:
	cmpl	$8, 16+equil_(%rip)
	jne	.L4020
	testl	%esi, %esi
	je	.L4889
.L4020:
	movl	$8261, %r10d
	movw	%r10w, -450(%rbp)
.L4023:
	incl	%esi
	vxorpd	%xmm4, %xmm4, %xmm4
	movl	%esi, 32+wal_(%rip)
	vmovsd	8+restart_(%rip), %xmm2
	movl	32+kier_(%rip), %esi
	movl	36+wal_(%rip), %edx
	vmovsd	%xmm4, -27704(%rbp)
	jmp	.L3986
.L4269:
	leaq	fut.4(%rip), %rax
	movq	%rax, -27472(%rbp)
	leaq	fbt2.13(%rip), %rax
	movl	$1, -27464(%rbp)
	movq	%rax, -27512(%rbp)
	xorl	%esi, %esi
	leaq	kbt.6(%rip), %r10
	leaq	fut2.3(%rip), %r8
	leaq	fbt.14(%rip), %rbx
	leaq	kut.5(%rip), %r11
	jmp	.L4143
.L4259:
	movq	$0x000000000, -27704(%rbp)
	vxorpd	%xmm4, %xmm4, %xmm4
	jmp	.L3986
.L4582:
	testl	%eax, %eax
	je	.L4259
	vmovsd	.LC72(%rip), %xmm4
	movl	%eax, %ecx
	vmulsd	%xmm6, %xmm4, %xmm4
	vmovsd	%xmm6, -27704(%rbp)
	jmp	.L3986
.L4252:
	xorl	%eax, %eax
	movl	%ecx, %edi
	subl	%eax, %edi
	movl	$1, %edx
	cmpl	$1, %edi
	jne	.L4574
.L4865:
	leaq	pos_(%rip), %rax
	jmp	.L3927
.L4247:
	xorl	%ecx, %ecx
	movl	$1, %eax
	jmp	.L3889
.L4888:
	vmovsd	%xmm5, -27568(%rbp)
	vmovsd	%xmm3, -27512(%rbp)
	vmovsd	%xmm1, -27464(%rbp)
	call	make_fcc_
	vmovsd	-27568(%rbp), %xmm5
	vmovsd	-27512(%rbp), %xmm3
	vmovsd	-27464(%rbp), %xmm1
	jmp	.L4002
.L4887:
	vmovsd	%xmm5, -27568(%rbp)
	vmovsd	%xmm3, -27512(%rbp)
	vmovsd	%xmm1, -27464(%rbp)
	call	connect_to_wal_
	vmovsd	-27568(%rbp), %xmm5
	vmovsd	-27512(%rbp), %xmm3
	vmovsd	-27464(%rbp), %xmm1
	jmp	.L4001
.L4829:
	movq	-27640(%rbp), %rax
	vmovsd	-26824(%rbp), %xmm0
	movq	%rax, -26264(%rbp)
	leaq	.LC526(%rip), %rax
	movq	%rax, -26192(%rbp)
	movq	%r13, %rdi
	movabsq	$4294971392, %rax
	vmovsd	%xmm0, -26800(%rbp)
	vmovsd	%xmm0, -27504(%rbp)
	movq	%rax, -26272(%rbp)
	movl	$1091, -26256(%rbp)
	movq	$22, -26184(%rbp)
	call	_gfortran_st_write@PLT
	movl	$5, %edx
	leaq	.LC527(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	-28056(%rbp), %rsi
	movl	$8, %edx
	movq	%r13, %rdi
	call	_gfortran_transfer_real_write@PLT
	movl	$15, %edx
	leaq	.LC528(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movl	equil_(%rip), %eax
	movq	-27752(%rbp), %rsi
	cltd
	idivl	-28096(%rbp)
	movq	%r13, %rdi
	movl	$4, %edx
	movl	%eax, -26704(%rbp)
	call	_gfortran_transfer_integer_write@PLT
	movl	$11, %edx
	leaq	.LC529(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	-27864(%rbp), %rsi
	movl	$8, %edx
	jmp	.L4621
.L4014:
	movl	32+wal_(%rip), %esi
	cmpl	%esi, %eax
	jle	.L4202
	movl	%r8d, %eax
	cltd
	idivl	-28092(%rbp)
	testl	%edx, %edx
	je	.L4200
	incl	%r8d
	vmovsd	%xmm5, -27920(%rbp)
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%r8d, %xmm5, %xmm0
	vmovsd	-26928(%rbp), %xmm2
	movl	%edi, -27944(%rbp)
	movl	%r8d, 28+wal_(%rip)
	vmulsd	%xmm2, %xmm0, %xmm0
	vmovsd	%xmm3, -27568(%rbp)
	vmovsd	%xmm1, -27512(%rbp)
	vmovsd	%xmm2, -27464(%rbp)
	vzeroupper
	call	sin@PLT
	vmovsd	%xmm0, %xmm0, %xmm4
	vmovsd	-27464(%rbp), %xmm2
	vmovsd	16+restart_(%rip), %xmm0
	vmulsd	%xmm4, %xmm2, %xmm2
	vmulsd	-27192(%rbp), %xmm0, %xmm0
	vmovsd	.LC72(%rip), %xmm4
	movl	-27944(%rbp), %edi
	movl	32+kier_(%rip), %esi
	movl	36+wal_(%rip), %edx
	vmulsd	%xmm2, %xmm0, %xmm0
	vmovsd	-27512(%rbp), %xmm1
	vmovsd	8+restart_(%rip), %xmm2
	vmovsd	-27568(%rbp), %xmm3
	movl	%edi, %ecx
	vxorpd	.LC11(%rip), %xmm0, %xmm5
	vmulsd	%xmm5, %xmm4, %xmm4
	vmovsd	%xmm5, -27704(%rbp)
	vmovsd	-27920(%rbp), %xmm5
	jmp	.L3986
.L4885:
	vmovsd	-27760(%rbp), %xmm7
	vmovsd	.LC72(%rip), %xmm4
	vxorpd	.LC11(%rip), %xmm7, %xmm6
	movl	$8271, %r11d
	vmulsd	-27704(%rbp), %xmm4, %xmm4
	movl	$-1, 28+wal_(%rip)
	movw	%r11w, -450(%rbp)
	movl	32+kier_(%rip), %esi
	vmovsd	8+restart_(%rip), %xmm2
	movl	36+wal_(%rip), %edx
	vmovsd	%xmm6, -27760(%rbp)
	movl	%edi, %ecx
	jmp	.L3986
.L4205:
	incl	%eax
	vxorps	%xmm6, %xmm6, %xmm6
	vcvtsi2ssl	%eax, %xmm6, %xmm0
	vxorpd	%xmm4, %xmm4, %xmm4
	vcvtsi2sdl	%edx, %xmm4, %xmm2
	vmovsd	.LC72(%rip), %xmm6
	vcvtss2sd	%xmm0, %xmm0, %xmm0
	vmulsd	-27760(%rbp), %xmm0, %xmm0
	movl	%eax, 20+wal_(%rip)
	movl	$8257, %eax
	movw	%ax, -450(%rbp)
	movl	36+wal_(%rip), %edx
	vdivsd	%xmm2, %xmm0, %xmm7
	movl	%edi, %ecx
	vmovsd	8+restart_(%rip), %xmm2
	vmulsd	%xmm7, %xmm6, %xmm4
	vmovsd	%xmm7, -27704(%rbp)
	jmp	.L3986
.L4008:
	leaq	-27424(%rbp), %rsi
	leaq	-27408(%rbp), %rdi
	vmovsd	%xmm5, -27568(%rbp)
	vmovsd	%xmm3, -27512(%rbp)
	vmovsd	%xmm1, -27464(%rbp)
	vzeroupper
	call	print_restart_
	cmpl	$5, 16+equil_(%rip)
	movl	$1, 24+wal_(%rip)
	vmovsd	-27464(%rbp), %xmm1
	vmovsd	-27512(%rbp), %xmm3
	vmovsd	-27568(%rbp), %xmm5
	je	.L4635
	movl	$8261, %ebx
	movw	%bx, -450(%rbp)
	jmp	.L4624
.L4830:
	leaq	cmap_(%rip), %rax
	movl	60000004(%rax), %ebx
	movl	$1, -27452(%rbp)
	testl	%ebx, %ebx
	jle	.L3847
	movslq	%ebx, %r8
	leaq	0(,%r8,8), %r15
	movq	%r15, %rdx
	xorl	%esi, %esi
	leaq	fbt.14(%rip), %rdi
	movl	%ecx, -27504(%rbp)
	movq	%r8, -27480(%rbp)
	call	memset@PLT
	movq	%r15, %rdx
	xorl	%esi, %esi
	leaq	fbt2.13(%rip), %rdi
	call	memset@PLT
	movq	-27480(%rbp), %r8
	xorl	%esi, %esi
	leaq	0(,%r8,4), %rdx
	leaq	mtraj.12(%rip), %rdi
	incl	%ebx
	call	memset@PLT
	movl	%ebx, -27452(%rbp)
	movl	-27504(%rbp), %ecx
	jmp	.L3847
.L4006:
	vmulsd	%xmm2, %xmm0, %xmm0
	vmulsd	.LC72(%rip), %xmm0, %xmm0
	vcomisd	24+kier_(%rip), %xmm0
	jbe	.L4008
	movl	20+wal_(%rip), %eax
	movl	8+equil_(%rip), %edx
	cmpl	%eax, %edx
	jg	.L4205
	vmovsd	-27760(%rbp), %xmm7
	vmovsd	.LC72(%rip), %xmm6
	vmovsd	8+restart_(%rip), %xmm2
	vmulsd	%xmm7, %xmm6, %xmm4
	movl	36+wal_(%rip), %edx
	movl	%esi, %ecx
	vmovsd	%xmm7, -27704(%rbp)
	jmp	.L4206
.L4879:
	vmovsd	%xmm5, -27568(%rbp)
	vmovsd	%xmm3, -27512(%rbp)
	vmovsd	%xmm1, -27464(%rbp)
	call	make_fcc_
	vmovsd	-27568(%rbp), %xmm5
	vmovsd	-27512(%rbp), %xmm3
	vmovsd	-27464(%rbp), %xmm1
	jmp	.L4012
.L4878:
	call	connect_to_wal_
	vmovsd	-27568(%rbp), %xmm5
	vmovsd	-27512(%rbp), %xmm3
	vmovsd	-27464(%rbp), %xmm1
	jmp	.L4011
.L4882:
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	-27428(%rbp), %xmm5, %xmm0
	vmovsd	.LC8(%rip), %xmm6
	movq	-27640(%rbp), %r14
	leaq	.LC582(%rip), %rax
	vdivsd	%xmm0, %xmm6, %xmm0
	movabsq	$4294971392, %r12
	movq	%r13, %rdi
	movq	%rax, -26192(%rbp)
	movq	%r14, -26264(%rbp)
	movl	$2342, -26256(%rbp)
	movq	$7, -26184(%rbp)
	movq	%r12, -26272(%rbp)
	vmulsd	-28016(%rbp), %xmm0, %xmm1
	vmovsd	%xmm1, -26904(%rbp)
	vmulsd	%xmm1, %xmm1, %xmm1
	vfmsub231sd	-28024(%rbp), %xmm0, %xmm1
	vandpd	.LC69(%rip), %xmm1, %xmm1
	vsqrtsd	%xmm1, %xmm1, %xmm1
	vmulsd	.LC72(%rip), %xmm1, %xmm1
	vmovsd	%xmm1, -26896(%rbp)
	vmulsd	-28000(%rbp), %xmm0, %xmm1
	vmovsd	%xmm1, -27096(%rbp)
	vmulsd	%xmm1, %xmm1, %xmm1
	vfmsub231sd	-28008(%rbp), %xmm0, %xmm1
	vandpd	.LC69(%rip), %xmm1, %xmm1
	vsqrtsd	%xmm1, %xmm1, %xmm1
	vmulsd	.LC72(%rip), %xmm1, %xmm1
	vmovsd	%xmm1, -27088(%rbp)
	vmulsd	-27984(%rbp), %xmm0, %xmm1
	vmovsd	%xmm1, -27072(%rbp)
	vmulsd	%xmm1, %xmm1, %xmm1
	vfmsub132sd	-27992(%rbp), %xmm1, %xmm0
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmulsd	.LC72(%rip), %xmm0, %xmm0
	vmovsd	%xmm0, -27064(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r13, %rdi
	movl	$53, %edx
	leaq	.LC583(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movl	$24, %edx
	leaq	.LC584(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC585(%rip), %rax
	movq	%r13, %rdi
	movq	%rax, -26192(%rbp)
	movq	%r14, -26264(%rbp)
	movl	$2344, -26256(%rbp)
	movq	$29, -26184(%rbp)
	movq	%r12, -26272(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r13, %rdi
	movl	$1, %edx
	leaq	.LC130(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	-28056(%rbp), %rsi
	movq	%r13, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26904(%rbp), %rsi
	movq	%r13, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26896(%rbp), %rsi
	movq	%r13, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-27096(%rbp), %rsi
	movq	%r13, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-27088(%rbp), %rsi
	movq	%r13, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-27072(%rbp), %rsi
	movq	%r13, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r13, %rdi
	leaq	-27064(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L4190
.L4881:
	leaq	-27428(%rbp), %r12
	leaq	-24528(%rbp), %rsi
	movq	%r12, %rdi
	call	sort_
	movl	-27228(%rbp), %edx
	movq	-27640(%rbp), %r14
	movl	%edx, %eax
	shrl	$31, %eax
	addl	%edx, %eax
	sarl	%eax
	cltq
	vmovsd	-24528(%rbp,%rax,8), %xmm0
	movabsq	$4294971392, %r15
	leaq	.LC574(%rip), %rax
	movq	%r13, %rdi
	vmovsd	%xmm0, -26808(%rbp)
	movq	%rax, -26192(%rbp)
	movq	%r14, -26264(%rbp)
	movl	$2326, -26256(%rbp)
	movq	$5, -26184(%rbp)
	movq	%r15, -26272(%rbp)
	call	_gfortran_st_write@PLT
	movl	$32, %edx
	leaq	.LC580(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC581(%rip), %rax
	movq	%r13, %rdi
	movq	%rax, -26192(%rbp)
	movq	%r14, -26264(%rbp)
	movl	$2327, -26256(%rbp)
	movq	$20, -26184(%rbp)
	movq	%r15, -26272(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r13, %rdi
	movl	$1, %edx
	leaq	.LC130(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	-28056(%rbp), %rsi
	movq	%r13, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	leaq	-26808(%rbp), %rsi
	movq	%r13, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real_write@PLT
	movq	%r12, %rsi
	movq	%r13, %rdi
	movl	$4, %edx
	call	_gfortran_transfer_integer_write@PLT
	movq	%r13, %rdi
	leaq	-27448(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_integer_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L4189
.L4880:
	movq	-27640(%rbp), %r14
	leaq	.LC574(%rip), %rax
	movabsq	$4294971392, %r12
	movq	%r13, %rdi
	movq	%rax, -26192(%rbp)
	movq	%r12, -26272(%rbp)
	movq	%r14, -26264(%rbp)
	movl	$2283, -26256(%rbp)
	movq	$5, -26184(%rbp)
	call	_gfortran_st_write@PLT
	movl	$45, %edx
	leaq	.LC575(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27936(%rbp), %rax
	movq	%r13, %rdi
	movq	%rax, -26192(%rbp)
	movq	%r12, -26272(%rbp)
	movq	%r14, -26264(%rbp)
	movl	$2284, -26256(%rbp)
	movq	$3, -26184(%rbp)
	call	_gfortran_st_write@PLT
	movl	$38, %edx
	leaq	.LC576(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	cmap_(%rip), %rax
	movl	60000004(%rax), %r12d
	testl	%r12d, %r12d
	jle	.L4169
	leal	-1(%r12), %eax
	movl	%eax, -27480(%rbp)
	cmpl	$8, %eax
	jbe	.L4273
	movl	mtraj.12(%rip), %eax
	vmovsd	fbt.14(%rip), %xmm1
	leaq	mtraj.12(%rip), %r9
	leaq	fbt.14(%rip), %rsi
	testl	%eax, %eax
	je	.L4171
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%eax, %xmm5, %xmm0
	vmovsd	fbt2.13(%rip), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm2
	vdivsd	%xmm0, %xmm1, %xmm1
	vmovsd	%xmm2, fbt2.13(%rip)
	vmovsd	fut.4(%rip), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm2
	vmovsd	%xmm1, fbt.14(%rip)
	vmovsd	%xmm2, fut.4(%rip)
	vmovsd	fut2.3(%rip), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm0
	vmovsd	%xmm0, fut2.3(%rip)
.L4171:
	movl	4+mtraj.12(%rip), %eax
	vmovsd	%xmm1, caac.2(%rip)
	movl	$1, kaak.1(%rip)
	vmovsd	8+fbt.14(%rip), %xmm1
	leaq	caac.2(%rip), %r11
	testl	%eax, %eax
	je	.L4174
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%eax, %xmm5, %xmm0
	vmovsd	8+fbt2.13(%rip), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm2
	vdivsd	%xmm0, %xmm1, %xmm1
	vmovsd	%xmm2, 8+fbt2.13(%rip)
	vmovsd	8+fut.4(%rip), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm2
	vmovsd	%xmm1, 8+fbt.14(%rip)
	vmovsd	%xmm2, 8+fut.4(%rip)
	vmovsd	8+fut2.3(%rip), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm0
	vmovsd	%xmm0, 8+fut2.3(%rip)
.L4174:
	leaq	cmap_(%rip), %rax
	leal	-2(%r12), %r15d
	leaq	60000032(%rax), %r10
	movl	%r15d, %eax
	shrl	$3, %eax
	movl	$2, 4+kaak.1(%rip)
	movq	%rsi, -27504(%rbp)
	salq	$5, %rax
	vmovdqa	.LC278(%rip), %ymm5
	movq	-27464(%rbp), %r14
	movq	%rax, -27472(%rbp)
	vmovsd	%xmm1, 8+caac.2(%rip)
	leaq	16+fut2.3(%rip), %r8
	leaq	16+fut.4(%rip), %rdi
	leaq	16+fbt2.13(%rip), %rcx
	leaq	16+fbt.14(%rip), %rdx
	xorl	%eax, %eax
	vpxor	%xmm6, %xmm6, %xmm6
.L4173:
	leaq	8+mtraj.12(%rip), %rsi
	vmovdqu	(%rsi,%rax), %ymm0
	vmovapd	.LC441(%rip), %ymm4
	vcvtdq2pd	%xmm0, %ymm2
	vdivpd	%ymm2, %ymm4, %ymm2
	vextracti128	$0x1, %ymm0, %xmm1
	vcvtdq2pd	%xmm1, %ymm1
	vmovupd	(%rdx), %ymm9
	vpcmpeqd	%ymm6, %ymm0, %ymm0
	vmovupd	32(%rdx), %ymm8
	leaq	16+caac.2(%rip), %rsi
	vpcmpeqd	%ymm6, %ymm0, %ymm3
	vmovdqa	%ymm5, %ymm7
	addq	$96, %r10
	vpaddd	.LC77(%rip), %ymm5, %ymm5
	addq	$64, %r8
	addq	$64, %rdi
	addq	$64, %rcx
	addq	$64, %rdx
	vdivpd	%ymm1, %ymm4, %ymm1
	vpmovsxdq	%xmm3, %ymm4
	vextracti128	$0x1, %ymm3, %xmm3
	vpmovsxdq	%xmm3, %ymm3
	vmulpd	%ymm2, %ymm9, %ymm10
	vblendvpd	%ymm4, %ymm10, %ymm9, %ymm4
	vmovupd	%ymm4, -64(%rdx)
	vmulpd	%ymm1, %ymm8, %ymm9
	vblendvpd	%ymm3, %ymm9, %ymm8, %ymm3
	vmovupd	%ymm3, -32(%rdx)
	vmovupd	-64(%rcx), %ymm11
	vmovupd	-32(%rcx), %ymm10
	vmulpd	%ymm2, %ymm11, %ymm9
	vpmovsxdq	%xmm0, %ymm8
	vextracti128	$0x1, %ymm0, %xmm0
	vpmovsxdq	%xmm0, %ymm0
	vblendvpd	%ymm8, %ymm11, %ymm9, %ymm9
	vmovupd	%ymm9, -64(%rcx)
	vmulpd	%ymm1, %ymm10, %ymm9
	vblendvpd	%ymm0, %ymm10, %ymm9, %ymm9
	vmovupd	%ymm9, -32(%rcx)
	vmovupd	-64(%rdi), %ymm11
	vmovupd	-32(%rdi), %ymm10
	vmulpd	%ymm2, %ymm11, %ymm9
	vblendvpd	%ymm8, %ymm11, %ymm9, %ymm9
	vmovupd	%ymm9, -64(%rdi)
	vmulpd	%ymm1, %ymm10, %ymm9
	vblendvpd	%ymm0, %ymm10, %ymm9, %ymm9
	vmovupd	%ymm9, -32(%rdi)
	vmovupd	-64(%r8), %ymm10
	vmovupd	-32(%r8), %ymm9
	vmulpd	%ymm2, %ymm10, %ymm2
	vmulpd	%ymm1, %ymm9, %ymm1
	vblendvpd	%ymm8, %ymm10, %ymm2, %ymm2
	vblendvpd	%ymm0, %ymm9, %ymm1, %ymm0
	vmovupd	%ymm0, -32(%r8)
	vmovupd	%ymm2, -64(%r8)
	vmovdqa	-32(%r10), %ymm0
	vmovupd	%ymm4, (%rsi,%rax,2)
	addq	$32, %rsi
	vmovupd	%ymm3, (%rsi,%rax,2)
	leaq	8+kaak.1(%rip), %rsi
	vmovdqu	%ymm7, (%rsi,%rax)
	addq	$32, %rax
	cmpq	%rax, -27472(%rbp)
	jne	.L4173
	movl	%r15d, %ecx
	vextracti128	$0x1, %ymm0, %xmm0
	andl	$-8, %ecx
	movq	%r14, -27464(%rbp)
	movq	-27504(%rbp), %rsi
	vpextrd	$2, %xmm0, %r10d
	vpextrd	$1, %xmm0, %eax
	leal	2(%rcx), %edx
	leal	3(%rcx), %edi
	cmpl	%r15d, %ecx
	je	.L4890
	vzeroupper
.L4170:
	movl	-27480(%rbp), %eax
	subl	%edx, %eax
	movl	%eax, -27472(%rbp)
	cmpl	$3, %eax
	jbe	.L4176
	leaq	0(,%rdx,4), %rcx
	leaq	(%r9,%rcx), %r15
	vmovd	%edi, %xmm5
	vpshufd	$0, %xmm5, %xmm7
	vmovapd	.LC68(%rip), %xmm1
	vmovdqu	(%r15), %xmm5
	salq	$3, %rdx
	vcvtdq2pd	%xmm5, %xmm2
	vdivpd	%xmm2, %xmm1, %xmm2
	vpshufd	$238, %xmm5, %xmm0
	vcvtdq2pd	%xmm0, %xmm0
	movq	%rcx, -27480(%rbp)
	vpxor	%xmm6, %xmm6, %xmm6
	leaq	(%rsi,%rdx), %rcx
	vmovupd	(%rcx), %xmm8
	vpcmpeqd	%xmm6, %xmm5, %xmm5
	vmovupd	16(%rcx), %xmm9
	leaq	fbt2.13(%rip), %rax
	vpcmpeqd	%xmm6, %xmm5, %xmm3
	leaq	(%rax,%rdx), %r8
	leaq	fut.4(%rip), %rax
	vpmovsxdq	%xmm3, %xmm10
	vpsrldq	$8, %xmm3, %xmm3
	vpmovsxdq	%xmm3, %xmm3
	leaq	(%rax,%rdx), %r10
	leaq	fut2.3(%rip), %rax
	addq	%rdx, %rax
	leaq	kaak.1(%rip), %r14
	vdivpd	%xmm0, %xmm1, %xmm1
	addq	-27480(%rbp), %r14
	addq	%r11, %rdx
	movq	%r14, -27480(%rbp)
	vpaddd	.LC577(%rip), %xmm7, %xmm4
	vmulpd	%xmm2, %xmm8, %xmm0
	vblendvpd	%xmm10, %xmm0, %xmm8, %xmm8
	vmovupd	%xmm8, (%rcx)
	vmulpd	%xmm1, %xmm9, %xmm0
	vblendvpd	%xmm3, %xmm0, %xmm9, %xmm3
	vmovupd	%xmm3, 16(%rcx)
	vmovupd	(%r8), %xmm11
	vpmovsxdq	%xmm5, %xmm9
	vpsrldq	$8, %xmm5, %xmm5
	vpmovsxdq	%xmm5, %xmm0
	vmulpd	%xmm2, %xmm11, %xmm5
	vmovupd	16(%r8), %xmm10
	vblendvpd	%xmm9, %xmm11, %xmm5, %xmm5
	vmovupd	%xmm5, (%r8)
	vmulpd	%xmm1, %xmm10, %xmm5
	vblendvpd	%xmm0, %xmm10, %xmm5, %xmm5
	vmovupd	%xmm5, 16(%r8)
	vmovupd	(%r10), %xmm11
	vmovupd	16(%r10), %xmm10
	vmulpd	%xmm11, %xmm2, %xmm5
	vblendvpd	%xmm9, %xmm11, %xmm5, %xmm5
	vmovupd	%xmm5, (%r10)
	vmulpd	%xmm10, %xmm1, %xmm5
	vblendvpd	%xmm0, %xmm10, %xmm5, %xmm5
	vmovupd	%xmm5, 16(%r10)
	vmovupd	16(%rax), %xmm5
	vmovupd	(%rax), %xmm10
	vmulpd	%xmm5, %xmm1, %xmm1
	vmulpd	%xmm10, %xmm2, %xmm2
	vblendvpd	%xmm0, %xmm5, %xmm1, %xmm0
	vmovupd	%xmm0, 16(%rax)
	vpaddd	.LC78(%rip), %xmm7, %xmm0
	vblendvpd	%xmm9, %xmm10, %xmm2, %xmm2
	vmovupd	%xmm2, (%rax)
	vmovupd	%xmm8, (%rdx)
	vmovupd	%xmm3, 16(%rdx)
	vmovdqu	%xmm0, (%r14)
	movl	-27472(%rbp), %r14d
	shrl	$2, %r14d
	cmpl	$1, %r14d
	je	.L4177
	vmovdqu	16(%r15), %xmm3
	vmovupd	32(%rcx), %xmm7
	vcvtdq2pd	%xmm3, %xmm2
	vpshufd	$238, %xmm3, %xmm1
	vpcmpeqd	%xmm6, %xmm3, %xmm3
	vmovupd	48(%rcx), %xmm5
	vcvtdq2pd	%xmm1, %xmm1
	vpcmpeqd	%xmm6, %xmm3, %xmm0
	vdivpd	%xmm2, %xmm7, %xmm6
	movq	-27480(%rbp), %r14
	vpmovsxdq	%xmm0, %xmm8
	vpsrldq	$8, %xmm0, %xmm0
	vpmovsxdq	%xmm0, %xmm0
	vblendvpd	%xmm8, %xmm6, %xmm7, %xmm6
	vdivpd	%xmm1, %xmm5, %xmm7
	vmovupd	%xmm6, 32(%rcx)
	vblendvpd	%xmm0, %xmm7, %xmm5, %xmm5
	vmovupd	%xmm5, 48(%rcx)
	vmovupd	32(%r8), %xmm9
	vpmovsxdq	%xmm3, %xmm7
	vpsrldq	$8, %xmm3, %xmm3
	vpmovsxdq	%xmm3, %xmm0
	vdivpd	%xmm2, %xmm9, %xmm3
	vmovupd	48(%r8), %xmm8
	vblendvpd	%xmm7, %xmm9, %xmm3, %xmm3
	vmovupd	%xmm3, 32(%r8)
	vdivpd	%xmm1, %xmm8, %xmm3
	vblendvpd	%xmm0, %xmm8, %xmm3, %xmm3
	vmovupd	%xmm3, 48(%r8)
	vmovupd	32(%r10), %xmm9
	vmovupd	48(%r10), %xmm8
	vdivpd	%xmm2, %xmm9, %xmm3
	vblendvpd	%xmm7, %xmm9, %xmm3, %xmm3
	vmovupd	%xmm3, 32(%r10)
	vdivpd	%xmm1, %xmm8, %xmm3
	vblendvpd	%xmm0, %xmm8, %xmm3, %xmm3
	vmovupd	%xmm3, 48(%r10)
	vmovupd	32(%rax), %xmm8
	vmovupd	48(%rax), %xmm3
	vdivpd	%xmm2, %xmm8, %xmm2
	vdivpd	%xmm1, %xmm3, %xmm1
	vblendvpd	%xmm7, %xmm8, %xmm2, %xmm2
	vmovupd	%xmm2, 32(%rax)
	vblendvpd	%xmm0, %xmm3, %xmm1, %xmm0
	vmovupd	%xmm0, 48(%rax)
	vmovupd	%xmm6, 32(%rdx)
	vmovupd	%xmm5, 48(%rdx)
	vmovdqu	%xmm4, 16(%r14)
.L4177:
	movl	-27472(%rbp), %eax
	andl	$-4, %eax
	addl	%eax, %edi
.L4176:
	leal	-1(%rdi), %edx
	movslq	%edx, %rdx
	movl	(%r9,%rdx,4), %eax
	vmovsd	(%rsi,%rdx,8), %xmm1
	movslq	%edi, %rcx
	testl	%eax, %eax
	je	.L4178
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%eax, %xmm5, %xmm0
	leaq	fbt2.13(%rip), %rax
	vmovsd	(%rax,%rdx,8), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm2
	vdivsd	%xmm0, %xmm1, %xmm1
	vmovsd	%xmm2, (%rax,%rdx,8)
	leaq	fut.4(%rip), %rax
	vmovsd	(%rax,%rdx,8), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm2
	vmovsd	%xmm1, (%rsi,%rdx,8)
	vmovsd	%xmm2, (%rax,%rdx,8)
	leaq	fut2.3(%rip), %rax
	vmovsd	(%rax,%rdx,8), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm0
	vmovsd	%xmm0, (%rax,%rdx,8)
.L4178:
	leaq	kaak.1(%rip), %r14
	leaq	(%rdx,%rdx,2), %r8
	leaq	cmap_(%rip), %r10
	movl	%edi, (%r14,%rdx,4)
	vmovsd	%xmm1, (%r11,%rdx,8)
	leal	1(%rdi), %edx
	movl	60000008(%r10,%r8,4), %eax
	movl	%edx, -27472(%rbp)
	movl	60000012(%r10,%r8,4), %r10d
	leaq	3(%r8), %r15
	cmpl	%r12d, %edx
	jg	.L4175
	movl	(%r9,%rcx,4), %eax
	vmovsd	(%rsi,%rcx,8), %xmm1
	movslq	%edx, %rdx
	testl	%eax, %eax
	je	.L4180
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%eax, %xmm5, %xmm0
	leaq	fbt2.13(%rip), %rax
	vmovsd	(%rax,%rcx,8), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm2
	vdivsd	%xmm0, %xmm1, %xmm1
	vmovsd	%xmm2, (%rax,%rcx,8)
	leaq	fut.4(%rip), %rax
	vmovsd	(%rax,%rcx,8), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm2
	vmovsd	%xmm1, (%rsi,%rcx,8)
	vmovsd	%xmm2, (%rax,%rcx,8)
	leaq	fut2.3(%rip), %rax
	vmovsd	(%rax,%rcx,8), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm0
	vmovsd	%xmm0, (%rax,%rcx,8)
.L4180:
	leaq	cmap_(%rip), %r10
	movl	60000008(%r10,%r15,4), %eax
	leaq	6(%r8), %r14
	movl	-27472(%rbp), %r15d
	movq	%r14, -27480(%rbp)
	leaq	kaak.1(%rip), %r14
	movl	%r15d, (%r14,%rcx,4)
	vmovsd	%xmm1, (%r11,%rcx,8)
	leal	2(%rdi), %ecx
	movl	60000024(%r10,%r8,4), %r10d
	movl	%ecx, %r15d
	cmpl	%ecx, %r12d
	jl	.L4175
	movl	(%r9,%rdx,4), %eax
	vmovsd	(%rsi,%rdx,8), %xmm1
	movslq	%ecx, %rcx
	testl	%eax, %eax
	je	.L4181
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%eax, %xmm5, %xmm0
	leaq	fbt2.13(%rip), %rax
	vmovsd	(%rax,%rdx,8), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm2
	vdivsd	%xmm0, %xmm1, %xmm1
	vmovsd	%xmm2, (%rax,%rdx,8)
	leaq	fut.4(%rip), %rax
	vmovsd	(%rax,%rdx,8), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm2
	vmovsd	%xmm1, (%rsi,%rdx,8)
	vmovsd	%xmm2, (%rax,%rdx,8)
	leaq	fut2.3(%rip), %rax
	vmovsd	(%rax,%rdx,8), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm0
	vmovsd	%xmm0, (%rax,%rdx,8)
.L4181:
	leaq	9(%r8), %r14
	leaq	cmap_(%rip), %r10
	movq	%r14, -27472(%rbp)
	leaq	6(%r8), %rax
	leaq	kaak.1(%rip), %r14
	addl	$3, %edi
	movl	60000008(%r10,%rax,4), %eax
	movl	%r15d, (%r14,%rdx,4)
	movl	60000036(%r10,%r8,4), %r10d
	vmovsd	%xmm1, (%r11,%rdx,8)
	cmpl	%edi, %r12d
	jl	.L4175
	movl	(%r9,%rcx,4), %eax
	vmovsd	(%rsi,%rcx,8), %xmm1
	testl	%eax, %eax
	je	.L4183
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%eax, %xmm5, %xmm0
	leaq	fbt2.13(%rip), %rax
	vmovsd	(%rax,%rcx,8), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm2
	vdivsd	%xmm0, %xmm1, %xmm1
	vmovsd	%xmm2, (%rax,%rcx,8)
	leaq	fut.4(%rip), %rax
	vmovsd	(%rax,%rcx,8), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm2
	vmovsd	%xmm1, (%rsi,%rcx,8)
	vmovsd	%xmm2, (%rax,%rcx,8)
	leaq	fut2.3(%rip), %rax
	vmovsd	(%rax,%rcx,8), %xmm2
	vdivsd	%xmm0, %xmm2, %xmm0
	vmovsd	%xmm0, (%rax,%rcx,8)
.L4183:
	leaq	cmap_(%rip), %rsi
	leaq	9(%r8), %rax
	movl	60000008(%rsi,%rax,4), %eax
	movl	60000048(%rsi,%r8,4), %r10d
	leaq	kaak.1(%rip), %rsi
	movl	%edi, (%rsi,%rcx,4)
	vmovsd	%xmm1, (%r11,%rcx,8)
.L4175:
	movl	%eax, -27452(%rbp)
	movl	%r10d, -27420(%rbp)
.L4169:
	leaq	cmap_(%rip), %rax
	movq	%rax, %r14
	leaq	kaak.1(%rip), %rdx
	leaq	caac.2(%rip), %rsi
	leaq	60000004(%rax), %rdi
	call	sort2_
	movl	60000004(%r14), %r9d
	testl	%r9d, %r9d
	jle	.L3856
	movl	%ebx, -27472(%rbp)
	movl	$1, %r12d
	leaq	-8+caac.2(%rip), %r15
	leaq	-4+kaak.1(%rip), %r8
	movl	%r9d, %r14d
	jmp	.L4188
.L4185:
	incq	%r12
	cmpl	%r12d, %r14d
	jl	.L4891
.L4188:
	vmovsd	(%r15,%r12,8), %xmm0
	vxorpd	%xmm5, %xmm5, %xmm5
	vcomisd	%xmm5, %xmm0
	vmovsd	%xmm0, -26968(%rbp)
	jbe	.L4185
	movslq	(%r8,%r12,4), %rax
	leaq	cmap_(%rip), %rbx
	movl	%eax, -27332(%rbp)
	leaq	-3(%rax,%rax,2), %rax
	movslq	60000008(%rbx,%rax,4), %rdx
	movl	60000012(%rbx,%rax,4), %ebx
	leaq	sequence_(%rip), %rax
	movl	%edx, -27452(%rbp)
	movq	%rdx, %r10
	movl	-4(%rax,%rdx,4), %edx
	vcomisd	.LC578(%rip), %xmm0
	movl	%edx, -27436(%rbp)
	movslq	%ebx, %rdx
	movl	-4(%rax,%rdx,4), %eax
	movl	%ebx, -27420(%rbp)
	movl	%eax, -27412(%rbp)
	jbe	.L4185
	movq	-27640(%rbp), %rax
	movq	%r13, %rdi
	movq	%rax, -26264(%rbp)
	leaq	.LC579(%rip), %rax
	movq	%rax, -26192(%rbp)
	movabsq	$4294971392, %rax
	movl	%r10d, -27480(%rbp)
	movq	%rax, -26272(%rbp)
	movl	$2317, -26256(%rbp)
	movq	$12, -26184(%rbp)
	call	_gfortran_st_write@PLT
	leaq	-27332(%rbp), %rsi
	movl	$4, %edx
	movq	%r13, %rdi
	call	_gfortran_transfer_integer_write@PLT
	leaq	-27436(%rbp), %rsi
	movl	$4, %edx
	movq	%r13, %rdi
	call	_gfortran_transfer_integer_write@PLT
	leaq	-27412(%rbp), %rsi
	movl	$4, %edx
	movq	%r13, %rdi
	call	_gfortran_transfer_integer_write@PLT
	movl	-27480(%rbp), %r10d
	movq	-27752(%rbp), %rsi
	movl	%ebx, %eax
	subl	%r10d, %eax
	movl	$4, %edx
	movq	%r13, %rdi
	movl	%eax, -26704(%rbp)
	call	_gfortran_transfer_integer_write@PLT
	leaq	-26968(%rbp), %rsi
	movl	$8, %edx
	movq	%r13, %rdi
	call	_gfortran_transfer_real_write@PLT
	incq	%r12
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	-4+kaak.1(%rip), %r8
	cmpl	%r12d, %r14d
	jge	.L4188
.L4891:
	movl	-27472(%rbp), %ebx
	jmp	.L3856
.L4883:
	movq	-27640(%rbp), %r14
	leaq	.LC586(%rip), %rax
	movabsq	$4294971392, %r12
	movq	%r13, %rdi
	movq	%rax, -26192(%rbp)
	movq	%r14, -26264(%rbp)
	movl	$2350, -26256(%rbp)
	movq	$6, -26184(%rbp)
	movq	%r12, -26272(%rbp)
	call	_gfortran_st_write@PLT
	movl	$52, %edx
	leaq	.LC587(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27936(%rbp), %rax
	movq	%r13, %rdi
	movq	%rax, -26192(%rbp)
	movq	%r14, -26264(%rbp)
	movl	$2351, -26256(%rbp)
	movq	$3, -26184(%rbp)
	movq	%r12, -26272(%rbp)
	call	_gfortran_st_write@PLT
	movl	$37, %edx
	leaq	.LC588(%rip), %rsi
	movq	%r13, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	movl	-28040(%rbp), %edx
	movl	$1, -27452(%rbp)
	testl	%edx, %edx
	jle	.L4193
	vxorpd	%xmm5, %xmm5, %xmm5
	vcvtsi2sdl	%r15d, %xmm5, %xmm1
	vmovsd	.LC8(%rip), %xmm6
	leaq	-26888(%rbp), %rsi
	movq	%rsi, -27504(%rbp)
	vdivsd	%xmm1, %xmm6, %xmm1
	leaq	-27216(%rbp), %rsi
	movq	%rsi, -27472(%rbp)
	leaq	-27208(%rbp), %rsi
	movl	-27380(%rbp), %ecx
	movq	%rsi, -27480(%rbp)
	movl	$2, %eax
	movl	%ebx, -27488(%rbp)
	movl	%ecx, %r15d
	leaq	bas_(%rip), %r11
	leaq	-16+aufres.11(%rip), %r10
	leaq	-16+aufres2.10(%rip), %r9
	leaq	-16+aree.9(%rip), %r8
	movq	%rax, %rbx
	movl	%ecx, %r14d
.L4194:
	vmulsd	(%r10,%rbx,8), %xmm1, %xmm0
	movq	-27640(%rbp), %rax
	movq	%r13, %rdi
	movq	%rax, -26264(%rbp)
	leaq	.LC589(%rip), %rax
	vmovsd	%xmm0, -27216(%rbp)
	vmulsd	%xmm0, %xmm0, %xmm0
	movq	%r11, -27520(%rbp)
	vmovsd	%xmm1, -27512(%rbp)
	movq	%rax, -26192(%rbp)
	movl	$2357, -26256(%rbp)
	vfmsub231sd	(%r9,%rbx,8), %xmm1, %xmm0
	movq	$18, -26184(%rbp)
	movq	%r12, -26272(%rbp)
	vandpd	.LC69(%rip), %xmm0, %xmm0
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vmulsd	.LC72(%rip), %xmm0, %xmm0
	vmovsd	%xmm0, -27208(%rbp)
	vmulsd	(%r11), %xmm1, %xmm0
	vmulsd	(%r8,%rbx,8), %xmm0, %xmm0
	vmovsd	%xmm0, -26888(%rbp)
	call	_gfortran_st_write@PLT
	vxorpd	%xmm7, %xmm7, %xmm7
	vcvtsi2sdl	%r15d, %xmm7, %xmm0
	leaq	restart_(%rip), %rax
	movq	-27752(%rbp), %rsi
	movl	$8, %edx
	vmulsd	(%rax), %xmm0, %xmm0
	movq	%r13, %rdi
	addl	%r14d, %r15d
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movq	-27504(%rbp), %rsi
	movl	$8, %edx
	movq	%r13, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	-27472(%rbp), %rsi
	movl	$8, %edx
	movq	%r13, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	-27480(%rbp), %rsi
	movl	$8, %edx
	movq	%r13, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r13, %rdi
	call	_gfortran_st_write_done@PLT
	movl	%ebx, -27452(%rbp)
	incq	%rbx
	leal	-1(%rbx), %edx
	cmpl	%edx, -28040(%rbp)
	vmovsd	-27512(%rbp), %xmm1
	movq	-27520(%rbp), %r11
	leaq	-16+aree.9(%rip), %r8
	leaq	-16+aufres2.10(%rip), %r9
	leaq	-16+aufres.11(%rip), %r10
	jge	.L4194
	movl	-27488(%rbp), %ebx
	jmp	.L4193
.L4822:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC495(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1019, -16480(%rbp)
	movq	$15, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$19, %edx
	leaq	.LC496(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	-26928(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	leaq	.LC497(%rip), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	leaq	-26912(%rbp), %rsi
	jmp	.L4620
.L3843:
	movq	-27752(%rbp), %r14
	movq	-27640(%rbp), %rbx
	movabsq	$4294967296, %rax
	movq	%r14, %rdi
	movq	%rax, -26704(%rbp)
	movq	%rbx, -26696(%rbp)
	movl	$2374, -26688(%rbp)
	call	_gfortran_st_close@PLT
	movabsq	$8589934592, %rax
	movq	%r14, %rdi
	movq	%rax, -26704(%rbp)
	movq	%rbx, -26696(%rbp)
	movl	$2376, -26688(%rbp)
	call	_gfortran_st_close@PLT
	movabsq	$94489280512, %rax
	movq	%r14, %rdi
	movq	%rax, -26704(%rbp)
	movq	%rbx, -26696(%rbp)
	movl	$2377, -26688(%rbp)
	call	_gfortran_st_close@PLT
	movq	-56(%rbp), %rax
	subq	%fs:40, %rax
	jne	.L4892
	addq	$28096, %rsp
	popq	%rbx
	popq	%r10
	.cfi_remember_state
	.cfi_def_cfa 10, 0
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	leaq	-8(%r10), %rsp
	.cfi_def_cfa 7, 8
	ret
.L4828:
	.cfi_restore_state
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	-27936(%rbp), %rax
	movl	$1044, -16480(%rbp)
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movq	$3, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$47, %edx
	leaq	.LC510(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3842
.L4827:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	-27936(%rbp), %rax
	movl	$1036, -16480(%rbp)
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movq	$3, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$35, %edx
	leaq	.LC509(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3841
.L4274:
	xorl	%eax, %eax
	movl	$1, %edx
	jmp	.L4209
.L4212:
	vxorpd	%xmm7, %xmm7, %xmm7
	vcvtsi2sdl	%r12d, %xmm7, %xmm0
	movq	.LC134(%rip), %rax
	vmovq	%rax, %xmm1
	vdivsd	-26856(%rbp), %xmm0, %xmm0
	vzeroupper
	call	pow@PLT
	vmulsd	.LC72(%rip), %xmm0, %xmm5
	movl	$1, -27764(%rbp)
	vxorpd	.LC11(%rip), %xmm5, %xmm4
	vmovsd	%xmm5, -27656(%rbp)
	vmovsd	%xmm4, -27648(%rbp)
	jmp	.L4211
.L4873:
	leaq	pos_(%rip), %rax
	jmp	.L3897
.L4241:
	movl	-27488(%rbp), %ebx
	jmp	.L3853
.L4889:
	cmpl	$0, 56+wal_(%rip)
	je	.L4893
.L4021:
	cmpl	$0, 36+bas_(%rip)
	jne	.L4894
.L4022:
	movw	$8258, -450(%rbp)
	movl	32+wal_(%rip), %esi
	movl	68+wal_(%rip), %ecx
	jmp	.L4023
.L4242:
	movl	-27488(%rbp), %ebx
	movq	%r15, %r13
	movq	%r14, -27464(%rbp)
	vzeroupper
	jmp	.L3856
.L4821:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC490(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movl	$1015, -16480(%rbp)
	movq	$8, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$21, %edx
	leaq	.LC491(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	leaq	-27244(%rbp), %rsi
	movq	%r15, %rdi
	movl	$4, %edx
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	.LC492(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3833
.L4820:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC488(%rip), %rax
	movq	%rax, -16416(%rbp)
	movq	%rbx, -16496(%rbp)
	movl	$1013, -16480(%rbp)
	movq	$10, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$27, %edx
	leaq	.LC489(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	vmovsd	bas_(%rip), %xmm0
	vmovsd	hhar_(%rip), %xmm1
	vmulsd	%xmm0, %xmm0, %xmm0
	movq	-27752(%rbp), %rbx
	movq	%r15, %rdi
	movq	%rbx, %rsi
	movl	$8, %edx
	vdivsd	%xmm0, %xmm1, %xmm0
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	vmovsd	bas_(%rip), %xmm0
	vmovsd	8+hhar_(%rip), %xmm1
	vmulsd	%xmm0, %xmm0, %xmm0
	movq	%r15, %rdi
	movl	$8, %edx
	movq	%rbx, %rsi
	vmulsd	%xmm0, %xmm0, %xmm0
	vdivsd	%xmm0, %xmm1, %xmm0
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3832
.L4826:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movq	-27936(%rbp), %rax
	movl	$1035, -16480(%rbp)
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movq	$3, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$31, %edx
	leaq	.LC508(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3840
.L4825:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC498(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movl	$1029, -16480(%rbp)
	movq	$8, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$28, %edx
	leaq	.LC507(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	32+plates_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3839
.L4824:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC505(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movl	$1028, -16480(%rbp)
	movq	$9, -16408(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$9, %edx
	leaq	.LC506(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	leaq	-27380(%rbp), %rsi
	movq	%r15, %rdi
	movl	$4, %edx
	call	_gfortran_transfer_integer_write@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	.LC492(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3838
.L4823:
	leaq	.LC500(%rip), %rbx
	movq	-27640(%rbp), %rax
	movq	%rbx, -16416(%rbp)
	movl	$1048577, %ebx
	salq	$12, %rbx
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	movl	$1024, -16480(%rbp)
	movq	$8, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$18, %edx
	leaq	.LC501(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	leaq	-27048(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC502(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1026, -16480(%rbp)
	movq	$10, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$16, %edx
	leaq	.LC503(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	vmovsd	bas_(%rip), %xmm1
	vmovsd	-27472(%rbp), %xmm6
	vmulsd	%xmm1, %xmm1, %xmm0
	movq	-27752(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	vmulsd	%xmm1, %xmm0, %xmm0
	vdivsd	%xmm0, %xmm6, %xmm0
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	movl	$13, %edx
	leaq	.LC504(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3837
.L3830:
	movq	-27936(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16416(%rbp)
	movl	$1007, -16480(%rbp)
	movq	$3, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$43, %edx
	leaq	.LC485(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3831
.L3825:
	leaq	-27284(%rbp), %rsi
	leaq	.LC479(%rip), %rdx
	movq	%r12, %rdi
	call	evalangles_
	cmpl	$0, 80016+chiral_(%rip)
	je	.L3827
.L4213:
	leaq	-27016(%rbp), %rdi
	call	eval_chirality_
	vmovsd	-27024(%rbp), %xmm0
	vaddsd	-27016(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, -27024(%rbp)
.L3827:
	movl	20+bas_(%rip), %edi
	testl	%edi, %edi
	je	.L3829
	leaq	.LC125(%rip), %rsi
	leaq	.LC478(%rip), %rdi
	call	print_map_
	jmp	.L3829
.L3823:
	movq	%r12, %rdi
	call	evalcpot_
	jmp	.L3824
.L4817:
	leaq	-27168(%rbp), %rdi
	call	gopotential_
	jmp	.L3820
.L4652:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$293, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-384(%rbp), %rsi
	movl	$32, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_character@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movl	$1, 20+bas_(%rip)
	jmp	.L3516
.L4894:
	vmovsd	%xmm5, -27568(%rbp)
	vmovsd	%xmm3, -27512(%rbp)
	vmovsd	%xmm1, -27464(%rbp)
	vzeroupper
	call	make_fcc_
	vmovsd	-27568(%rbp), %xmm5
	vmovsd	-27512(%rbp), %xmm3
	vmovsd	-27464(%rbp), %xmm1
	jmp	.L4022
.L4893:
	vmovsd	%xmm5, -27568(%rbp)
	vmovsd	%xmm3, -27512(%rbp)
	vmovsd	%xmm1, -27464(%rbp)
	vzeroupper
	call	connect_to_wal_
	vmovsd	-27568(%rbp), %xmm5
	vmovsd	-27512(%rbp), %xmm3
	vmovsd	-27464(%rbp), %xmm1
	jmp	.L4021
.L4890:
	vzeroupper
	jmp	.L4175
.L4273:
	xorl	%edx, %edx
	movl	$1, %edi
	leaq	fbt.14(%rip), %rsi
	leaq	mtraj.12(%rip), %r9
	leaq	caac.2(%rip), %r11
	jmp	.L4170
.L4886:
	movq	-27640(%rbp), %rax
	leaq	-1(%rcx), %rbx
	movq	%rax, -26264(%rbp)
	leaq	.LC552(%rip), %rax
	movq	%rax, -26192(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%r15, %rdi
	movq	%rcx, -27512(%rbp)
	vmovsd	%xmm4, -28104(%rbp)
	vmovsd	%xmm5, -27944(%rbp)
	vmovsd	%xmm3, -27920(%rbp)
	vmovsd	%xmm1, -27568(%rbp)
	movq	%rax, -26272(%rbp)
	vmovsd	%xmm2, -20512(%rbp,%rbx,8)
	movl	$1717, -26256(%rbp)
	movq	$16, -26184(%rbp)
	call	_gfortran_st_write@PLT
	movl	$1, %edx
	leaq	.LC130(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	testb	$1, -26272(%rbp)
	movl	$1, -27420(%rbp)
	movq	-27512(%rbp), %rcx
	vmovsd	-27568(%rbp), %xmm1
	vmovsd	-27920(%rbp), %xmm3
	vmovsd	-27944(%rbp), %xmm5
	vmovsd	-28104(%rbp), %xmm4
	jne	.L4018
	movq	%rcx, %rax
	salq	$5, %rax
	addq	-27976(%rbp), %rax
	movl	$2, %ecx
	leaq	bas_(%rip), %r8
	movl	%r13d, -28104(%rbp)
	movq	%r14, -28112(%rbp)
	movq	%r12, -28120(%rbp)
	movq	%rbx, %r14
	vmovsd	%xmm1, -27512(%rbp)
	vmovsd	%xmm3, -27568(%rbp)
	vmovsd	%xmm5, -27920(%rbp)
	vmovsd	%xmm4, -27944(%rbp)
	movq	%r8, %r13
	movq	%rcx, %rbx
	movq	%rax, %r12
.L4216:
	vmovsd	0(%r13), %xmm2
	movq	-27752(%rbp), %rsi
	vmulsd	%xmm2, %xmm2, %xmm0
	movl	$8, %edx
	movq	%r15, %rdi
	vmulsd	%xmm2, %xmm0, %xmm2
	vmovsd	-48(%r12,%rbx,8), %xmm0
	vdivsd	%xmm2, %xmm0, %xmm0
	vmovsd	%xmm0, -26704(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movl	%ebx, -27420(%rbp)
	testb	$1, -26272(%rbp)
	jne	.L4600
	incq	%rbx
	cmpq	$6, %rbx
	jne	.L4216
.L4600:
	movq	%r14, %rbx
	vmovsd	-27512(%rbp), %xmm1
	vmovsd	-27568(%rbp), %xmm3
	vmovsd	-27920(%rbp), %xmm5
	vmovsd	-27944(%rbp), %xmm4
	movl	-28104(%rbp), %r13d
	movq	-28112(%rbp), %r14
	movq	-28120(%rbp), %r12
.L4018:
	leaq	-20512(%rbp,%rbx,8), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	vmovsd	%xmm4, -27944(%rbp)
	vmovsd	%xmm5, -27920(%rbp)
	vmovsd	%xmm3, -27568(%rbp)
	vmovsd	%xmm1, -27512(%rbp)
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	-27408(%rbp), %rdi
	leaq	-27424(%rbp), %rsi
	incl	48+kier_(%rip)
	movq	$0x000000000, 8+restart_(%rip)
	call	print_restart_
	incl	28+wal_(%rip)
	movslq	48+kier_(%rip), %rcx
	vmovsd	8+restart_(%rip), %xmm2
	movl	68+wal_(%rip), %edi
	movl	-27408(%rbp), %ebx
	vmovsd	-27512(%rbp), %xmm1
	vmovsd	-27568(%rbp), %xmm3
	vmovsd	-27920(%rbp), %xmm5
	vmovsd	-27944(%rbp), %xmm4
	jmp	.L4016
.L4819:
	movq	%r12, %rdi
	call	evalwall_
	jmp	.L3822
.L4230:
	xorl	%eax, %eax
	vxorpd	%xmm9, %xmm9, %xmm9
	movl	$1, %ecx
	jmp	.L3742
.L4229:
	xorl	%esi, %esi
	vxorpd	%xmm9, %xmm9, %xmm9
	movl	$1, %eax
	jmp	.L3735
.L4645:
	vzeroupper
	jmp	.L3732
.L4227:
	vmovsd	%xmm0, %xmm0, %xmm6
	vmovsd	%xmm1, %xmm1, %xmm5
	vmovsd	%xmm2, %xmm2, %xmm4
	jmp	.L3729
.L4644:
	vzeroupper
	jmp	.L3727
.L4226:
	movl	$1, %eax
	leaq	mass_(%rip), %rdx
	jmp	.L3725
.L4225:
	xorl	%edx, %edx
	movl	$1, %eax
	jmp	.L3707
.L4651:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$291, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$64, %edx
	leaq	24+restart_(%rip), %rsi
	call	_gfortran_transfer_character@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4653:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$296, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	-27776(%rbp), %rsi
	movq	%r15, %rdi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L3769:
	movq	-27640(%rbp), %rax
	movq	%r15, %rdi
	movq	%rax, -16488(%rbp)
	leaq	.LC460(%rip), %rax
	movq	%rax, -16416(%rbp)
	movl	$1048577, %eax
	salq	$12, %rax
	movq	%rax, -16496(%rbp)
	movl	$863, -16480(%rbp)
	movq	$8, -16408(%rbp)
	movl	$1, 80036+misc_(%rip)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$33, %edx
	leaq	.LC461(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	32+sig_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3771
.L4815:
	movq	%r15, %rdi
	movq	%r13, -16488(%rbp)
	movl	$855, -16480(%rbp)
	movq	%r12, -16416(%rbp)
	movq	$3, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movl	$45, %edx
	leaq	.LC453(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	leaq	.LC454(%rip), %rax
	movq	%r15, %rdi
	movq	%rax, -16416(%rbp)
	movq	%r13, -16488(%rbp)
	movl	$856, -16480(%rbp)
	movq	$15, -16408(%rbp)
	movq	%rbx, -16496(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$6, %edx
	leaq	.LC455(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	80024+ssb_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	movl	$7, %edx
	leaq	.LC456(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	ssb2_(%rip), %rsi
	call	_gfortran_transfer_real_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3768
.L4233:
	leal	-1(%rbx), %eax
	movl	$1, -27764(%rbp)
	movl	%eax, -27464(%rbp)
	jmp	.L3788
.L4232:
	xorl	%r9d, %r9d
	jmp	.L3778
.L4806:
	vzeroupper
	jmp	.L3744
.L4238:
	vxorpd	%xmm0, %xmm0, %xmm0
	jmp	.L3804
.L4892:
	call	__stack_chk_fail@PLT
.L4813:
	vzeroupper
	jmp	.L3792
.L4235:
	movl	$1, %eax
	jmp	.L3797
.L4816:
	vzeroupper
	jmp	.L3799
.L4234:
	movl	$1, %eax
	jmp	.L3790
.L4656:
	leaq	-183(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$302, -16480(%rbp)
	movq	$119, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27348(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4228:
	vmovsd	%xmm0, %xmm0, %xmm5
	vmovsd	%xmm1, %xmm1, %xmm4
	vmovsd	%xmm2, %xmm2, %xmm3
	movl	$2, %edx
	jmp	.L3730
.L4818:
	leaq	.LC125(%rip), %rsi
	leaq	.LC478(%rip), %rdi
	call	print_cmap_
	movq	-27752(%rbp), %r14
	movq	-27640(%rbp), %rbx
	movl	$1, %eax
	salq	$32, %rax
	movq	%r14, %rdi
	movq	%rax, -26704(%rbp)
	movq	%rbx, -26696(%rbp)
	movl	$980, -26688(%rbp)
	call	_gfortran_st_close@PLT
	movl	$1, %eax
	salq	$33, %rax
	movq	%r14, %rdi
	movq	%rax, -26704(%rbp)
	movq	%rbx, -26696(%rbp)
	movl	$981, -26688(%rbp)
	call	_gfortran_st_close@PLT
	movl	$11, %eax
	salq	$33, %rax
	movq	%r14, %rdi
	movq	%rbx, -26696(%rbp)
	movl	$982, -26688(%rbp)
	movq	%rax, -26704(%rbp)
	call	_gfortran_st_close@PLT
	xorl	%edx, %edx
	xorl	%esi, %esi
	xorl	%edi, %edi
	call	_gfortran_stop_string@PLT
.L4655:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$300, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	64+hhar_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4654:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$298, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27032(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L3689:
	movl	$201326593, %eax
	salq	$7, %rax
	movq	%r15, %rdi
	movq	%rax, -16496(%rbp)
	movl	$617, -16480(%rbp)
	call	_gfortran_st_write@PLT
	movq	%r15, %rdi
	movl	$21, %edx
	leaq	.LC424(%rip), %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	movl	$128, %edx
	movq	%r13, %rsi
	call	_gfortran_transfer_character_write@PLT
	movq	%r15, %rdi
	call	_gfortran_st_write_done@PLT
	jmp	.L3516
.L4805:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$609, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	152+restart_(%rip), %rsi
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4804:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$607, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-26792(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4803:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$605, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-26784(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4802:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$603, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-26832(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4801:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$600, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-26824(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movl	$1, -27948(%rbp)
	jmp	.L3516
.L4800:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$597, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-26792(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	vmovsd	-26792(%rbp), %xmm0
	vmovsd	%xmm0, -26832(%rbp)
	jmp	.L3516
.L4799:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$595, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	56+sig_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4798:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$592, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movl	$8, %edx
	leaq	40+sig_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	vmovsd	40+sig_(%rip), %xmm0
	vmovsd	%xmm0, 48+sig_(%rip)
	jmp	.L3516
.L4797:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$590, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	32+sig_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4796:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$588, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	24+sig_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4795:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$586, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	32+pid_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4794:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$584, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	24+pid_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4793:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$582, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	56+pid_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4792:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$580, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	48+pid_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4791:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$578, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	40+pid_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4790:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$576, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	16+pid_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4789:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$574, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	8+pid_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4788:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$572, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	pid_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4787:
	leaq	-189(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$570, -16480(%rbp)
	movq	$125, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	7924008+sig_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4786:
	leaq	-189(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$568, -16480(%rbp)
	movq	$125, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27192(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4785:
	leaq	-189(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$566, -16480(%rbp)
	movq	$125, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	hhar_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4784:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$564, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80024+neigh_(%rip), %rsi
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4783:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$562, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80020+neigh_(%rip), %rsi
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4782:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$560, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	80000+neigh_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4781:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$558, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	240024+pull_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4780:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$556, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	7924016+sig_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4779:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$554, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27040(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4778:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$552, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	bon_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4777:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$550, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	120008+respul_(%rip), %rsi
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4776:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$548, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	16+bas_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4775:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$546, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80032+misc_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4774:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$544, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27248(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4773:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$542, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27228(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4772:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$540, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27432(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4771:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$537, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-26912(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	vmovsd	-26776(%rbp), %xmm0
	vdivsd	-26912(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, -26928(%rbp)
	jmp	.L3516
.L4770:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$534, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-26928(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	vmovsd	-26776(%rbp), %xmm0
	vdivsd	-26928(%rbp), %xmm0, %xmm0
	vmovsd	%xmm0, -26912(%rbp)
	jmp	.L3516
.L4769:
	leaq	-181(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$532, -16480(%rbp)
	movq	$117, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27404(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4768:
	leaq	-182(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$530, -16480(%rbp)
	movq	$118, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27312(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4767:
	leaq	-183(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$527, -16480(%rbp)
	movq	$119, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-320(%rbp), %rsi
	movl	$32, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_character@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movl	$1, -27308(%rbp)
	jmp	.L3516
.L4766:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$525, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	32+kier_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4765:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$523, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	64+wal_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4764:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$521, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	60+wal_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4763:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$519, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-26848(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4762:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$517, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27376(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4761:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$515, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	4+equil_(%rip), %rsi
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4760:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$513, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27400(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4759:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$511, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27388(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4758:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$509, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	equil_(%rip), %rsi
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4757:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$507, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27396(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4756:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$505, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-26856(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4755:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$503, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-26840(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4754:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$501, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	68+wal_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4753:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$499, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27280(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4752:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$497, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	leaq	cmap_(%rip), %rax
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	66000008(%rax), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4751:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$495, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	24+ssb2_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4750:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$493, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80036+ssb_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4749:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$491, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27308(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4748:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$489, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80032+ssb_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4747:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$487, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80032+ssb_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4746:
	leaq	-182(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$485, -16480(%rbp)
	movq	$118, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27288(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4745:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$483, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27316(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4744:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$481, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27340(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4743:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$479, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27272(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4742:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$477, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80016+neigh_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4741:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$475, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27320(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4740:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$473, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27120(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4739:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$471, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80028+misc_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4738:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$469, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80016+chiral_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4737:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$467, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80020+chiral_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4736:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$465, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27328(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4735:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$463, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27264(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4734:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$461, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	80000+misc_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4733:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$459, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	32+plates_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4732:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$457, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	-27472(%rbp), %rsi
	movq	%r15, %rdi
	movl	$4, %edx
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4731:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$455, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	56+hhar_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4730:
	leaq	-189(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$453, -16480(%rbp)
	movq	$125, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	10004076+nmapi_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4729:
	leaq	-189(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$451, -16480(%rbp)
	movq	$125, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	16+ang_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4728:
	leaq	-189(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$449, -16480(%rbp)
	movq	$125, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	8+ang_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4727:
	leaq	-189(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$447, -16480(%rbp)
	movq	$125, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	ang_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4726:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$445, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	2592152+mr_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4725:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$443, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27324(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4724:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$441, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80024+chiral_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4723:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$439, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	102432+ang_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4722:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$437, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	32+bas_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4721:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$435, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	160008+bon_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4720:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$433, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27304(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4719:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$431, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	10004068+nmapi_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4718:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$429, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80036+misc_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4717:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$427, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	52+wal_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4716:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$425, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	44+kier_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4715:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$423, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	40+kier_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4714:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$421, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	36+kier_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4713:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$419, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	12+bas_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4712:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$417, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	cmapi_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4711:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$415, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27048(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4710:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$413, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	32+hhar_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4709:
	leaq	-183(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$411, -16480(%rbp)
	movq	$119, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27184(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4708:
	leaq	-183(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$409, -16480(%rbp)
	movq	$119, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27360(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4707:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$407, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27372(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4706:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$405, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	240000+angtemp_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4705:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$403, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	200004+angnat_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4704:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$401, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	200000+angnat_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4703:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$399, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27292(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4702:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$397, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27152(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4701:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$395, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	8+restr_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4700:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$393, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	16+restr_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4699:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$391, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-26864(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4698:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$389, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27144(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4697:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$387, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	restr_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4696:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$385, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	48+hhar_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4695:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$383, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	32+restr_(%rip), %rsi
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4694:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$381, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	28+ssb2_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4693:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$379, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27300(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4692:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$376, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-27444(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer@PLT
	leaq	-27416(%rbp), %rsi
	movl	$4, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_integer@PLT
	leaq	-27160(%rbp), %rsi
	movl	$8, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movl	$1, -27964(%rbp)
	jmp	.L3516
.L4691:
	leaq	-180(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$374, -16480(%rbp)
	movq	$116, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	16+equil_(%rip), %rsi
	call	_gfortran_transfer_integer@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4690:
	leaq	-182(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$372, -16480(%rbp)
	movq	$118, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27368(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4689:
	leaq	-182(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$370, -16480(%rbp)
	movq	$118, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27336(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4688:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$368, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27268(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4687:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$366, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27260(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4686:
	leaq	-181(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$364, -16480(%rbp)
	movq	$117, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27260(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4685:
	leaq	-180(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$362, -16480(%rbp)
	movq	$116, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27336(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4684:
	leaq	-181(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$360, -16480(%rbp)
	movq	$117, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	wal_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4683:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$358, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27296(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4682:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$355, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movl	$4, %edx
	leaq	36+restr_(%rip), %rsi
	movq	%r15, %rdi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movq	.LC341(%rip), %rax
	movq	%rax, 56+hhar_(%rip)
	jmp	.L3516
.L4681:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$353, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27344(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4680:
	leaq	-185(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$351, -16480(%rbp)
	movq	$121, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	80028+chiral_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4679:
	leaq	-183(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$349, -16480(%rbp)
	movq	$119, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27256(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4678:
	leaq	-183(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$347, -16480(%rbp)
	movq	$119, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	20+bas_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4677:
	leaq	-183(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$345, -16480(%rbp)
	movq	$119, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27356(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4676:
	leaq	-183(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$343, -16480(%rbp)
	movq	$119, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	40+hhar_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4675:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$340, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	leaq	-416(%rbp), %rsi
	movl	$32, %edx
	movq	%r15, %rdi
	call	_gfortran_transfer_character@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	movl	$1, -27352(%rbp)
	jmp	.L3516
.L4674:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$338, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-26944(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4673:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$336, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27000(%rbp), %rsi
	movl	$8, %edx
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4672:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$334, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	ssb2_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4671:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$332, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$8, %edx
	leaq	80000+ssb_(%rip), %rsi
	call	_gfortran_transfer_real@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4670:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$330, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	32+ssb2_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4669:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$328, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	56+wal_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4668:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$326, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27364(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4667:
	leaq	-186(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$324, -16480(%rbp)
	movq	$122, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	24+bas_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4666:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$322, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27292(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4665:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$320, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	88+pid_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4664:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$318, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	160004+bon_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4663:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$316, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	36+bas_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4662:
	leaq	-188(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$314, -16480(%rbp)
	movq	$124, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	10004072+nmapi_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4661:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$312, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	movl	$4, %edx
	leaq	28+bas_(%rip), %rsi
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4660:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$310, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27352(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4659:
	leaq	-187(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$308, -16480(%rbp)
	movq	$123, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27284(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4658:
	leaq	-184(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$306, -16480(%rbp)
	movq	$120, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27284(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
.L4657:
	leaq	-183(%rbp), %rax
	movq	%rax, -16384(%rbp)
	movq	%r15, %rdi
	movabsq	$-4294950784, %rax
	movq	%rax, -16496(%rbp)
	movq	%rbx, -16488(%rbp)
	movl	$304, -16480(%rbp)
	movq	$119, -16376(%rbp)
	movq	$0, -16424(%rbp)
	call	_gfortran_st_read@PLT
	movq	%r15, %rdi
	leaq	-27276(%rbp), %rsi
	movl	$4, %edx
	call	_gfortran_transfer_logical@PLT
	movq	%r15, %rdi
	call	_gfortran_st_read_done@PLT
	jmp	.L3516
	.cfi_endproc
	.section	.text.unlikely
	.cfi_startproc
	.type	MAIN__.cold, @function
MAIN__.cold:
.LFSB55:
.L4896:
	.cfi_escape 0xf,0x3,0x76,0x58,0x6
	.cfi_escape 0x10,0x3,0x2,0x76,0x50
	.cfi_escape 0x10,0x6,0x2,0x76,0
	.cfi_escape 0x10,0xc,0x2,0x76,0x60
	.cfi_escape 0x10,0xd,0x2,0x76,0x68
	.cfi_escape 0x10,0xe,0x2,0x76,0x70
	.cfi_escape 0x10,0xf,0x2,0x76,0x78
	movl	%ecx, %esi
	subl	%edx, %esi
	cmpl	$2, %esi
	jle	.L3785
.L4277:
	movslq	%r9d, %rsi
	leaq	(%rsi,%rsi,2), %rsi
	leaq	cmap_(%rip), %rbx
	movl	%edx, 60000008(%rbx,%rsi,4)
	movl	%ecx, 60000012(%rbx,%rsi,4)
	incl	%r9d
	movl	60000004(%rax), %edi
	movl	%edi, 60000016(%rbx,%rsi,4)
.L3785:
	incl	%r13d
	addq	$12, %rax
	cmpl	%r10d, %r13d
	jg	.L4895
.L3787:
	movslq	59999996(%rax), %rsi
	movl	60000000(%rax), %ecx
	movq	%rsi, %rdx
	testb	$1, 79996(%r11,%rsi,4)
	jne	.L4896
	jmp	.L4277
.L4895:
	movl	%edx, -27452(%rbp)
	movl	%ecx, -27420(%rbp)
	jmp	.L3778
	.cfi_endproc
.LFE55:
	.text
	.size	MAIN__, .-MAIN__
	.section	.text.unlikely
	.size	MAIN__.cold, .-MAIN__.cold
.LCOLDE598:
	.text
.LHOTE598:
	.section	.text.startup,"ax",@progbits
	.p2align 4
	.globl	main
	.type	main, @function
main:
.LFB56:
	.cfi_startproc
	subq	$8, %rsp
	.cfi_def_cfa_offset 16
	call	_gfortran_set_args@PLT
	leaq	options.594.15(%rip), %rsi
	movl	$7, %edi
	call	_gfortran_set_options@PLT
	call	MAIN__
	xorl	%eax, %eax
	addq	$8, %rsp
	.cfi_def_cfa_offset 8
	ret
	.cfi_endproc
.LFE56:
	.size	main, .-main
	.text
	.p2align 4
	.globl	compute_ssbonds_
	.type	compute_ssbonds_, @function
compute_ssbonds_:
.LFB57:
	.cfi_startproc
	pushq	%r14
	.cfi_def_cfa_offset 16
	.cfi_offset 14, -16
	pushq	%r13
	.cfi_def_cfa_offset 24
	.cfi_offset 13, -24
	pushq	%r12
	.cfi_def_cfa_offset 32
	.cfi_offset 12, -32
	pushq	%rbp
	.cfi_def_cfa_offset 40
	.cfi_offset 6, -40
	pushq	%rbx
	.cfi_def_cfa_offset 48
	.cfi_offset 3, -48
	subq	$40032, %rsp
	.cfi_def_cfa_offset 40080
	movslq	8+bas_(%rip), %rdx
	movq	%fs:40, %rax
	movq	%rax, 40024(%rsp)
	xorl	%eax, %eax
	testl	%edx, %edx
	jle	.L4903
	leaq	0(,%rdx,4), %r12
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	ssb_(%rip), %rdi
	call	memset@PLT
	movq	%r12, %rdx
	xorl	%esi, %esi
	leaq	40000+ssb_(%rip), %rdi
	call	memset@PLT
.L4903:
	movl	cmap_(%rip), %edi
	movl	$0, 12(%rsp)
	testl	%edi, %edi
	jle	.L4899
	vmovsd	.LC87(%rip), %xmm5
	vmovsd	7924024+sig_(%rip), %xmm4
	vmulsd	80024+ssb_(%rip), %xmm5, %xmm5
	leaq	4+cmap_(%rip), %rdx
	incl	%edi
	xorl	%r8d, %r8d
	movl	$1, %esi
	leaq	pos_(%rip), %rax
	leaq	rsortssbond.0(%rip), %r9
	jmp	.L4906
	.p2align 4,,10
	.p2align 3
.L4904:
	incl	%esi
	addq	$12, %rdx
	cmpl	%esi, %edi
	je	.L4918
.L4906:
	movslq	(%rdx), %r10
	movslq	4(%rdx), %rcx
	vmovsd	79992(%rax,%r10,8), %xmm3
	vmovsd	-8(%rax,%r10,8), %xmm2
	vsubsd	79992(%rax,%rcx,8), %xmm3, %xmm3
	vsubsd	-8(%rax,%rcx,8), %xmm2, %xmm2
	vmovsd	159992(%rax,%r10,8), %xmm0
	vmulsd	%xmm3, %xmm3, %xmm3
	vsubsd	159992(%rax,%rcx,8), %xmm0, %xmm0
	vfmadd132sd	%xmm2, %xmm3, %xmm2
	vfmadd132sd	%xmm0, %xmm2, %xmm0
	vcomisd	%xmm4, %xmm0
	ja	.L4904
	cmpl	$-1, 8(%rdx)
	jne	.L4904
	vsqrtsd	%xmm0, %xmm0, %xmm0
	vcomisd	%xmm0, %xmm5
	jb	.L4904
	movslq	%r8d, %rcx
	movl	%esi, 16(%rsp,%rcx,4)
	incl	%esi
	vmovsd	%xmm0, (%r9,%rcx,8)
	incl	%r8d
	addq	$12, %rdx
	cmpl	%esi, %edi
	jne	.L4906
	.p2align 4,,10
	.p2align 3
.L4918:
	movl	%r8d, 12(%rsp)
	cmpl	$1, %r8d
	jg	.L4919
.L4907:
	testl	%r8d, %r8d
	jle	.L4899
	leal	-1(%r8), %edx
	movl	2000016+cmapi_(%rip), %r12d
	movl	2000024+cmapi_(%rip), %ebp
	leaq	16(%rsp), %rax
	leaq	20(%rsp,%rdx,4), %rbx
	leaq	cmap_(%rip), %r8
	leaq	ssb_(%rip), %rsi
	jmp	.L4910
	.p2align 4,,10
	.p2align 3
.L4921:
	incl	%ebp
	.p2align 4,,10
	.p2align 3
.L4908:
	addq	$4, %rax
	cmpq	%rax, %rbx
	je	.L4920
.L4910:
	movslq	(%rax), %rdx
	leaq	-3(%rdx,%rdx,2), %rcx
	movslq	4(%r8,%rcx,4), %rdx
	movl	39996(%rsi,%rdx,4), %r10d
	movq	%rdx, %rdi
	leaq	-1(%rdx), %r9
	leaq	9999(%rdx), %r11
	testl	%r10d, %r10d
	jne	.L4908
	movslq	8(%r8,%rcx,4), %rdx
	movq	%rdx, %r10
	leaq	-1(%rdx), %r13
	leaq	9999(%rdx), %r14
	movl	39996(%rsi,%rdx,4), %edx
	testl	%edx, %edx
	jne	.L4908
	movl	$1, (%rsi,%r11,4)
	movl	%r10d, (%rsi,%r9,4)
	movl	$1, (%rsi,%r14,4)
	movl	%edi, (%rsi,%r13,4)
	testb	$1, 12(%r8,%rcx,4)
	je	.L4921
	addq	$4, %rax
	incl	%r12d
	cmpq	%rax, %rbx
	jne	.L4910
	.p2align 4,,10
	.p2align 3
.L4920:
	movl	%ebp, 2000024+cmapi_(%rip)
	movl	%r12d, 2000016+cmapi_(%rip)
.L4899:
	movq	40024(%rsp), %rax
	subq	%fs:40, %rax
	jne	.L4922
	addq	$40032, %rsp
	.cfi_remember_state
	.cfi_def_cfa_offset 48
	popq	%rbx
	.cfi_def_cfa_offset 40
	popq	%rbp
	.cfi_def_cfa_offset 32
	popq	%r12
	.cfi_def_cfa_offset 24
	popq	%r13
	.cfi_def_cfa_offset 16
	popq	%r14
	.cfi_def_cfa_offset 8
	ret
	.p2align 4,,10
	.p2align 3
.L4919:
	.cfi_restore_state
	leaq	16(%rsp), %rdx
	leaq	12(%rsp), %rdi
	leaq	rsortssbond.0(%rip), %rsi
	call	sort2_
	movl	12(%rsp), %r8d
	jmp	.L4907
.L4922:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE57:
	.size	compute_ssbonds_, .-compute_ssbonds_
	.p2align 4
	.globl	angeval_
	.type	angeval_, @function
angeval_:
.LFB58:
	.cfi_startproc
	leaq	8(%rsp), %r10
	.cfi_def_cfa 10, 0
	andq	$-32, %rsp
	pushq	-8(%r10)
	pushq	%rbp
	.cfi_escape 0x10,0x6,0x2,0x76,0
	movq	%rsp, %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%r10
	.cfi_escape 0xf,0x3,0x76,0x58,0x6
	.cfi_escape 0x10,0xf,0x2,0x76,0x78
	.cfi_escape 0x10,0xe,0x2,0x76,0x70
	.cfi_escape 0x10,0xd,0x2,0x76,0x68
	.cfi_escape 0x10,0xc,0x2,0x76,0x60
	pushq	%rbx
	subq	$192, %rsp
	.cfi_escape 0x10,0x3,0x2,0x76,0x50
	movq	%rdi, -200(%rbp)
	movq	%fs:40, %rax
	movq	%rax, -56(%rbp)
	xorl	%eax, %eax
	movslq	8+bas_(%rip), %rax
	cmpl	$2, %eax
	jle	.L4923
	leaq	8+angnat_(%rip), %rsi
	leaq	159992(%rsi), %r14
	leaq	80000+for_(%rip), %rbx
	leaq	pos_(%rip), %r15
	movl	$2, %r13d
	movq	%r14, %rcx
	movq	%rax, -104(%rbp)
	movq	%r15, %r14
	movq	%r13, %rax
	movq	%rbx, %r15
	leaq	79992+bon_(%rip), %r12
	movq	%rsi, %r13
	movq	%rcx, %rbx
	jmp	.L4945
	.p2align 4,,10
	.p2align 3
.L4925:
	incq	%rax
	addq	$8, %r13
	addq	$4, %rbx
	addq	$8, %r15
	addq	$8, %r14
	cmpq	%rax, -104(%rbp)
	je	.L4971
.L4945:
	movl	(%r12,%rax,4), %ecx
	testl	%ecx, %ecx
	je	.L4925
	leaq	79996+bon_(%rip), %rdi
	movl	(%rdi,%rax,4), %edx
	testl	%edx, %edx
	je	.L4925
	vmovsd	(%r14), %xmm0
	movq	%rax, -120(%rbp)
	vmovsd	%xmm0, four_(%rip)
	vmovsd	80000(%r14), %xmm0
	leaq	-64(%rbp), %rax
	vmovsd	%xmm0, 32+four_(%rip)
	vmovsd	160000(%r14), %xmm0
	movq	%rax, %rdi
	vmovsd	%xmm0, 64+four_(%rip)
	vmovsd	8(%r14), %xmm0
	movq	%rax, -112(%rbp)
	vmovsd	%xmm0, 8+four_(%rip)
	vmovsd	80008(%r14), %xmm0
	vmovsd	%xmm0, 40+four_(%rip)
	vmovsd	160008(%r14), %xmm0
	vmovsd	%xmm0, 72+four_(%rip)
	vmovsd	16(%r14), %xmm0
	vmovsd	%xmm0, 16+four_(%rip)
	vmovsd	80016(%r14), %xmm0
	vmovsd	%xmm0, 48+four_(%rip)
	vmovsd	160016(%r14), %xmm0
	vmovsd	%xmm0, 80+four_(%rip)
	call	bondangle_
	vmovsd	-64(%rbp), %xmm0
	movq	-120(%rbp), %rax
	movl	80020+chiral_(%rip), %r11d
	leaq	-8+angtemp_(%rip), %rdi
	vmovsd	%xmm0, (%rdi,%rax,8)
	testl	%r11d, %r11d
	je	.L4925
	movl	(%rbx), %r10d
	testl	%r10d, %r10d
	jne	.L4972
.L4926:
	vmovdqa	.LC101(%rip), %xmm1
	leaq	39996+sequence_(%rip), %rdi
	vmovd	(%rdi,%rax,4), %xmm2
	addq	$4, %rdi
	vpminsd	%xmm1, %xmm2, %xmm2
	vmovdqa	%xmm1, %xmm3
	vmovd	(%rdi,%rax,4), %xmm1
	vpminsd	%xmm3, %xmm1, %xmm1
	vmovd	%xmm1, %esi
	vmovd	%xmm2, %ecx
	movslq	%esi, %r10
	vmovd	%xmm1, -240(%rbp)
	leaq	(%r10,%r10,4), %rdi
	vmulsd	%xmm0, %xmm0, %xmm1
	movslq	%ecx, %r11
	leaq	(%r11,%rdi,4), %rdi
	salq	$4, %rdi
	leaq	ang_(%rip), %r9
	vmovd	%xmm2, -236(%rbp)
	vmovsd	-2624(%r9,%rdi,8), %xmm2
	vmulsd	%xmm1, %xmm0, %xmm3
	vfmadd213sd	-2640(%r9,%rdi,8), %xmm1, %xmm2
	vmulsd	%xmm2, %xmm1, %xmm2
	vfmadd132sd	-2648(%r9,%rdi,8), %xmm2, %xmm0
	vmulsd	-2608(%r9,%rdi,8), %xmm3, %xmm2
	vfmadd132sd	-2616(%r9,%rdi,8), %xmm2, %xmm1
	vaddsd	-2632(%r9,%rdi,8), %xmm1, %xmm1
	vfmadd132sd	%xmm1, %xmm0, %xmm3
	vmovsd	%xmm3, -120(%rbp)
	vmovsd	%xmm3, %xmm3, %xmm5
.L4927:
	movq	-200(%rbp), %rsi
	leaq	(%r10,%r10,4), %rdi
	vaddsd	(%rsi), %xmm5, %xmm0
	leaq	(%r11,%rdi,4), %rdi
	salq	$4, %rdi
	vmovsd	%xmm0, (%rsi)
	leaq	-335(%rdi), %rsi
	leaq	-333(%rdi), %rcx
	movq	%rsi, -144(%rbp)
	leaq	-334(%rdi), %rsi
	movq	%rsi, -152(%rbp)
	movq	%rcx, -160(%rbp)
	leaq	-332(%rdi), %rdx
	leaq	-331(%rdi), %rsi
	leaq	-330(%rdi), %rcx
	movq	%rdx, -168(%rbp)
	movq	%rsi, -176(%rbp)
	movq	%rcx, -184(%rbp)
	movq	%rax, -232(%rbp)
	leaq	four_(%rip), %r10
	vmovsd	24+ang_(%rip), %xmm0
	movq	%r14, -216(%rbp)
	movq	%r15, -224(%rbp)
	movq	%r13, -208(%rbp)
	movq	%r15, %r14
	movq	%r9, %r13
	movq	%r10, %r15
.L4944:
	vmovsd	(%r15), %xmm3
	vmovsd	32(%r15), %xmm5
	vaddsd	%xmm0, %xmm3, %xmm0
	vmovsd	64(%r15), %xmm6
	movq	-112(%rbp), %rdi
	vmovsd	%xmm0, (%r15)
	vmovsd	%xmm3, -192(%rbp)
	vmovsd	%xmm5, -128(%rbp)
	vmovsd	%xmm6, -136(%rbp)
	call	bondangle_
	movl	(%rbx), %r8d
	vmovsd	-64(%rbp), %xmm1
	testl	%r8d, %r8d
	vmovsd	-192(%rbp), %xmm3
	je	.L4929
	movl	8(%rbx), %edi
	testl	%edi, %edi
	je	.L4929
	movq	-208(%rbp), %rax
	vsubsd	(%rax), %xmm1, %xmm0
	vmovsd	%xmm0, -64(%rbp)
	vmulsd	%xmm0, %xmm0, %xmm0
	vmulsd	0(%r13), %xmm0, %xmm0
.L4930:
	vsubsd	-120(%rbp), %xmm0, %xmm0
	vmovsd	24+ang_(%rip), %xmm1
	vmovsd	.LC82(%rip), %xmm5
	vdivsd	%xmm1, %xmm0, %xmm0
	vaddsd	-128(%rbp), %xmm1, %xmm1
	movq	-112(%rbp), %rdi
	vmovsd	%xmm3, (%r15)
	vmovsd	%xmm1, 32(%r15)
	vandpd	.LC69(%rip), %xmm0, %xmm2
	vmovsd	%xmm0, %xmm0, %xmm4
	vandpd	.LC11(%rip), %xmm0, %xmm0
	vcmpltsd	%xmm2, %xmm5, %xmm2
	vorpd	.LC599(%rip), %xmm0, %xmm0
	vblendvpd	%xmm2, %xmm0, %xmm4, %xmm0
	vmovsd	-80000(%r14), %xmm2
	vsubsd	%xmm0, %xmm2, %xmm0
	vmovsd	%xmm0, -80000(%r14)
	call	bondangle_
	movl	(%rbx), %esi
	vmovsd	-64(%rbp), %xmm1
	testl	%esi, %esi
	je	.L4934
	movl	8(%rbx), %ecx
	testl	%ecx, %ecx
	je	.L4934
	movq	-208(%rbp), %rax
	vsubsd	(%rax), %xmm1, %xmm0
	vmovsd	%xmm0, -64(%rbp)
	vmulsd	%xmm0, %xmm0, %xmm0
	vmulsd	0(%r13), %xmm0, %xmm0
.L4935:
	vsubsd	-120(%rbp), %xmm0, %xmm0
	vmovsd	24+ang_(%rip), %xmm1
	vmovsd	.LC82(%rip), %xmm5
	vdivsd	%xmm1, %xmm0, %xmm0
	vaddsd	-136(%rbp), %xmm1, %xmm1
	vmovsd	-128(%rbp), %xmm6
	movq	-112(%rbp), %rdi
	vmovsd	%xmm1, 64(%r15)
	vmovsd	%xmm6, 32(%r15)
	vandpd	.LC69(%rip), %xmm0, %xmm2
	vmovsd	%xmm0, %xmm0, %xmm3
	vandpd	.LC11(%rip), %xmm0, %xmm0
	vcmpltsd	%xmm2, %xmm5, %xmm2
	vorpd	.LC599(%rip), %xmm0, %xmm0
	vblendvpd	%xmm2, %xmm0, %xmm3, %xmm0
	vmovsd	(%r14), %xmm2
	vsubsd	%xmm0, %xmm2, %xmm0
	vmovsd	%xmm0, (%r14)
	call	bondangle_
	movl	(%rbx), %edx
	vmovsd	-64(%rbp), %xmm1
	testl	%edx, %edx
	je	.L4939
	movl	8(%rbx), %eax
	testl	%eax, %eax
	je	.L4939
	movq	-208(%rbp), %rax
	vsubsd	(%rax), %xmm1, %xmm1
	vmovsd	%xmm1, -64(%rbp)
	vmulsd	%xmm1, %xmm1, %xmm1
	vmulsd	0(%r13), %xmm1, %xmm1
.L4940:
	vsubsd	-120(%rbp), %xmm1, %xmm1
	vmovsd	24+ang_(%rip), %xmm0
	vdivsd	%xmm0, %xmm1, %xmm1
	vandpd	.LC69(%rip), %xmm1, %xmm2
	vcomisd	.LC82(%rip), %xmm2
	jbe	.L4967
	vandpd	.LC11(%rip), %xmm1, %xmm1
	vmovsd	80000(%r14), %xmm2
	vorpd	.LC599(%rip), %xmm1, %xmm1
	vmovsd	-136(%rbp), %xmm4
	vsubsd	%xmm1, %xmm2, %xmm1
	vmovsd	%xmm4, 64(%r15)
	leaq	24+four_(%rip), %rax
	addq	$8, %r15
	vmovsd	%xmm1, 80000(%r14)
	addq	$8, %r14
	cmpq	%rax, %r15
	jne	.L4944
.L4970:
	movq	-216(%rbp), %r14
	movq	-224(%rbp), %r15
	movq	-208(%rbp), %r13
	movq	-232(%rbp), %rax
	jmp	.L4925
	.p2align 4,,10
	.p2align 3
.L4971:
	movl	8+bas_(%rip), %r10d
	cmpl	$3, %r10d
	jle	.L4923
	leaq	80016+angnat_(%rip), %r14
	leaq	79984(%r14), %rbx
	leaq	pos_(%rip), %r13
	movslq	%r10d, %r12
	movl	$3, %r15d
	movq	%r14, %rsi
	leaq	80000+bon_(%rip), %rax
	movq	%r12, %r14
	movq	%r15, %rdx
	movq	%rsi, %r12
	movq	%r13, %r15
	movq	%rbx, %r13
	movq	%rax, %rbx
	.p2align 4,,10
	.p2align 3
.L4960:
	movl	(%rbx), %eax
	testl	%eax, %eax
	je	.L4947
	movl	4(%rbx), %eax
	testl	%eax, %eax
	je	.L4947
	movl	8(%rbx), %eax
	testl	%eax, %eax
	jne	.L4973
	.p2align 4,,10
	.p2align 3
.L4947:
	incq	%rdx
	addq	$4, %rbx
	addq	$8, %r12
	addq	$4, %r13
	addq	$8, %r15
	cmpq	%rdx, %r14
	jne	.L4960
.L4923:
	movq	-56(%rbp), %rax
	subq	%fs:40, %rax
	jne	.L4974
	addq	$192, %rsp
	popq	%rbx
	popq	%r10
	.cfi_remember_state
	.cfi_def_cfa 10, 0
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	leaq	-8(%r10), %rsp
	.cfi_def_cfa 7, 8
	ret
	.p2align 4,,10
	.p2align 3
.L4973:
	.cfi_restore_state
	vmovsd	160016(%r15), %xmm0
	leaq	-72(%rbp), %rax
	vmovhpd	160024(%r15), %xmm0, %xmm1
	vmovupd	160000(%r15), %xmm0
	movq	%rax, %rdi
	vinsertf128	$0x1, %xmm1, %ymm0, %ymm0
	vmovsd	80016(%r15), %xmm1
	movq	%rdx, -104(%rbp)
	vmovhpd	80024(%r15), %xmm1, %xmm2
	vmovupd	80000(%r15), %xmm1
	movq	%rax, -112(%rbp)
	vinsertf128	$0x1, %xmm2, %ymm1, %ymm1
	vmovsd	16(%r15), %xmm2
	vmovapd	%ymm1, 32+four_(%rip)
	vmovhpd	24(%r15), %xmm2, %xmm3
	vmovupd	(%r15), %xmm2
	vmovapd	%ymm0, 64+four_(%rip)
	vinsertf128	$0x1, %xmm3, %ymm2, %ymm2
	vmovapd	%ymm2, four_(%rip)
	vzeroupper
	call	dihedral_
	vmovsd	-72(%rbp), %xmm0
	movq	-104(%rbp), %rdx
	leaq	79992+angtemp_(%rip), %rax
	vmovsd	%xmm0, (%rax,%rdx,8)
	movl	80020+chiral_(%rip), %eax
	testl	%eax, %eax
	je	.L4947
	movl	102432+ang_(%rip), %r11d
	testl	%r11d, %r11d
	je	.L4947
	movl	0(%r13), %r10d
	testl	%r10d, %r10d
	jne	.L4975
.L4948:
	leaq	-88(%rbp), %rdi
	leaq	-96(%rbp), %rsi
	movq	%rdx, -104(%rbp)
	call	sincos@PLT
	movq	-104(%rbp), %rdx
	leaq	39992+sequence_(%rip), %rsi
	vmovd	(%rsi,%rdx,4), %xmm0
	vmovdqa	%xmm0, %xmm1
	vmovdqa	.LC101(%rip), %xmm0
	addq	$4, %rsi
	vmovdqa	%xmm0, %xmm2
	vpminsd	%xmm0, %xmm1, %xmm0
	vmovd	%xmm0, %ecx
	vmovd	%xmm0, -236(%rbp)
	vmovd	(%rsi,%rdx,4), %xmm0
	vpminsd	%xmm2, %xmm0, %xmm0
	vmovd	%xmm0, %eax
	movslq	%eax, %rsi
	leaq	(%rsi,%rsi,4), %r11
	movslq	%ecx, %rdi
	vmovsd	-88(%rbp), %xmm3
	leaq	(%rdi,%r11,4), %r11
	salq	$4, %r11
	leaq	ang_(%rip), %rax
	vmovd	%xmm0, -240(%rbp)
	vmulsd	48584(%rax,%r11,8), %xmm3, %xmm0
	vmovsd	-96(%rbp), %xmm4
	vmovsd	48568(%rax,%r11,8), %xmm1
	vfmadd213sd	48552(%rax,%r11,8), %xmm3, %xmm1
	vfmadd231sd	48576(%rax,%r11,8), %xmm4, %xmm0
	vaddsd	48560(%rax,%r11,8), %xmm0, %xmm0
	vmulsd	%xmm4, %xmm0, %xmm0
	vfmadd132sd	%xmm3, %xmm0, %xmm1
	vmovsd	%xmm1, -104(%rbp)
	vmovsd	%xmm1, %xmm1, %xmm6
.L4949:
	movq	-200(%rbp), %rax
	leaq	(%rsi,%rsi,4), %rsi
	leaq	(%rdi,%rsi,4), %rsi
	salq	$4, %rsi
	vaddsd	(%rax), %xmm6, %xmm0
	leaq	-334(%rsi), %rcx
	movq	%rcx, -128(%rbp)
	leaq	-333(%rsi), %rcx
	movq	%rcx, -136(%rbp)
	vmovsd	%xmm0, (%rax)
	leaq	-332(%rsi), %rcx
	leaq	-335(%rsi), %rax
	subq	$331, %rsi
	movq	%rsi, -152(%rbp)
	movq	%rdx, -216(%rbp)
	leaq	for_(%rip), %rsi
	movq	%rcx, -144(%rbp)
	movq	%r15, -192(%rbp)
	leaq	four_(%rip), %rcx
	leaq	(%rsi,%rdx,8), %rsi
	vmovsd	24+ang_(%rip), %xmm1
	movq	-112(%rbp), %r15
	movq	%r14, -184(%rbp)
	movq	%r12, -168(%rbp)
	movq	%rbx, -208(%rbp)
	movq	%rsi, %r14
	movq	%rax, %r12
	movq	%rcx, %rbx
.L4959:
	vmovsd	(%rbx), %xmm7
	vmovsd	32(%rbx), %xmm4
	vaddsd	%xmm7, %xmm1, %xmm1
	vmovsd	64(%rbx), %xmm6
	movq	%r15, %rdi
	vmovsd	%xmm1, (%rbx)
	vmovsd	%xmm7, -160(%rbp)
	vmovsd	%xmm4, -112(%rbp)
	vmovsd	%xmm6, -120(%rbp)
	call	dihedral_
	movl	0(%r13), %r8d
	vmovsd	-72(%rbp), %xmm0
	testl	%r8d, %r8d
	je	.L4951
	movl	12(%r13), %edi
	testl	%edi, %edi
	je	.L4951
	movq	-168(%rbp), %rax
	vsubsd	(%rax), %xmm0, %xmm1
	vmovsd	%xmm1, %xmm1, %xmm0
	vmovsd	%xmm1, -72(%rbp)
	vmovsd	%xmm1, -224(%rbp)
	call	cos@PLT
	vmovsd	-224(%rbp), %xmm1
	vmovsd	%xmm0, -176(%rbp)
	vmulsd	.LC100(%rip), %xmm1, %xmm0
	call	cos@PLT
	vmovsd	.LC8(%rip), %xmm7
	vmovsd	%xmm0, %xmm0, %xmm2
	vsubsd	%xmm2, %xmm7, %xmm2
	vsubsd	-176(%rbp), %xmm7, %xmm0
	vmulsd	16+ang_(%rip), %xmm2, %xmm2
	vfmadd132sd	8+ang_(%rip), %xmm2, %xmm0
.L4952:
	vmovsd	-104(%rbp), %xmm5
	vmovsd	24+ang_(%rip), %xmm1
	vsubsd	%xmm0, %xmm5, %xmm0
	vmovsd	-160(%rbp), %xmm4
	movq	%r15, %rdi
	vdivsd	%xmm1, %xmm0, %xmm0
	vaddsd	-112(%rbp), %xmm1, %xmm1
	vmovsd	%xmm4, (%rbx)
	vmovsd	%xmm1, 32(%rbx)
	vaddsd	-24(%r14), %xmm0, %xmm0
	vmovsd	%xmm0, -24(%r14)
	call	dihedral_
	movl	0(%r13), %esi
	vmovsd	-72(%rbp), %xmm0
	testl	%esi, %esi
	je	.L4954
	movl	12(%r13), %ecx
	testl	%ecx, %ecx
	je	.L4954
	movq	-168(%rbp), %rax
	vsubsd	(%rax), %xmm0, %xmm1
	vmovsd	%xmm1, %xmm1, %xmm0
	vmovsd	%xmm1, -72(%rbp)
	vmovsd	%xmm1, -176(%rbp)
	call	cos@PLT
	vmovsd	-176(%rbp), %xmm1
	vmovsd	%xmm0, -160(%rbp)
	vmulsd	.LC100(%rip), %xmm1, %xmm0
	call	cos@PLT
	vmovsd	.LC8(%rip), %xmm6
	vmovsd	%xmm0, %xmm0, %xmm2
	vsubsd	%xmm2, %xmm6, %xmm2
	vsubsd	-160(%rbp), %xmm6, %xmm0
	vmulsd	16+ang_(%rip), %xmm2, %xmm2
	vfmadd132sd	8+ang_(%rip), %xmm2, %xmm0
.L4955:
	vmovsd	-104(%rbp), %xmm5
	vmovsd	24+ang_(%rip), %xmm1
	vsubsd	%xmm0, %xmm5, %xmm0
	vmovsd	-112(%rbp), %xmm4
	movq	%r15, %rdi
	vdivsd	%xmm1, %xmm0, %xmm0
	vaddsd	-120(%rbp), %xmm1, %xmm1
	vmovsd	%xmm4, 32(%rbx)
	vmovsd	%xmm1, 64(%rbx)
	vaddsd	79976(%r14), %xmm0, %xmm0
	vmovsd	%xmm0, 79976(%r14)
	call	dihedral_
	movl	0(%r13), %edx
	vmovsd	-72(%rbp), %xmm0
	testl	%edx, %edx
	je	.L4957
	movl	12(%r13), %eax
	testl	%eax, %eax
	je	.L4957
	movq	-168(%rbp), %rax
	vsubsd	(%rax), %xmm0, %xmm1
	vmovsd	%xmm1, %xmm1, %xmm0
	vmovsd	%xmm1, -72(%rbp)
	vmovsd	%xmm1, -160(%rbp)
	call	cos@PLT
	vmovsd	-160(%rbp), %xmm1
	vmovsd	%xmm0, -112(%rbp)
	vmulsd	.LC100(%rip), %xmm1, %xmm0
	call	cos@PLT
	vmovsd	.LC8(%rip), %xmm1
	vmovsd	%xmm0, %xmm0, %xmm2
	vsubsd	-112(%rbp), %xmm1, %xmm0
	vsubsd	%xmm2, %xmm1, %xmm1
	vmulsd	16+ang_(%rip), %xmm1, %xmm1
	vfmadd132sd	8+ang_(%rip), %xmm1, %xmm0
.L4958:
	vmovsd	-104(%rbp), %xmm7
	vmovsd	24+ang_(%rip), %xmm1
	vsubsd	%xmm0, %xmm7, %xmm0
	vmovsd	-120(%rbp), %xmm5
	addq	$8, %rbx
	vdivsd	%xmm1, %xmm0, %xmm0
	leaq	32+four_(%rip), %rax
	vmovsd	%xmm5, 56(%rbx)
	addq	$8, %r14
	vaddsd	159968(%r14), %xmm0, %xmm0
	vmovsd	%xmm0, 159968(%r14)
	cmpq	%rax, %rbx
	jne	.L4959
	movq	-184(%rbp), %r14
	movq	-192(%rbp), %r15
	movq	-168(%rbp), %r12
	movq	-208(%rbp), %rbx
	movq	-216(%rbp), %rdx
	jmp	.L4947
	.p2align 4,,10
	.p2align 3
.L4939:
	vmulsd	%xmm1, %xmm1, %xmm0
	movq	-168(%rbp), %rax
	movq	-152(%rbp), %rsi
	vmovsd	32(%r13,%rax,8), %xmm2
	movq	-144(%rbp), %rax
	vfmadd213sd	32(%r13,%rsi,8), %xmm0, %xmm2
	vmulsd	%xmm1, %xmm0, %xmm3
	movq	-160(%rbp), %rsi
	vmulsd	%xmm0, %xmm2, %xmm2
	vfmadd231sd	32(%r13,%rax,8), %xmm1, %xmm2
	movq	-176(%rbp), %rax
	vmovsd	32(%r13,%rax,8), %xmm1
	movq	-184(%rbp), %rax
	vfmadd213sd	32(%r13,%rsi,8), %xmm0, %xmm1
	vfmadd231sd	32(%r13,%rax,8), %xmm3, %xmm1
	vfmadd132sd	%xmm3, %xmm2, %xmm1
	jmp	.L4940
	.p2align 4,,10
	.p2align 3
.L4934:
	vmulsd	%xmm1, %xmm1, %xmm2
	movq	-168(%rbp), %rax
	movq	-152(%rbp), %rsi
	vmovsd	32(%r13,%rax,8), %xmm3
	movq	-144(%rbp), %rax
	vfmadd213sd	32(%r13,%rsi,8), %xmm2, %xmm3
	movq	-160(%rbp), %rsi
	vmulsd	%xmm1, %xmm2, %xmm0
	vmovsd	32(%r13,%rsi,8), %xmm7
	vmulsd	%xmm3, %xmm2, %xmm3
	vfmadd132sd	32(%r13,%rax,8), %xmm3, %xmm1
	movq	-176(%rbp), %rax
	vfmadd132sd	32(%r13,%rax,8), %xmm7, %xmm2
	movq	-184(%rbp), %rax
	vfmadd231sd	32(%r13,%rax,8), %xmm0, %xmm2
	vfmadd132sd	%xmm2, %xmm1, %xmm0
	jmp	.L4935
	.p2align 4,,10
	.p2align 3
.L4929:
	vmulsd	%xmm1, %xmm1, %xmm2
	movq	-168(%rbp), %rax
	movq	-152(%rbp), %rsi
	vmovsd	32(%r13,%rax,8), %xmm4
	movq	-144(%rbp), %rax
	vfmadd213sd	32(%r13,%rsi,8), %xmm2, %xmm4
	movq	-160(%rbp), %rsi
	vmulsd	%xmm1, %xmm2, %xmm0
	vmovsd	32(%r13,%rsi,8), %xmm6
	vmulsd	%xmm4, %xmm2, %xmm4
	vfmadd132sd	32(%r13,%rax,8), %xmm4, %xmm1
	movq	-176(%rbp), %rax
	vfmadd132sd	32(%r13,%rax,8), %xmm6, %xmm2
	movq	-184(%rbp), %rax
	vfmadd231sd	32(%r13,%rax,8), %xmm0, %xmm2
	vfmadd132sd	%xmm2, %xmm1, %xmm0
	jmp	.L4930
	.p2align 4,,10
	.p2align 3
.L4967:
	vmovsd	80000(%r14), %xmm2
	vmovsd	-136(%rbp), %xmm6
	vsubsd	%xmm1, %xmm2, %xmm1
	vmovsd	%xmm6, 64(%r15)
	leaq	24+four_(%rip), %rax
	addq	$8, %r15
	vmovsd	%xmm1, 80000(%r14)
	addq	$8, %r14
	cmpq	%r15, %rax
	jne	.L4944
	jmp	.L4970
	.p2align 4,,10
	.p2align 3
.L4972:
	movl	8(%rbx), %r9d
	testl	%r9d, %r9d
	je	.L4926
	vsubsd	0(%r13), %xmm0, %xmm0
	movslq	-240(%rbp), %r10
	movslq	-236(%rbp), %r11
	vmovsd	%xmm0, -64(%rbp)
	vmulsd	%xmm0, %xmm0, %xmm0
	leaq	ang_(%rip), %r9
	vmulsd	ang_(%rip), %xmm0, %xmm4
	vmovsd	%xmm4, -120(%rbp)
	vmovsd	%xmm4, %xmm4, %xmm5
	jmp	.L4927
	.p2align 4,,10
	.p2align 3
.L4957:
	leaq	-96(%rbp), %rsi
	leaq	-88(%rbp), %rdi
	call	sincos@PLT
	vmovsd	-88(%rbp), %xmm0
	movq	-152(%rbp), %rcx
	leaq	ang_(%rip), %rax
	vmulsd	51232(%rax,%rcx,8), %xmm0, %xmm1
	vmovsd	-96(%rbp), %xmm2
	movq	-144(%rbp), %rsi
	movq	-136(%rbp), %rdx
	vfmadd231sd	51232(%rax,%rsi,8), %xmm2, %xmm1
	vmovsd	51232(%rax,%rdx,8), %xmm3
	movq	-128(%rbp), %rdx
	vfmadd213sd	51232(%rax,%r12,8), %xmm0, %xmm3
	vaddsd	51232(%rax,%rdx,8), %xmm1, %xmm1
	vmulsd	%xmm2, %xmm1, %xmm1
	vfmadd132sd	%xmm3, %xmm1, %xmm0
	jmp	.L4958
	.p2align 4,,10
	.p2align 3
.L4954:
	leaq	-96(%rbp), %rsi
	leaq	-88(%rbp), %rdi
	call	sincos@PLT
	vmovsd	-88(%rbp), %xmm2
	movq	-152(%rbp), %rdx
	leaq	ang_(%rip), %rax
	vmulsd	51232(%rax,%rdx,8), %xmm2, %xmm1
	vmovsd	-96(%rbp), %xmm3
	movq	-144(%rbp), %rcx
	movq	-136(%rbp), %rsi
	vfmadd231sd	51232(%rax,%rcx,8), %xmm3, %xmm1
	vmovsd	51232(%rax,%rsi,8), %xmm0
	movq	-128(%rbp), %rsi
	vfmadd213sd	51232(%rax,%r12,8), %xmm2, %xmm0
	vaddsd	51232(%rax,%rsi,8), %xmm1, %xmm1
	vmulsd	%xmm3, %xmm1, %xmm1
	vfmadd132sd	%xmm2, %xmm1, %xmm0
	jmp	.L4955
	.p2align 4,,10
	.p2align 3
.L4951:
	leaq	-96(%rbp), %rsi
	leaq	-88(%rbp), %rdi
	call	sincos@PLT
	vmovsd	-88(%rbp), %xmm2
	movq	-152(%rbp), %rsi
	leaq	ang_(%rip), %rax
	vmulsd	51232(%rax,%rsi,8), %xmm2, %xmm1
	movq	-136(%rbp), %rdx
	vmovsd	-96(%rbp), %xmm3
	vmovsd	51232(%rax,%rdx,8), %xmm0
	movq	-144(%rbp), %rdx
	movq	-128(%rbp), %rcx
	vfmadd231sd	51232(%rax,%rdx,8), %xmm3, %xmm1
	vfmadd213sd	51232(%rax,%r12,8), %xmm2, %xmm0
	vaddsd	51232(%rax,%rcx,8), %xmm1, %xmm1
	vmulsd	%xmm3, %xmm1, %xmm1
	vfmadd132sd	%xmm2, %xmm1, %xmm0
	jmp	.L4952
.L4975:
	movl	12(%r13), %r9d
	testl	%r9d, %r9d
	je	.L4948
	vsubsd	(%r12), %xmm0, %xmm1
	movq	%rdx, -128(%rbp)
	vmovsd	%xmm1, %xmm1, %xmm0
	vmovsd	%xmm1, -72(%rbp)
	vmovsd	%xmm1, -120(%rbp)
	call	cos@PLT
	vmovsd	-120(%rbp), %xmm1
	vmovsd	%xmm0, -104(%rbp)
	vmulsd	.LC100(%rip), %xmm1, %xmm0
	call	cos@PLT
	vmovsd	%xmm0, %xmm0, %xmm1
	vmovsd	.LC8(%rip), %xmm0
	movslq	-240(%rbp), %rsi
	vsubsd	-104(%rbp), %xmm0, %xmm3
	vsubsd	%xmm1, %xmm0, %xmm0
	movslq	-236(%rbp), %rdi
	movq	-128(%rbp), %rdx
	vmulsd	16+ang_(%rip), %xmm0, %xmm0
	vfmadd132sd	8+ang_(%rip), %xmm0, %xmm3
	vmovsd	%xmm3, -104(%rbp)
	vmovsd	%xmm3, %xmm3, %xmm6
	jmp	.L4949
.L4974:
	call	__stack_chk_fail@PLT
	.cfi_endproc
.LFE58:
	.size	angeval_, .-angeval_
	.local	rsortssbond.0
	.comm	rsortssbond.0,80000,32
	.local	kaak.1
	.comm	kaak.1,2000000,32
	.local	caac.2
	.comm	caac.2,4000000,32
	.local	fut2.3
	.comm	fut2.3,4000000,32
	.local	fut.4
	.comm	fut.4,4000000,32
	.local	kut.5
	.comm	kut.5,2000000,32
	.local	kbt.6
	.comm	kbt.6,2000000,32
	.local	adfres2.7
	.comm	adfres2.7,800000,32
	.local	adfres.8
	.comm	adfres.8,800000,32
	.local	aree.9
	.comm	aree.9,800000,32
	.local	aufres2.10
	.comm	aufres2.10,800000,32
	.local	aufres.11
	.comm	aufres.11,800000,32
	.local	mtraj.12
	.comm	mtraj.12,800000,32
	.local	fbt2.13
	.comm	fbt2.13,4000000,32
	.local	fbt.14
	.comm	fbt.14,4000000,32
	.section	.rodata
	.align 16
	.type	options.594.15, @object
	.size	options.594.15, 28
options.594.15:
	.long	2116
	.long	4095
	.long	0
	.long	1
	.long	1
	.long	0
	.long	31
	.local	klst.16
	.comm	klst.16,2400000,32
	.local	zs.17
	.comm	zs.17,80000,32
	.local	ys.18
	.comm	ys.18,80000,32
	.local	xs.19
	.comm	xs.19,80000,32
	.local	histo.20
	.comm	histo.20,80000,32
	.local	r.21
	.comm	r.21,240000,32
	.local	t.22
	.comm	t.22,720000,32
	.local	theta.23
	.comm	theta.23,80000,32
	.local	phi.24
	.comm	phi.24,80000,32
	.local	iy.25
	.comm	iy.25,4,4
	.local	iv.26
	.comm	iv.26,128,32
	.data
	.align 4
	.type	idum2.27, @object
	.size	idum2.27, 4
idum2.27:
	.long	123456789
	.local	zs.28
	.comm	zs.28,80000,32
	.local	ys.29
	.comm	ys.29,80000,32
	.local	xs.30
	.comm	xs.30,80000,32
	.local	qkk.31
	.comm	qkk.31,240000,32
	.local	qk.32
	.comm	qk.32,240000,32
	.local	rn.33
	.comm	rn.33,240000,32
	.local	r.34
	.comm	r.34,240000,32
	.comm	rall_,3360000,32
	.comm	radi_,1120000,32
	.comm	nall_,460000,32
	.comm	rans_,4,32
	.comm	parm_,40,32
	.comm	der2_,480000,32
	.comm	der_,480000,32
	.comm	xyforces_,32,32
	.comm	mr_,2592160,32
	.comm	ang_,102440,32
	.comm	hhar_,72,32
	.comm	equil_,20,32
	.comm	verl_,120240024,32
	.comm	sdch_,200360,32
	.comm	sig_,7924040,32
	.comm	restr_,40,32
	.comm	pid_,96,32
	.comm	nmapi_,10004080,32
	.comm	for_,240048,32
	.comm	cmp2_,540000012,32
	.comm	cmap_,66000012,32
	.comm	chiral_,80032,32
	.comm	angtemp_,240008,32
	.comm	angnat_,200008,32
	.comm	vel_,240000,32
	.comm	ssb2_,40,32
	.comm	restart_,160,32
	.comm	respul_,200016,32
	.comm	pull_,240032,32
	.comm	kier_,56,32
	.comm	cmapi_,2000032,32
	.comm	wal_,72,32
	.comm	ssb_,80040,32
	.comm	sequence_,110000,32
	.comm	neigh_,80032,32
	.comm	misc_,80040,32
	.comm	gyr_,560000,32
	.comm	bon_,160016,32
	.comm	plates_,72,32
	.comm	masscenter_,48,32
	.comm	mass_,160000,32
	.comm	pos_,1280000,32
	.comm	nat_,248016,32
	.comm	four_,96,32
	.comm	bas_,40,32
	.section	.rodata.cst8,"aM",@progbits,8
	.align 8
.LC0:
	.long	536870912
	.long	1040187392
	.align 8
.LC1:
	.long	-1080863872
	.long	1072693247
	.align 8
.LC8:
	.long	0
	.long	1072693248
	.align 8
.LC9:
	.long	0
	.long	-1074790400
	.align 8
.LC10:
	.long	0
	.long	0
	.section	.rodata.cst16,"aM",@progbits,16
	.align 16
.LC11:
	.long	0
	.long	-2147483648
	.long	0
	.long	0
	.section	.rodata.cst8
	.align 8
.LC23:
	.long	0
	.long	1083127808
	.section	.rodata.cst32,"aM",@progbits,32
	.align 32
.LC24:
	.long	0
	.long	-153
	.long	-306
	.long	-459
	.long	-612
	.long	-765
	.long	-918
	.long	-1071
	.align 32
.LC25:
	.long	-1224
	.long	-1224
	.long	-1224
	.long	-1224
	.long	-1224
	.long	-1224
	.long	-1224
	.long	-1224
	.align 32
.LC26:
	.long	-153
	.long	-153
	.long	-153
	.long	-153
	.long	-153
	.long	-153
	.long	-153
	.long	-153
	.section	.rodata.cst8
	.align 8
.LC60:
	.long	-1
	.long	1071644671
	.section	.rodata.cst32
	.align 32
.LC66:
	.quad	4
	.quad	1
	.quad	1
	.quad	8
	.section	.rodata.cst16
	.align 16
.LC68:
	.long	0
	.long	1072693248
	.long	0
	.long	1072693248
	.align 16
.LC69:
	.long	-1
	.long	2147483647
	.long	0
	.long	0
	.section	.rodata.cst8
	.align 8
.LC70:
	.long	-1610612736
	.long	1070176665
	.align 8
.LC71:
	.long	0
	.long	1079574528
	.align 8
.LC72:
	.long	0
	.long	1071644672
	.align 8
.LC74:
	.long	0
	.long	1073741824
	.section	.rodata.cst32
	.align 32
.LC76:
	.long	1
	.long	2
	.long	3
	.long	4
	.long	5
	.long	6
	.long	7
	.long	8
	.align 32
.LC77:
	.long	8
	.long	8
	.long	8
	.long	8
	.long	8
	.long	8
	.long	8
	.long	8
	.section	.rodata.cst16
	.align 16
.LC78:
	.long	0
	.long	1
	.long	2
	.long	3
	.align 16
.LC79:
	.long	0
	.long	-2147483648
	.long	0
	.long	-2147483648
	.section	.rodata.cst8
	.align 8
.LC80:
	.long	-536870912
	.long	1062232653
	.align 8
.LC82:
	.long	0
	.long	1083129856
	.align 8
.LC83:
	.long	0
	.long	1074790400
	.align 8
.LC84:
	.long	0
	.long	1076363264
	.align 8
.LC85:
	.long	0
	.long	1075314688
	.align 8
.LC86:
	.long	0
	.long	-1064353792
	.align 8
.LC87:
	.long	0
	.long	1073217536
	.align 8
.LC88:
	.long	0
	.long	1077411840
	.align 8
.LC89:
	.long	210911780
	.long	1002937505
	.align 8
.LC90:
	.long	0
	.long	-2147483648
	.align 8
.LC91:
	.long	-536870912
	.long	1072412282
	.section	.rodata.cst4,"aM",@progbits,4
	.align 4
.LC92:
	.long	1056964608
	.section	.rodata.cst16
	.align 16
.LC93:
	.long	-1
	.long	0
	.long	1
	.long	2
	.section	.rodata.cst32
	.align 32
.LC94:
	.long	-1
	.long	-1
	.long	-1
	.long	-1
	.long	-1
	.long	-1
	.long	-1
	.long	-1
	.align 32
.LC95:
	.long	7
	.long	6
	.long	5
	.long	4
	.long	3
	.long	2
	.long	1
	.long	0
	.align 32
.LC96:
	.long	-1
	.long	1
	.long	-1
	.long	1
	.long	-1
	.long	1
	.long	-1
	.long	1
	.section	.rodata.cst16
	.align 16
.LC97:
	.long	-1
	.long	-1
	.long	-1
	.long	-1
	.align 16
.LC98:
	.long	-1
	.long	1
	.long	-1
	.long	1
	.section	.rodata.cst8
	.align 8
.LC99:
	.long	-1926227757
	.long	-1084697855
	.align 8
.LC100:
	.long	0
	.long	1074266112
	.section	.rodata.cst16
	.align 16
.LC101:
	.long	3
	.long	0
	.long	0
	.long	0
	.section	.rodata.cst8
	.align 8
.LC102:
	.long	-1610612736
	.long	1069128089
	.align 8
.LC103:
	.long	0
	.long	-1073741824
	.align 8
.LC104:
	.long	1202590843
	.long	1065646817
	.align 8
.LC105:
	.long	-536870912
	.long	1057634018
	.align 8
.LC106:
	.long	0
	.long	1077018624
	.align 8
.LC107:
	.long	0
	.long	1076494336
	.align 8
.LC108:
	.long	0
	.long	1077215232
	.align 8
.LC109:
	.long	0
	.long	-1070989312
	.align 8
.LC110:
	.long	0
	.long	1075838976
	.section	.rodata.cst32
	.align 32
.LC111:
	.long	0
	.long	1074266112
	.long	0
	.long	1074266112
	.long	0
	.long	1074266112
	.long	0
	.long	1074266112
	.align 32
.LC112:
	.long	0
	.long	1073741824
	.long	0
	.long	1073741824
	.long	0
	.long	1073741824
	.long	0
	.long	1073741824
	.align 32
.LC113:
	.long	0
	.long	1075052544
	.long	0
	.long	1075052544
	.long	0
	.long	1075052544
	.long	0
	.long	1075052544
	.align 32
.LC114:
	.long	0
	.long	1074790400
	.long	0
	.long	1074790400
	.long	0
	.long	1074790400
	.long	0
	.long	1074790400
	.align 32
.LC115:
	.long	0
	.long	1075314688
	.long	0
	.long	1075314688
	.long	0
	.long	1075314688
	.long	0
	.long	1075314688
	.align 32
.LC116:
	.long	0
	.long	1076101120
	.long	0
	.long	1076101120
	.long	0
	.long	1076101120
	.long	0
	.long	1076101120
	.section	.rodata.cst16
	.align 16
.LC117:
	.long	0
	.long	1074266112
	.long	0
	.long	1074266112
	.align 16
.LC118:
	.long	0
	.long	1073741824
	.long	0
	.long	1073741824
	.align 16
.LC119:
	.long	0
	.long	1075052544
	.long	0
	.long	1075052544
	.align 16
.LC120:
	.long	0
	.long	1074790400
	.long	0
	.long	1074790400
	.align 16
.LC121:
	.long	0
	.long	1075314688
	.long	0
	.long	1075314688
	.align 16
.LC122:
	.long	0
	.long	1076101120
	.long	0
	.long	1076101120
	.section	.rodata.cst8
	.align 8
.LC123:
	.long	0
	.long	1075052544
	.align 8
.LC124:
	.long	0
	.long	1076101120
	.align 8
.LC134:
	.long	1610612736
	.long	1070945621
	.align 8
.LC136:
	.long	1431655765
	.long	1070945621
	.align 8
.LC138:
	.long	0
	.long	1079558144
	.section	.rodata.cst16
	.align 16
.LC139:
	.long	-1
	.long	2147483647
	.long	-1
	.long	2147483647
	.section	.rodata.cst8
	.align 8
.LC158:
	.long	122601769
	.long	1072464446
	.section	.rodata.cst32
	.align 32
.LC159:
	.long	3
	.long	3
	.long	3
	.long	3
	.long	3
	.long	3
	.long	3
	.long	3
	.section	.rodata.cst16
	.align 16
.LC160:
	.long	3
	.long	3
	.long	3
	.long	3
	.section	.rodata.cst8
	.align 8
.LC162:
	.long	-536870912
	.long	1078757031
	.align 8
.LC164:
	.long	1610612736
	.long	1079100686
	.align 8
.LC166:
	.long	0
	.long	1079362814
	.align 8
.LC168:
	.long	-536870912
	.long	1079527292
	.align 8
.LC170:
	.long	536870912
	.long	1079560323
	.align 8
.LC172:
	.long	1610612736
	.long	1079592632
	.align 8
.LC174:
	.long	1073741824
	.long	1079626039
	.align 8
.LC176:
	.long	-2147483648
	.long	1079790141
	.align 8
.LC179:
	.long	-536870912
	.long	1079805607
	.align 8
.LC181:
	.long	536870912
	.long	1079821746
	.align 8
.LC183:
	.long	536870912
	.long	1080034353
	.align 8
.LC185:
	.long	1610612736
	.long	1080034705
	.align 8
.LC187:
	.long	1073741824
	.long	1080042422
	.align 8
.LC189:
	.long	0
	.long	1080059478
	.align 8
.LC191:
	.long	1073741824
	.long	1080108171
	.align 8
.LC193:
	.long	0
	.long	1080190378
	.align 8
.LC195:
	.long	536870912
	.long	1080264196
	.align 8
.LC197:
	.long	-1610612736
	.long	1080321392
	.align 8
.LC199:
	.long	-536870912
	.long	1080510160
	.section	.rodata.cst32
	.align 32
.LC202:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC203:
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC204:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC205:
	.long	0
	.long	1
	.long	2
	.long	3
	.long	4
	.long	1
	.long	4
	.long	7
	.align 32
.LC206:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC207:
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC208:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC209:
	.long	0
	.long	1
	.long	2
	.long	3
	.long	4
	.long	5
	.long	2
	.long	5
	.align 32
.LC210:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC211:
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC212:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC213:
	.long	0
	.long	1
	.long	2
	.long	3
	.long	4
	.long	0
	.long	3
	.long	6
	.align 32
.LC214:
	.long	0
	.long	4
	.long	0
	.long	1
	.long	5
	.long	0
	.long	2
	.long	6
	.align 32
.LC215:
	.long	0
	.long	1
	.long	0
	.long	3
	.long	4
	.long	1
	.long	6
	.long	7
	.align 32
.LC216:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC217:
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.align 32
.LC218:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC219:
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC220:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.align 32
.LC221:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.align 32
.LC222:
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC223:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC224:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC225:
	.long	0
	.long	5
	.long	2
	.long	3
	.long	6
	.long	5
	.long	6
	.long	7
	.section	.rodata.cst16
	.align 16
.LC226:
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.align 16
.LC227:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 16
.LC228:
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.align 16
.LC229:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 16
.LC230:
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.align 16
.LC231:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 16
.LC232:
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.align 16
.LC233:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	0
	.byte	1
	.byte	2
	.byte	3
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 16
.LC234:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 16
.LC235:
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.align 16
.LC236:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	8
	.byte	9
	.byte	10
	.byte	11
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.section	.rodata.cst32
	.align 32
.LC240:
	.quad	4
	.quad	1
	.quad	1
	.quad	2
	.section	.rodata.cst8
	.align 8
.LC241:
	.long	-1610612736
	.long	1073364336
	.align 8
.LC242:
	.long	-536870912
	.long	1073615994
	.align 8
.LC243:
	.long	1610612736
	.long	1073332879
	.align 8
.LC244:
	.long	-536870912
	.long	1073133649
	.align 8
.LC245:
	.long	-2147483648
	.long	1073500651
	.align 8
.LC246:
	.long	-1073741824
	.long	1073490165
	.align 8
.LC247:
	.long	0
	.long	1073175593
	.align 8
.LC253:
	.long	-1073741824
	.long	1072949577
	.align 8
.LC263:
	.long	1841940611
	.long	1069834032
	.align 8
.LC264:
	.long	1413754136
	.long	1075388923
	.align 8
.LC265:
	.long	1413754136
	.long	1074340347
	.section	.rodata.cst32
	.align 32
.LC266:
	.long	-1
	.long	2147483647
	.long	-1
	.long	2147483647
	.long	-1
	.long	2147483647
	.long	-1
	.long	2147483647
	.align 32
.LC267:
	.quad	8
	.quad	1
	.quad	1
	.quad	7
	.section	.rodata.cst8
	.align 8
.LC268:
	.long	128
	.long	88
	.section	.rodata.cst32
	.align 32
.LC269:
	.quad	8
	.quad	1
	.quad	1
	.quad	6
	.align 32
.LC270:
	.quad	4
	.quad	1
	.quad	1
	.quad	20
	.align 32
.LC271:
	.quad	8
	.quad	1
	.quad	1
	.quad	20
	.align 32
.LC272:
	.long	122601769
	.long	1072464446
	.long	122601769
	.long	1072464446
	.long	122601769
	.long	1072464446
	.long	122601769
	.long	1072464446
	.section	.rodata.cst16
	.align 16
.LC273:
	.long	122601769
	.long	1072464446
	.long	122601769
	.long	1072464446
	.section	.rodata.cst32
	.align 32
.LC276:
	.quad	8
	.quad	54003
	.quad	1
	.quad	3
	.section	.rodata.cst8
	.align 8
.LC277:
	.long	-2147483648
	.long	1059512410
	.section	.rodata.cst32
	.align 32
.LC278:
	.long	3
	.long	4
	.long	5
	.long	6
	.long	7
	.long	8
	.long	9
	.long	10
	.section	.rodata.cst8
	.align 8
.LC279:
	.long	0
	.long	1
	.section	.rodata.cst16
	.align 16
.LC280:
	.long	0
	.long	1
	.long	0
	.long	1
	.section	.rodata.cst8
	.align 8
.LC281:
	.long	1
	.long	0
	.section	.rodata.cst16
	.align 16
.LC282:
	.long	1
	.long	0
	.long	0
	.long	0
	.align 16
.LC283:
	.long	0
	.long	1
	.long	0
	.long	0
	.section	.rodata.cst8
	.align 8
.LC284:
	.long	-1010313536
	.long	1072821658
	.align 8
.LC285:
	.long	0
	.long	10000
	.align 8
.LC286:
	.long	1610612736
	.long	1071015526
	.align 8
.LC287:
	.long	-1610612736
	.long	1068079513
	.section	.rodata.cst16
	.align 16
.LC288:
	.long	0
	.long	1071644672
	.long	-1610612736
	.long	1075288473
	.section	.rodata.cst8
	.align 8
.LC289:
	.long	0
	.long	9
	.section	.rodata.cst16
	.align 16
.LC290:
	.long	0
	.long	1072693248
	.long	0
	.long	1074439127
	.section	.rodata.cst32
	.align 32
.LC291:
	.long	0
	.long	1077805056
	.long	1610612736
	.long	1071980216
	.long	1610612736
	.long	1071980216
	.long	-640172613
	.long	1037794527
	.section	.rodata.cst8
	.align 8
.LC292:
	.long	1073741824
	.long	1064598241
	.align 8
.LC293:
	.long	-536870912
	.long	1058682594
	.align 8
.LC294:
	.long	1073741824
	.long	1066695393
	.align 8
.LC295:
	.long	1499330067
	.long	1089383931
	.section	.rodata.cst32
	.align 32
.LC296:
	.long	-1610612736
	.long	1075419545
	.long	0
	.long	1075314688
	.long	1073741824
	.long	1072902963
	.long	1610612736
	.long	1075209830
	.align 32
.LC297:
	.long	-1073741824
	.long	1075367116
	.long	-536870912
	.long	-1077055325
	.long	-1073741824
	.long	1072745676
	.long	-2147483648
	.long	-1074329027
	.section	.rodata.cst8
	.align 8
.LC298:
	.long	0
	.long	1075707904
	.align 8
.LC299:
	.long	-858993459
	.long	1073007820
	.align 8
.LC300:
	.long	-1610612736
	.long	1074937200
	.align 8
.LC301:
	.long	1610612736
	.long	1074685542
	.section	.rodata.cst16
	.align 16
.LC302:
	.long	0
	.long	1084178432
	.long	0
	.long	1072693248
	.section	.rodata.cst32
	.align 32
.LC303:
	.long	0
	.long	1073217536
	.long	0
	.long	1073217536
	.long	0
	.long	1073217536
	.long	0
	.long	1075052544
	.align 32
.LC304:
	.long	0
	.long	1075707904
	.long	1610612736
	.long	1075471974
	.long	1610612736
	.long	1075471974
	.long	1610612736
	.long	1075340902
	.align 32
.LC305:
	.long	0
	.long	1077805056
	.long	0
	.long	0
	.long	0
	.long	1078525952
	.long	0
	.long	0
	.align 32
.LC306:
	.long	0
	.long	1072693248
	.long	0
	.long	0
	.long	0
	.long	1076101120
	.long	-2147483648
	.long	1074072125
	.section	.rodata.cst16
	.align 16
.LC307:
	.long	0
	.long	1075052544
	.long	0
	.long	1077018624
	.align 16
.LC308:
	.long	0
	.long	1072168960
	.long	-536870912
	.long	1072525475
	.section	.rodata.cst8
	.align 8
.LC341:
	.long	0
	.long	1080705024
	.section	.rodata.cst32
	.align 32
.LC425:
	.long	0
	.long	-1074790400
	.long	0
	.long	-1074790400
	.long	0
	.long	-1074790400
	.long	0
	.long	-1074790400
	.section	.rodata.cst8
	.align 8
.LC427:
	.long	0
	.long	1070596096
	.section	.rodata.cst32
	.align 32
.LC441:
	.long	0
	.long	1072693248
	.long	0
	.long	1072693248
	.long	0
	.long	1072693248
	.long	0
	.long	1072693248
	.section	.rodata.cst8
	.align 8
.LC465:
	.long	0
	.long	1076756480
	.section	.rodata.cst32
	.align 32
.LC524:
	.long	0
	.long	1070071808
	.long	0
	.long	1072058277
	.long	-536870912
	.long	1071877688
	.long	1610612736
	.long	1069897045
	.section	.rodata.cst8
	.align 8
.LC525:
	.long	536870912
	.long	1066471697
	.section	.rodata.cst32
	.align 32
.LC532:
	.long	0
	.long	0
	.long	0
	.long	0
	.long	0
	.long	-2
	.long	0
	.long	0
	.section	.rodata.cst8
	.align 8
.LC533:
	.long	1073741824
	.long	1072640819
	.section	.rodata.cst4
	.align 4
.LC553:
	.long	1073741824
	.section	.rodata.cst32
	.align 32
.LC554:
	.long	1
	.long	1
	.long	1
	.long	1
	.long	1
	.long	1
	.long	1
	.long	1
	.section	.rodata.cst16
	.align 16
.LC555:
	.long	1
	.long	1
	.long	1
	.long	1
	.section	.rodata.cst8
	.align 8
.LC563:
	.long	0
	.long	1100470148
	.section	.rodata.cst16
	.align 16
.LC577:
	.long	4
	.long	5
	.long	6
	.long	7
	.section	.rodata.cst8
	.align 8
.LC578:
	.long	1073741824
	.long	1065646817
	.section	.rodata.cst16
	.align 16
.LC590:
	.quad	7089915058161087793
	.quad	2314885530818453536
	.align 16
.LC591:
	.quad	2314885530818453536
	.quad	2314885530818453536
	.align 16
.LC592:
	.quad	8392585648476089447
	.quad	2314885530818453536
	.align 16
.LC593:
	.quad	2338623226893525363
	.quad	2314885530818453536
	.align 16
.LC594:
	.quad	2333537989910028659
	.quad	2314885530818453536
	.align 16
.LC595:
	.quad	2338621040755171699
	.quad	2314885530818453536
	.align 16
.LC596:
	.quad	7310579615589884272
	.quad	2314978269162533746
	.align 16
.LC597:
	.quad	2317490325673500968
	.quad	2314885530818453536
	.align 16
.LC599:
	.long	0
	.long	1083129856
	.long	0
	.long	0
	.ident	"GCC: (GNU) 10.2.0"
	.section	.note.GNU-stack,"",@progbits
